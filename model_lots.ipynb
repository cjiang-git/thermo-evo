{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aed12b8-dd24-4573-883a-a4e35f6ae7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoConfig, AutoModelForCausalLM,AutoTokenizer,BitsAndBytesConfig,AutoModel,TrainingArguments, Trainer,DataCollatorWithPadding, EarlyStoppingCallback, get_constant_schedule_with_warmup\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "from stripedhyena.tokenizer import CharLevelTokenizer\n",
    "from stripedhyena.model import StripedHyena\n",
    "from stripedhyena.layers import VocabParallelEmbedding\n",
    "from stripedhyena.utils import dotdict\n",
    "import yaml\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f02902-79c7-4466-bd45-4c586513d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = './processed_data'\n",
    "cpu_cnt = multiprocessing.cpu_count()\n",
    "max_length = 300\n",
    "model_name = './evo-1-8k-base'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3164c7-93a9-4773-b28b-4057aa25931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA A100-SXM4-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "11.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/thermo-evo/miniconda3/envs/thermo-evo/lib/python3.10/site-packages/torch/cuda/memory.py:440: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "\n",
    "\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65fa93b0-9da6-4914-ba91-bedb1b58fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,padding='max_length',bos_token='\\x00')\n",
    "tokenizer.pad_token = '\\x01'\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer,max_length=max_length,padding='max_length')\n",
    "#Evo utilizes a custom tokenizer named \"CharLevelTokenizer\", huggingface version does not have pad_token defined. Thus pad_token is manually defined to have same value as the pad_token utilizes in CharLevelTokenizer\n",
    "\n",
    "def prefix_function(d):\n",
    "    d['dna_seq'] = tokenizer.bos_token + d['dna_seq']\n",
    "    return d\n",
    "\n",
    "def tokenize_function(d):\n",
    "    return tokenizer(d['dna_seq'], padding='max_length',max_length = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26474337-bdcd-4e98-90c7-7f46a46e35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dsets(data_path,batch_size):\n",
    "    dsets = load_from_disk(data_path)\n",
    "    dsets = dsets.map(prefix_function, num_proc=cpu_cnt)\n",
    "    dsets = dsets.map(tokenize_function, batched=True, num_proc=cpu_cnt)\n",
    "    useful_col = ['input_ids', 'attention_mask', 'labels']\n",
    "    dsets = dsets.remove_columns([col for col in dsets['train'].column_names if col not in useful_col])\n",
    "    train_loader = DataLoader(\n",
    "        dsets['train'],\n",
    "        collate_fn=data_collator,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size\n",
    "        )\n",
    "    val_loader = DataLoader(\n",
    "            dsets['val'],\n",
    "            collate_fn=data_collator,\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "    test_loader = DataLoader(\n",
    "            dsets['test'],\n",
    "            collate_fn=data_collator,\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "    return train_loader,val_loader,test_loader, len(dsets['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01d40196-89fc-499d-926c-03827a33828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,OUT_DIR,data_path,batch_size = 128,warmup_steps = 10,epochs = 3,learning_rate=2e-5,checkpointing_steps=1000):\n",
    "\n",
    "    train_loader,val_loader,test_loader, epoch_size = prepare_dsets(data_path,batch_size)\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    accelerator = Accelerator(\n",
    "        gradient_accumulation_steps=1,\n",
    "        mixed_precision=\"bf16\"\n",
    "    )\n",
    "    \n",
    "    accelerator.print(f\"Total GPUS: {accelerator.num_processes}\")\n",
    "    \n",
    "    \n",
    "    num_training_steps = epoch_size * epochs // batch_size\n",
    "    num_epoch_steps = num_training_steps // epochs\n",
    "\n",
    "    optim = torch.optim.AdamW(list(model.parameters()), lr=learning_rate)\n",
    "    scheduler = transformers.get_cosine_schedule_with_warmup(optim, num_warmup_steps=warmup_steps,num_training_steps = num_training_steps)\n",
    "                                                  \n",
    "    model,optim, train_loader, scheduler= accelerator.prepare(model,optim, train_loader, scheduler)\n",
    "    \n",
    "    accelerator.register_for_checkpointing(scheduler)\n",
    "    \n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    completed_steps = 0\n",
    "    \n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    \n",
    "\n",
    "    stp_lst = []\n",
    "    for i in os.listdir(OUT_DIR):\n",
    "        if i[:4]=='step':\n",
    "            stp_lst.append(int(i[5:]))\n",
    "\n",
    "    if stp_lst != []:\n",
    "        resume_from_checkpoint = True\n",
    "        resume_step = max(stp_lst)\n",
    "        latest = 'step_' + str(resume_step)\n",
    "        checkpoint_dir = os.path.join(OUT_DIR,latest)\n",
    "        path = os.path.basename(checkpoint_dir)\n",
    "        accelerator.print(\n",
    "                f\"Resuming from checkpoint {latest}\")\n",
    "        accelerator.load_state(checkpoint_dir, strict=False)\n",
    "    else: \n",
    "        resume_from_checkpoint = False\n",
    "    \n",
    "    if resume_from_checkpoint and resume_step is not None:\n",
    "        train_loader_skipped = accelerator.skip_first_batches(\n",
    "            train_loader, resume_step % num_epoch_steps)\n",
    "        completed_steps += resume_step\n",
    "        progress_bar.update(resume_step)\n",
    "        accelerator.print(f\"Resuming training from step {resume_step}\")\n",
    "        epoch = resume_step // num_epoch_steps\n",
    "        skip = True\n",
    "    else:\n",
    "        epoch = 0\n",
    "        skip = False\n",
    "\n",
    "    \n",
    "    log_loss = os.path.join(OUT_DIR,'train_log')\n",
    "    #loss_file = open(log_loss, \"w\", encoding=\"utf-8\") if accelerator.is_main_process else None\n",
    "    loss_file = open(log_loss, \"a\" if resume_from_checkpoint else \"w\", encoding=\"utf-8\") if accelerator.is_main_process else None\n",
    "    \n",
    "    print(f'Starting epoch: {epoch}, Ending Epoch: {epochs}, Total training steps: {num_training_steps}')\n",
    "    \n",
    "    for epoch in range(epoch,epochs):\n",
    "        model.train()\n",
    "        if skip:\n",
    "            for step, batch in enumerate(train_loader_skipped):\n",
    "                loss_log = None\n",
    "                skip = False\n",
    "                with accelerator.accumulate(model):\n",
    "                    outputs = model(**batch)\n",
    "                    loss = loss_fn(outputs.squeeze(),batch['labels'].squeeze())\n",
    "                    accelerator.backward(loss)\n",
    "                    \n",
    "                    if accelerator.sync_gradients:\n",
    "                        last_lr = scheduler.get_last_lr()\n",
    "                        if isinstance(last_lr, list):\n",
    "                            last_lr = last_lr[0]\n",
    "                        loss_log = {\n",
    "                            \"loss\": loss.item(),\n",
    "                            \"epoch\": completed_steps / num_epoch_steps,\n",
    "                            \"learning_rate\": last_lr\n",
    "                        }\n",
    "                        accelerator.log(loss_log, step=completed_steps)\n",
    "                        if loss_file is not None:\n",
    "                            loss_file.write(f\"{loss_log['loss']},\")\n",
    "                            loss_file.flush()\n",
    "        \n",
    "                        \n",
    "                    optim.step()\n",
    "                    scheduler.step()\n",
    "                    optim.zero_grad()\n",
    "                \n",
    "                if accelerator.sync_gradients:\n",
    "                    progress_bar.update(1)\n",
    "                    if loss_log is not None:\n",
    "                        progress_bar.set_postfix(loss_log)\n",
    "                    completed_steps += 1\n",
    "                    \n",
    "        \n",
    "                    if completed_steps > 0:\n",
    "                        if completed_steps % checkpointing_steps == 0:\n",
    "                            output_dir = f\"step_{completed_steps}\"\n",
    "                            if OUT_DIR is not None:\n",
    "                                output_dir = os.path.join(\n",
    "                                    OUT_DIR, output_dir)\n",
    "                            accelerator.save_state(output_dir)\n",
    "    \n",
    "            \n",
    "                if completed_steps >= num_training_steps:\n",
    "                    print(completed_steps)\n",
    "                    print(num_training_steps)\n",
    "                    print('broke')\n",
    "                    break\n",
    "        else: \n",
    "            for step, batch in enumerate(train_loader):\n",
    "                loss_log = None\n",
    "                with accelerator.accumulate(model):\n",
    "                    outputs = model(**batch)\n",
    "                    loss = loss_fn(outputs.squeeze(),batch['labels'].squeeze())\n",
    "                    accelerator.backward(loss)\n",
    "                    \n",
    "                    if accelerator.sync_gradients:\n",
    "                        last_lr = scheduler.get_last_lr()\n",
    "                        if isinstance(last_lr, list):\n",
    "                            last_lr = last_lr[0]\n",
    "                        loss_log = {\n",
    "                            \"loss\": loss.item(),\n",
    "                            \"epoch\": completed_steps / num_epoch_steps,\n",
    "                            \"learning_rate\": last_lr\n",
    "                        }\n",
    "                        accelerator.log(loss_log, step=completed_steps)\n",
    "                        if loss_file is not None:\n",
    "                            loss_file.write(f\"{loss_log['loss']},\")\n",
    "                            loss_file.flush()\n",
    "        \n",
    "                        \n",
    "                    optim.step()\n",
    "                    scheduler.step()\n",
    "                    optim.zero_grad()\n",
    "                \n",
    "                if accelerator.sync_gradients:\n",
    "                    progress_bar.update(1)\n",
    "                    if loss_log is not None:\n",
    "                        progress_bar.set_postfix(loss_log)\n",
    "                    completed_steps += 1\n",
    "                    \n",
    "        \n",
    "                    if completed_steps > 0:\n",
    "                        if completed_steps % checkpointing_steps == 0:\n",
    "                            output_dir = f\"step_{completed_steps}\"\n",
    "                            if OUT_DIR is not None:\n",
    "                                output_dir = os.path.join(\n",
    "                                    OUT_DIR, output_dir)\n",
    "                            accelerator.save_state(output_dir)\n",
    "    \n",
    "            \n",
    "                if completed_steps >= num_training_steps:\n",
    "                    print(completed_steps)\n",
    "                    print(num_training_steps)\n",
    "                    print('broke')\n",
    "                    break\n",
    "                    \n",
    "        \n",
    "            \n",
    "        if completed_steps >= num_training_steps:\n",
    "            print(completed_steps)\n",
    "            print(num_training_steps)\n",
    "            print('broke')\n",
    "            break\n",
    "    \n",
    "    accelerator.print(\"Training Finished\")\n",
    "    accelerator.end_training()\n",
    "\n",
    "    if OUT_DIR is not None:\n",
    "            accelerator.print(f\"Saving model to {OUT_DIR}\")\n",
    "    \n",
    "            accelerator.wait_for_everyone()\n",
    "    \n",
    "            if accelerator.distributed_type == DistributedType.FSDP:\n",
    "                full_state_dict_config = FullStateDictConfig(\n",
    "                    offload_to_cpu=True, rank0_only=True)\n",
    "                with FSDP.state_dict_type(model, StateDictType.FULL_STATE_DICT, full_state_dict_config):\n",
    "                    state_dict = accelerator.get_state_dict(model, unwrap=False)\n",
    "            else:\n",
    "                state_dict = accelerator.get_state_dict(model)\n",
    "    \n",
    "            torch.save(state_dict,os.path.join(OUT_DIR,\"final.pickle\"))\n",
    "            accelerator.print(\"Saving Finished\")\n",
    "    model, optim, train_loader, scheduler = accelerator.free_memory(model,optim, train_loader, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4f4e6-7f32-4727-818d-366171ef817e",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59fa897-8ab1-4a45-bbb5-a37578f189cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3fdf5c5cdd4e04977afb82ef168717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained(model_name,trust_remote_code=True)\n",
    "model_config.use_cache = False\n",
    "model_og = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=model_config,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "config_path = './custom_config.yaml'\n",
    "state_dict = model_og.backbone.state_dict()\n",
    "config = yaml.safe_load(open(config_path, 'rb').read())\n",
    "global_config = dotdict(config, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d10859e-a374-41bf-9cf9-1ee24572391b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass MyEmbed(VocabParallelEmbedding):\\n    def __init__(self, config):\\n        vocab_size, process_group, padding_idx = (\\n            config.vocab_size,\\n            config.get(\"process_group\", None),\\n            config.get(\"padding_idx\", None),\\n        )\\n        self.process_group = process_group\\n        if process_group is not None:\\n            world_size = torch.distributed.get_world_size(process_group)\\n            if vocab_size % world_size != 0:\\n                raise ValueError(f\"vocab_size ({vocab_size}) must be divisible by \" f\"world_size ({world_size})\")\\n            if world_size > 1 and padding_idx is not None:\\n                raise RuntimeError(\"ParallelEmbedding does not support padding_idx\")\\n        else:\\n            world_size = 1\\n        super().__init__(\\n            vocab_size // world_size,\\n            embedding_dim=config.hidden_size,\\n            padding_idx=padding_idx,\\n        )\\n    def embed(self, input: Tensor) -> Tensor:\\n        if self.process_group is None:\\n            return self.forward(input)\\n        else:\\n            rank = torch.distributed.get_rank(self.process_group)\\n            vocab_size = self.num_embeddings\\n            vocab_start_index, vocab_end_index = (\\n                rank * vocab_size,\\n                (rank + 1) * vocab_size,\\n            )\\n            # Create a mask of valid vocab ids (1 means it needs to be masked).\\n            input_ids_mask = (input < vocab_start_index) | (input >= vocab_end_index)\\n            input = input - vocab_start_index\\n            input[input_ids_mask] = 0\\n            embeddings = self.forward(input)\\n            embeddings[input_ids_mask] = 0.0\\n            # Reduce to the global process group\\n            torch.distributed.all_reduce(embeddings, group=self.process_group)\\n            return embeddings\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class MyEmbed(VocabParallelEmbedding):\n",
    "    def __init__(self, config):\n",
    "        vocab_size, process_group, padding_idx = (\n",
    "            config.vocab_size,\n",
    "            config.get(\"process_group\", None),\n",
    "            config.get(\"padding_idx\", None),\n",
    "        )\n",
    "        self.process_group = process_group\n",
    "        if process_group is not None:\n",
    "            world_size = torch.distributed.get_world_size(process_group)\n",
    "            if vocab_size % world_size != 0:\n",
    "                raise ValueError(f\"vocab_size ({vocab_size}) must be divisible by \" f\"world_size ({world_size})\")\n",
    "            if world_size > 1 and padding_idx is not None:\n",
    "                raise RuntimeError(\"ParallelEmbedding does not support padding_idx\")\n",
    "        else:\n",
    "            world_size = 1\n",
    "        super().__init__(\n",
    "            vocab_size // world_size,\n",
    "            embedding_dim=config.hidden_size,\n",
    "            padding_idx=padding_idx,\n",
    "        )\n",
    "    def embed(self, input: Tensor) -> Tensor:\n",
    "        if self.process_group is None:\n",
    "            return self.forward(input)\n",
    "        else:\n",
    "            rank = torch.distributed.get_rank(self.process_group)\n",
    "            vocab_size = self.num_embeddings\n",
    "            vocab_start_index, vocab_end_index = (\n",
    "                rank * vocab_size,\n",
    "                (rank + 1) * vocab_size,\n",
    "            )\n",
    "            # Create a mask of valid vocab ids (1 means it needs to be masked).\n",
    "            input_ids_mask = (input < vocab_start_index) | (input >= vocab_end_index)\n",
    "            input = input - vocab_start_index\n",
    "            input[input_ids_mask] = 0\n",
    "            embeddings = self.forward(input)\n",
    "            embeddings[input_ids_mask] = 0.0\n",
    "            # Reduce to the global process group\n",
    "            torch.distributed.all_reduce(embeddings, group=self.process_group)\n",
    "            return embeddings\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f49a13-c505-4735-88c1-a8b0ae91176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyena(StripedHyena):\n",
    "    def __init_(self,config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embedding_layer = VocabParallelEmbedding(config)\n",
    "        self.norm = RMSNorm(config) if config.get(\"final_norm\", True) else None\n",
    "        #self.unembed = self.embedding_layer if config.tie_embeddings else VocabParallelEmbedding(config)\n",
    "\n",
    "        if config.get(\"use_flashfft\", \"True\"):\n",
    "            try:\n",
    "                from flashfftconv import FlashFFTConv\n",
    "\n",
    "                self.flash_fft = FlashFFTConv(config.seqlen, dtype=torch.bfloat16)\n",
    "            except ImportError:\n",
    "                \"flashfftconv not installed\"\n",
    "        else:\n",
    "            self.flash_fft = None\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            get_block(config, layer_idx, flash_fft=self.flash_fft) for layer_idx in range(config.num_layers)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, inference_params_dict=None, padding_mask=None):\n",
    "        L = x.shape[1]\n",
    "        x = self.embedding_layer.embed(x)\n",
    "        if inference_params_dict is not None:\n",
    "            x, inference_params_dict_out = self.stateful_forward(\n",
    "                x,\n",
    "                inference_params_dict=inference_params_dict,\n",
    "            )\n",
    "        else:\n",
    "            x, inference_params_dict_out = self.stateless_forward(x, padding_mask=padding_mask)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        #Removed unembedding\n",
    "        #x = self.unembed.unembed(x)\n",
    "        return x, inference_params_dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4f6850a-bcc3-4665-93ff-9399c47a0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_hyena = MyHyena(global_config)\n",
    "custom_hyena.load_state_dict(state_dict,strict=True)\n",
    "\n",
    "\n",
    "for p in custom_hyena.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abfe9559-36d8-4ff1-bdb7-c5a2536eb639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvoForRegression(nn.Module):\n",
    "  def __init__(self): \n",
    "    super(EvoForRegression,self).__init__() \n",
    "\n",
    "    self.model = custom_hyena\n",
    "    self.dropout = nn.Dropout(0.1) \n",
    "    #First_Token representation\n",
    "\n",
    "    self.lin = nn.Linear(model_config.hidden_size,model_config.hidden_size) \n",
    "    self.out = nn.Linear(model_config.hidden_size,1) \n",
    "      \n",
    "\n",
    "  def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
    "    #Extract outputs from the hyena\n",
    "    outputs = self.model(x=input_ids, padding_mask=attention_mask)[0][:,0,:]\n",
    "    #Add custom layers\n",
    "    outputs = self.dropout(outputs)\n",
    "\n",
    "    outputs = self.lin(outputs)\n",
    "      \n",
    "    outputs = nn.ReLU()(outputs)  # (bs, dim)\n",
    "    outputs = self.dropout(outputs)  # (bs, dim)\n",
    "    out = self.out(outputs)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92b4498-d01e-4312-bb14-883a9a4aa67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EvoForRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efd3154f-47ae-4c84-9bed-6c698eb76c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPUS: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8441 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoint step_8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▍| 8000/8441 [01:46<00:05, 75.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from step 8000\n",
      "Starting epoch: 0, Ending Epoch: 1, Total training steps: 8441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▍| 8001/8441 [01:49<00:05, 75.19it/s, loss=2.83, epoch=0.948, learning_rate=1.35e-7]\u001b[A\n",
      " 95%|█████████▍| 8002/8441 [01:51<00:05, 75.19it/s, loss=2.44, epoch=0.948, learning_rate=1.34e-7]\u001b[A\n",
      " 95%|█████████▍| 8003/8441 [01:54<00:05, 75.19it/s, loss=2.94, epoch=0.948, learning_rate=1.33e-7]\u001b[A\n",
      " 95%|█████████▍| 8004/8441 [01:56<00:05, 75.19it/s, loss=2.48, epoch=0.948, learning_rate=1.33e-7]\u001b[A\n",
      " 95%|█████████▍| 8005/8441 [01:58<00:05, 75.19it/s, loss=2.76, epoch=0.948, learning_rate=1.32e-7]\u001b[A\n",
      " 95%|█████████▍| 8006/8441 [02:00<00:05, 75.19it/s, loss=3.18, epoch=0.948, learning_rate=1.32e-7]\u001b[A\n",
      " 95%|█████████▍| 8007/8441 [02:03<00:05, 75.19it/s, loss=2.91, epoch=0.948, learning_rate=1.31e-7]\u001b[A\n",
      " 95%|█████████▍| 8007/8441 [02:05<00:05, 75.19it/s, loss=2.91, epoch=0.948, learning_rate=1.31e-7]\u001b[A\n",
      " 95%|█████████▍| 8008/8441 [02:05<00:07, 60.09it/s, loss=2.91, epoch=0.948, learning_rate=1.31e-7]\u001b[A\n",
      " 95%|█████████▍| 8008/8441 [02:05<00:07, 60.09it/s, loss=2.76, epoch=0.949, learning_rate=1.3e-7] \u001b[A\n",
      " 95%|█████████▍| 8009/8441 [02:07<00:07, 58.21it/s, loss=2.76, epoch=0.949, learning_rate=1.3e-7]\u001b[A\n",
      " 95%|█████████▍| 8009/8441 [02:07<00:07, 58.21it/s, loss=2.67, epoch=0.949, learning_rate=1.3e-7]\u001b[A\n",
      " 95%|█████████▍| 8010/8441 [02:09<00:07, 55.68it/s, loss=2.67, epoch=0.949, learning_rate=1.3e-7]\u001b[A\n",
      " 95%|█████████▍| 8010/8441 [02:09<00:07, 55.68it/s, loss=2.64, epoch=0.949, learning_rate=1.29e-7]\u001b[A\n",
      " 95%|█████████▍| 8011/8441 [02:11<00:08, 52.43it/s, loss=2.64, epoch=0.949, learning_rate=1.29e-7]\u001b[A\n",
      " 95%|█████████▍| 8011/8441 [02:11<00:08, 52.43it/s, loss=2.7, epoch=0.949, learning_rate=1.29e-7] \u001b[A\n",
      " 95%|█████████▍| 8012/8441 [02:13<00:08, 48.44it/s, loss=2.7, epoch=0.949, learning_rate=1.29e-7]\u001b[A\n",
      " 95%|█████████▍| 8012/8441 [02:13<00:08, 48.44it/s, loss=1.89, epoch=0.949, learning_rate=1.28e-7]\u001b[A\n",
      " 95%|█████████▍| 8013/8441 [02:15<00:09, 43.65it/s, loss=1.89, epoch=0.949, learning_rate=1.28e-7]\u001b[A\n",
      " 95%|█████████▍| 8013/8441 [02:15<00:09, 43.65it/s, loss=2.93, epoch=0.949, learning_rate=1.27e-7]\u001b[A\n",
      " 95%|█████████▍| 8014/8441 [02:18<00:11, 38.40it/s, loss=2.93, epoch=0.949, learning_rate=1.27e-7]\u001b[A\n",
      " 95%|█████████▍| 8014/8441 [02:18<00:11, 38.40it/s, loss=2.61, epoch=0.949, learning_rate=1.27e-7]\u001b[A\n",
      " 95%|█████████▍| 8015/8441 [02:20<00:12, 32.88it/s, loss=2.61, epoch=0.949, learning_rate=1.27e-7]\u001b[A\n",
      " 95%|█████████▍| 8015/8441 [02:20<00:12, 32.88it/s, loss=2.85, epoch=0.949, learning_rate=1.26e-7]\u001b[A\n",
      " 95%|█████████▍| 8016/8441 [02:22<00:15, 27.29it/s, loss=2.85, epoch=0.949, learning_rate=1.26e-7]\u001b[A\n",
      " 95%|█████████▍| 8016/8441 [02:22<00:15, 27.29it/s, loss=2.75, epoch=0.95, learning_rate=1.26e-7] \u001b[A\n",
      " 95%|█████████▍| 8017/8441 [02:24<00:19, 21.96it/s, loss=2.75, epoch=0.95, learning_rate=1.26e-7]\u001b[A\n",
      " 95%|█████████▍| 8017/8441 [02:24<00:19, 21.96it/s, loss=2.57, epoch=0.95, learning_rate=1.25e-7]\u001b[A\n",
      " 95%|█████████▍| 8018/8441 [02:26<00:24, 17.25it/s, loss=2.57, epoch=0.95, learning_rate=1.25e-7]\u001b[A\n",
      " 95%|█████████▍| 8018/8441 [02:26<00:24, 17.25it/s, loss=3.03, epoch=0.95, learning_rate=1.25e-7]\u001b[A\n",
      " 95%|█████████▌| 8019/8441 [02:28<00:31, 13.26it/s, loss=3.03, epoch=0.95, learning_rate=1.25e-7]\u001b[A\n",
      " 95%|█████████▌| 8019/8441 [02:28<00:31, 13.26it/s, loss=2.95, epoch=0.95, learning_rate=1.24e-7]\u001b[A\n",
      " 95%|█████████▌| 8020/8441 [02:30<00:41, 10.04it/s, loss=2.95, epoch=0.95, learning_rate=1.24e-7]\u001b[A\n",
      " 95%|█████████▌| 8020/8441 [02:30<00:41, 10.04it/s, loss=2.82, epoch=0.95, learning_rate=1.23e-7]\u001b[A\n",
      " 95%|█████████▌| 8021/8441 [02:32<00:56,  7.48it/s, loss=2.82, epoch=0.95, learning_rate=1.23e-7]\u001b[A\n",
      " 95%|█████████▌| 8021/8441 [02:32<00:56,  7.48it/s, loss=3.04, epoch=0.95, learning_rate=1.23e-7]\u001b[A\n",
      " 95%|█████████▌| 8022/8441 [02:34<01:15,  5.56it/s, loss=3.04, epoch=0.95, learning_rate=1.23e-7]\u001b[A\n",
      " 95%|█████████▌| 8022/8441 [02:34<01:15,  5.56it/s, loss=2.76, epoch=0.95, learning_rate=1.22e-7]\u001b[A\n",
      " 95%|█████████▌| 8023/8441 [02:36<01:41,  4.12it/s, loss=2.76, epoch=0.95, learning_rate=1.22e-7]\u001b[A\n",
      " 95%|█████████▌| 8023/8441 [02:36<01:41,  4.12it/s, loss=2.64, epoch=0.95, learning_rate=1.22e-7]\u001b[A\n",
      " 95%|█████████▌| 8024/8441 [02:38<02:15,  3.08it/s, loss=2.64, epoch=0.95, learning_rate=1.22e-7]\u001b[A\n",
      " 95%|█████████▌| 8024/8441 [02:38<02:15,  3.08it/s, loss=2.48, epoch=0.95, learning_rate=1.21e-7]\u001b[A\n",
      " 95%|█████████▌| 8025/8441 [02:40<02:59,  2.32it/s, loss=2.48, epoch=0.95, learning_rate=1.21e-7]\u001b[A\n",
      " 95%|█████████▌| 8025/8441 [02:40<02:59,  2.32it/s, loss=2.35, epoch=0.951, learning_rate=1.2e-7]\u001b[A\n",
      " 95%|█████████▌| 8026/8441 [02:42<03:51,  1.79it/s, loss=2.35, epoch=0.951, learning_rate=1.2e-7]\u001b[A\n",
      " 95%|█████████▌| 8026/8441 [02:42<03:51,  1.79it/s, loss=2.63, epoch=0.951, learning_rate=1.2e-7]\u001b[A\n",
      " 95%|█████████▌| 8027/8441 [02:44<04:53,  1.41it/s, loss=2.63, epoch=0.951, learning_rate=1.2e-7]\u001b[A\n",
      " 95%|█████████▌| 8027/8441 [02:44<04:53,  1.41it/s, loss=3.58, epoch=0.951, learning_rate=1.19e-7]\u001b[A\n",
      " 95%|█████████▌| 8028/8441 [02:46<06:00,  1.14it/s, loss=3.58, epoch=0.951, learning_rate=1.19e-7]\u001b[A\n",
      " 95%|█████████▌| 8028/8441 [02:46<06:00,  1.14it/s, loss=3.56, epoch=0.951, learning_rate=1.19e-7]\u001b[A\n",
      " 95%|█████████▌| 8029/8441 [02:48<07:13,  1.05s/it, loss=3.56, epoch=0.951, learning_rate=1.19e-7]\u001b[A\n",
      " 95%|█████████▌| 8029/8441 [02:48<07:13,  1.05s/it, loss=2.89, epoch=0.951, learning_rate=1.18e-7]\u001b[A\n",
      " 95%|█████████▌| 8030/8441 [02:50<08:24,  1.23s/it, loss=2.89, epoch=0.951, learning_rate=1.18e-7]\u001b[A\n",
      " 95%|█████████▌| 8030/8441 [02:50<08:24,  1.23s/it, loss=2.51, epoch=0.951, learning_rate=1.18e-7]\u001b[A\n",
      " 95%|█████████▌| 8031/8441 [02:52<09:28,  1.39s/it, loss=2.51, epoch=0.951, learning_rate=1.18e-7]\u001b[A\n",
      " 95%|█████████▌| 8031/8441 [02:52<09:28,  1.39s/it, loss=2.24, epoch=0.951, learning_rate=1.17e-7]\u001b[A\n",
      " 95%|█████████▌| 8032/8441 [02:54<10:24,  1.53s/it, loss=2.24, epoch=0.951, learning_rate=1.17e-7]\u001b[A\n",
      " 95%|█████████▌| 8032/8441 [02:54<10:24,  1.53s/it, loss=3.54, epoch=0.951, learning_rate=1.16e-7]\u001b[A\n",
      " 95%|█████████▌| 8033/8441 [02:56<11:09,  1.64s/it, loss=3.54, epoch=0.951, learning_rate=1.16e-7]\u001b[A\n",
      " 95%|█████████▌| 8033/8441 [02:56<11:09,  1.64s/it, loss=2.54, epoch=0.952, learning_rate=1.16e-7]\u001b[A\n",
      " 95%|█████████▌| 8034/8441 [02:58<11:42,  1.73s/it, loss=2.54, epoch=0.952, learning_rate=1.16e-7]\u001b[A\n",
      " 95%|█████████▌| 8034/8441 [02:58<11:42,  1.73s/it, loss=2.55, epoch=0.952, learning_rate=1.15e-7]\u001b[A\n",
      " 95%|█████████▌| 8035/8441 [03:00<12:10,  1.80s/it, loss=2.55, epoch=0.952, learning_rate=1.15e-7]\u001b[A\n",
      " 95%|█████████▌| 8035/8441 [03:00<12:10,  1.80s/it, loss=2.37, epoch=0.952, learning_rate=1.15e-7]\u001b[A\n",
      " 95%|█████████▌| 8036/8441 [03:02<12:29,  1.85s/it, loss=2.37, epoch=0.952, learning_rate=1.15e-7]\u001b[A\n",
      " 95%|█████████▌| 8036/8441 [03:02<12:29,  1.85s/it, loss=2.66, epoch=0.952, learning_rate=1.14e-7]\u001b[A\n",
      " 95%|█████████▌| 8037/8441 [03:04<12:45,  1.89s/it, loss=2.66, epoch=0.952, learning_rate=1.14e-7]\u001b[A\n",
      " 95%|█████████▌| 8037/8441 [03:04<12:45,  1.89s/it, loss=3.09, epoch=0.952, learning_rate=1.14e-7]\u001b[A\n",
      " 95%|█████████▌| 8038/8441 [03:06<12:58,  1.93s/it, loss=3.09, epoch=0.952, learning_rate=1.14e-7]\u001b[A\n",
      " 95%|█████████▌| 8038/8441 [03:06<12:58,  1.93s/it, loss=2.65, epoch=0.952, learning_rate=1.13e-7]\u001b[A\n",
      " 95%|█████████▌| 8039/8441 [03:08<13:03,  1.95s/it, loss=2.65, epoch=0.952, learning_rate=1.13e-7]\u001b[A\n",
      " 95%|█████████▌| 8039/8441 [03:08<13:03,  1.95s/it, loss=2.33, epoch=0.952, learning_rate=1.13e-7]\u001b[A\n",
      " 95%|█████████▌| 8040/8441 [03:10<13:02,  1.95s/it, loss=2.33, epoch=0.952, learning_rate=1.13e-7]\u001b[A\n",
      " 95%|█████████▌| 8040/8441 [03:10<13:02,  1.95s/it, loss=2.64, epoch=0.952, learning_rate=1.12e-7]\u001b[A\n",
      " 95%|█████████▌| 8041/8441 [03:12<13:05,  1.96s/it, loss=2.64, epoch=0.952, learning_rate=1.12e-7]\u001b[A\n",
      " 95%|█████████▌| 8041/8441 [03:12<13:05,  1.96s/it, loss=3.3, epoch=0.952, learning_rate=1.11e-7] \u001b[A\n",
      " 95%|█████████▌| 8042/8441 [03:14<13:07,  1.97s/it, loss=3.3, epoch=0.952, learning_rate=1.11e-7]\u001b[A\n",
      " 95%|█████████▌| 8042/8441 [03:14<13:07,  1.97s/it, loss=2.25, epoch=0.953, learning_rate=1.11e-7]\u001b[A\n",
      " 95%|█████████▌| 8043/8441 [03:16<13:07,  1.98s/it, loss=2.25, epoch=0.953, learning_rate=1.11e-7]\u001b[A\n",
      " 95%|█████████▌| 8043/8441 [03:16<13:07,  1.98s/it, loss=2.86, epoch=0.953, learning_rate=1.1e-7] \u001b[A\n",
      " 95%|█████████▌| 8044/8441 [03:18<13:03,  1.97s/it, loss=2.86, epoch=0.953, learning_rate=1.1e-7]\u001b[A\n",
      " 95%|█████████▌| 8044/8441 [03:18<13:03,  1.97s/it, loss=2.61, epoch=0.953, learning_rate=1.1e-7]\u001b[A\n",
      " 95%|█████████▌| 8045/8441 [03:20<13:00,  1.97s/it, loss=2.61, epoch=0.953, learning_rate=1.1e-7]\u001b[A\n",
      " 95%|█████████▌| 8045/8441 [03:20<13:00,  1.97s/it, loss=2.9, epoch=0.953, learning_rate=1.09e-7]\u001b[A\n",
      " 95%|█████████▌| 8046/8441 [03:22<12:56,  1.96s/it, loss=2.9, epoch=0.953, learning_rate=1.09e-7]\u001b[A\n",
      " 95%|█████████▌| 8046/8441 [03:22<12:56,  1.96s/it, loss=3.62, epoch=0.953, learning_rate=1.09e-7]\u001b[A\n",
      " 95%|█████████▌| 8047/8441 [03:24<12:53,  1.96s/it, loss=3.62, epoch=0.953, learning_rate=1.09e-7]\u001b[A\n",
      " 95%|█████████▌| 8047/8441 [03:24<12:53,  1.96s/it, loss=3.54, epoch=0.953, learning_rate=1.08e-7]\u001b[A\n",
      " 95%|█████████▌| 8048/8441 [03:26<12:50,  1.96s/it, loss=3.54, epoch=0.953, learning_rate=1.08e-7]\u001b[A\n",
      " 95%|█████████▌| 8048/8441 [03:26<12:50,  1.96s/it, loss=3.37, epoch=0.953, learning_rate=1.08e-7]\u001b[A\n",
      " 95%|█████████▌| 8049/8441 [03:28<12:49,  1.96s/it, loss=3.37, epoch=0.953, learning_rate=1.08e-7]\u001b[A\n",
      " 95%|█████████▌| 8049/8441 [03:28<12:49,  1.96s/it, loss=2.73, epoch=0.953, learning_rate=1.07e-7]\u001b[A\n",
      " 95%|█████████▌| 8050/8441 [03:30<12:50,  1.97s/it, loss=2.73, epoch=0.953, learning_rate=1.07e-7]\u001b[A\n",
      " 95%|█████████▌| 8050/8441 [03:30<12:50,  1.97s/it, loss=3.22, epoch=0.954, learning_rate=1.06e-7]\u001b[A\n",
      " 95%|█████████▌| 8051/8441 [03:32<12:47,  1.97s/it, loss=3.22, epoch=0.954, learning_rate=1.06e-7]\u001b[A\n",
      " 95%|█████████▌| 8051/8441 [03:32<12:47,  1.97s/it, loss=2.37, epoch=0.954, learning_rate=1.06e-7]\u001b[A\n",
      " 95%|█████████▌| 8052/8441 [03:34<12:45,  1.97s/it, loss=2.37, epoch=0.954, learning_rate=1.06e-7]\u001b[A\n",
      " 95%|█████████▌| 8052/8441 [03:34<12:45,  1.97s/it, loss=2.67, epoch=0.954, learning_rate=1.05e-7]\u001b[A\n",
      " 95%|█████████▌| 8053/8441 [03:36<12:43,  1.97s/it, loss=2.67, epoch=0.954, learning_rate=1.05e-7]\u001b[A\n",
      " 95%|█████████▌| 8053/8441 [03:36<12:43,  1.97s/it, loss=3.17, epoch=0.954, learning_rate=1.05e-7]\u001b[A\n",
      " 95%|█████████▌| 8054/8441 [03:38<12:42,  1.97s/it, loss=3.17, epoch=0.954, learning_rate=1.05e-7]\u001b[A\n",
      " 95%|█████████▌| 8054/8441 [03:38<12:42,  1.97s/it, loss=2.64, epoch=0.954, learning_rate=1.04e-7]\u001b[A\n",
      " 95%|█████████▌| 8055/8441 [03:40<12:38,  1.97s/it, loss=2.64, epoch=0.954, learning_rate=1.04e-7]\u001b[A\n",
      " 95%|█████████▌| 8055/8441 [03:40<12:38,  1.97s/it, loss=1.98, epoch=0.954, learning_rate=1.04e-7]\u001b[A\n",
      " 95%|█████████▌| 8056/8441 [03:42<12:36,  1.96s/it, loss=1.98, epoch=0.954, learning_rate=1.04e-7]\u001b[A\n",
      " 95%|█████████▌| 8056/8441 [03:42<12:36,  1.96s/it, loss=2.98, epoch=0.954, learning_rate=1.03e-7]\u001b[A\n",
      " 95%|█████████▌| 8057/8441 [03:44<12:32,  1.96s/it, loss=2.98, epoch=0.954, learning_rate=1.03e-7]\u001b[A\n",
      " 95%|█████████▌| 8057/8441 [03:44<12:32,  1.96s/it, loss=2.36, epoch=0.954, learning_rate=1.03e-7]\u001b[A\n",
      " 95%|█████████▌| 8058/8441 [03:46<12:32,  1.96s/it, loss=2.36, epoch=0.954, learning_rate=1.03e-7]\u001b[A\n",
      " 95%|█████████▌| 8058/8441 [03:46<12:32,  1.96s/it, loss=3.16, epoch=0.955, learning_rate=1.02e-7]\u001b[A\n",
      " 95%|█████████▌| 8059/8441 [03:48<12:31,  1.97s/it, loss=3.16, epoch=0.955, learning_rate=1.02e-7]\u001b[A\n",
      " 95%|█████████▌| 8059/8441 [03:48<12:31,  1.97s/it, loss=2.46, epoch=0.955, learning_rate=1.02e-7]\u001b[A\n",
      " 95%|█████████▌| 8060/8441 [03:50<12:27,  1.96s/it, loss=2.46, epoch=0.955, learning_rate=1.02e-7]\u001b[A\n",
      " 95%|█████████▌| 8060/8441 [03:50<12:27,  1.96s/it, loss=2.11, epoch=0.955, learning_rate=1.01e-7]\u001b[A\n",
      " 95%|█████████▌| 8061/8441 [03:52<12:24,  1.96s/it, loss=2.11, epoch=0.955, learning_rate=1.01e-7]\u001b[A\n",
      " 95%|█████████▌| 8061/8441 [03:52<12:24,  1.96s/it, loss=2.89, epoch=0.955, learning_rate=1.01e-7]\u001b[A\n",
      " 96%|█████████▌| 8062/8441 [03:53<12:20,  1.95s/it, loss=2.89, epoch=0.955, learning_rate=1.01e-7]\u001b[A\n",
      " 96%|█████████▌| 8062/8441 [03:53<12:20,  1.95s/it, loss=2.48, epoch=0.955, learning_rate=1e-7]   \u001b[A\n",
      " 96%|█████████▌| 8063/8441 [03:55<12:19,  1.96s/it, loss=2.48, epoch=0.955, learning_rate=1e-7]\u001b[A\n",
      " 96%|█████████▌| 8063/8441 [03:55<12:19,  1.96s/it, loss=2.85, epoch=0.955, learning_rate=9.96e-8]\u001b[A\n",
      " 96%|█████████▌| 8064/8441 [03:57<12:17,  1.96s/it, loss=2.85, epoch=0.955, learning_rate=9.96e-8]\u001b[A\n",
      " 96%|█████████▌| 8064/8441 [03:57<12:17,  1.96s/it, loss=2.87, epoch=0.955, learning_rate=9.9e-8] \u001b[A\n",
      " 96%|█████████▌| 8065/8441 [03:59<12:14,  1.95s/it, loss=2.87, epoch=0.955, learning_rate=9.9e-8]\u001b[A\n",
      " 96%|█████████▌| 8065/8441 [03:59<12:14,  1.95s/it, loss=3.78, epoch=0.955, learning_rate=9.85e-8]\u001b[A\n",
      " 96%|█████████▌| 8066/8441 [04:01<12:10,  1.95s/it, loss=3.78, epoch=0.955, learning_rate=9.85e-8]\u001b[A\n",
      " 96%|█████████▌| 8066/8441 [04:01<12:10,  1.95s/it, loss=2.58, epoch=0.955, learning_rate=9.8e-8] \u001b[A\n",
      " 96%|█████████▌| 8067/8441 [04:03<12:09,  1.95s/it, loss=2.58, epoch=0.955, learning_rate=9.8e-8]\u001b[A\n",
      " 96%|█████████▌| 8067/8441 [04:03<12:09,  1.95s/it, loss=3.15, epoch=0.956, learning_rate=9.75e-8]\u001b[A\n",
      " 96%|█████████▌| 8068/8441 [04:05<12:07,  1.95s/it, loss=3.15, epoch=0.956, learning_rate=9.75e-8]\u001b[A\n",
      " 96%|█████████▌| 8068/8441 [04:05<12:07,  1.95s/it, loss=3.34, epoch=0.956, learning_rate=9.7e-8] \u001b[A\n",
      " 96%|█████████▌| 8069/8441 [04:07<12:05,  1.95s/it, loss=3.34, epoch=0.956, learning_rate=9.7e-8]\u001b[A\n",
      " 96%|█████████▌| 8069/8441 [04:07<12:05,  1.95s/it, loss=3.08, epoch=0.956, learning_rate=9.64e-8]\u001b[A\n",
      " 96%|█████████▌| 8070/8441 [04:09<12:03,  1.95s/it, loss=3.08, epoch=0.956, learning_rate=9.64e-8]\u001b[A\n",
      " 96%|█████████▌| 8070/8441 [04:09<12:03,  1.95s/it, loss=3.11, epoch=0.956, learning_rate=9.59e-8]\u001b[A\n",
      " 96%|█████████▌| 8071/8441 [04:11<12:00,  1.95s/it, loss=3.11, epoch=0.956, learning_rate=9.59e-8]\u001b[A\n",
      " 96%|█████████▌| 8071/8441 [04:11<12:00,  1.95s/it, loss=2.74, epoch=0.956, learning_rate=9.54e-8]\u001b[A\n",
      " 96%|█████████▌| 8072/8441 [04:13<11:59,  1.95s/it, loss=2.74, epoch=0.956, learning_rate=9.54e-8]\u001b[A\n",
      " 96%|█████████▌| 8072/8441 [04:13<11:59,  1.95s/it, loss=2.06, epoch=0.956, learning_rate=9.49e-8]\u001b[A\n",
      " 96%|█████████▌| 8073/8441 [04:15<11:55,  1.95s/it, loss=2.06, epoch=0.956, learning_rate=9.49e-8]\u001b[A\n",
      " 96%|█████████▌| 8073/8441 [04:15<11:55,  1.95s/it, loss=3.37, epoch=0.956, learning_rate=9.44e-8]\u001b[A\n",
      " 96%|█████████▌| 8074/8441 [04:17<11:54,  1.95s/it, loss=3.37, epoch=0.956, learning_rate=9.44e-8]\u001b[A\n",
      " 96%|█████████▌| 8074/8441 [04:17<11:54,  1.95s/it, loss=2.16, epoch=0.956, learning_rate=9.39e-8]\u001b[A\n",
      " 96%|█████████▌| 8075/8441 [04:19<11:53,  1.95s/it, loss=2.16, epoch=0.956, learning_rate=9.39e-8]\u001b[A\n",
      " 96%|█████████▌| 8075/8441 [04:19<11:53,  1.95s/it, loss=2.22, epoch=0.957, learning_rate=9.34e-8]\u001b[A\n",
      " 96%|█████████▌| 8076/8441 [04:21<11:51,  1.95s/it, loss=2.22, epoch=0.957, learning_rate=9.34e-8]\u001b[A\n",
      " 96%|█████████▌| 8076/8441 [04:21<11:51,  1.95s/it, loss=2.97, epoch=0.957, learning_rate=9.29e-8]\u001b[A\n",
      " 96%|█████████▌| 8077/8441 [04:23<11:48,  1.95s/it, loss=2.97, epoch=0.957, learning_rate=9.29e-8]\u001b[A\n",
      " 96%|█████████▌| 8077/8441 [04:23<11:48,  1.95s/it, loss=3.05, epoch=0.957, learning_rate=9.23e-8]\u001b[A\n",
      " 96%|█████████▌| 8078/8441 [04:25<11:46,  1.95s/it, loss=3.05, epoch=0.957, learning_rate=9.23e-8]\u001b[A\n",
      " 96%|█████████▌| 8078/8441 [04:25<11:46,  1.95s/it, loss=3.17, epoch=0.957, learning_rate=9.18e-8]\u001b[A\n",
      " 96%|█████████▌| 8079/8441 [04:27<11:44,  1.95s/it, loss=3.17, epoch=0.957, learning_rate=9.18e-8]\u001b[A\n",
      " 96%|█████████▌| 8079/8441 [04:27<11:44,  1.95s/it, loss=2.53, epoch=0.957, learning_rate=9.13e-8]\u001b[A\n",
      " 96%|█████████▌| 8080/8441 [04:29<11:41,  1.94s/it, loss=2.53, epoch=0.957, learning_rate=9.13e-8]\u001b[A\n",
      " 96%|█████████▌| 8080/8441 [04:29<11:41,  1.94s/it, loss=2.74, epoch=0.957, learning_rate=9.08e-8]\u001b[A\n",
      " 96%|█████████▌| 8081/8441 [04:30<11:41,  1.95s/it, loss=2.74, epoch=0.957, learning_rate=9.08e-8]\u001b[A\n",
      " 96%|█████████▌| 8081/8441 [04:30<11:41,  1.95s/it, loss=2.41, epoch=0.957, learning_rate=9.03e-8]\u001b[A\n",
      " 96%|█████████▌| 8082/8441 [04:32<11:39,  1.95s/it, loss=2.41, epoch=0.957, learning_rate=9.03e-8]\u001b[A\n",
      " 96%|█████████▌| 8082/8441 [04:32<11:39,  1.95s/it, loss=3.35, epoch=0.957, learning_rate=8.98e-8]\u001b[A\n",
      " 96%|█████████▌| 8083/8441 [04:34<11:35,  1.94s/it, loss=3.35, epoch=0.957, learning_rate=8.98e-8]\u001b[A\n",
      " 96%|█████████▌| 8083/8441 [04:34<11:35,  1.94s/it, loss=2.34, epoch=0.957, learning_rate=8.93e-8]\u001b[A\n",
      " 96%|█████████▌| 8084/8441 [04:36<11:32,  1.94s/it, loss=2.34, epoch=0.957, learning_rate=8.93e-8]\u001b[A\n",
      " 96%|█████████▌| 8084/8441 [04:36<11:32,  1.94s/it, loss=2.8, epoch=0.958, learning_rate=8.88e-8] \u001b[A\n",
      " 96%|█████████▌| 8085/8441 [04:38<11:30,  1.94s/it, loss=2.8, epoch=0.958, learning_rate=8.88e-8]\u001b[A\n",
      " 96%|█████████▌| 8085/8441 [04:38<11:30,  1.94s/it, loss=2.2, epoch=0.958, learning_rate=8.84e-8]\u001b[A\n",
      " 96%|█████████▌| 8086/8441 [04:40<11:29,  1.94s/it, loss=2.2, epoch=0.958, learning_rate=8.84e-8]\u001b[A\n",
      " 96%|█████████▌| 8086/8441 [04:40<11:29,  1.94s/it, loss=2.85, epoch=0.958, learning_rate=8.79e-8]\u001b[A\n",
      " 96%|█████████▌| 8087/8441 [04:42<11:27,  1.94s/it, loss=2.85, epoch=0.958, learning_rate=8.79e-8]\u001b[A\n",
      " 96%|█████████▌| 8087/8441 [04:42<11:27,  1.94s/it, loss=2.73, epoch=0.958, learning_rate=8.74e-8]\u001b[A\n",
      " 96%|█████████▌| 8088/8441 [04:44<11:24,  1.94s/it, loss=2.73, epoch=0.958, learning_rate=8.74e-8]\u001b[A\n",
      " 96%|█████████▌| 8088/8441 [04:44<11:24,  1.94s/it, loss=3.24, epoch=0.958, learning_rate=8.69e-8]\u001b[A\n",
      " 96%|█████████▌| 8089/8441 [04:46<11:20,  1.93s/it, loss=3.24, epoch=0.958, learning_rate=8.69e-8]\u001b[A\n",
      " 96%|█████████▌| 8089/8441 [04:46<11:20,  1.93s/it, loss=2.94, epoch=0.958, learning_rate=8.64e-8]\u001b[A\n",
      " 96%|█████████▌| 8090/8441 [04:48<11:19,  1.93s/it, loss=2.94, epoch=0.958, learning_rate=8.64e-8]\u001b[A\n",
      " 96%|█████████▌| 8090/8441 [04:48<11:19,  1.93s/it, loss=3.01, epoch=0.958, learning_rate=8.59e-8]\u001b[A\n",
      " 96%|█████████▌| 8091/8441 [04:50<11:18,  1.94s/it, loss=3.01, epoch=0.958, learning_rate=8.59e-8]\u001b[A\n",
      " 96%|█████████▌| 8091/8441 [04:50<11:18,  1.94s/it, loss=2.42, epoch=0.958, learning_rate=8.54e-8]\u001b[A\n",
      " 96%|█████████▌| 8092/8441 [04:52<11:15,  1.94s/it, loss=2.42, epoch=0.958, learning_rate=8.54e-8]\u001b[A\n",
      " 96%|█████████▌| 8092/8441 [04:52<11:15,  1.94s/it, loss=2.79, epoch=0.959, learning_rate=8.49e-8]\u001b[A\n",
      " 96%|█████████▌| 8093/8441 [04:54<11:14,  1.94s/it, loss=2.79, epoch=0.959, learning_rate=8.49e-8]\u001b[A\n",
      " 96%|█████████▌| 8093/8441 [04:54<11:14,  1.94s/it, loss=2.79, epoch=0.959, learning_rate=8.44e-8]\u001b[A\n",
      " 96%|█████████▌| 8094/8441 [04:56<11:12,  1.94s/it, loss=2.79, epoch=0.959, learning_rate=8.44e-8]\u001b[A\n",
      " 96%|█████████▌| 8094/8441 [04:56<11:12,  1.94s/it, loss=2.85, epoch=0.959, learning_rate=8.4e-8] \u001b[A\n",
      " 96%|█████████▌| 8095/8441 [04:58<11:09,  1.94s/it, loss=2.85, epoch=0.959, learning_rate=8.4e-8]\u001b[A\n",
      " 96%|█████████▌| 8095/8441 [04:58<11:09,  1.94s/it, loss=2.57, epoch=0.959, learning_rate=8.35e-8]\u001b[A\n",
      " 96%|█████████▌| 8096/8441 [05:00<11:07,  1.93s/it, loss=2.57, epoch=0.959, learning_rate=8.35e-8]\u001b[A\n",
      " 96%|█████████▌| 8096/8441 [05:00<11:07,  1.93s/it, loss=2.35, epoch=0.959, learning_rate=8.3e-8] \u001b[A\n",
      " 96%|█████████▌| 8097/8441 [05:01<11:05,  1.94s/it, loss=2.35, epoch=0.959, learning_rate=8.3e-8]\u001b[A\n",
      " 96%|█████████▌| 8097/8441 [05:01<11:05,  1.94s/it, loss=3.28, epoch=0.959, learning_rate=8.25e-8]\u001b[A\n",
      " 96%|█████████▌| 8098/8441 [05:03<11:01,  1.93s/it, loss=3.28, epoch=0.959, learning_rate=8.25e-8]\u001b[A\n",
      " 96%|█████████▌| 8098/8441 [05:03<11:01,  1.93s/it, loss=2.73, epoch=0.959, learning_rate=8.2e-8] \u001b[A\n",
      " 96%|█████████▌| 8099/8441 [05:05<11:00,  1.93s/it, loss=2.73, epoch=0.959, learning_rate=8.2e-8]\u001b[A\n",
      " 96%|█████████▌| 8099/8441 [05:05<11:00,  1.93s/it, loss=3.13, epoch=0.959, learning_rate=8.16e-8]\u001b[A\n",
      " 96%|█████████▌| 8100/8441 [05:07<10:59,  1.94s/it, loss=3.13, epoch=0.959, learning_rate=8.16e-8]\u001b[A\n",
      " 96%|█████████▌| 8100/8441 [05:07<10:59,  1.94s/it, loss=2.84, epoch=0.959, learning_rate=8.11e-8]\u001b[A\n",
      " 96%|█████████▌| 8101/8441 [05:09<10:57,  1.93s/it, loss=2.84, epoch=0.959, learning_rate=8.11e-8]\u001b[A\n",
      " 96%|█████████▌| 8101/8441 [05:09<10:57,  1.93s/it, loss=2.86, epoch=0.96, learning_rate=8.06e-8] \u001b[A\n",
      " 96%|█████████▌| 8102/8441 [05:11<10:55,  1.93s/it, loss=2.86, epoch=0.96, learning_rate=8.06e-8]\u001b[A\n",
      " 96%|█████████▌| 8102/8441 [05:11<10:55,  1.93s/it, loss=3.69, epoch=0.96, learning_rate=8.01e-8]\u001b[A\n",
      " 96%|█████████▌| 8103/8441 [05:13<10:52,  1.93s/it, loss=3.69, epoch=0.96, learning_rate=8.01e-8]\u001b[A\n",
      " 96%|█████████▌| 8103/8441 [05:13<10:52,  1.93s/it, loss=2.3, epoch=0.96, learning_rate=7.97e-8] \u001b[A\n",
      " 96%|█████████▌| 8104/8441 [05:15<10:50,  1.93s/it, loss=2.3, epoch=0.96, learning_rate=7.97e-8]\u001b[A\n",
      " 96%|█████████▌| 8104/8441 [05:15<10:50,  1.93s/it, loss=3.02, epoch=0.96, learning_rate=7.92e-8]\u001b[A\n",
      " 96%|█████████▌| 8105/8441 [05:17<10:49,  1.93s/it, loss=3.02, epoch=0.96, learning_rate=7.92e-8]\u001b[A\n",
      " 96%|█████████▌| 8105/8441 [05:17<10:49,  1.93s/it, loss=2.39, epoch=0.96, learning_rate=7.87e-8]\u001b[A\n",
      " 96%|█████████▌| 8106/8441 [05:19<10:48,  1.94s/it, loss=2.39, epoch=0.96, learning_rate=7.87e-8]\u001b[A\n",
      " 96%|█████████▌| 8106/8441 [05:19<10:48,  1.94s/it, loss=2.97, epoch=0.96, learning_rate=7.83e-8]\u001b[A\n",
      " 96%|█████████▌| 8107/8441 [05:21<10:46,  1.94s/it, loss=2.97, epoch=0.96, learning_rate=7.83e-8]\u001b[A\n",
      " 96%|█████████▌| 8107/8441 [05:21<10:46,  1.94s/it, loss=2.43, epoch=0.96, learning_rate=7.78e-8]\u001b[A\n",
      " 96%|█████████▌| 8108/8441 [05:23<10:45,  1.94s/it, loss=2.43, epoch=0.96, learning_rate=7.78e-8]\u001b[A\n",
      " 96%|█████████▌| 8108/8441 [05:23<10:45,  1.94s/it, loss=2.86, epoch=0.96, learning_rate=7.73e-8]\u001b[A\n",
      " 96%|█████████▌| 8109/8441 [05:25<10:42,  1.94s/it, loss=2.86, epoch=0.96, learning_rate=7.73e-8]\u001b[A\n",
      " 96%|█████████▌| 8109/8441 [05:25<10:42,  1.94s/it, loss=2.58, epoch=0.961, learning_rate=7.69e-8]\u001b[A\n",
      " 96%|█████████▌| 8110/8441 [05:27<10:40,  1.93s/it, loss=2.58, epoch=0.961, learning_rate=7.69e-8]\u001b[A\n",
      " 96%|█████████▌| 8110/8441 [05:27<10:40,  1.93s/it, loss=2.18, epoch=0.961, learning_rate=7.64e-8]\u001b[A\n",
      " 96%|█████████▌| 8111/8441 [05:29<10:39,  1.94s/it, loss=2.18, epoch=0.961, learning_rate=7.64e-8]\u001b[A\n",
      " 96%|█████████▌| 8111/8441 [05:29<10:39,  1.94s/it, loss=2.76, epoch=0.961, learning_rate=7.6e-8] \u001b[A\n",
      " 96%|█████████▌| 8112/8441 [05:31<10:37,  1.94s/it, loss=2.76, epoch=0.961, learning_rate=7.6e-8]\u001b[A\n",
      " 96%|█████████▌| 8112/8441 [05:31<10:37,  1.94s/it, loss=3.1, epoch=0.961, learning_rate=7.55e-8]\u001b[A\n",
      " 96%|█████████▌| 8113/8441 [05:32<10:33,  1.93s/it, loss=3.1, epoch=0.961, learning_rate=7.55e-8]\u001b[A\n",
      " 96%|█████████▌| 8113/8441 [05:32<10:33,  1.93s/it, loss=2.8, epoch=0.961, learning_rate=7.51e-8]\u001b[A\n",
      " 96%|█████████▌| 8114/8441 [05:34<10:31,  1.93s/it, loss=2.8, epoch=0.961, learning_rate=7.51e-8]\u001b[A\n",
      " 96%|█████████▌| 8114/8441 [05:34<10:31,  1.93s/it, loss=3.03, epoch=0.961, learning_rate=7.46e-8]\u001b[A\n",
      " 96%|█████████▌| 8115/8441 [05:36<10:28,  1.93s/it, loss=3.03, epoch=0.961, learning_rate=7.46e-8]\u001b[A\n",
      " 96%|█████████▌| 8115/8441 [05:36<10:28,  1.93s/it, loss=2.71, epoch=0.961, learning_rate=7.41e-8]\u001b[A\n",
      " 96%|█████████▌| 8116/8441 [05:38<10:27,  1.93s/it, loss=2.71, epoch=0.961, learning_rate=7.41e-8]\u001b[A\n",
      " 96%|█████████▌| 8116/8441 [05:38<10:27,  1.93s/it, loss=2.89, epoch=0.961, learning_rate=7.37e-8]\u001b[A\n",
      " 96%|█████████▌| 8117/8441 [05:40<10:25,  1.93s/it, loss=2.89, epoch=0.961, learning_rate=7.37e-8]\u001b[A\n",
      " 96%|█████████▌| 8117/8441 [05:40<10:25,  1.93s/it, loss=3.2, epoch=0.961, learning_rate=7.32e-8] \u001b[A\n",
      " 96%|█████████▌| 8118/8441 [05:42<10:23,  1.93s/it, loss=3.2, epoch=0.961, learning_rate=7.32e-8]\u001b[A\n",
      " 96%|█████████▌| 8118/8441 [05:42<10:23,  1.93s/it, loss=3.15, epoch=0.962, learning_rate=7.28e-8]\u001b[A\n",
      " 96%|█████████▌| 8119/8441 [05:44<10:21,  1.93s/it, loss=3.15, epoch=0.962, learning_rate=7.28e-8]\u001b[A\n",
      " 96%|█████████▌| 8119/8441 [05:44<10:21,  1.93s/it, loss=2.56, epoch=0.962, learning_rate=7.23e-8]\u001b[A\n",
      " 96%|█████████▌| 8120/8441 [05:46<10:18,  1.93s/it, loss=2.56, epoch=0.962, learning_rate=7.23e-8]\u001b[A\n",
      " 96%|█████████▌| 8120/8441 [05:46<10:18,  1.93s/it, loss=3.25, epoch=0.962, learning_rate=7.19e-8]\u001b[A\n",
      " 96%|█████████▌| 8121/8441 [05:48<10:17,  1.93s/it, loss=3.25, epoch=0.962, learning_rate=7.19e-8]\u001b[A\n",
      " 96%|█████████▌| 8121/8441 [05:48<10:17,  1.93s/it, loss=2.97, epoch=0.962, learning_rate=7.15e-8]\u001b[A\n",
      " 96%|█████████▌| 8122/8441 [05:50<10:16,  1.93s/it, loss=2.97, epoch=0.962, learning_rate=7.15e-8]\u001b[A\n",
      " 96%|█████████▌| 8122/8441 [05:50<10:16,  1.93s/it, loss=3.62, epoch=0.962, learning_rate=7.1e-8] \u001b[A\n",
      " 96%|█████████▌| 8123/8441 [05:52<10:13,  1.93s/it, loss=3.62, epoch=0.962, learning_rate=7.1e-8]\u001b[A\n",
      " 96%|█████████▌| 8123/8441 [05:52<10:13,  1.93s/it, loss=3.19, epoch=0.962, learning_rate=7.06e-8]\u001b[A\n",
      " 96%|█████████▌| 8124/8441 [05:54<10:11,  1.93s/it, loss=3.19, epoch=0.962, learning_rate=7.06e-8]\u001b[A\n",
      " 96%|█████████▌| 8124/8441 [05:54<10:11,  1.93s/it, loss=2.81, epoch=0.962, learning_rate=7.01e-8]\u001b[A\n",
      " 96%|█████████▋| 8125/8441 [05:56<10:09,  1.93s/it, loss=2.81, epoch=0.962, learning_rate=7.01e-8]\u001b[A\n",
      " 96%|█████████▋| 8125/8441 [05:56<10:09,  1.93s/it, loss=2.64, epoch=0.962, learning_rate=6.97e-8]\u001b[A\n",
      " 96%|█████████▋| 8126/8441 [05:57<10:06,  1.93s/it, loss=2.64, epoch=0.962, learning_rate=6.97e-8]\u001b[A\n",
      " 96%|█████████▋| 8126/8441 [05:57<10:06,  1.93s/it, loss=2.34, epoch=0.963, learning_rate=6.92e-8]\u001b[A\n",
      " 96%|█████████▋| 8127/8441 [05:59<10:04,  1.93s/it, loss=2.34, epoch=0.963, learning_rate=6.92e-8]\u001b[A\n",
      " 96%|█████████▋| 8127/8441 [05:59<10:04,  1.93s/it, loss=3.25, epoch=0.963, learning_rate=6.88e-8]\u001b[A\n",
      " 96%|█████████▋| 8128/8441 [06:01<10:02,  1.92s/it, loss=3.25, epoch=0.963, learning_rate=6.88e-8]\u001b[A\n",
      " 96%|█████████▋| 8128/8441 [06:01<10:02,  1.92s/it, loss=2.55, epoch=0.963, learning_rate=6.84e-8]\u001b[A\n",
      " 96%|█████████▋| 8129/8441 [06:03<09:59,  1.92s/it, loss=2.55, epoch=0.963, learning_rate=6.84e-8]\u001b[A\n",
      " 96%|█████████▋| 8129/8441 [06:03<09:59,  1.92s/it, loss=2.9, epoch=0.963, learning_rate=6.79e-8] \u001b[A\n",
      " 96%|█████████▋| 8130/8441 [06:05<09:58,  1.92s/it, loss=2.9, epoch=0.963, learning_rate=6.79e-8]\u001b[A\n",
      " 96%|█████████▋| 8130/8441 [06:05<09:58,  1.92s/it, loss=2.88, epoch=0.963, learning_rate=6.75e-8]\u001b[A\n",
      " 96%|█████████▋| 8131/8441 [06:07<09:55,  1.92s/it, loss=2.88, epoch=0.963, learning_rate=6.75e-8]\u001b[A\n",
      " 96%|█████████▋| 8131/8441 [06:07<09:55,  1.92s/it, loss=2.53, epoch=0.963, learning_rate=6.71e-8]\u001b[A\n",
      " 96%|█████████▋| 8132/8441 [06:09<09:53,  1.92s/it, loss=2.53, epoch=0.963, learning_rate=6.71e-8]\u001b[A\n",
      " 96%|█████████▋| 8132/8441 [06:09<09:53,  1.92s/it, loss=3.01, epoch=0.963, learning_rate=6.66e-8]\u001b[A\n",
      " 96%|█████████▋| 8133/8441 [06:11<09:51,  1.92s/it, loss=3.01, epoch=0.963, learning_rate=6.66e-8]\u001b[A\n",
      " 96%|█████████▋| 8133/8441 [06:11<09:51,  1.92s/it, loss=2.9, epoch=0.963, learning_rate=6.62e-8] \u001b[A\n",
      " 96%|█████████▋| 8134/8441 [06:13<09:48,  1.92s/it, loss=2.9, epoch=0.963, learning_rate=6.62e-8]\u001b[A\n",
      " 96%|█████████▋| 8134/8441 [06:13<09:48,  1.92s/it, loss=2.31, epoch=0.964, learning_rate=6.58e-8]\u001b[A\n",
      " 96%|█████████▋| 8135/8441 [06:15<09:47,  1.92s/it, loss=2.31, epoch=0.964, learning_rate=6.58e-8]\u001b[A\n",
      " 96%|█████████▋| 8135/8441 [06:15<09:47,  1.92s/it, loss=3.88, epoch=0.964, learning_rate=6.54e-8]\u001b[A\n",
      " 96%|█████████▋| 8136/8441 [06:17<09:46,  1.92s/it, loss=3.88, epoch=0.964, learning_rate=6.54e-8]\u001b[A\n",
      " 96%|█████████▋| 8136/8441 [06:17<09:46,  1.92s/it, loss=2.37, epoch=0.964, learning_rate=6.49e-8]\u001b[A\n",
      " 96%|█████████▋| 8137/8441 [06:19<09:45,  1.92s/it, loss=2.37, epoch=0.964, learning_rate=6.49e-8]\u001b[A\n",
      " 96%|█████████▋| 8137/8441 [06:19<09:45,  1.92s/it, loss=2.74, epoch=0.964, learning_rate=6.45e-8]\u001b[A\n",
      " 96%|█████████▋| 8138/8441 [06:21<09:43,  1.93s/it, loss=2.74, epoch=0.964, learning_rate=6.45e-8]\u001b[A\n",
      " 96%|█████████▋| 8138/8441 [06:21<09:43,  1.93s/it, loss=2.67, epoch=0.964, learning_rate=6.41e-8]\u001b[A\n",
      " 96%|█████████▋| 8139/8441 [06:22<09:41,  1.93s/it, loss=2.67, epoch=0.964, learning_rate=6.41e-8]\u001b[A\n",
      " 96%|█████████▋| 8139/8441 [06:22<09:41,  1.93s/it, loss=2.64, epoch=0.964, learning_rate=6.37e-8]\u001b[A\n",
      " 96%|█████████▋| 8140/8441 [06:24<09:38,  1.92s/it, loss=2.64, epoch=0.964, learning_rate=6.37e-8]\u001b[A\n",
      " 96%|█████████▋| 8140/8441 [06:24<09:38,  1.92s/it, loss=2.22, epoch=0.964, learning_rate=6.33e-8]\u001b[A\n",
      " 96%|█████████▋| 8141/8441 [06:26<09:36,  1.92s/it, loss=2.22, epoch=0.964, learning_rate=6.33e-8]\u001b[A\n",
      " 96%|█████████▋| 8141/8441 [06:26<09:36,  1.92s/it, loss=3.27, epoch=0.964, learning_rate=6.28e-8]\u001b[A\n",
      " 96%|█████████▋| 8142/8441 [06:28<09:33,  1.92s/it, loss=3.27, epoch=0.964, learning_rate=6.28e-8]\u001b[A\n",
      " 96%|█████████▋| 8142/8441 [06:28<09:33,  1.92s/it, loss=2.82, epoch=0.964, learning_rate=6.24e-8]\u001b[A\n",
      " 96%|█████████▋| 8143/8441 [06:30<09:31,  1.92s/it, loss=2.82, epoch=0.964, learning_rate=6.24e-8]\u001b[A\n",
      " 96%|█████████▋| 8143/8441 [06:30<09:31,  1.92s/it, loss=2.94, epoch=0.965, learning_rate=6.2e-8] \u001b[A\n",
      " 96%|█████████▋| 8144/8441 [06:32<09:30,  1.92s/it, loss=2.94, epoch=0.965, learning_rate=6.2e-8]\u001b[A\n",
      " 96%|█████████▋| 8144/8441 [06:32<09:30,  1.92s/it, loss=3.11, epoch=0.965, learning_rate=6.16e-8]\u001b[A\n",
      " 96%|█████████▋| 8145/8441 [06:34<09:28,  1.92s/it, loss=3.11, epoch=0.965, learning_rate=6.16e-8]\u001b[A\n",
      " 96%|█████████▋| 8145/8441 [06:34<09:28,  1.92s/it, loss=2.98, epoch=0.965, learning_rate=6.12e-8]\u001b[A\n",
      " 97%|█████████▋| 8146/8441 [06:36<09:26,  1.92s/it, loss=2.98, epoch=0.965, learning_rate=6.12e-8]\u001b[A\n",
      " 97%|█████████▋| 8146/8441 [06:36<09:26,  1.92s/it, loss=2.69, epoch=0.965, learning_rate=6.08e-8]\u001b[A\n",
      " 97%|█████████▋| 8147/8441 [06:38<09:23,  1.92s/it, loss=2.69, epoch=0.965, learning_rate=6.08e-8]\u001b[A\n",
      " 97%|█████████▋| 8147/8441 [06:38<09:23,  1.92s/it, loss=3, epoch=0.965, learning_rate=6.04e-8]   \u001b[A\n",
      " 97%|█████████▋| 8148/8441 [06:40<09:22,  1.92s/it, loss=3, epoch=0.965, learning_rate=6.04e-8]\u001b[A\n",
      " 97%|█████████▋| 8148/8441 [06:40<09:22,  1.92s/it, loss=2.74, epoch=0.965, learning_rate=5.99e-8]\u001b[A\n",
      " 97%|█████████▋| 8149/8441 [06:42<09:20,  1.92s/it, loss=2.74, epoch=0.965, learning_rate=5.99e-8]\u001b[A\n",
      " 97%|█████████▋| 8149/8441 [06:42<09:20,  1.92s/it, loss=2.77, epoch=0.965, learning_rate=5.95e-8]\u001b[A\n",
      " 97%|█████████▋| 8150/8441 [06:44<09:18,  1.92s/it, loss=2.77, epoch=0.965, learning_rate=5.95e-8]\u001b[A\n",
      " 97%|█████████▋| 8150/8441 [06:44<09:18,  1.92s/it, loss=2.52, epoch=0.965, learning_rate=5.91e-8]\u001b[A\n",
      " 97%|█████████▋| 8151/8441 [06:46<09:17,  1.92s/it, loss=2.52, epoch=0.965, learning_rate=5.91e-8]\u001b[A\n",
      " 97%|█████████▋| 8151/8441 [06:46<09:17,  1.92s/it, loss=3.03, epoch=0.966, learning_rate=5.87e-8]\u001b[A\n",
      " 97%|█████████▋| 8152/8441 [06:47<09:15,  1.92s/it, loss=3.03, epoch=0.966, learning_rate=5.87e-8]\u001b[A\n",
      " 97%|█████████▋| 8152/8441 [06:47<09:15,  1.92s/it, loss=2.7, epoch=0.966, learning_rate=5.83e-8] \u001b[A\n",
      " 97%|█████████▋| 8153/8441 [06:49<09:12,  1.92s/it, loss=2.7, epoch=0.966, learning_rate=5.83e-8]\u001b[A\n",
      " 97%|█████████▋| 8153/8441 [06:49<09:12,  1.92s/it, loss=2.34, epoch=0.966, learning_rate=5.79e-8]\u001b[A\n",
      " 97%|█████████▋| 8154/8441 [06:51<09:10,  1.92s/it, loss=2.34, epoch=0.966, learning_rate=5.79e-8]\u001b[A\n",
      " 97%|█████████▋| 8154/8441 [06:51<09:10,  1.92s/it, loss=3.05, epoch=0.966, learning_rate=5.75e-8]\u001b[A\n",
      " 97%|█████████▋| 8155/8441 [06:53<09:09,  1.92s/it, loss=3.05, epoch=0.966, learning_rate=5.75e-8]\u001b[A\n",
      " 97%|█████████▋| 8155/8441 [06:53<09:09,  1.92s/it, loss=2.25, epoch=0.966, learning_rate=5.71e-8]\u001b[A\n",
      " 97%|█████████▋| 8156/8441 [06:55<09:06,  1.92s/it, loss=2.25, epoch=0.966, learning_rate=5.71e-8]\u001b[A\n",
      " 97%|█████████▋| 8156/8441 [06:55<09:06,  1.92s/it, loss=3.2, epoch=0.966, learning_rate=5.67e-8] \u001b[A\n",
      " 97%|█████████▋| 8157/8441 [06:57<09:05,  1.92s/it, loss=3.2, epoch=0.966, learning_rate=5.67e-8]\u001b[A\n",
      " 97%|█████████▋| 8157/8441 [06:57<09:05,  1.92s/it, loss=2.81, epoch=0.966, learning_rate=5.63e-8]\u001b[A\n",
      " 97%|█████████▋| 8158/8441 [06:59<09:02,  1.92s/it, loss=2.81, epoch=0.966, learning_rate=5.63e-8]\u001b[A\n",
      " 97%|█████████▋| 8158/8441 [06:59<09:02,  1.92s/it, loss=2.9, epoch=0.966, learning_rate=5.59e-8] \u001b[A\n",
      " 97%|█████████▋| 8159/8441 [07:01<09:00,  1.92s/it, loss=2.9, epoch=0.966, learning_rate=5.59e-8]\u001b[A\n",
      " 97%|█████████▋| 8159/8441 [07:01<09:00,  1.92s/it, loss=3.08, epoch=0.966, learning_rate=5.55e-8]\u001b[A\n",
      " 97%|█████████▋| 8160/8441 [07:03<08:58,  1.92s/it, loss=3.08, epoch=0.966, learning_rate=5.55e-8]\u001b[A\n",
      " 97%|█████████▋| 8160/8441 [07:03<08:58,  1.92s/it, loss=3.2, epoch=0.967, learning_rate=5.52e-8] \u001b[A\n",
      " 97%|█████████▋| 8161/8441 [07:05<08:57,  1.92s/it, loss=3.2, epoch=0.967, learning_rate=5.52e-8]\u001b[A\n",
      " 97%|█████████▋| 8161/8441 [07:05<08:57,  1.92s/it, loss=3.16, epoch=0.967, learning_rate=5.48e-8]\u001b[A\n",
      " 97%|█████████▋| 8162/8441 [07:07<08:54,  1.92s/it, loss=3.16, epoch=0.967, learning_rate=5.48e-8]\u001b[A\n",
      " 97%|█████████▋| 8162/8441 [07:07<08:54,  1.92s/it, loss=3.44, epoch=0.967, learning_rate=5.44e-8]\u001b[A\n",
      " 97%|█████████▋| 8163/8441 [07:09<08:53,  1.92s/it, loss=3.44, epoch=0.967, learning_rate=5.44e-8]\u001b[A\n",
      " 97%|█████████▋| 8163/8441 [07:09<08:53,  1.92s/it, loss=2.96, epoch=0.967, learning_rate=5.4e-8] \u001b[A\n",
      " 97%|█████████▋| 8164/8441 [07:10<08:51,  1.92s/it, loss=2.96, epoch=0.967, learning_rate=5.4e-8]\u001b[A\n",
      " 97%|█████████▋| 8164/8441 [07:10<08:51,  1.92s/it, loss=2.78, epoch=0.967, learning_rate=5.36e-8]\u001b[A\n",
      " 97%|█████████▋| 8165/8441 [07:12<08:48,  1.92s/it, loss=2.78, epoch=0.967, learning_rate=5.36e-8]\u001b[A\n",
      " 97%|█████████▋| 8165/8441 [07:12<08:48,  1.92s/it, loss=2.68, epoch=0.967, learning_rate=5.32e-8]\u001b[A\n",
      " 97%|█████████▋| 8166/8441 [07:14<08:47,  1.92s/it, loss=2.68, epoch=0.967, learning_rate=5.32e-8]\u001b[A\n",
      " 97%|█████████▋| 8166/8441 [07:14<08:47,  1.92s/it, loss=2.92, epoch=0.967, learning_rate=5.28e-8]\u001b[A\n",
      " 97%|█████████▋| 8167/8441 [07:16<08:44,  1.92s/it, loss=2.92, epoch=0.967, learning_rate=5.28e-8]\u001b[A\n",
      " 97%|█████████▋| 8167/8441 [07:16<08:44,  1.92s/it, loss=2.39, epoch=0.967, learning_rate=5.25e-8]\u001b[A\n",
      " 97%|█████████▋| 8168/8441 [07:18<08:42,  1.92s/it, loss=2.39, epoch=0.967, learning_rate=5.25e-8]\u001b[A\n",
      " 97%|█████████▋| 8168/8441 [07:18<08:42,  1.92s/it, loss=2.59, epoch=0.968, learning_rate=5.21e-8]\u001b[A\n",
      " 97%|█████████▋| 8169/8441 [07:20<08:40,  1.91s/it, loss=2.59, epoch=0.968, learning_rate=5.21e-8]\u001b[A\n",
      " 97%|█████████▋| 8169/8441 [07:20<08:40,  1.91s/it, loss=3.07, epoch=0.968, learning_rate=5.17e-8]\u001b[A\n",
      " 97%|█████████▋| 8170/8441 [07:22<08:38,  1.91s/it, loss=3.07, epoch=0.968, learning_rate=5.17e-8]\u001b[A\n",
      " 97%|█████████▋| 8170/8441 [07:22<08:38,  1.91s/it, loss=3.13, epoch=0.968, learning_rate=5.13e-8]\u001b[A\n",
      " 97%|█████████▋| 8171/8441 [07:24<08:37,  1.91s/it, loss=3.13, epoch=0.968, learning_rate=5.13e-8]\u001b[A\n",
      " 97%|█████████▋| 8171/8441 [07:24<08:37,  1.91s/it, loss=2.76, epoch=0.968, learning_rate=5.09e-8]\u001b[A\n",
      " 97%|█████████▋| 8172/8441 [07:26<08:35,  1.92s/it, loss=2.76, epoch=0.968, learning_rate=5.09e-8]\u001b[A\n",
      " 97%|█████████▋| 8172/8441 [07:26<08:35,  1.92s/it, loss=3.12, epoch=0.968, learning_rate=5.06e-8]\u001b[A\n",
      " 97%|█████████▋| 8173/8441 [07:28<08:33,  1.92s/it, loss=3.12, epoch=0.968, learning_rate=5.06e-8]\u001b[A\n",
      " 97%|█████████▋| 8173/8441 [07:28<08:33,  1.92s/it, loss=2.39, epoch=0.968, learning_rate=5.02e-8]\u001b[A\n",
      " 97%|█████████▋| 8174/8441 [07:30<08:31,  1.92s/it, loss=2.39, epoch=0.968, learning_rate=5.02e-8]\u001b[A\n",
      " 97%|█████████▋| 8174/8441 [07:30<08:31,  1.92s/it, loss=1.98, epoch=0.968, learning_rate=4.98e-8]\u001b[A\n",
      " 97%|█████████▋| 8175/8441 [07:32<08:29,  1.91s/it, loss=1.98, epoch=0.968, learning_rate=4.98e-8]\u001b[A\n",
      " 97%|█████████▋| 8175/8441 [07:32<08:29,  1.91s/it, loss=2.92, epoch=0.968, learning_rate=4.95e-8]\u001b[A\n",
      " 97%|█████████▋| 8176/8441 [07:33<08:27,  1.92s/it, loss=2.92, epoch=0.968, learning_rate=4.95e-8]\u001b[A\n",
      " 97%|█████████▋| 8176/8441 [07:33<08:27,  1.92s/it, loss=3.35, epoch=0.968, learning_rate=4.91e-8]\u001b[A\n",
      " 97%|█████████▋| 8177/8441 [07:35<08:25,  1.91s/it, loss=3.35, epoch=0.968, learning_rate=4.91e-8]\u001b[A\n",
      " 97%|█████████▋| 8177/8441 [07:35<08:25,  1.91s/it, loss=2.2, epoch=0.969, learning_rate=4.87e-8] \u001b[A\n",
      " 97%|█████████▋| 8178/8441 [07:37<08:23,  1.92s/it, loss=2.2, epoch=0.969, learning_rate=4.87e-8]\u001b[A\n",
      " 97%|█████████▋| 8178/8441 [07:37<08:23,  1.92s/it, loss=2.31, epoch=0.969, learning_rate=4.83e-8]\u001b[A\n",
      " 97%|█████████▋| 8179/8441 [07:39<08:21,  1.91s/it, loss=2.31, epoch=0.969, learning_rate=4.83e-8]\u001b[A\n",
      " 97%|█████████▋| 8179/8441 [07:39<08:21,  1.91s/it, loss=2.64, epoch=0.969, learning_rate=4.8e-8] \u001b[A\n",
      " 97%|█████████▋| 8180/8441 [07:41<08:20,  1.92s/it, loss=2.64, epoch=0.969, learning_rate=4.8e-8]\u001b[A\n",
      " 97%|█████████▋| 8180/8441 [07:41<08:20,  1.92s/it, loss=3.47, epoch=0.969, learning_rate=4.76e-8]\u001b[A\n",
      " 97%|█████████▋| 8181/8441 [07:43<08:18,  1.92s/it, loss=3.47, epoch=0.969, learning_rate=4.76e-8]\u001b[A\n",
      " 97%|█████████▋| 8181/8441 [07:43<08:18,  1.92s/it, loss=2.74, epoch=0.969, learning_rate=4.73e-8]\u001b[A\n",
      " 97%|█████████▋| 8182/8441 [07:45<08:16,  1.92s/it, loss=2.74, epoch=0.969, learning_rate=4.73e-8]\u001b[A\n",
      " 97%|█████████▋| 8182/8441 [07:45<08:16,  1.92s/it, loss=1.93, epoch=0.969, learning_rate=4.69e-8]\u001b[A\n",
      " 97%|█████████▋| 8183/8441 [07:47<08:13,  1.91s/it, loss=1.93, epoch=0.969, learning_rate=4.69e-8]\u001b[A\n",
      " 97%|█████████▋| 8183/8441 [07:47<08:13,  1.91s/it, loss=2.81, epoch=0.969, learning_rate=4.65e-8]\u001b[A\n",
      " 97%|█████████▋| 8184/8441 [07:49<08:11,  1.91s/it, loss=2.81, epoch=0.969, learning_rate=4.65e-8]\u001b[A\n",
      " 97%|█████████▋| 8184/8441 [07:49<08:11,  1.91s/it, loss=3.02, epoch=0.969, learning_rate=4.62e-8]\u001b[A\n",
      " 97%|█████████▋| 8185/8441 [07:51<08:09,  1.91s/it, loss=3.02, epoch=0.969, learning_rate=4.62e-8]\u001b[A\n",
      " 97%|█████████▋| 8185/8441 [07:51<08:09,  1.91s/it, loss=2.28, epoch=0.97, learning_rate=4.58e-8] \u001b[A\n",
      " 97%|█████████▋| 8186/8441 [07:53<08:07,  1.91s/it, loss=2.28, epoch=0.97, learning_rate=4.58e-8]\u001b[A\n",
      " 97%|█████████▋| 8186/8441 [07:53<08:07,  1.91s/it, loss=2.98, epoch=0.97, learning_rate=4.55e-8]\u001b[A\n",
      " 97%|█████████▋| 8187/8441 [07:54<08:06,  1.92s/it, loss=2.98, epoch=0.97, learning_rate=4.55e-8]\u001b[A\n",
      " 97%|█████████▋| 8187/8441 [07:54<08:06,  1.92s/it, loss=2.9, epoch=0.97, learning_rate=4.51e-8] \u001b[A\n",
      " 97%|█████████▋| 8188/8441 [07:56<08:04,  1.92s/it, loss=2.9, epoch=0.97, learning_rate=4.51e-8]\u001b[A\n",
      " 97%|█████████▋| 8188/8441 [07:56<08:04,  1.92s/it, loss=2.72, epoch=0.97, learning_rate=4.48e-8]\u001b[A\n",
      " 97%|█████████▋| 8189/8441 [07:58<08:03,  1.92s/it, loss=2.72, epoch=0.97, learning_rate=4.48e-8]\u001b[A\n",
      " 97%|█████████▋| 8189/8441 [07:58<08:03,  1.92s/it, loss=2.72, epoch=0.97, learning_rate=4.44e-8]\u001b[A\n",
      " 97%|█████████▋| 8190/8441 [08:00<08:01,  1.92s/it, loss=2.72, epoch=0.97, learning_rate=4.44e-8]\u001b[A\n",
      " 97%|█████████▋| 8190/8441 [08:00<08:01,  1.92s/it, loss=2.67, epoch=0.97, learning_rate=4.41e-8]\u001b[A\n",
      " 97%|█████████▋| 8191/8441 [08:02<07:59,  1.92s/it, loss=2.67, epoch=0.97, learning_rate=4.41e-8]\u001b[A\n",
      " 97%|█████████▋| 8191/8441 [08:02<07:59,  1.92s/it, loss=2.88, epoch=0.97, learning_rate=4.37e-8]\u001b[A\n",
      " 97%|█████████▋| 8192/8441 [08:04<07:56,  1.92s/it, loss=2.88, epoch=0.97, learning_rate=4.37e-8]\u001b[A\n",
      " 97%|█████████▋| 8192/8441 [08:04<07:56,  1.92s/it, loss=3.19, epoch=0.97, learning_rate=4.34e-8]\u001b[A\n",
      " 97%|█████████▋| 8193/8441 [08:06<07:55,  1.92s/it, loss=3.19, epoch=0.97, learning_rate=4.34e-8]\u001b[A\n",
      " 97%|█████████▋| 8193/8441 [08:06<07:55,  1.92s/it, loss=3.15, epoch=0.971, learning_rate=4.3e-8]\u001b[A\n",
      " 97%|█████████▋| 8194/8441 [08:08<07:53,  1.92s/it, loss=3.15, epoch=0.971, learning_rate=4.3e-8]\u001b[A\n",
      " 97%|█████████▋| 8194/8441 [08:08<07:53,  1.92s/it, loss=2.39, epoch=0.971, learning_rate=4.27e-8]\u001b[A\n",
      " 97%|█████████▋| 8195/8441 [08:10<07:51,  1.92s/it, loss=2.39, epoch=0.971, learning_rate=4.27e-8]\u001b[A\n",
      " 97%|█████████▋| 8195/8441 [08:10<07:51,  1.92s/it, loss=2.29, epoch=0.971, learning_rate=4.23e-8]\u001b[A\n",
      " 97%|█████████▋| 8196/8441 [08:12<07:49,  1.92s/it, loss=2.29, epoch=0.971, learning_rate=4.23e-8]\u001b[A\n",
      " 97%|█████████▋| 8196/8441 [08:12<07:49,  1.92s/it, loss=3.3, epoch=0.971, learning_rate=4.2e-8]  \u001b[A\n",
      " 97%|█████████▋| 8197/8441 [08:14<07:47,  1.91s/it, loss=3.3, epoch=0.971, learning_rate=4.2e-8]\u001b[A\n",
      " 97%|█████████▋| 8197/8441 [08:14<07:47,  1.91s/it, loss=3.3, epoch=0.971, learning_rate=4.16e-8]\u001b[A\n",
      " 97%|█████████▋| 8198/8441 [08:16<07:45,  1.91s/it, loss=3.3, epoch=0.971, learning_rate=4.16e-8]\u001b[A\n",
      " 97%|█████████▋| 8198/8441 [08:16<07:45,  1.91s/it, loss=4.05, epoch=0.971, learning_rate=4.13e-8]\u001b[A\n",
      " 97%|█████████▋| 8199/8441 [08:17<07:42,  1.91s/it, loss=4.05, epoch=0.971, learning_rate=4.13e-8]\u001b[A\n",
      " 97%|█████████▋| 8199/8441 [08:17<07:42,  1.91s/it, loss=2.97, epoch=0.971, learning_rate=4.1e-8] \u001b[A\n",
      " 97%|█████████▋| 8200/8441 [08:19<07:40,  1.91s/it, loss=2.97, epoch=0.971, learning_rate=4.1e-8]\u001b[A\n",
      " 97%|█████████▋| 8200/8441 [08:19<07:40,  1.91s/it, loss=2.89, epoch=0.971, learning_rate=4.06e-8]\u001b[A\n",
      " 97%|█████████▋| 8201/8441 [08:21<07:38,  1.91s/it, loss=2.89, epoch=0.971, learning_rate=4.06e-8]\u001b[A\n",
      " 97%|█████████▋| 8201/8441 [08:21<07:38,  1.91s/it, loss=2.47, epoch=0.971, learning_rate=4.03e-8]\u001b[A\n",
      " 97%|█████████▋| 8202/8441 [08:23<07:37,  1.91s/it, loss=2.47, epoch=0.971, learning_rate=4.03e-8]\u001b[A\n",
      " 97%|█████████▋| 8202/8441 [08:23<07:37,  1.91s/it, loss=2.27, epoch=0.972, learning_rate=4e-8]   \u001b[A\n",
      " 97%|█████████▋| 8203/8441 [08:25<07:35,  1.91s/it, loss=2.27, epoch=0.972, learning_rate=4e-8]\u001b[A\n",
      " 97%|█████████▋| 8203/8441 [08:25<07:35,  1.91s/it, loss=3.3, epoch=0.972, learning_rate=3.96e-8]\u001b[A\n",
      " 97%|█████████▋| 8204/8441 [08:27<07:33,  1.91s/it, loss=3.3, epoch=0.972, learning_rate=3.96e-8]\u001b[A\n",
      " 97%|█████████▋| 8204/8441 [08:27<07:33,  1.91s/it, loss=2.37, epoch=0.972, learning_rate=3.93e-8]\u001b[A\n",
      " 97%|█████████▋| 8205/8441 [08:29<07:31,  1.91s/it, loss=2.37, epoch=0.972, learning_rate=3.93e-8]\u001b[A\n",
      " 97%|█████████▋| 8205/8441 [08:29<07:31,  1.91s/it, loss=2.08, epoch=0.972, learning_rate=3.9e-8] \u001b[A\n",
      " 97%|█████████▋| 8206/8441 [08:31<07:29,  1.91s/it, loss=2.08, epoch=0.972, learning_rate=3.9e-8]\u001b[A\n",
      " 97%|█████████▋| 8206/8441 [08:31<07:29,  1.91s/it, loss=3.56, epoch=0.972, learning_rate=3.86e-8]\u001b[A\n",
      " 97%|█████████▋| 8207/8441 [08:33<07:27,  1.91s/it, loss=3.56, epoch=0.972, learning_rate=3.86e-8]\u001b[A\n",
      " 97%|█████████▋| 8207/8441 [08:33<07:27,  1.91s/it, loss=2.89, epoch=0.972, learning_rate=3.83e-8]\u001b[A\n",
      " 97%|█████████▋| 8208/8441 [08:35<07:25,  1.91s/it, loss=2.89, epoch=0.972, learning_rate=3.83e-8]\u001b[A\n",
      " 97%|█████████▋| 8208/8441 [08:35<07:25,  1.91s/it, loss=2.99, epoch=0.972, learning_rate=3.8e-8] \u001b[A\n",
      " 97%|█████████▋| 8209/8441 [08:37<07:23,  1.91s/it, loss=2.99, epoch=0.972, learning_rate=3.8e-8]\u001b[A\n",
      " 97%|█████████▋| 8209/8441 [08:37<07:23,  1.91s/it, loss=2.67, epoch=0.972, learning_rate=3.77e-8]\u001b[A\n",
      " 97%|█████████▋| 8210/8441 [08:39<07:21,  1.91s/it, loss=2.67, epoch=0.972, learning_rate=3.77e-8]\u001b[A\n",
      " 97%|█████████▋| 8210/8441 [08:39<07:21,  1.91s/it, loss=2.54, epoch=0.973, learning_rate=3.73e-8]\u001b[A\n",
      " 97%|█████████▋| 8211/8441 [08:40<07:20,  1.91s/it, loss=2.54, epoch=0.973, learning_rate=3.73e-8]\u001b[A\n",
      " 97%|█████████▋| 8211/8441 [08:40<07:20,  1.91s/it, loss=2.15, epoch=0.973, learning_rate=3.7e-8] \u001b[A\n",
      " 97%|█████████▋| 8212/8441 [08:42<07:17,  1.91s/it, loss=2.15, epoch=0.973, learning_rate=3.7e-8]\u001b[A\n",
      " 97%|█████████▋| 8212/8441 [08:42<07:17,  1.91s/it, loss=2.73, epoch=0.973, learning_rate=3.67e-8]\u001b[A\n",
      " 97%|█████████▋| 8213/8441 [08:44<07:15,  1.91s/it, loss=2.73, epoch=0.973, learning_rate=3.67e-8]\u001b[A\n",
      " 97%|█████████▋| 8213/8441 [08:44<07:15,  1.91s/it, loss=3, epoch=0.973, learning_rate=3.64e-8]   \u001b[A\n",
      " 97%|█████████▋| 8214/8441 [08:46<07:13,  1.91s/it, loss=3, epoch=0.973, learning_rate=3.64e-8]\u001b[A\n",
      " 97%|█████████▋| 8214/8441 [08:46<07:13,  1.91s/it, loss=3.12, epoch=0.973, learning_rate=3.61e-8]\u001b[A\n",
      " 97%|█████████▋| 8215/8441 [08:48<07:11,  1.91s/it, loss=3.12, epoch=0.973, learning_rate=3.61e-8]\u001b[A\n",
      " 97%|█████████▋| 8215/8441 [08:48<07:11,  1.91s/it, loss=2.93, epoch=0.973, learning_rate=3.58e-8]\u001b[A\n",
      " 97%|█████████▋| 8216/8441 [08:50<07:10,  1.91s/it, loss=2.93, epoch=0.973, learning_rate=3.58e-8]\u001b[A\n",
      " 97%|█████████▋| 8216/8441 [08:50<07:10,  1.91s/it, loss=2.94, epoch=0.973, learning_rate=3.54e-8]\u001b[A\n",
      " 97%|█████████▋| 8217/8441 [08:52<07:08,  1.91s/it, loss=2.94, epoch=0.973, learning_rate=3.54e-8]\u001b[A\n",
      " 97%|█████████▋| 8217/8441 [08:52<07:08,  1.91s/it, loss=2.83, epoch=0.973, learning_rate=3.51e-8]\u001b[A\n",
      " 97%|█████████▋| 8218/8441 [08:54<07:05,  1.91s/it, loss=2.83, epoch=0.973, learning_rate=3.51e-8]\u001b[A\n",
      " 97%|█████████▋| 8218/8441 [08:54<07:05,  1.91s/it, loss=2.6, epoch=0.973, learning_rate=3.48e-8] \u001b[A\n",
      " 97%|█████████▋| 8219/8441 [08:56<07:04,  1.91s/it, loss=2.6, epoch=0.973, learning_rate=3.48e-8]\u001b[A\n",
      " 97%|█████████▋| 8219/8441 [08:56<07:04,  1.91s/it, loss=2.83, epoch=0.974, learning_rate=3.45e-8]\u001b[A\n",
      " 97%|█████████▋| 8220/8441 [08:58<07:02,  1.91s/it, loss=2.83, epoch=0.974, learning_rate=3.45e-8]\u001b[A\n",
      " 97%|█████████▋| 8220/8441 [08:58<07:02,  1.91s/it, loss=2.23, epoch=0.974, learning_rate=3.42e-8]\u001b[A\n",
      " 97%|█████████▋| 8221/8441 [09:00<07:00,  1.91s/it, loss=2.23, epoch=0.974, learning_rate=3.42e-8]\u001b[A\n",
      " 97%|█████████▋| 8221/8441 [09:00<07:00,  1.91s/it, loss=3.29, epoch=0.974, learning_rate=3.39e-8]\u001b[A\n",
      " 97%|█████████▋| 8222/8441 [09:01<06:58,  1.91s/it, loss=3.29, epoch=0.974, learning_rate=3.39e-8]\u001b[A\n",
      " 97%|█████████▋| 8222/8441 [09:01<06:58,  1.91s/it, loss=2.67, epoch=0.974, learning_rate=3.36e-8]\u001b[A\n",
      " 97%|█████████▋| 8223/8441 [09:03<06:56,  1.91s/it, loss=2.67, epoch=0.974, learning_rate=3.36e-8]\u001b[A\n",
      " 97%|█████████▋| 8223/8441 [09:03<06:56,  1.91s/it, loss=2.78, epoch=0.974, learning_rate=3.33e-8]\u001b[A\n",
      " 97%|█████████▋| 8224/8441 [09:05<06:54,  1.91s/it, loss=2.78, epoch=0.974, learning_rate=3.33e-8]\u001b[A\n",
      " 97%|█████████▋| 8224/8441 [09:05<06:54,  1.91s/it, loss=2.46, epoch=0.974, learning_rate=3.3e-8] \u001b[A\n",
      " 97%|█████████▋| 8225/8441 [09:07<06:53,  1.91s/it, loss=2.46, epoch=0.974, learning_rate=3.3e-8]\u001b[A\n",
      " 97%|█████████▋| 8225/8441 [09:07<06:53,  1.91s/it, loss=2.67, epoch=0.974, learning_rate=3.27e-8]\u001b[A\n",
      " 97%|█████████▋| 8226/8441 [09:09<06:51,  1.91s/it, loss=2.67, epoch=0.974, learning_rate=3.27e-8]\u001b[A\n",
      " 97%|█████████▋| 8226/8441 [09:09<06:51,  1.91s/it, loss=1.96, epoch=0.974, learning_rate=3.24e-8]\u001b[A\n",
      " 97%|█████████▋| 8227/8441 [09:11<06:49,  1.91s/it, loss=1.96, epoch=0.974, learning_rate=3.24e-8]\u001b[A\n",
      " 97%|█████████▋| 8227/8441 [09:11<06:49,  1.91s/it, loss=2.09, epoch=0.975, learning_rate=3.21e-8]\u001b[A\n",
      " 97%|█████████▋| 8228/8441 [09:13<06:47,  1.91s/it, loss=2.09, epoch=0.975, learning_rate=3.21e-8]\u001b[A\n",
      " 97%|█████████▋| 8228/8441 [09:13<06:47,  1.91s/it, loss=3.69, epoch=0.975, learning_rate=3.18e-8]\u001b[A\n",
      " 97%|█████████▋| 8229/8441 [09:15<06:44,  1.91s/it, loss=3.69, epoch=0.975, learning_rate=3.18e-8]\u001b[A\n",
      " 97%|█████████▋| 8229/8441 [09:15<06:44,  1.91s/it, loss=2.61, epoch=0.975, learning_rate=3.15e-8]\u001b[A\n",
      " 98%|█████████▊| 8230/8441 [09:17<06:43,  1.91s/it, loss=2.61, epoch=0.975, learning_rate=3.15e-8]\u001b[A\n",
      " 98%|█████████▊| 8230/8441 [09:17<06:43,  1.91s/it, loss=2.79, epoch=0.975, learning_rate=3.12e-8]\u001b[A\n",
      " 98%|█████████▊| 8231/8441 [09:19<06:41,  1.91s/it, loss=2.79, epoch=0.975, learning_rate=3.12e-8]\u001b[A\n",
      " 98%|█████████▊| 8231/8441 [09:19<06:41,  1.91s/it, loss=3.38, epoch=0.975, learning_rate=3.09e-8]\u001b[A\n",
      " 98%|█████████▊| 8232/8441 [09:21<06:39,  1.91s/it, loss=3.38, epoch=0.975, learning_rate=3.09e-8]\u001b[A\n",
      " 98%|█████████▊| 8232/8441 [09:21<06:39,  1.91s/it, loss=2.98, epoch=0.975, learning_rate=3.06e-8]\u001b[A\n",
      " 98%|█████████▊| 8233/8441 [09:22<06:37,  1.91s/it, loss=2.98, epoch=0.975, learning_rate=3.06e-8]\u001b[A\n",
      " 98%|█████████▊| 8233/8441 [09:22<06:37,  1.91s/it, loss=2.75, epoch=0.975, learning_rate=3.03e-8]\u001b[A\n",
      " 98%|█████████▊| 8234/8441 [09:24<06:35,  1.91s/it, loss=2.75, epoch=0.975, learning_rate=3.03e-8]\u001b[A\n",
      " 98%|█████████▊| 8234/8441 [09:24<06:35,  1.91s/it, loss=2.92, epoch=0.975, learning_rate=3e-8]   \u001b[A\n",
      " 98%|█████████▊| 8235/8441 [09:26<06:33,  1.91s/it, loss=2.92, epoch=0.975, learning_rate=3e-8]\u001b[A\n",
      " 98%|█████████▊| 8235/8441 [09:26<06:33,  1.91s/it, loss=2.71, epoch=0.975, learning_rate=2.97e-8]\u001b[A\n",
      " 98%|█████████▊| 8236/8441 [09:28<06:31,  1.91s/it, loss=2.71, epoch=0.975, learning_rate=2.97e-8]\u001b[A\n",
      " 98%|█████████▊| 8236/8441 [09:28<06:31,  1.91s/it, loss=2.8, epoch=0.976, learning_rate=2.94e-8] \u001b[A\n",
      " 98%|█████████▊| 8237/8441 [09:30<06:29,  1.91s/it, loss=2.8, epoch=0.976, learning_rate=2.94e-8]\u001b[A\n",
      " 98%|█████████▊| 8237/8441 [09:30<06:29,  1.91s/it, loss=2.71, epoch=0.976, learning_rate=2.92e-8]\u001b[A\n",
      " 98%|█████████▊| 8238/8441 [09:32<06:27,  1.91s/it, loss=2.71, epoch=0.976, learning_rate=2.92e-8]\u001b[A\n",
      " 98%|█████████▊| 8238/8441 [09:32<06:27,  1.91s/it, loss=2.82, epoch=0.976, learning_rate=2.89e-8]\u001b[A\n",
      " 98%|█████████▊| 8239/8441 [09:34<06:25,  1.91s/it, loss=2.82, epoch=0.976, learning_rate=2.89e-8]\u001b[A\n",
      " 98%|█████████▊| 8239/8441 [09:34<06:25,  1.91s/it, loss=2.66, epoch=0.976, learning_rate=2.86e-8]\u001b[A\n",
      " 98%|█████████▊| 8240/8441 [09:36<06:23,  1.91s/it, loss=2.66, epoch=0.976, learning_rate=2.86e-8]\u001b[A\n",
      " 98%|█████████▊| 8240/8441 [09:36<06:23,  1.91s/it, loss=2.87, epoch=0.976, learning_rate=2.83e-8]\u001b[A\n",
      " 98%|█████████▊| 8241/8441 [09:38<06:21,  1.91s/it, loss=2.87, epoch=0.976, learning_rate=2.83e-8]\u001b[A\n",
      " 98%|█████████▊| 8241/8441 [09:38<06:21,  1.91s/it, loss=2.71, epoch=0.976, learning_rate=2.8e-8] \u001b[A\n",
      " 98%|█████████▊| 8242/8441 [09:40<06:19,  1.91s/it, loss=2.71, epoch=0.976, learning_rate=2.8e-8]\u001b[A\n",
      " 98%|█████████▊| 8242/8441 [09:40<06:19,  1.91s/it, loss=2.34, epoch=0.976, learning_rate=2.78e-8]\u001b[A\n",
      " 98%|█████████▊| 8243/8441 [09:42<06:17,  1.91s/it, loss=2.34, epoch=0.976, learning_rate=2.78e-8]\u001b[A\n",
      " 98%|█████████▊| 8243/8441 [09:42<06:17,  1.91s/it, loss=2.87, epoch=0.976, learning_rate=2.75e-8]\u001b[A\n",
      " 98%|█████████▊| 8244/8441 [09:43<06:15,  1.91s/it, loss=2.87, epoch=0.976, learning_rate=2.75e-8]\u001b[A\n",
      " 98%|█████████▊| 8244/8441 [09:43<06:15,  1.91s/it, loss=2.56, epoch=0.977, learning_rate=2.72e-8]\u001b[A\n",
      " 98%|█████████▊| 8245/8441 [09:45<06:13,  1.91s/it, loss=2.56, epoch=0.977, learning_rate=2.72e-8]\u001b[A\n",
      " 98%|█████████▊| 8245/8441 [09:45<06:13,  1.91s/it, loss=3.02, epoch=0.977, learning_rate=2.69e-8]\u001b[A\n",
      " 98%|█████████▊| 8246/8441 [09:47<06:11,  1.91s/it, loss=3.02, epoch=0.977, learning_rate=2.69e-8]\u001b[A\n",
      " 98%|█████████▊| 8246/8441 [09:47<06:11,  1.91s/it, loss=3.37, epoch=0.977, learning_rate=2.67e-8]\u001b[A\n",
      " 98%|█████████▊| 8247/8441 [09:49<06:10,  1.91s/it, loss=3.37, epoch=0.977, learning_rate=2.67e-8]\u001b[A\n",
      " 98%|█████████▊| 8247/8441 [09:49<06:10,  1.91s/it, loss=2.97, epoch=0.977, learning_rate=2.64e-8]\u001b[A\n",
      " 98%|█████████▊| 8248/8441 [09:51<06:08,  1.91s/it, loss=2.97, epoch=0.977, learning_rate=2.64e-8]\u001b[A\n",
      " 98%|█████████▊| 8248/8441 [09:51<06:08,  1.91s/it, loss=2.76, epoch=0.977, learning_rate=2.61e-8]\u001b[A\n",
      " 98%|█████████▊| 8249/8441 [09:53<06:06,  1.91s/it, loss=2.76, epoch=0.977, learning_rate=2.61e-8]\u001b[A\n",
      " 98%|█████████▊| 8249/8441 [09:53<06:06,  1.91s/it, loss=3.24, epoch=0.977, learning_rate=2.58e-8]\u001b[A\n",
      " 98%|█████████▊| 8250/8441 [09:55<06:05,  1.91s/it, loss=3.24, epoch=0.977, learning_rate=2.58e-8]\u001b[A\n",
      " 98%|█████████▊| 8250/8441 [09:55<06:05,  1.91s/it, loss=3.47, epoch=0.977, learning_rate=2.56e-8]\u001b[A\n",
      " 98%|█████████▊| 8251/8441 [09:57<06:02,  1.91s/it, loss=3.47, epoch=0.977, learning_rate=2.56e-8]\u001b[A\n",
      " 98%|█████████▊| 8251/8441 [09:57<06:02,  1.91s/it, loss=3.23, epoch=0.977, learning_rate=2.53e-8]\u001b[A\n",
      " 98%|█████████▊| 8252/8441 [09:59<06:01,  1.91s/it, loss=3.23, epoch=0.977, learning_rate=2.53e-8]\u001b[A\n",
      " 98%|█████████▊| 8252/8441 [09:59<06:01,  1.91s/it, loss=3, epoch=0.977, learning_rate=2.51e-8]   \u001b[A\n",
      " 98%|█████████▊| 8253/8441 [10:01<05:59,  1.91s/it, loss=3, epoch=0.977, learning_rate=2.51e-8]\u001b[A\n",
      " 98%|█████████▊| 8253/8441 [10:01<05:59,  1.91s/it, loss=2.95, epoch=0.978, learning_rate=2.48e-8]\u001b[A\n",
      " 98%|█████████▊| 8254/8441 [10:03<05:57,  1.91s/it, loss=2.95, epoch=0.978, learning_rate=2.48e-8]\u001b[A\n",
      " 98%|█████████▊| 8254/8441 [10:03<05:57,  1.91s/it, loss=2.78, epoch=0.978, learning_rate=2.45e-8]\u001b[A\n",
      " 98%|█████████▊| 8255/8441 [10:04<05:55,  1.91s/it, loss=2.78, epoch=0.978, learning_rate=2.45e-8]\u001b[A\n",
      " 98%|█████████▊| 8255/8441 [10:04<05:55,  1.91s/it, loss=3.19, epoch=0.978, learning_rate=2.43e-8]\u001b[A\n",
      " 98%|█████████▊| 8256/8441 [10:06<05:53,  1.91s/it, loss=3.19, epoch=0.978, learning_rate=2.43e-8]\u001b[A\n",
      " 98%|█████████▊| 8256/8441 [10:06<05:53,  1.91s/it, loss=2.79, epoch=0.978, learning_rate=2.4e-8] \u001b[A\n",
      " 98%|█████████▊| 8257/8441 [10:08<05:51,  1.91s/it, loss=2.79, epoch=0.978, learning_rate=2.4e-8]\u001b[A\n",
      " 98%|█████████▊| 8257/8441 [10:08<05:51,  1.91s/it, loss=3.25, epoch=0.978, learning_rate=2.38e-8]\u001b[A\n",
      " 98%|█████████▊| 8258/8441 [10:10<05:49,  1.91s/it, loss=3.25, epoch=0.978, learning_rate=2.38e-8]\u001b[A\n",
      " 98%|█████████▊| 8258/8441 [10:10<05:49,  1.91s/it, loss=3.49, epoch=0.978, learning_rate=2.35e-8]\u001b[A\n",
      " 98%|█████████▊| 8259/8441 [10:12<05:47,  1.91s/it, loss=3.49, epoch=0.978, learning_rate=2.35e-8]\u001b[A\n",
      " 98%|█████████▊| 8259/8441 [10:12<05:47,  1.91s/it, loss=3.08, epoch=0.978, learning_rate=2.32e-8]\u001b[A\n",
      " 98%|█████████▊| 8260/8441 [10:14<05:45,  1.91s/it, loss=3.08, epoch=0.978, learning_rate=2.32e-8]\u001b[A\n",
      " 98%|█████████▊| 8260/8441 [10:14<05:45,  1.91s/it, loss=3.09, epoch=0.978, learning_rate=2.3e-8] \u001b[A\n",
      " 98%|█████████▊| 8261/8441 [10:16<05:43,  1.91s/it, loss=3.09, epoch=0.978, learning_rate=2.3e-8]\u001b[A\n",
      " 98%|█████████▊| 8261/8441 [10:16<05:43,  1.91s/it, loss=3.2, epoch=0.979, learning_rate=2.27e-8]\u001b[A\n",
      " 98%|█████████▊| 8262/8441 [10:18<05:41,  1.91s/it, loss=3.2, epoch=0.979, learning_rate=2.27e-8]\u001b[A\n",
      " 98%|█████████▊| 8262/8441 [10:18<05:41,  1.91s/it, loss=2.95, epoch=0.979, learning_rate=2.25e-8]\u001b[A\n",
      " 98%|█████████▊| 8263/8441 [10:20<05:39,  1.91s/it, loss=2.95, epoch=0.979, learning_rate=2.25e-8]\u001b[A\n",
      " 98%|█████████▊| 8263/8441 [10:20<05:39,  1.91s/it, loss=2.69, epoch=0.979, learning_rate=2.22e-8]\u001b[A\n",
      " 98%|█████████▊| 8264/8441 [10:22<05:37,  1.91s/it, loss=2.69, epoch=0.979, learning_rate=2.22e-8]\u001b[A\n",
      " 98%|█████████▊| 8264/8441 [10:22<05:37,  1.91s/it, loss=2.99, epoch=0.979, learning_rate=2.2e-8] \u001b[A\n",
      " 98%|█████████▊| 8265/8441 [10:24<05:35,  1.91s/it, loss=2.99, epoch=0.979, learning_rate=2.2e-8]\u001b[A\n",
      " 98%|█████████▊| 8265/8441 [10:24<05:35,  1.91s/it, loss=2.87, epoch=0.979, learning_rate=2.17e-8]\u001b[A\n",
      " 98%|█████████▊| 8266/8441 [10:25<05:34,  1.91s/it, loss=2.87, epoch=0.979, learning_rate=2.17e-8]\u001b[A\n",
      " 98%|█████████▊| 8266/8441 [10:25<05:34,  1.91s/it, loss=2.81, epoch=0.979, learning_rate=2.15e-8]\u001b[A\n",
      " 98%|█████████▊| 8267/8441 [10:27<05:32,  1.91s/it, loss=2.81, epoch=0.979, learning_rate=2.15e-8]\u001b[A\n",
      " 98%|█████████▊| 8267/8441 [10:27<05:32,  1.91s/it, loss=2.98, epoch=0.979, learning_rate=2.13e-8]\u001b[A\n",
      " 98%|█████████▊| 8268/8441 [10:29<05:30,  1.91s/it, loss=2.98, epoch=0.979, learning_rate=2.13e-8]\u001b[A\n",
      " 98%|█████████▊| 8268/8441 [10:29<05:30,  1.91s/it, loss=2.56, epoch=0.979, learning_rate=2.1e-8] \u001b[A\n",
      " 98%|█████████▊| 8269/8441 [10:31<05:28,  1.91s/it, loss=2.56, epoch=0.979, learning_rate=2.1e-8]\u001b[A\n",
      " 98%|█████████▊| 8269/8441 [10:31<05:28,  1.91s/it, loss=2.97, epoch=0.98, learning_rate=2.08e-8]\u001b[A\n",
      " 98%|█████████▊| 8270/8441 [10:33<05:26,  1.91s/it, loss=2.97, epoch=0.98, learning_rate=2.08e-8]\u001b[A\n",
      " 98%|█████████▊| 8270/8441 [10:33<05:26,  1.91s/it, loss=3.29, epoch=0.98, learning_rate=2.05e-8]\u001b[A\n",
      " 98%|█████████▊| 8271/8441 [10:35<05:24,  1.91s/it, loss=3.29, epoch=0.98, learning_rate=2.05e-8]\u001b[A\n",
      " 98%|█████████▊| 8271/8441 [10:35<05:24,  1.91s/it, loss=2.73, epoch=0.98, learning_rate=2.03e-8]\u001b[A\n",
      " 98%|█████████▊| 8272/8441 [10:37<05:22,  1.91s/it, loss=2.73, epoch=0.98, learning_rate=2.03e-8]\u001b[A\n",
      " 98%|█████████▊| 8272/8441 [10:37<05:22,  1.91s/it, loss=3.55, epoch=0.98, learning_rate=2.01e-8]\u001b[A\n",
      " 98%|█████████▊| 8273/8441 [10:39<05:20,  1.91s/it, loss=3.55, epoch=0.98, learning_rate=2.01e-8]\u001b[A\n",
      " 98%|█████████▊| 8273/8441 [10:39<05:20,  1.91s/it, loss=2.87, epoch=0.98, learning_rate=1.98e-8]\u001b[A\n",
      " 98%|█████████▊| 8274/8441 [10:41<05:18,  1.91s/it, loss=2.87, epoch=0.98, learning_rate=1.98e-8]\u001b[A\n",
      " 98%|█████████▊| 8274/8441 [10:41<05:18,  1.91s/it, loss=3.61, epoch=0.98, learning_rate=1.96e-8]\u001b[A\n",
      " 98%|█████████▊| 8275/8441 [10:43<05:16,  1.91s/it, loss=3.61, epoch=0.98, learning_rate=1.96e-8]\u001b[A\n",
      " 98%|█████████▊| 8275/8441 [10:43<05:16,  1.91s/it, loss=2.92, epoch=0.98, learning_rate=1.94e-8]\u001b[A\n",
      " 98%|█████████▊| 8276/8441 [10:45<05:15,  1.91s/it, loss=2.92, epoch=0.98, learning_rate=1.94e-8]\u001b[A\n",
      " 98%|█████████▊| 8276/8441 [10:45<05:15,  1.91s/it, loss=2.72, epoch=0.98, learning_rate=1.91e-8]\u001b[A\n",
      " 98%|█████████▊| 8277/8441 [10:46<05:13,  1.91s/it, loss=2.72, epoch=0.98, learning_rate=1.91e-8]\u001b[A\n",
      " 98%|█████████▊| 8277/8441 [10:46<05:13,  1.91s/it, loss=2.78, epoch=0.98, learning_rate=1.89e-8]\u001b[A\n",
      " 98%|█████████▊| 8278/8441 [10:48<05:10,  1.91s/it, loss=2.78, epoch=0.98, learning_rate=1.89e-8]\u001b[A\n",
      " 98%|█████████▊| 8278/8441 [10:48<05:10,  1.91s/it, loss=3.38, epoch=0.981, learning_rate=1.87e-8]\u001b[A\n",
      " 98%|█████████▊| 8279/8441 [10:50<05:09,  1.91s/it, loss=3.38, epoch=0.981, learning_rate=1.87e-8]\u001b[A\n",
      " 98%|█████████▊| 8279/8441 [10:50<05:09,  1.91s/it, loss=3.43, epoch=0.981, learning_rate=1.84e-8]\u001b[A\n",
      " 98%|█████████▊| 8280/8441 [10:52<05:07,  1.91s/it, loss=3.43, epoch=0.981, learning_rate=1.84e-8]\u001b[A\n",
      " 98%|█████████▊| 8280/8441 [10:52<05:07,  1.91s/it, loss=2.06, epoch=0.981, learning_rate=1.82e-8]\u001b[A\n",
      " 98%|█████████▊| 8281/8441 [10:54<05:05,  1.91s/it, loss=2.06, epoch=0.981, learning_rate=1.82e-8]\u001b[A\n",
      " 98%|█████████▊| 8281/8441 [10:54<05:05,  1.91s/it, loss=2.67, epoch=0.981, learning_rate=1.8e-8] \u001b[A\n",
      " 98%|█████████▊| 8282/8441 [10:56<05:03,  1.91s/it, loss=2.67, epoch=0.981, learning_rate=1.8e-8]\u001b[A\n",
      " 98%|█████████▊| 8282/8441 [10:56<05:03,  1.91s/it, loss=2.47, epoch=0.981, learning_rate=1.78e-8]\u001b[A\n",
      " 98%|█████████▊| 8283/8441 [10:58<05:01,  1.91s/it, loss=2.47, epoch=0.981, learning_rate=1.78e-8]\u001b[A\n",
      " 98%|█████████▊| 8283/8441 [10:58<05:01,  1.91s/it, loss=2.32, epoch=0.981, learning_rate=1.75e-8]\u001b[A\n",
      " 98%|█████████▊| 8284/8441 [11:00<04:59,  1.91s/it, loss=2.32, epoch=0.981, learning_rate=1.75e-8]\u001b[A\n",
      " 98%|█████████▊| 8284/8441 [11:00<04:59,  1.91s/it, loss=2.33, epoch=0.981, learning_rate=1.73e-8]\u001b[A\n",
      " 98%|█████████▊| 8285/8441 [11:02<04:57,  1.91s/it, loss=2.33, epoch=0.981, learning_rate=1.73e-8]\u001b[A\n",
      " 98%|█████████▊| 8285/8441 [11:02<04:57,  1.91s/it, loss=3.19, epoch=0.981, learning_rate=1.71e-8]\u001b[A\n",
      " 98%|█████████▊| 8286/8441 [11:04<04:55,  1.91s/it, loss=3.19, epoch=0.981, learning_rate=1.71e-8]\u001b[A\n",
      " 98%|█████████▊| 8286/8441 [11:04<04:55,  1.91s/it, loss=3.06, epoch=0.982, learning_rate=1.69e-8]\u001b[A\n",
      " 98%|█████████▊| 8287/8441 [11:06<04:53,  1.91s/it, loss=3.06, epoch=0.982, learning_rate=1.69e-8]\u001b[A\n",
      " 98%|█████████▊| 8287/8441 [11:06<04:53,  1.91s/it, loss=2.53, epoch=0.982, learning_rate=1.67e-8]\u001b[A\n",
      " 98%|█████████▊| 8288/8441 [11:07<04:51,  1.91s/it, loss=2.53, epoch=0.982, learning_rate=1.67e-8]\u001b[A\n",
      " 98%|█████████▊| 8288/8441 [11:07<04:51,  1.91s/it, loss=2.95, epoch=0.982, learning_rate=1.65e-8]\u001b[A\n",
      " 98%|█████████▊| 8289/8441 [11:09<04:49,  1.91s/it, loss=2.95, epoch=0.982, learning_rate=1.65e-8]\u001b[A\n",
      " 98%|█████████▊| 8289/8441 [11:09<04:49,  1.91s/it, loss=3.02, epoch=0.982, learning_rate=1.62e-8]\u001b[A\n",
      " 98%|█████████▊| 8290/8441 [11:11<04:47,  1.91s/it, loss=3.02, epoch=0.982, learning_rate=1.62e-8]\u001b[A\n",
      " 98%|█████████▊| 8290/8441 [11:11<04:47,  1.91s/it, loss=2.57, epoch=0.982, learning_rate=1.6e-8] \u001b[A\n",
      " 98%|█████████▊| 8291/8441 [11:13<04:46,  1.91s/it, loss=2.57, epoch=0.982, learning_rate=1.6e-8]\u001b[A\n",
      " 98%|█████████▊| 8291/8441 [11:13<04:46,  1.91s/it, loss=2.97, epoch=0.982, learning_rate=1.58e-8]\u001b[A\n",
      " 98%|█████████▊| 8292/8441 [11:15<04:44,  1.91s/it, loss=2.97, epoch=0.982, learning_rate=1.58e-8]\u001b[A\n",
      " 98%|█████████▊| 8292/8441 [11:15<04:44,  1.91s/it, loss=2.2, epoch=0.982, learning_rate=1.56e-8] \u001b[A\n",
      " 98%|█████████▊| 8293/8441 [11:17<04:42,  1.91s/it, loss=2.2, epoch=0.982, learning_rate=1.56e-8]\u001b[A\n",
      " 98%|█████████▊| 8293/8441 [11:17<04:42,  1.91s/it, loss=2.46, epoch=0.982, learning_rate=1.54e-8]\u001b[A\n",
      " 98%|█████████▊| 8294/8441 [11:19<04:40,  1.91s/it, loss=2.46, epoch=0.982, learning_rate=1.54e-8]\u001b[A\n",
      " 98%|█████████▊| 8294/8441 [11:19<04:40,  1.91s/it, loss=3.15, epoch=0.982, learning_rate=1.52e-8]\u001b[A\n",
      " 98%|█████████▊| 8295/8441 [11:21<04:38,  1.91s/it, loss=3.15, epoch=0.982, learning_rate=1.52e-8]\u001b[A\n",
      " 98%|█████████▊| 8295/8441 [11:21<04:38,  1.91s/it, loss=2.85, epoch=0.983, learning_rate=1.5e-8] \u001b[A\n",
      " 98%|█████████▊| 8296/8441 [11:23<04:36,  1.91s/it, loss=2.85, epoch=0.983, learning_rate=1.5e-8]\u001b[A\n",
      " 98%|█████████▊| 8296/8441 [11:23<04:36,  1.91s/it, loss=2.14, epoch=0.983, learning_rate=1.48e-8]\u001b[A\n",
      " 98%|█████████▊| 8297/8441 [11:25<04:34,  1.91s/it, loss=2.14, epoch=0.983, learning_rate=1.48e-8]\u001b[A\n",
      " 98%|█████████▊| 8297/8441 [11:25<04:34,  1.91s/it, loss=3.04, epoch=0.983, learning_rate=1.46e-8]\u001b[A\n",
      " 98%|█████████▊| 8298/8441 [11:27<04:32,  1.91s/it, loss=3.04, epoch=0.983, learning_rate=1.46e-8]\u001b[A\n",
      " 98%|█████████▊| 8298/8441 [11:27<04:32,  1.91s/it, loss=3, epoch=0.983, learning_rate=1.44e-8]   \u001b[A\n",
      " 98%|█████████▊| 8299/8441 [11:28<04:30,  1.91s/it, loss=3, epoch=0.983, learning_rate=1.44e-8]\u001b[A\n",
      " 98%|█████████▊| 8299/8441 [11:28<04:30,  1.91s/it, loss=3.14, epoch=0.983, learning_rate=1.42e-8]\u001b[A\n",
      " 98%|█████████▊| 8300/8441 [11:30<04:28,  1.91s/it, loss=3.14, epoch=0.983, learning_rate=1.42e-8]\u001b[A\n",
      " 98%|█████████▊| 8300/8441 [11:30<04:28,  1.91s/it, loss=2.18, epoch=0.983, learning_rate=1.4e-8] \u001b[A\n",
      " 98%|█████████▊| 8301/8441 [11:32<04:26,  1.91s/it, loss=2.18, epoch=0.983, learning_rate=1.4e-8]\u001b[A\n",
      " 98%|█████████▊| 8301/8441 [11:32<04:26,  1.91s/it, loss=2.56, epoch=0.983, learning_rate=1.38e-8]\u001b[A\n",
      " 98%|█████████▊| 8302/8441 [11:34<04:25,  1.91s/it, loss=2.56, epoch=0.983, learning_rate=1.38e-8]\u001b[A\n",
      " 98%|█████████▊| 8302/8441 [11:34<04:25,  1.91s/it, loss=2.79, epoch=0.983, learning_rate=1.36e-8]\u001b[A\n",
      " 98%|█████████▊| 8303/8441 [11:36<04:23,  1.91s/it, loss=2.79, epoch=0.983, learning_rate=1.36e-8]\u001b[A\n",
      " 98%|█████████▊| 8303/8441 [11:36<04:23,  1.91s/it, loss=2.83, epoch=0.984, learning_rate=1.34e-8]\u001b[A\n",
      " 98%|█████████▊| 8304/8441 [11:38<04:21,  1.91s/it, loss=2.83, epoch=0.984, learning_rate=1.34e-8]\u001b[A\n",
      " 98%|█████████▊| 8304/8441 [11:38<04:21,  1.91s/it, loss=2.9, epoch=0.984, learning_rate=1.32e-8] \u001b[A\n",
      " 98%|█████████▊| 8305/8441 [11:40<04:19,  1.91s/it, loss=2.9, epoch=0.984, learning_rate=1.32e-8]\u001b[A\n",
      " 98%|█████████▊| 8305/8441 [11:40<04:19,  1.91s/it, loss=3.41, epoch=0.984, learning_rate=1.3e-8]\u001b[A\n",
      " 98%|█████████▊| 8306/8441 [11:42<04:17,  1.91s/it, loss=3.41, epoch=0.984, learning_rate=1.3e-8]\u001b[A\n",
      " 98%|█████████▊| 8306/8441 [11:42<04:17,  1.91s/it, loss=2.86, epoch=0.984, learning_rate=1.28e-8]\u001b[A\n",
      " 98%|█████████▊| 8307/8441 [11:44<04:15,  1.91s/it, loss=2.86, epoch=0.984, learning_rate=1.28e-8]\u001b[A\n",
      " 98%|█████████▊| 8307/8441 [11:44<04:15,  1.91s/it, loss=2.63, epoch=0.984, learning_rate=1.26e-8]\u001b[A\n",
      " 98%|█████████▊| 8308/8441 [11:46<04:13,  1.91s/it, loss=2.63, epoch=0.984, learning_rate=1.26e-8]\u001b[A\n",
      " 98%|█████████▊| 8308/8441 [11:46<04:13,  1.91s/it, loss=2.92, epoch=0.984, learning_rate=1.25e-8]\u001b[A\n",
      " 98%|█████████▊| 8309/8441 [11:47<04:11,  1.91s/it, loss=2.92, epoch=0.984, learning_rate=1.25e-8]\u001b[A\n",
      " 98%|█████████▊| 8309/8441 [11:47<04:11,  1.91s/it, loss=2.96, epoch=0.984, learning_rate=1.23e-8]\u001b[A\n",
      " 98%|█████████▊| 8310/8441 [11:49<04:09,  1.91s/it, loss=2.96, epoch=0.984, learning_rate=1.23e-8]\u001b[A\n",
      " 98%|█████████▊| 8310/8441 [11:49<04:09,  1.91s/it, loss=2.77, epoch=0.984, learning_rate=1.21e-8]\u001b[A\n",
      " 98%|█████████▊| 8311/8441 [11:51<04:07,  1.91s/it, loss=2.77, epoch=0.984, learning_rate=1.21e-8]\u001b[A\n",
      " 98%|█████████▊| 8311/8441 [11:51<04:07,  1.91s/it, loss=3.14, epoch=0.984, learning_rate=1.19e-8]\u001b[A\n",
      " 98%|█████████▊| 8312/8441 [11:53<04:06,  1.91s/it, loss=3.14, epoch=0.984, learning_rate=1.19e-8]\u001b[A\n",
      " 98%|█████████▊| 8312/8441 [11:53<04:06,  1.91s/it, loss=2.65, epoch=0.985, learning_rate=1.17e-8]\u001b[A\n",
      " 98%|█████████▊| 8313/8441 [11:55<04:04,  1.91s/it, loss=2.65, epoch=0.985, learning_rate=1.17e-8]\u001b[A\n",
      " 98%|█████████▊| 8313/8441 [11:55<04:04,  1.91s/it, loss=2.94, epoch=0.985, learning_rate=1.16e-8]\u001b[A\n",
      " 98%|█████████▊| 8314/8441 [11:57<04:02,  1.91s/it, loss=2.94, epoch=0.985, learning_rate=1.16e-8]\u001b[A\n",
      " 98%|█████████▊| 8314/8441 [11:57<04:02,  1.91s/it, loss=2.76, epoch=0.985, learning_rate=1.14e-8]\u001b[A\n",
      " 99%|█████████▊| 8315/8441 [11:59<04:00,  1.91s/it, loss=2.76, epoch=0.985, learning_rate=1.14e-8]\u001b[A\n",
      " 99%|█████████▊| 8315/8441 [11:59<04:00,  1.91s/it, loss=2.4, epoch=0.985, learning_rate=1.12e-8] \u001b[A\n",
      " 99%|█████████▊| 8316/8441 [12:01<03:58,  1.91s/it, loss=2.4, epoch=0.985, learning_rate=1.12e-8]\u001b[A\n",
      " 99%|█████████▊| 8316/8441 [12:01<03:58,  1.91s/it, loss=2.89, epoch=0.985, learning_rate=1.1e-8]\u001b[A\n",
      " 99%|█████████▊| 8317/8441 [12:03<03:56,  1.91s/it, loss=2.89, epoch=0.985, learning_rate=1.1e-8]\u001b[A\n",
      " 99%|█████████▊| 8317/8441 [12:03<03:56,  1.91s/it, loss=3.41, epoch=0.985, learning_rate=1.08e-8]\u001b[A\n",
      " 99%|█████████▊| 8318/8441 [12:05<03:54,  1.91s/it, loss=3.41, epoch=0.985, learning_rate=1.08e-8]\u001b[A\n",
      " 99%|█████████▊| 8318/8441 [12:05<03:54,  1.91s/it, loss=2.85, epoch=0.985, learning_rate=1.07e-8]\u001b[A\n",
      " 99%|█████████▊| 8319/8441 [12:07<03:52,  1.91s/it, loss=2.85, epoch=0.985, learning_rate=1.07e-8]\u001b[A\n",
      " 99%|█████████▊| 8319/8441 [12:07<03:52,  1.91s/it, loss=2.93, epoch=0.985, learning_rate=1.05e-8]\u001b[A\n",
      " 99%|█████████▊| 8320/8441 [12:08<03:50,  1.91s/it, loss=2.93, epoch=0.985, learning_rate=1.05e-8]\u001b[A\n",
      " 99%|█████████▊| 8320/8441 [12:08<03:50,  1.91s/it, loss=2.75, epoch=0.986, learning_rate=1.03e-8]\u001b[A\n",
      " 99%|█████████▊| 8321/8441 [12:10<03:48,  1.91s/it, loss=2.75, epoch=0.986, learning_rate=1.03e-8]\u001b[A\n",
      " 99%|█████████▊| 8321/8441 [12:10<03:48,  1.91s/it, loss=2.89, epoch=0.986, learning_rate=1.02e-8]\u001b[A\n",
      " 99%|█████████▊| 8322/8441 [12:12<03:47,  1.91s/it, loss=2.89, epoch=0.986, learning_rate=1.02e-8]\u001b[A\n",
      " 99%|█████████▊| 8322/8441 [12:12<03:47,  1.91s/it, loss=2.47, epoch=0.986, learning_rate=1e-8]   \u001b[A\n",
      " 99%|█████████▊| 8323/8441 [12:14<03:45,  1.91s/it, loss=2.47, epoch=0.986, learning_rate=1e-8]\u001b[A\n",
      " 99%|█████████▊| 8323/8441 [12:14<03:45,  1.91s/it, loss=2.47, epoch=0.986, learning_rate=9.83e-9]\u001b[A\n",
      " 99%|█████████▊| 8324/8441 [12:16<03:52,  1.99s/it, loss=2.47, epoch=0.986, learning_rate=9.83e-9]\u001b[A\n",
      " 99%|█████████▊| 8324/8441 [12:16<03:52,  1.99s/it, loss=2.66, epoch=0.986, learning_rate=9.67e-9]\u001b[A\n",
      " 99%|█████████▊| 8325/8441 [12:18<03:47,  1.96s/it, loss=2.66, epoch=0.986, learning_rate=9.67e-9]\u001b[A\n",
      " 99%|█████████▊| 8325/8441 [12:18<03:47,  1.96s/it, loss=2.63, epoch=0.986, learning_rate=9.5e-9] \u001b[A\n",
      " 99%|█████████▊| 8326/8441 [12:20<03:43,  1.95s/it, loss=2.63, epoch=0.986, learning_rate=9.5e-9]\u001b[A\n",
      " 99%|█████████▊| 8326/8441 [12:20<03:43,  1.95s/it, loss=2.83, epoch=0.986, learning_rate=9.34e-9]\u001b[A\n",
      " 99%|█████████▊| 8327/8441 [12:22<03:40,  1.93s/it, loss=2.83, epoch=0.986, learning_rate=9.34e-9]\u001b[A\n",
      " 99%|█████████▊| 8327/8441 [12:22<03:40,  1.93s/it, loss=2.57, epoch=0.986, learning_rate=9.18e-9]\u001b[A\n",
      " 99%|█████████▊| 8328/8441 [12:24<03:37,  1.93s/it, loss=2.57, epoch=0.986, learning_rate=9.18e-9]\u001b[A\n",
      " 99%|█████████▊| 8328/8441 [12:24<03:37,  1.93s/it, loss=2.91, epoch=0.986, learning_rate=9.02e-9]\u001b[A\n",
      " 99%|█████████▊| 8329/8441 [12:26<03:35,  1.92s/it, loss=2.91, epoch=0.986, learning_rate=9.02e-9]\u001b[A\n",
      " 99%|█████████▊| 8329/8441 [12:26<03:35,  1.92s/it, loss=2.87, epoch=0.987, learning_rate=8.86e-9]\u001b[A\n",
      " 99%|█████████▊| 8330/8441 [12:28<03:32,  1.92s/it, loss=2.87, epoch=0.987, learning_rate=8.86e-9]\u001b[A\n",
      " 99%|█████████▊| 8330/8441 [12:28<03:32,  1.92s/it, loss=2.4, epoch=0.987, learning_rate=8.71e-9] \u001b[A\n",
      " 99%|█████████▊| 8331/8441 [12:30<03:30,  1.91s/it, loss=2.4, epoch=0.987, learning_rate=8.71e-9]\u001b[A\n",
      " 99%|█████████▊| 8331/8441 [12:30<03:30,  1.91s/it, loss=3.26, epoch=0.987, learning_rate=8.55e-9]\u001b[A\n",
      " 99%|█████████▊| 8332/8441 [12:32<03:28,  1.91s/it, loss=3.26, epoch=0.987, learning_rate=8.55e-9]\u001b[A\n",
      " 99%|█████████▊| 8332/8441 [12:32<03:28,  1.91s/it, loss=3.31, epoch=0.987, learning_rate=8.4e-9] \u001b[A\n",
      " 99%|█████████▊| 8333/8441 [12:34<03:26,  1.91s/it, loss=3.31, epoch=0.987, learning_rate=8.4e-9]\u001b[A\n",
      " 99%|█████████▊| 8333/8441 [12:34<03:26,  1.91s/it, loss=2.69, epoch=0.987, learning_rate=8.25e-9]\u001b[A\n",
      " 99%|█████████▊| 8334/8441 [12:35<03:24,  1.91s/it, loss=2.69, epoch=0.987, learning_rate=8.25e-9]\u001b[A\n",
      " 99%|█████████▊| 8334/8441 [12:35<03:24,  1.91s/it, loss=2.12, epoch=0.987, learning_rate=8.1e-9] \u001b[A\n",
      " 99%|█████████▊| 8335/8441 [12:37<03:22,  1.91s/it, loss=2.12, epoch=0.987, learning_rate=8.1e-9]\u001b[A\n",
      " 99%|█████████▊| 8335/8441 [12:37<03:22,  1.91s/it, loss=3, epoch=0.987, learning_rate=7.95e-9]  \u001b[A\n",
      " 99%|█████████▉| 8336/8441 [12:39<03:20,  1.91s/it, loss=3, epoch=0.987, learning_rate=7.95e-9]\u001b[A\n",
      " 99%|█████████▉| 8336/8441 [12:39<03:20,  1.91s/it, loss=2.16, epoch=0.987, learning_rate=7.8e-9]\u001b[A\n",
      " 99%|█████████▉| 8337/8441 [12:41<03:18,  1.91s/it, loss=2.16, epoch=0.987, learning_rate=7.8e-9]\u001b[A\n",
      " 99%|█████████▉| 8337/8441 [12:41<03:18,  1.91s/it, loss=2.98, epoch=0.988, learning_rate=7.65e-9]\u001b[A\n",
      " 99%|█████████▉| 8338/8441 [12:43<03:16,  1.91s/it, loss=2.98, epoch=0.988, learning_rate=7.65e-9]\u001b[A\n",
      " 99%|█████████▉| 8338/8441 [12:43<03:16,  1.91s/it, loss=2.5, epoch=0.988, learning_rate=7.51e-9] \u001b[A\n",
      " 99%|█████████▉| 8339/8441 [12:45<03:14,  1.91s/it, loss=2.5, epoch=0.988, learning_rate=7.51e-9]\u001b[A\n",
      " 99%|█████████▉| 8339/8441 [12:45<03:14,  1.91s/it, loss=2.84, epoch=0.988, learning_rate=7.36e-9]\u001b[A\n",
      " 99%|█████████▉| 8340/8441 [12:47<03:12,  1.90s/it, loss=2.84, epoch=0.988, learning_rate=7.36e-9]\u001b[A\n",
      " 99%|█████████▉| 8340/8441 [12:47<03:12,  1.90s/it, loss=2.61, epoch=0.988, learning_rate=7.22e-9]\u001b[A\n",
      " 99%|█████████▉| 8341/8441 [12:49<03:10,  1.90s/it, loss=2.61, epoch=0.988, learning_rate=7.22e-9]\u001b[A\n",
      " 99%|█████████▉| 8341/8441 [12:49<03:10,  1.90s/it, loss=3.21, epoch=0.988, learning_rate=7.08e-9]\u001b[A\n",
      " 99%|█████████▉| 8342/8441 [12:51<03:08,  1.91s/it, loss=3.21, epoch=0.988, learning_rate=7.08e-9]\u001b[A\n",
      " 99%|█████████▉| 8342/8441 [12:51<03:08,  1.91s/it, loss=3.12, epoch=0.988, learning_rate=6.94e-9]\u001b[A\n",
      " 99%|█████████▉| 8343/8441 [12:53<03:06,  1.91s/it, loss=3.12, epoch=0.988, learning_rate=6.94e-9]\u001b[A\n",
      " 99%|█████████▉| 8343/8441 [12:53<03:06,  1.91s/it, loss=2.83, epoch=0.988, learning_rate=6.8e-9] \u001b[A\n",
      " 99%|█████████▉| 8344/8441 [12:54<03:04,  1.91s/it, loss=2.83, epoch=0.988, learning_rate=6.8e-9]\u001b[A\n",
      " 99%|█████████▉| 8344/8441 [12:54<03:04,  1.91s/it, loss=3.15, epoch=0.988, learning_rate=6.67e-9]\u001b[A\n",
      " 99%|█████████▉| 8345/8441 [12:56<03:03,  1.91s/it, loss=3.15, epoch=0.988, learning_rate=6.67e-9]\u001b[A\n",
      " 99%|█████████▉| 8345/8441 [12:56<03:03,  1.91s/it, loss=2.08, epoch=0.989, learning_rate=6.53e-9]\u001b[A\n",
      " 99%|█████████▉| 8346/8441 [12:58<03:01,  1.91s/it, loss=2.08, epoch=0.989, learning_rate=6.53e-9]\u001b[A\n",
      " 99%|█████████▉| 8346/8441 [12:58<03:01,  1.91s/it, loss=2.39, epoch=0.989, learning_rate=6.4e-9] \u001b[A\n",
      " 99%|█████████▉| 8347/8441 [13:00<02:59,  1.91s/it, loss=2.39, epoch=0.989, learning_rate=6.4e-9]\u001b[A\n",
      " 99%|█████████▉| 8347/8441 [13:00<02:59,  1.91s/it, loss=2.62, epoch=0.989, learning_rate=6.26e-9]\u001b[A\n",
      " 99%|█████████▉| 8348/8441 [13:02<02:57,  1.91s/it, loss=2.62, epoch=0.989, learning_rate=6.26e-9]\u001b[A\n",
      " 99%|█████████▉| 8348/8441 [13:02<02:57,  1.91s/it, loss=2.01, epoch=0.989, learning_rate=6.13e-9]\u001b[A\n",
      " 99%|█████████▉| 8349/8441 [13:04<02:55,  1.91s/it, loss=2.01, epoch=0.989, learning_rate=6.13e-9]\u001b[A\n",
      " 99%|█████████▉| 8349/8441 [13:04<02:55,  1.91s/it, loss=3.15, epoch=0.989, learning_rate=6e-9]   \u001b[A\n",
      " 99%|█████████▉| 8350/8441 [13:06<02:53,  1.91s/it, loss=3.15, epoch=0.989, learning_rate=6e-9]\u001b[A\n",
      " 99%|█████████▉| 8350/8441 [13:06<02:53,  1.91s/it, loss=3.11, epoch=0.989, learning_rate=5.88e-9]\u001b[A\n",
      " 99%|█████████▉| 8351/8441 [13:08<02:51,  1.91s/it, loss=3.11, epoch=0.989, learning_rate=5.88e-9]\u001b[A\n",
      " 99%|█████████▉| 8351/8441 [13:08<02:51,  1.91s/it, loss=2.85, epoch=0.989, learning_rate=5.75e-9]\u001b[A\n",
      " 99%|█████████▉| 8352/8441 [13:10<02:49,  1.91s/it, loss=2.85, epoch=0.989, learning_rate=5.75e-9]\u001b[A\n",
      " 99%|█████████▉| 8352/8441 [13:10<02:49,  1.91s/it, loss=2.51, epoch=0.989, learning_rate=5.62e-9]\u001b[A\n",
      " 99%|█████████▉| 8353/8441 [13:12<02:47,  1.91s/it, loss=2.51, epoch=0.989, learning_rate=5.62e-9]\u001b[A\n",
      " 99%|█████████▉| 8353/8441 [13:12<02:47,  1.91s/it, loss=3.42, epoch=0.989, learning_rate=5.5e-9] \u001b[A\n",
      " 99%|█████████▉| 8354/8441 [13:14<02:45,  1.91s/it, loss=3.42, epoch=0.989, learning_rate=5.5e-9]\u001b[A\n",
      " 99%|█████████▉| 8354/8441 [13:14<02:45,  1.91s/it, loss=2.94, epoch=0.99, learning_rate=5.38e-9]\u001b[A\n",
      " 99%|█████████▉| 8355/8441 [13:15<02:43,  1.91s/it, loss=2.94, epoch=0.99, learning_rate=5.38e-9]\u001b[A\n",
      " 99%|█████████▉| 8355/8441 [13:15<02:43,  1.91s/it, loss=2.4, epoch=0.99, learning_rate=5.25e-9] \u001b[A\n",
      " 99%|█████████▉| 8356/8441 [13:17<02:41,  1.90s/it, loss=2.4, epoch=0.99, learning_rate=5.25e-9]\u001b[A\n",
      " 99%|█████████▉| 8356/8441 [13:17<02:41,  1.90s/it, loss=1.51, epoch=0.99, learning_rate=5.13e-9]\u001b[A\n",
      " 99%|█████████▉| 8357/8441 [13:19<02:40,  1.90s/it, loss=1.51, epoch=0.99, learning_rate=5.13e-9]\u001b[A\n",
      " 99%|█████████▉| 8357/8441 [13:19<02:40,  1.90s/it, loss=3.61, epoch=0.99, learning_rate=5.02e-9]\u001b[A\n",
      " 99%|█████████▉| 8358/8441 [13:21<02:38,  1.91s/it, loss=3.61, epoch=0.99, learning_rate=5.02e-9]\u001b[A\n",
      " 99%|█████████▉| 8358/8441 [13:21<02:38,  1.91s/it, loss=3.05, epoch=0.99, learning_rate=4.9e-9] \u001b[A\n",
      " 99%|█████████▉| 8359/8441 [13:23<02:36,  1.91s/it, loss=3.05, epoch=0.99, learning_rate=4.9e-9]\u001b[A\n",
      " 99%|█████████▉| 8359/8441 [13:23<02:36,  1.91s/it, loss=2.63, epoch=0.99, learning_rate=4.78e-9]\u001b[A\n",
      " 99%|█████████▉| 8360/8441 [13:25<02:34,  1.90s/it, loss=2.63, epoch=0.99, learning_rate=4.78e-9]\u001b[A\n",
      " 99%|█████████▉| 8360/8441 [13:25<02:34,  1.90s/it, loss=2.37, epoch=0.99, learning_rate=4.67e-9]\u001b[A\n",
      " 99%|█████████▉| 8361/8441 [13:27<02:32,  1.90s/it, loss=2.37, epoch=0.99, learning_rate=4.67e-9]\u001b[A\n",
      " 99%|█████████▉| 8361/8441 [13:27<02:32,  1.90s/it, loss=2.55, epoch=0.99, learning_rate=4.55e-9]\u001b[A\n",
      " 99%|█████████▉| 8362/8441 [13:29<02:30,  1.90s/it, loss=2.55, epoch=0.99, learning_rate=4.55e-9]\u001b[A\n",
      " 99%|█████████▉| 8362/8441 [13:29<02:30,  1.90s/it, loss=2.93, epoch=0.991, learning_rate=4.44e-9]\u001b[A\n",
      " 99%|█████████▉| 8363/8441 [13:31<02:28,  1.90s/it, loss=2.93, epoch=0.991, learning_rate=4.44e-9]\u001b[A\n",
      " 99%|█████████▉| 8363/8441 [13:31<02:28,  1.90s/it, loss=2.99, epoch=0.991, learning_rate=4.33e-9]\u001b[A\n",
      " 99%|█████████▉| 8364/8441 [13:33<02:26,  1.90s/it, loss=2.99, epoch=0.991, learning_rate=4.33e-9]\u001b[A\n",
      " 99%|█████████▉| 8364/8441 [13:33<02:26,  1.90s/it, loss=2.67, epoch=0.991, learning_rate=4.22e-9]\u001b[A\n",
      " 99%|█████████▉| 8365/8441 [13:34<02:24,  1.91s/it, loss=2.67, epoch=0.991, learning_rate=4.22e-9]\u001b[A\n",
      " 99%|█████████▉| 8365/8441 [13:34<02:24,  1.91s/it, loss=2.93, epoch=0.991, learning_rate=4.12e-9]\u001b[A\n",
      " 99%|█████████▉| 8366/8441 [13:36<02:22,  1.90s/it, loss=2.93, epoch=0.991, learning_rate=4.12e-9]\u001b[A\n",
      " 99%|█████████▉| 8366/8441 [13:36<02:22,  1.90s/it, loss=3.33, epoch=0.991, learning_rate=4.01e-9]\u001b[A\n",
      " 99%|█████████▉| 8367/8441 [13:38<02:20,  1.90s/it, loss=3.33, epoch=0.991, learning_rate=4.01e-9]\u001b[A\n",
      " 99%|█████████▉| 8367/8441 [13:38<02:20,  1.90s/it, loss=2.03, epoch=0.991, learning_rate=3.9e-9] \u001b[A\n",
      " 99%|█████████▉| 8368/8441 [13:40<02:18,  1.90s/it, loss=2.03, epoch=0.991, learning_rate=3.9e-9]\u001b[A\n",
      " 99%|█████████▉| 8368/8441 [13:40<02:18,  1.90s/it, loss=3.25, epoch=0.991, learning_rate=3.8e-9]\u001b[A\n",
      " 99%|█████████▉| 8369/8441 [13:42<02:17,  1.90s/it, loss=3.25, epoch=0.991, learning_rate=3.8e-9]\u001b[A\n",
      " 99%|█████████▉| 8369/8441 [13:42<02:17,  1.90s/it, loss=2.82, epoch=0.991, learning_rate=3.7e-9]\u001b[A\n",
      " 99%|█████████▉| 8370/8441 [13:44<02:15,  1.90s/it, loss=2.82, epoch=0.991, learning_rate=3.7e-9]\u001b[A\n",
      " 99%|█████████▉| 8370/8441 [13:44<02:15,  1.90s/it, loss=2.52, epoch=0.991, learning_rate=3.6e-9]\u001b[A\n",
      " 99%|█████████▉| 8371/8441 [13:46<02:13,  1.90s/it, loss=2.52, epoch=0.991, learning_rate=3.6e-9]\u001b[A\n",
      " 99%|█████████▉| 8371/8441 [13:46<02:13,  1.90s/it, loss=3.54, epoch=0.992, learning_rate=3.5e-9]\u001b[A\n",
      " 99%|█████████▉| 8372/8441 [13:48<02:11,  1.90s/it, loss=3.54, epoch=0.992, learning_rate=3.5e-9]\u001b[A\n",
      " 99%|█████████▉| 8372/8441 [13:48<02:11,  1.90s/it, loss=3.05, epoch=0.992, learning_rate=3.4e-9]\u001b[A\n",
      " 99%|█████████▉| 8373/8441 [13:50<02:09,  1.90s/it, loss=3.05, epoch=0.992, learning_rate=3.4e-9]\u001b[A\n",
      " 99%|█████████▉| 8373/8441 [13:50<02:09,  1.90s/it, loss=2.64, epoch=0.992, learning_rate=3.31e-9]\u001b[A\n",
      " 99%|█████████▉| 8374/8441 [13:52<02:07,  1.91s/it, loss=2.64, epoch=0.992, learning_rate=3.31e-9]\u001b[A\n",
      " 99%|█████████▉| 8374/8441 [13:52<02:07,  1.91s/it, loss=3.52, epoch=0.992, learning_rate=3.21e-9]\u001b[A\n",
      " 99%|█████████▉| 8375/8441 [13:54<02:05,  1.91s/it, loss=3.52, epoch=0.992, learning_rate=3.21e-9]\u001b[A\n",
      " 99%|█████████▉| 8375/8441 [13:54<02:05,  1.91s/it, loss=2.34, epoch=0.992, learning_rate=3.12e-9]\u001b[A\n",
      " 99%|█████████▉| 8376/8441 [13:55<02:03,  1.90s/it, loss=2.34, epoch=0.992, learning_rate=3.12e-9]\u001b[A\n",
      " 99%|█████████▉| 8376/8441 [13:55<02:03,  1.90s/it, loss=3.02, epoch=0.992, learning_rate=3.02e-9]\u001b[A\n",
      " 99%|█████████▉| 8377/8441 [13:57<02:01,  1.90s/it, loss=3.02, epoch=0.992, learning_rate=3.02e-9]\u001b[A\n",
      " 99%|█████████▉| 8377/8441 [13:57<02:01,  1.90s/it, loss=3.83, epoch=0.992, learning_rate=2.93e-9]\u001b[A\n",
      " 99%|█████████▉| 8378/8441 [13:59<02:00,  1.90s/it, loss=3.83, epoch=0.992, learning_rate=2.93e-9]\u001b[A\n",
      " 99%|█████████▉| 8378/8441 [13:59<02:00,  1.90s/it, loss=3.18, epoch=0.992, learning_rate=2.84e-9]\u001b[A\n",
      " 99%|█████████▉| 8379/8441 [14:01<01:58,  1.91s/it, loss=3.18, epoch=0.992, learning_rate=2.84e-9]\u001b[A\n",
      " 99%|█████████▉| 8379/8441 [14:01<01:58,  1.91s/it, loss=3.15, epoch=0.993, learning_rate=2.76e-9]\u001b[A\n",
      " 99%|█████████▉| 8380/8441 [14:03<01:56,  1.91s/it, loss=3.15, epoch=0.993, learning_rate=2.76e-9]\u001b[A\n",
      " 99%|█████████▉| 8380/8441 [14:03<01:56,  1.91s/it, loss=2.82, epoch=0.993, learning_rate=2.67e-9]\u001b[A\n",
      " 99%|█████████▉| 8381/8441 [14:05<01:54,  1.91s/it, loss=2.82, epoch=0.993, learning_rate=2.67e-9]\u001b[A\n",
      " 99%|█████████▉| 8381/8441 [14:05<01:54,  1.91s/it, loss=3.21, epoch=0.993, learning_rate=2.58e-9]\u001b[A\n",
      " 99%|█████████▉| 8382/8441 [14:07<01:52,  1.90s/it, loss=3.21, epoch=0.993, learning_rate=2.58e-9]\u001b[A\n",
      " 99%|█████████▉| 8382/8441 [14:07<01:52,  1.90s/it, loss=2.79, epoch=0.993, learning_rate=2.5e-9] \u001b[A\n",
      " 99%|█████████▉| 8383/8441 [14:09<01:50,  1.90s/it, loss=2.79, epoch=0.993, learning_rate=2.5e-9]\u001b[A\n",
      " 99%|█████████▉| 8383/8441 [14:09<01:50,  1.90s/it, loss=2.6, epoch=0.993, learning_rate=2.42e-9]\u001b[A\n",
      " 99%|█████████▉| 8384/8441 [14:11<01:48,  1.90s/it, loss=2.6, epoch=0.993, learning_rate=2.42e-9]\u001b[A\n",
      " 99%|█████████▉| 8384/8441 [14:11<01:48,  1.90s/it, loss=2.75, epoch=0.993, learning_rate=2.34e-9]\u001b[A\n",
      " 99%|█████████▉| 8385/8441 [14:13<01:46,  1.90s/it, loss=2.75, epoch=0.993, learning_rate=2.34e-9]\u001b[A\n",
      " 99%|█████████▉| 8385/8441 [14:13<01:46,  1.90s/it, loss=3.11, epoch=0.993, learning_rate=2.26e-9]\u001b[A\n",
      " 99%|█████████▉| 8386/8441 [14:14<01:44,  1.90s/it, loss=3.11, epoch=0.993, learning_rate=2.26e-9]\u001b[A\n",
      " 99%|█████████▉| 8386/8441 [14:14<01:44,  1.90s/it, loss=3.07, epoch=0.993, learning_rate=2.18e-9]\u001b[A\n",
      " 99%|█████████▉| 8387/8441 [14:16<01:42,  1.90s/it, loss=3.07, epoch=0.993, learning_rate=2.18e-9]\u001b[A\n",
      " 99%|█████████▉| 8387/8441 [14:16<01:42,  1.90s/it, loss=2.08, epoch=0.993, learning_rate=2.1e-9] \u001b[A\n",
      " 99%|█████████▉| 8388/8441 [14:18<01:40,  1.90s/it, loss=2.08, epoch=0.993, learning_rate=2.1e-9]\u001b[A\n",
      " 99%|█████████▉| 8388/8441 [14:18<01:40,  1.90s/it, loss=3.71, epoch=0.994, learning_rate=2.02e-9]\u001b[A\n",
      " 99%|█████████▉| 8389/8441 [14:20<01:39,  1.90s/it, loss=3.71, epoch=0.994, learning_rate=2.02e-9]\u001b[A\n",
      " 99%|█████████▉| 8389/8441 [14:20<01:39,  1.90s/it, loss=2.84, epoch=0.994, learning_rate=1.95e-9]\u001b[A\n",
      " 99%|█████████▉| 8390/8441 [14:22<01:37,  1.90s/it, loss=2.84, epoch=0.994, learning_rate=1.95e-9]\u001b[A\n",
      " 99%|█████████▉| 8390/8441 [14:22<01:37,  1.90s/it, loss=2.31, epoch=0.994, learning_rate=1.88e-9]\u001b[A\n",
      " 99%|█████████▉| 8391/8441 [14:24<01:35,  1.90s/it, loss=2.31, epoch=0.994, learning_rate=1.88e-9]\u001b[A\n",
      " 99%|█████████▉| 8391/8441 [14:24<01:35,  1.90s/it, loss=2.75, epoch=0.994, learning_rate=1.81e-9]\u001b[A\n",
      " 99%|█████████▉| 8392/8441 [14:26<01:33,  1.90s/it, loss=2.75, epoch=0.994, learning_rate=1.81e-9]\u001b[A\n",
      " 99%|█████████▉| 8392/8441 [14:26<01:33,  1.90s/it, loss=2.91, epoch=0.994, learning_rate=1.74e-9]\u001b[A\n",
      " 99%|█████████▉| 8393/8441 [14:28<01:31,  1.91s/it, loss=2.91, epoch=0.994, learning_rate=1.74e-9]\u001b[A\n",
      " 99%|█████████▉| 8393/8441 [14:28<01:31,  1.91s/it, loss=2.62, epoch=0.994, learning_rate=1.67e-9]\u001b[A\n",
      " 99%|█████████▉| 8394/8441 [14:30<01:29,  1.90s/it, loss=2.62, epoch=0.994, learning_rate=1.67e-9]\u001b[A\n",
      " 99%|█████████▉| 8394/8441 [14:30<01:29,  1.90s/it, loss=2.19, epoch=0.994, learning_rate=1.6e-9] \u001b[A\n",
      " 99%|█████████▉| 8395/8441 [14:32<01:27,  1.91s/it, loss=2.19, epoch=0.994, learning_rate=1.6e-9]\u001b[A\n",
      " 99%|█████████▉| 8395/8441 [14:32<01:27,  1.91s/it, loss=2.97, epoch=0.994, learning_rate=1.53e-9]\u001b[A\n",
      " 99%|█████████▉| 8396/8441 [14:34<01:25,  1.91s/it, loss=2.97, epoch=0.994, learning_rate=1.53e-9]\u001b[A\n",
      " 99%|█████████▉| 8396/8441 [14:34<01:25,  1.91s/it, loss=2.69, epoch=0.995, learning_rate=1.47e-9]\u001b[A\n",
      " 99%|█████████▉| 8397/8441 [14:35<01:23,  1.91s/it, loss=2.69, epoch=0.995, learning_rate=1.47e-9]\u001b[A\n",
      " 99%|█████████▉| 8397/8441 [14:35<01:23,  1.91s/it, loss=2.55, epoch=0.995, learning_rate=1.41e-9]\u001b[A\n",
      " 99%|█████████▉| 8398/8441 [14:37<01:21,  1.90s/it, loss=2.55, epoch=0.995, learning_rate=1.41e-9]\u001b[A\n",
      " 99%|█████████▉| 8398/8441 [14:37<01:21,  1.90s/it, loss=2.91, epoch=0.995, learning_rate=1.34e-9]\u001b[A\n",
      "100%|█████████▉| 8399/8441 [14:39<01:20,  1.91s/it, loss=2.91, epoch=0.995, learning_rate=1.34e-9]\u001b[A\n",
      "100%|█████████▉| 8399/8441 [14:39<01:20,  1.91s/it, loss=3.43, epoch=0.995, learning_rate=1.28e-9]\u001b[A\n",
      "100%|█████████▉| 8400/8441 [14:41<01:18,  1.90s/it, loss=3.43, epoch=0.995, learning_rate=1.28e-9]\u001b[A\n",
      "100%|█████████▉| 8400/8441 [14:41<01:18,  1.90s/it, loss=3.21, epoch=0.995, learning_rate=1.22e-9]\u001b[A\n",
      "100%|█████████▉| 8401/8441 [14:43<01:16,  1.90s/it, loss=3.21, epoch=0.995, learning_rate=1.22e-9]\u001b[A\n",
      "100%|█████████▉| 8401/8441 [14:43<01:16,  1.90s/it, loss=3.74, epoch=0.995, learning_rate=1.17e-9]\u001b[A\n",
      "100%|█████████▉| 8402/8441 [14:45<01:14,  1.90s/it, loss=3.74, epoch=0.995, learning_rate=1.17e-9]\u001b[A\n",
      "100%|█████████▉| 8402/8441 [14:45<01:14,  1.90s/it, loss=2.77, epoch=0.995, learning_rate=1.11e-9]\u001b[A\n",
      "100%|█████████▉| 8403/8441 [14:47<01:12,  1.90s/it, loss=2.77, epoch=0.995, learning_rate=1.11e-9]\u001b[A\n",
      "100%|█████████▉| 8403/8441 [14:47<01:12,  1.90s/it, loss=2.85, epoch=0.995, learning_rate=1.06e-9]\u001b[A\n",
      "100%|█████████▉| 8404/8441 [14:49<01:10,  1.90s/it, loss=2.85, epoch=0.995, learning_rate=1.06e-9]\u001b[A\n",
      "100%|█████████▉| 8404/8441 [14:49<01:10,  1.90s/it, loss=2.26, epoch=0.995, learning_rate=1e-9]   \u001b[A\n",
      "100%|█████████▉| 8405/8441 [14:51<01:08,  1.90s/it, loss=2.26, epoch=0.995, learning_rate=1e-9]\u001b[A\n",
      "100%|█████████▉| 8405/8441 [14:51<01:08,  1.90s/it, loss=2.82, epoch=0.996, learning_rate=9.5e-10]\u001b[A\n",
      "100%|█████████▉| 8406/8441 [14:53<01:06,  1.90s/it, loss=2.82, epoch=0.996, learning_rate=9.5e-10]\u001b[A\n",
      "100%|█████████▉| 8406/8441 [14:53<01:06,  1.90s/it, loss=2.76, epoch=0.996, learning_rate=9e-10]  \u001b[A\n",
      "100%|█████████▉| 8407/8441 [14:54<01:04,  1.90s/it, loss=2.76, epoch=0.996, learning_rate=9e-10]\u001b[A\n",
      "100%|█████████▉| 8407/8441 [14:54<01:04,  1.90s/it, loss=2.59, epoch=0.996, learning_rate=8.5e-10]\u001b[A\n",
      "100%|█████████▉| 8408/8441 [14:56<01:02,  1.90s/it, loss=2.59, epoch=0.996, learning_rate=8.5e-10]\u001b[A\n",
      "100%|█████████▉| 8408/8441 [14:56<01:02,  1.90s/it, loss=3, epoch=0.996, learning_rate=8.03e-10]  \u001b[A\n",
      "100%|█████████▉| 8409/8441 [14:58<01:00,  1.90s/it, loss=3, epoch=0.996, learning_rate=8.03e-10]\u001b[A\n",
      "100%|█████████▉| 8409/8441 [14:58<01:00,  1.90s/it, loss=2.31, epoch=0.996, learning_rate=7.56e-10]\u001b[A\n",
      "100%|█████████▉| 8410/8441 [15:00<00:59,  1.90s/it, loss=2.31, epoch=0.996, learning_rate=7.56e-10]\u001b[A\n",
      "100%|█████████▉| 8410/8441 [15:00<00:59,  1.90s/it, loss=2.6, epoch=0.996, learning_rate=7.11e-10] \u001b[A\n",
      "100%|█████████▉| 8411/8441 [15:02<00:57,  1.90s/it, loss=2.6, epoch=0.996, learning_rate=7.11e-10]\u001b[A\n",
      "100%|█████████▉| 8411/8441 [15:02<00:57,  1.90s/it, loss=2.81, epoch=0.996, learning_rate=6.67e-10]\u001b[A\n",
      "100%|█████████▉| 8412/8441 [15:04<00:55,  1.90s/it, loss=2.81, epoch=0.996, learning_rate=6.67e-10]\u001b[A\n",
      "100%|█████████▉| 8412/8441 [15:04<00:55,  1.90s/it, loss=3.03, epoch=0.996, learning_rate=6.25e-10]\u001b[A\n",
      "100%|█████████▉| 8413/8441 [15:06<00:53,  1.90s/it, loss=3.03, epoch=0.996, learning_rate=6.25e-10]\u001b[A\n",
      "100%|█████████▉| 8413/8441 [15:06<00:53,  1.90s/it, loss=2.79, epoch=0.997, learning_rate=5.84e-10]\u001b[A\n",
      "100%|█████████▉| 8414/8441 [15:08<00:51,  1.90s/it, loss=2.79, epoch=0.997, learning_rate=5.84e-10]\u001b[A\n",
      "100%|█████████▉| 8414/8441 [15:08<00:51,  1.90s/it, loss=2.1, epoch=0.997, learning_rate=5.44e-10] \u001b[A\n",
      "100%|█████████▉| 8415/8441 [15:10<00:49,  1.91s/it, loss=2.1, epoch=0.997, learning_rate=5.44e-10]\u001b[A\n",
      "100%|█████████▉| 8415/8441 [15:10<00:49,  1.91s/it, loss=2.84, epoch=0.997, learning_rate=5.06e-10]\u001b[A\n",
      "100%|█████████▉| 8416/8441 [15:12<00:47,  1.90s/it, loss=2.84, epoch=0.997, learning_rate=5.06e-10]\u001b[A\n",
      "100%|█████████▉| 8416/8441 [15:12<00:47,  1.90s/it, loss=2.98, epoch=0.997, learning_rate=4.69e-10]\u001b[A\n",
      "100%|█████████▉| 8417/8441 [15:14<00:45,  1.90s/it, loss=2.98, epoch=0.997, learning_rate=4.69e-10]\u001b[A\n",
      "100%|█████████▉| 8417/8441 [15:14<00:45,  1.90s/it, loss=2.18, epoch=0.997, learning_rate=4.34e-10]\u001b[A\n",
      "100%|█████████▉| 8418/8441 [15:15<00:43,  1.90s/it, loss=2.18, epoch=0.997, learning_rate=4.34e-10]\u001b[A\n",
      "100%|█████████▉| 8418/8441 [15:15<00:43,  1.90s/it, loss=2.98, epoch=0.997, learning_rate=4e-10]   \u001b[A\n",
      "100%|█████████▉| 8419/8441 [15:17<00:41,  1.90s/it, loss=2.98, epoch=0.997, learning_rate=4e-10]\u001b[A\n",
      "100%|█████████▉| 8419/8441 [15:17<00:41,  1.90s/it, loss=2.68, epoch=0.997, learning_rate=3.67e-10]\u001b[A\n",
      "100%|█████████▉| 8420/8441 [15:19<00:40,  1.90s/it, loss=2.68, epoch=0.997, learning_rate=3.67e-10]\u001b[A\n",
      "100%|█████████▉| 8420/8441 [15:19<00:40,  1.90s/it, loss=2.28, epoch=0.997, learning_rate=3.36e-10]\u001b[A\n",
      "100%|█████████▉| 8421/8441 [15:21<00:38,  1.90s/it, loss=2.28, epoch=0.997, learning_rate=3.36e-10]\u001b[A\n",
      "100%|█████████▉| 8421/8441 [15:21<00:38,  1.90s/it, loss=2.25, epoch=0.998, learning_rate=3.06e-10]\u001b[A\n",
      "100%|█████████▉| 8422/8441 [15:23<00:36,  1.90s/it, loss=2.25, epoch=0.998, learning_rate=3.06e-10]\u001b[A\n",
      "100%|█████████▉| 8422/8441 [15:23<00:36,  1.90s/it, loss=2.73, epoch=0.998, learning_rate=2.78e-10]\u001b[A\n",
      "100%|█████████▉| 8423/8441 [15:25<00:34,  1.90s/it, loss=2.73, epoch=0.998, learning_rate=2.78e-10]\u001b[A\n",
      "100%|█████████▉| 8423/8441 [15:25<00:34,  1.90s/it, loss=2.37, epoch=0.998, learning_rate=2.51e-10]\u001b[A\n",
      "100%|█████████▉| 8424/8441 [15:27<00:32,  1.91s/it, loss=2.37, epoch=0.998, learning_rate=2.51e-10]\u001b[A\n",
      "100%|█████████▉| 8424/8441 [15:27<00:32,  1.91s/it, loss=3.29, epoch=0.998, learning_rate=2.25e-10]\u001b[A\n",
      "100%|█████████▉| 8425/8441 [15:29<00:30,  1.91s/it, loss=3.29, epoch=0.998, learning_rate=2.25e-10]\u001b[A\n",
      "100%|█████████▉| 8425/8441 [15:29<00:30,  1.91s/it, loss=1.98, epoch=0.998, learning_rate=2.01e-10]\u001b[A\n",
      "100%|█████████▉| 8426/8441 [15:31<00:28,  1.91s/it, loss=1.98, epoch=0.998, learning_rate=2.01e-10]\u001b[A\n",
      "100%|█████████▉| 8426/8441 [15:31<00:28,  1.91s/it, loss=2.68, epoch=0.998, learning_rate=1.78e-10]\u001b[A\n",
      "100%|█████████▉| 8427/8441 [15:33<00:26,  1.91s/it, loss=2.68, epoch=0.998, learning_rate=1.78e-10]\u001b[A\n",
      "100%|█████████▉| 8427/8441 [15:33<00:26,  1.91s/it, loss=2.02, epoch=0.998, learning_rate=1.56e-10]\u001b[A\n",
      "100%|█████████▉| 8428/8441 [15:34<00:24,  1.91s/it, loss=2.02, epoch=0.998, learning_rate=1.56e-10]\u001b[A\n",
      "100%|█████████▉| 8428/8441 [15:34<00:24,  1.91s/it, loss=3.33, epoch=0.998, learning_rate=1.36e-10]\u001b[A\n",
      "100%|█████████▉| 8429/8441 [15:36<00:22,  1.91s/it, loss=3.33, epoch=0.998, learning_rate=1.36e-10]\u001b[A\n",
      "100%|█████████▉| 8429/8441 [15:36<00:22,  1.91s/it, loss=2.43, epoch=0.998, learning_rate=1.17e-10]\u001b[A\n",
      "100%|█████████▉| 8430/8441 [15:38<00:20,  1.91s/it, loss=2.43, epoch=0.998, learning_rate=1.17e-10]\u001b[A\n",
      "100%|█████████▉| 8430/8441 [15:38<00:20,  1.91s/it, loss=2.3, epoch=0.999, learning_rate=1e-10]    \u001b[A\n",
      "100%|█████████▉| 8431/8441 [15:40<00:19,  1.90s/it, loss=2.3, epoch=0.999, learning_rate=1e-10]\u001b[A\n",
      "100%|█████████▉| 8431/8441 [15:40<00:19,  1.90s/it, loss=2.51, epoch=0.999, learning_rate=8.4e-11]\u001b[A\n",
      "100%|█████████▉| 8432/8441 [15:42<00:17,  1.90s/it, loss=2.51, epoch=0.999, learning_rate=8.4e-11]\u001b[A\n",
      "100%|█████████▉| 8432/8441 [15:42<00:17,  1.90s/it, loss=2.74, epoch=0.999, learning_rate=6.94e-11]\u001b[A\n",
      "100%|█████████▉| 8433/8441 [15:44<00:15,  1.91s/it, loss=2.74, epoch=0.999, learning_rate=6.94e-11]\u001b[A\n",
      "100%|█████████▉| 8433/8441 [15:44<00:15,  1.91s/it, loss=2.7, epoch=0.999, learning_rate=5.62e-11] \u001b[A\n",
      "100%|█████████▉| 8434/8441 [15:46<00:13,  1.90s/it, loss=2.7, epoch=0.999, learning_rate=5.62e-11]\u001b[A\n",
      "100%|█████████▉| 8434/8441 [15:46<00:13,  1.90s/it, loss=3.05, epoch=0.999, learning_rate=4.44e-11]\u001b[A\n",
      "100%|█████████▉| 8435/8441 [15:48<00:11,  1.91s/it, loss=3.05, epoch=0.999, learning_rate=4.44e-11]\u001b[A\n",
      "100%|█████████▉| 8435/8441 [15:48<00:11,  1.91s/it, loss=2.84, epoch=0.999, learning_rate=3.4e-11] \u001b[A\n",
      "100%|█████████▉| 8436/8441 [15:50<00:09,  1.91s/it, loss=2.84, epoch=0.999, learning_rate=3.4e-11]\u001b[A\n",
      "100%|█████████▉| 8436/8441 [15:50<00:09,  1.91s/it, loss=3.15, epoch=0.999, learning_rate=2.5e-11]\u001b[A\n",
      "100%|█████████▉| 8437/8441 [15:52<00:07,  1.91s/it, loss=3.15, epoch=0.999, learning_rate=2.5e-11]\u001b[A\n",
      "100%|█████████▉| 8437/8441 [15:52<00:07,  1.91s/it, loss=2.53, epoch=0.999, learning_rate=1.74e-11]\u001b[A\n",
      "100%|█████████▉| 8438/8441 [15:54<00:05,  1.91s/it, loss=2.53, epoch=0.999, learning_rate=1.74e-11]\u001b[A\n",
      "100%|█████████▉| 8438/8441 [15:54<00:05,  1.91s/it, loss=2.65, epoch=1, learning_rate=1.11e-11]    \u001b[A\n",
      "100%|█████████▉| 8439/8441 [15:55<00:03,  1.91s/it, loss=2.65, epoch=1, learning_rate=1.11e-11]\u001b[A\n",
      "100%|█████████▉| 8439/8441 [15:55<00:03,  1.91s/it, loss=2.44, epoch=1, learning_rate=6.25e-12]\u001b[A\n",
      "100%|█████████▉| 8440/8441 [15:57<00:01,  1.91s/it, loss=2.44, epoch=1, learning_rate=6.25e-12]\u001b[A\n",
      "100%|█████████▉| 8440/8441 [15:57<00:01,  1.91s/it, loss=2.21, epoch=1, learning_rate=2.78e-12]\u001b[A\n",
      "100%|██████████| 8441/8441 [15:59<00:00,  1.92s/it, loss=2.21, epoch=1, learning_rate=2.78e-12]\u001b[A\n",
      "100%|██████████| 8441/8441 [15:59<00:00,  1.92s/it, loss=2.48, epoch=1, learning_rate=6.94e-13]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8441\n",
      "8441\n",
      "broke\n",
      "8441\n",
      "8441\n",
      "broke\n",
      "Training Finished\n",
      "Saving model to ./loop/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8441/8441 [16:56<00:00,  8.31it/s, loss=2.48, epoch=1, learning_rate=6.94e-13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPUS: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4220 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0, Ending Epoch: 1, Total training steps: 4220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/4220 [00:04<4:44:44,  4.05s/it]\u001b[A\n",
      "  0%|          | 1/4220 [00:04<4:44:44,  4.05s/it, loss=6.57, epoch=0, learning_rate=0]\u001b[A\n",
      "  0%|          | 2/4220 [00:07<4:34:08,  3.90s/it, loss=6.57, epoch=0, learning_rate=0]\u001b[A\n",
      "  0%|          | 2/4220 [00:07<4:34:08,  3.90s/it, loss=6.43, epoch=0.000237, learning_rate=2e-6]\u001b[A\n",
      "  0%|          | 3/4220 [00:11<4:31:03,  3.86s/it, loss=6.43, epoch=0.000237, learning_rate=2e-6]\u001b[A\n",
      "  0%|          | 3/4220 [00:11<4:31:03,  3.86s/it, loss=5.55, epoch=0.000474, learning_rate=4e-6]\u001b[A\n",
      "  0%|          | 4/4220 [00:15<4:29:23,  3.83s/it, loss=5.55, epoch=0.000474, learning_rate=4e-6]\u001b[A\n",
      "  0%|          | 4/4220 [00:15<4:29:23,  3.83s/it, loss=6.98, epoch=0.000711, learning_rate=6e-6]\u001b[A\n",
      "  0%|          | 5/4220 [00:19<4:28:21,  3.82s/it, loss=6.98, epoch=0.000711, learning_rate=6e-6]\u001b[A\n",
      "  0%|          | 5/4220 [00:19<4:28:21,  3.82s/it, loss=5.5, epoch=0.000948, learning_rate=8e-6] \u001b[A\n",
      "  0%|          | 6/4220 [00:23<4:27:39,  3.81s/it, loss=5.5, epoch=0.000948, learning_rate=8e-6]\u001b[A\n",
      "  0%|          | 6/4220 [00:23<4:27:39,  3.81s/it, loss=5.6, epoch=0.00118, learning_rate=1e-5] \u001b[A\n",
      "  0%|          | 7/4220 [00:26<4:27:06,  3.80s/it, loss=5.6, epoch=0.00118, learning_rate=1e-5]\u001b[A\n",
      "  0%|          | 7/4220 [00:26<4:27:06,  3.80s/it, loss=5.52, epoch=0.00142, learning_rate=1.2e-5]\u001b[A\n",
      "  0%|          | 8/4220 [00:30<4:26:49,  3.80s/it, loss=5.52, epoch=0.00142, learning_rate=1.2e-5]\u001b[A\n",
      "  0%|          | 8/4220 [00:30<4:26:49,  3.80s/it, loss=4.17, epoch=0.00166, learning_rate=1.4e-5]\u001b[A\n",
      "  0%|          | 9/4220 [00:34<4:26:35,  3.80s/it, loss=4.17, epoch=0.00166, learning_rate=1.4e-5]\u001b[A\n",
      "  0%|          | 9/4220 [00:34<4:26:35,  3.80s/it, loss=3.44, epoch=0.0019, learning_rate=1.6e-5] \u001b[A\n",
      "  0%|          | 10/4220 [00:38<4:26:27,  3.80s/it, loss=3.44, epoch=0.0019, learning_rate=1.6e-5]\u001b[A\n",
      "  0%|          | 10/4220 [00:38<4:26:27,  3.80s/it, loss=2.82, epoch=0.00213, learning_rate=1.8e-5]\u001b[A\n",
      "  0%|          | 11/4220 [00:42<4:26:21,  3.80s/it, loss=2.82, epoch=0.00213, learning_rate=1.8e-5]\u001b[A\n",
      "  0%|          | 11/4220 [00:42<4:26:21,  3.80s/it, loss=3.64, epoch=0.00237, learning_rate=2e-5]  \u001b[A\n",
      "  0%|          | 12/4220 [00:45<4:26:27,  3.80s/it, loss=3.64, epoch=0.00237, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 12/4220 [00:45<4:26:27,  3.80s/it, loss=3, epoch=0.00261, learning_rate=2e-5]   \u001b[A\n",
      "  0%|          | 13/4220 [00:49<4:26:16,  3.80s/it, loss=3, epoch=0.00261, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 13/4220 [00:49<4:26:16,  3.80s/it, loss=3.06, epoch=0.00284, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 14/4220 [00:53<4:26:01,  3.80s/it, loss=3.06, epoch=0.00284, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 14/4220 [00:53<4:26:01,  3.80s/it, loss=2.74, epoch=0.00308, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 15/4220 [00:57<4:25:59,  3.80s/it, loss=2.74, epoch=0.00308, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 15/4220 [00:57<4:25:59,  3.80s/it, loss=2.79, epoch=0.00332, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 16/4220 [01:00<4:25:49,  3.79s/it, loss=2.79, epoch=0.00332, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 16/4220 [01:00<4:25:49,  3.79s/it, loss=2.92, epoch=0.00355, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 17/4220 [01:04<4:25:38,  3.79s/it, loss=2.92, epoch=0.00355, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 17/4220 [01:04<4:25:38,  3.79s/it, loss=3.58, epoch=0.00379, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 18/4220 [01:08<4:25:49,  3.80s/it, loss=3.58, epoch=0.00379, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 18/4220 [01:08<4:25:49,  3.80s/it, loss=3.3, epoch=0.00403, learning_rate=2e-5] \u001b[A\n",
      "  0%|          | 19/4220 [01:12<4:25:48,  3.80s/it, loss=3.3, epoch=0.00403, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 19/4220 [01:12<4:25:48,  3.80s/it, loss=4.42, epoch=0.00427, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 20/4220 [01:16<4:25:42,  3.80s/it, loss=4.42, epoch=0.00427, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 20/4220 [01:16<4:25:42,  3.80s/it, loss=3.4, epoch=0.0045, learning_rate=2e-5]  \u001b[A\n",
      "  0%|          | 21/4220 [01:19<4:25:49,  3.80s/it, loss=3.4, epoch=0.0045, learning_rate=2e-5]\u001b[A\n",
      "  0%|          | 21/4220 [01:19<4:25:49,  3.80s/it, loss=2.83, epoch=0.00474, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 22/4220 [01:23<4:25:41,  3.80s/it, loss=2.83, epoch=0.00474, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 22/4220 [01:23<4:25:41,  3.80s/it, loss=3.58, epoch=0.00498, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 23/4220 [01:27<4:25:23,  3.79s/it, loss=3.58, epoch=0.00498, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 23/4220 [01:27<4:25:23,  3.79s/it, loss=3.26, epoch=0.00521, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 24/4220 [01:31<4:25:10,  3.79s/it, loss=3.26, epoch=0.00521, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 24/4220 [01:31<4:25:10,  3.79s/it, loss=3.41, epoch=0.00545, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 25/4220 [01:35<4:25:11,  3.79s/it, loss=3.41, epoch=0.00545, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 25/4220 [01:35<4:25:11,  3.79s/it, loss=3.08, epoch=0.00569, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 26/4220 [01:38<4:25:05,  3.79s/it, loss=3.08, epoch=0.00569, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 26/4220 [01:38<4:25:05,  3.79s/it, loss=3.04, epoch=0.00592, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 27/4220 [01:42<4:24:53,  3.79s/it, loss=3.04, epoch=0.00592, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 27/4220 [01:42<4:24:53,  3.79s/it, loss=2.81, epoch=0.00616, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 28/4220 [01:46<4:25:00,  3.79s/it, loss=2.81, epoch=0.00616, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 28/4220 [01:46<4:25:00,  3.79s/it, loss=2.97, epoch=0.0064, learning_rate=2e-5] \u001b[A\n",
      "  1%|          | 29/4220 [01:50<4:24:54,  3.79s/it, loss=2.97, epoch=0.0064, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 29/4220 [01:50<4:24:54,  3.79s/it, loss=2.93, epoch=0.00664, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 30/4220 [01:54<4:24:50,  3.79s/it, loss=2.93, epoch=0.00664, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 30/4220 [01:54<4:24:50,  3.79s/it, loss=3.12, epoch=0.00687, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 31/4220 [01:57<4:25:01,  3.80s/it, loss=3.12, epoch=0.00687, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 31/4220 [01:57<4:25:01,  3.80s/it, loss=2.82, epoch=0.00711, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 32/4220 [02:01<4:24:52,  3.79s/it, loss=2.82, epoch=0.00711, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 32/4220 [02:01<4:24:52,  3.79s/it, loss=3.37, epoch=0.00735, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 33/4220 [02:05<4:24:32,  3.79s/it, loss=3.37, epoch=0.00735, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 33/4220 [02:05<4:24:32,  3.79s/it, loss=3.13, epoch=0.00758, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 34/4220 [02:09<4:24:30,  3.79s/it, loss=3.13, epoch=0.00758, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 34/4220 [02:09<4:24:30,  3.79s/it, loss=2.9, epoch=0.00782, learning_rate=2e-5] \u001b[A\n",
      "  1%|          | 35/4220 [02:13<4:24:19,  3.79s/it, loss=2.9, epoch=0.00782, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 35/4220 [02:13<4:24:19,  3.79s/it, loss=2.77, epoch=0.00806, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 36/4220 [02:16<4:24:14,  3.79s/it, loss=2.77, epoch=0.00806, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 36/4220 [02:16<4:24:14,  3.79s/it, loss=2.91, epoch=0.00829, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 37/4220 [02:20<4:24:12,  3.79s/it, loss=2.91, epoch=0.00829, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 37/4220 [02:20<4:24:12,  3.79s/it, loss=3, epoch=0.00853, learning_rate=2e-5]   \u001b[A\n",
      "  1%|          | 38/4220 [02:24<4:24:16,  3.79s/it, loss=3, epoch=0.00853, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 38/4220 [02:24<4:24:16,  3.79s/it, loss=3.43, epoch=0.00877, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 39/4220 [02:28<4:24:12,  3.79s/it, loss=3.43, epoch=0.00877, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 39/4220 [02:28<4:24:12,  3.79s/it, loss=3.15, epoch=0.009, learning_rate=2e-5]  \u001b[A\n",
      "  1%|          | 40/4220 [02:31<4:23:56,  3.79s/it, loss=3.15, epoch=0.009, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 40/4220 [02:31<4:23:56,  3.79s/it, loss=2.73, epoch=0.00924, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 41/4220 [02:35<4:23:54,  3.79s/it, loss=2.73, epoch=0.00924, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 41/4220 [02:35<4:23:54,  3.79s/it, loss=2.95, epoch=0.00948, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 42/4220 [02:39<4:23:57,  3.79s/it, loss=2.95, epoch=0.00948, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 42/4220 [02:39<4:23:57,  3.79s/it, loss=2.02, epoch=0.00972, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 43/4220 [02:43<4:23:49,  3.79s/it, loss=2.02, epoch=0.00972, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 43/4220 [02:43<4:23:49,  3.79s/it, loss=3.1, epoch=0.00995, learning_rate=2e-5] \u001b[A\n",
      "  1%|          | 44/4220 [02:47<4:23:39,  3.79s/it, loss=3.1, epoch=0.00995, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 44/4220 [02:47<4:23:39,  3.79s/it, loss=2.66, epoch=0.0102, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 45/4220 [02:50<4:23:35,  3.79s/it, loss=2.66, epoch=0.0102, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 45/4220 [02:50<4:23:35,  3.79s/it, loss=2.85, epoch=0.0104, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 46/4220 [02:54<4:23:30,  3.79s/it, loss=2.85, epoch=0.0104, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 46/4220 [02:54<4:23:30,  3.79s/it, loss=3.11, epoch=0.0107, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 47/4220 [02:58<4:23:19,  3.79s/it, loss=3.11, epoch=0.0107, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 47/4220 [02:58<4:23:19,  3.79s/it, loss=2.69, epoch=0.0109, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 48/4220 [03:02<4:23:18,  3.79s/it, loss=2.69, epoch=0.0109, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 48/4220 [03:02<4:23:18,  3.79s/it, loss=3.08, epoch=0.0111, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 49/4220 [03:06<4:23:13,  3.79s/it, loss=3.08, epoch=0.0111, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 49/4220 [03:06<4:23:13,  3.79s/it, loss=2.86, epoch=0.0114, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 50/4220 [03:09<4:23:12,  3.79s/it, loss=2.86, epoch=0.0114, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 50/4220 [03:09<4:23:12,  3.79s/it, loss=2.87, epoch=0.0116, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 51/4220 [03:13<4:23:14,  3.79s/it, loss=2.87, epoch=0.0116, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 51/4220 [03:13<4:23:14,  3.79s/it, loss=2.82, epoch=0.0118, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 52/4220 [03:17<4:23:10,  3.79s/it, loss=2.82, epoch=0.0118, learning_rate=2e-5]\u001b[A\n",
      "  1%|          | 52/4220 [03:17<4:23:10,  3.79s/it, loss=2.9, epoch=0.0121, learning_rate=2e-5] \u001b[A\n",
      "  1%|▏         | 53/4220 [03:21<4:23:02,  3.79s/it, loss=2.9, epoch=0.0121, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 53/4220 [03:21<4:23:02,  3.79s/it, loss=2.68, epoch=0.0123, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 54/4220 [03:25<4:22:52,  3.79s/it, loss=2.68, epoch=0.0123, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 54/4220 [03:25<4:22:52,  3.79s/it, loss=2.79, epoch=0.0126, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 55/4220 [03:28<4:22:43,  3.78s/it, loss=2.79, epoch=0.0126, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 55/4220 [03:28<4:22:43,  3.78s/it, loss=3.19, epoch=0.0128, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 56/4220 [03:32<4:22:44,  3.79s/it, loss=3.19, epoch=0.0128, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 56/4220 [03:32<4:22:44,  3.79s/it, loss=3.04, epoch=0.013, learning_rate=2e-5] \u001b[A\n",
      "  1%|▏         | 57/4220 [03:36<4:22:38,  3.79s/it, loss=3.04, epoch=0.013, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 57/4220 [03:36<4:22:38,  3.79s/it, loss=2.79, epoch=0.0133, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 58/4220 [03:40<4:22:31,  3.78s/it, loss=2.79, epoch=0.0133, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 58/4220 [03:40<4:22:31,  3.78s/it, loss=2.45, epoch=0.0135, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 59/4220 [03:43<4:22:25,  3.78s/it, loss=2.45, epoch=0.0135, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 59/4220 [03:43<4:22:25,  3.78s/it, loss=2.81, epoch=0.0137, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 60/4220 [03:47<4:22:29,  3.79s/it, loss=2.81, epoch=0.0137, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 60/4220 [03:47<4:22:29,  3.79s/it, loss=2.77, epoch=0.014, learning_rate=2e-5] \u001b[A\n",
      "  1%|▏         | 61/4220 [03:51<4:22:24,  3.79s/it, loss=2.77, epoch=0.014, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 61/4220 [03:51<4:22:24,  3.79s/it, loss=2.73, epoch=0.0142, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 62/4220 [03:55<4:22:20,  3.79s/it, loss=2.73, epoch=0.0142, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 62/4220 [03:55<4:22:20,  3.79s/it, loss=2.82, epoch=0.0145, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 63/4220 [03:59<4:22:12,  3.78s/it, loss=2.82, epoch=0.0145, learning_rate=2e-5]\u001b[A\n",
      "  1%|▏         | 63/4220 [03:59<4:22:12,  3.78s/it, loss=2.61, epoch=0.0147, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 64/4220 [04:02<4:22:16,  3.79s/it, loss=2.61, epoch=0.0147, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 64/4220 [04:02<4:22:16,  3.79s/it, loss=3.08, epoch=0.0149, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 65/4220 [04:06<4:22:12,  3.79s/it, loss=3.08, epoch=0.0149, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 65/4220 [04:06<4:22:12,  3.79s/it, loss=2.54, epoch=0.0152, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 66/4220 [04:10<4:22:04,  3.79s/it, loss=2.54, epoch=0.0152, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 66/4220 [04:10<4:22:04,  3.79s/it, loss=3.03, epoch=0.0154, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 67/4220 [04:14<4:21:59,  3.79s/it, loss=3.03, epoch=0.0154, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 67/4220 [04:14<4:21:59,  3.79s/it, loss=4, epoch=0.0156, learning_rate=2e-5]   \u001b[A\n",
      "  2%|▏         | 68/4220 [04:18<4:21:50,  3.78s/it, loss=4, epoch=0.0156, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 68/4220 [04:18<4:21:50,  3.78s/it, loss=2.88, epoch=0.0159, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 69/4220 [04:21<4:21:50,  3.78s/it, loss=2.88, epoch=0.0159, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 69/4220 [04:21<4:21:50,  3.78s/it, loss=2.51, epoch=0.0161, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 70/4220 [04:25<4:21:44,  3.78s/it, loss=2.51, epoch=0.0161, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 70/4220 [04:25<4:21:44,  3.78s/it, loss=2.73, epoch=0.0164, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 71/4220 [04:29<4:21:45,  3.79s/it, loss=2.73, epoch=0.0164, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 71/4220 [04:29<4:21:45,  3.79s/it, loss=2.81, epoch=0.0166, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 72/4220 [04:33<4:21:44,  3.79s/it, loss=2.81, epoch=0.0166, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 72/4220 [04:33<4:21:44,  3.79s/it, loss=2.89, epoch=0.0168, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 73/4220 [04:36<4:21:36,  3.79s/it, loss=2.89, epoch=0.0168, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 73/4220 [04:36<4:21:36,  3.79s/it, loss=2.53, epoch=0.0171, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 74/4220 [04:40<4:21:33,  3.79s/it, loss=2.53, epoch=0.0171, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 74/4220 [04:40<4:21:33,  3.79s/it, loss=2.72, epoch=0.0173, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 75/4220 [04:44<4:21:33,  3.79s/it, loss=2.72, epoch=0.0173, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 75/4220 [04:44<4:21:33,  3.79s/it, loss=2.83, epoch=0.0175, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 76/4220 [04:48<4:21:24,  3.78s/it, loss=2.83, epoch=0.0175, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 76/4220 [04:48<4:21:24,  3.78s/it, loss=2.87, epoch=0.0178, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 77/4220 [04:52<4:21:19,  3.78s/it, loss=2.87, epoch=0.0178, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 77/4220 [04:52<4:21:19,  3.78s/it, loss=2.72, epoch=0.018, learning_rate=2e-5] \u001b[A\n",
      "  2%|▏         | 78/4220 [04:55<4:21:15,  3.78s/it, loss=2.72, epoch=0.018, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 78/4220 [04:55<4:21:15,  3.78s/it, loss=2.83, epoch=0.0182, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 79/4220 [04:59<4:21:05,  3.78s/it, loss=2.83, epoch=0.0182, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 79/4220 [04:59<4:21:05,  3.78s/it, loss=2.36, epoch=0.0185, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 80/4220 [05:03<4:21:03,  3.78s/it, loss=2.36, epoch=0.0185, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 80/4220 [05:03<4:21:03,  3.78s/it, loss=2.47, epoch=0.0187, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 81/4220 [05:07<4:21:00,  3.78s/it, loss=2.47, epoch=0.0187, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 81/4220 [05:07<4:21:00,  3.78s/it, loss=2.92, epoch=0.019, learning_rate=2e-5] \u001b[A\n",
      "  2%|▏         | 82/4220 [05:10<4:20:59,  3.78s/it, loss=2.92, epoch=0.019, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 82/4220 [05:10<4:20:59,  3.78s/it, loss=2.64, epoch=0.0192, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 83/4220 [05:14<4:20:58,  3.78s/it, loss=2.64, epoch=0.0192, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 83/4220 [05:14<4:20:58,  3.78s/it, loss=2.69, epoch=0.0194, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 84/4220 [05:18<4:20:54,  3.78s/it, loss=2.69, epoch=0.0194, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 84/4220 [05:18<4:20:54,  3.78s/it, loss=3.02, epoch=0.0197, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 85/4220 [05:22<4:20:46,  3.78s/it, loss=3.02, epoch=0.0197, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 85/4220 [05:22<4:20:46,  3.78s/it, loss=2.56, epoch=0.0199, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 86/4220 [05:26<4:20:40,  3.78s/it, loss=2.56, epoch=0.0199, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 86/4220 [05:26<4:20:40,  3.78s/it, loss=2.47, epoch=0.0201, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 87/4220 [05:29<4:20:37,  3.78s/it, loss=2.47, epoch=0.0201, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 87/4220 [05:29<4:20:37,  3.78s/it, loss=2.75, epoch=0.0204, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 88/4220 [05:33<4:20:36,  3.78s/it, loss=2.75, epoch=0.0204, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 88/4220 [05:33<4:20:36,  3.78s/it, loss=3.03, epoch=0.0206, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 89/4220 [05:37<4:20:29,  3.78s/it, loss=3.03, epoch=0.0206, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 89/4220 [05:37<4:20:29,  3.78s/it, loss=3.04, epoch=0.0209, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 90/4220 [05:41<4:20:26,  3.78s/it, loss=3.04, epoch=0.0209, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 90/4220 [05:41<4:20:26,  3.78s/it, loss=2.4, epoch=0.0211, learning_rate=2e-5] \u001b[A\n",
      "  2%|▏         | 91/4220 [05:45<4:20:19,  3.78s/it, loss=2.4, epoch=0.0211, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 91/4220 [05:45<4:20:19,  3.78s/it, loss=2.79, epoch=0.0213, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 92/4220 [05:48<4:20:25,  3.79s/it, loss=2.79, epoch=0.0213, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 92/4220 [05:48<4:20:25,  3.79s/it, loss=2.77, epoch=0.0216, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 93/4220 [05:52<4:20:21,  3.79s/it, loss=2.77, epoch=0.0216, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 93/4220 [05:52<4:20:21,  3.79s/it, loss=2.93, epoch=0.0218, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 94/4220 [05:56<4:20:09,  3.78s/it, loss=2.93, epoch=0.0218, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 94/4220 [05:56<4:20:09,  3.78s/it, loss=2.61, epoch=0.022, learning_rate=2e-5] \u001b[A\n",
      "  2%|▏         | 95/4220 [06:00<4:20:09,  3.78s/it, loss=2.61, epoch=0.022, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 95/4220 [06:00<4:20:09,  3.78s/it, loss=2.69, epoch=0.0223, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 96/4220 [06:03<4:19:56,  3.78s/it, loss=2.69, epoch=0.0223, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 96/4220 [06:03<4:19:56,  3.78s/it, loss=2.24, epoch=0.0225, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 97/4220 [06:07<4:19:54,  3.78s/it, loss=2.24, epoch=0.0225, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 97/4220 [06:07<4:19:54,  3.78s/it, loss=2.79, epoch=0.0227, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 98/4220 [06:11<4:19:42,  3.78s/it, loss=2.79, epoch=0.0227, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 98/4220 [06:11<4:19:42,  3.78s/it, loss=2.88, epoch=0.023, learning_rate=2e-5] \u001b[A\n",
      "  2%|▏         | 99/4220 [06:15<4:19:45,  3.78s/it, loss=2.88, epoch=0.023, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 99/4220 [06:15<4:19:45,  3.78s/it, loss=3.24, epoch=0.0232, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 100/4220 [06:19<4:19:50,  3.78s/it, loss=3.24, epoch=0.0232, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 100/4220 [06:19<4:19:50,  3.78s/it, loss=2.76, epoch=0.0235, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 101/4220 [06:22<4:19:46,  3.78s/it, loss=2.76, epoch=0.0235, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 101/4220 [06:22<4:19:46,  3.78s/it, loss=2.97, epoch=0.0237, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 102/4220 [06:26<4:19:44,  3.78s/it, loss=2.97, epoch=0.0237, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 102/4220 [06:26<4:19:44,  3.78s/it, loss=2.56, epoch=0.0239, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 103/4220 [06:30<4:19:39,  3.78s/it, loss=2.56, epoch=0.0239, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 103/4220 [06:30<4:19:39,  3.78s/it, loss=2.9, epoch=0.0242, learning_rate=2e-5] \u001b[A\n",
      "  2%|▏         | 104/4220 [06:34<4:19:38,  3.78s/it, loss=2.9, epoch=0.0242, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 104/4220 [06:34<4:19:38,  3.78s/it, loss=3.05, epoch=0.0244, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 105/4220 [06:38<4:19:22,  3.78s/it, loss=3.05, epoch=0.0244, learning_rate=2e-5]\u001b[A\n",
      "  2%|▏         | 105/4220 [06:38<4:19:22,  3.78s/it, loss=2.64, epoch=0.0246, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 106/4220 [06:41<4:19:16,  3.78s/it, loss=2.64, epoch=0.0246, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 106/4220 [06:41<4:19:16,  3.78s/it, loss=2.82, epoch=0.0249, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 107/4220 [06:45<4:19:19,  3.78s/it, loss=2.82, epoch=0.0249, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 107/4220 [06:45<4:19:19,  3.78s/it, loss=3, epoch=0.0251, learning_rate=2e-5]   \u001b[A\n",
      "  3%|▎         | 108/4220 [06:49<4:19:21,  3.78s/it, loss=3, epoch=0.0251, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 108/4220 [06:49<4:19:21,  3.78s/it, loss=2.85, epoch=0.0254, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 109/4220 [06:53<4:19:16,  3.78s/it, loss=2.85, epoch=0.0254, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 109/4220 [06:53<4:19:16,  3.78s/it, loss=3.01, epoch=0.0256, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 110/4220 [06:56<4:19:10,  3.78s/it, loss=3.01, epoch=0.0256, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 110/4220 [06:56<4:19:10,  3.78s/it, loss=3.05, epoch=0.0258, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 111/4220 [07:00<4:19:06,  3.78s/it, loss=3.05, epoch=0.0258, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 111/4220 [07:00<4:19:06,  3.78s/it, loss=2.93, epoch=0.0261, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 112/4220 [07:04<4:18:58,  3.78s/it, loss=2.93, epoch=0.0261, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 112/4220 [07:04<4:18:58,  3.78s/it, loss=2.3, epoch=0.0263, learning_rate=2e-5] \u001b[A\n",
      "  3%|▎         | 113/4220 [07:08<4:19:01,  3.78s/it, loss=2.3, epoch=0.0263, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 113/4220 [07:08<4:19:01,  3.78s/it, loss=2.3, epoch=0.0265, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 114/4220 [07:12<4:18:51,  3.78s/it, loss=2.3, epoch=0.0265, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 114/4220 [07:12<4:18:51,  3.78s/it, loss=2.48, epoch=0.0268, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 115/4220 [07:15<4:18:49,  3.78s/it, loss=2.48, epoch=0.0268, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 115/4220 [07:15<4:18:49,  3.78s/it, loss=3.1, epoch=0.027, learning_rate=2e-5]  \u001b[A\n",
      "  3%|▎         | 116/4220 [07:19<4:18:39,  3.78s/it, loss=3.1, epoch=0.027, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 116/4220 [07:19<4:18:39,  3.78s/it, loss=2.9, epoch=0.0273, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 117/4220 [07:23<4:18:35,  3.78s/it, loss=2.9, epoch=0.0273, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 117/4220 [07:23<4:18:35,  3.78s/it, loss=3.15, epoch=0.0275, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 118/4220 [07:27<4:18:31,  3.78s/it, loss=3.15, epoch=0.0275, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 118/4220 [07:27<4:18:31,  3.78s/it, loss=3.12, epoch=0.0277, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 119/4220 [07:30<4:18:19,  3.78s/it, loss=3.12, epoch=0.0277, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 119/4220 [07:30<4:18:19,  3.78s/it, loss=2.71, epoch=0.028, learning_rate=2e-5] \u001b[A\n",
      "  3%|▎         | 120/4220 [07:34<4:18:19,  3.78s/it, loss=2.71, epoch=0.028, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 120/4220 [07:34<4:18:19,  3.78s/it, loss=2.52, epoch=0.0282, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 121/4220 [07:38<4:18:08,  3.78s/it, loss=2.52, epoch=0.0282, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 121/4220 [07:38<4:18:08,  3.78s/it, loss=3, epoch=0.0284, learning_rate=2e-5]   \u001b[A\n",
      "  3%|▎         | 122/4220 [07:42<4:18:06,  3.78s/it, loss=3, epoch=0.0284, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 122/4220 [07:42<4:18:06,  3.78s/it, loss=2.73, epoch=0.0287, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 123/4220 [07:46<4:18:10,  3.78s/it, loss=2.73, epoch=0.0287, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 123/4220 [07:46<4:18:10,  3.78s/it, loss=2.93, epoch=0.0289, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 124/4220 [07:49<4:18:08,  3.78s/it, loss=2.93, epoch=0.0289, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 124/4220 [07:49<4:18:08,  3.78s/it, loss=2.59, epoch=0.0291, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 125/4220 [07:53<4:18:03,  3.78s/it, loss=2.59, epoch=0.0291, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 125/4220 [07:53<4:18:03,  3.78s/it, loss=2.31, epoch=0.0294, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 126/4220 [07:57<4:18:01,  3.78s/it, loss=2.31, epoch=0.0294, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 126/4220 [07:57<4:18:01,  3.78s/it, loss=3.61, epoch=0.0296, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 127/4220 [08:01<4:18:00,  3.78s/it, loss=3.61, epoch=0.0296, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 127/4220 [08:01<4:18:00,  3.78s/it, loss=3.25, epoch=0.0299, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 128/4220 [08:05<4:18:00,  3.78s/it, loss=3.25, epoch=0.0299, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 128/4220 [08:05<4:18:00,  3.78s/it, loss=2.66, epoch=0.0301, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 129/4220 [08:08<4:18:03,  3.78s/it, loss=2.66, epoch=0.0301, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 129/4220 [08:08<4:18:03,  3.78s/it, loss=3.15, epoch=0.0303, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 130/4220 [08:12<4:17:50,  3.78s/it, loss=3.15, epoch=0.0303, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 130/4220 [08:12<4:17:50,  3.78s/it, loss=2.75, epoch=0.0306, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 131/4220 [08:16<4:17:47,  3.78s/it, loss=2.75, epoch=0.0306, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 131/4220 [08:16<4:17:47,  3.78s/it, loss=2.75, epoch=0.0308, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 132/4220 [08:20<4:17:40,  3.78s/it, loss=2.75, epoch=0.0308, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 132/4220 [08:20<4:17:40,  3.78s/it, loss=3.03, epoch=0.031, learning_rate=2e-5] \u001b[A\n",
      "  3%|▎         | 133/4220 [08:23<4:17:41,  3.78s/it, loss=3.03, epoch=0.031, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 133/4220 [08:23<4:17:41,  3.78s/it, loss=2.42, epoch=0.0313, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 134/4220 [08:27<4:17:38,  3.78s/it, loss=2.42, epoch=0.0313, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 134/4220 [08:27<4:17:38,  3.78s/it, loss=3.03, epoch=0.0315, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 135/4220 [08:31<4:17:30,  3.78s/it, loss=3.03, epoch=0.0315, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 135/4220 [08:31<4:17:30,  3.78s/it, loss=2.93, epoch=0.0318, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 136/4220 [08:35<4:17:24,  3.78s/it, loss=2.93, epoch=0.0318, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 136/4220 [08:35<4:17:24,  3.78s/it, loss=2.42, epoch=0.032, learning_rate=2e-5] \u001b[A\n",
      "  3%|▎         | 137/4220 [08:39<4:17:18,  3.78s/it, loss=2.42, epoch=0.032, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 137/4220 [08:39<4:17:18,  3.78s/it, loss=2.69, epoch=0.0322, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 138/4220 [08:42<4:17:19,  3.78s/it, loss=2.69, epoch=0.0322, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 138/4220 [08:42<4:17:19,  3.78s/it, loss=2.72, epoch=0.0325, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 139/4220 [08:46<4:17:15,  3.78s/it, loss=2.72, epoch=0.0325, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 139/4220 [08:46<4:17:15,  3.78s/it, loss=2.57, epoch=0.0327, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 140/4220 [08:50<4:17:11,  3.78s/it, loss=2.57, epoch=0.0327, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 140/4220 [08:50<4:17:11,  3.78s/it, loss=2.76, epoch=0.0329, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 141/4220 [08:54<4:17:05,  3.78s/it, loss=2.76, epoch=0.0329, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 141/4220 [08:54<4:17:05,  3.78s/it, loss=2.55, epoch=0.0332, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 142/4220 [08:57<4:16:57,  3.78s/it, loss=2.55, epoch=0.0332, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 142/4220 [08:57<4:16:57,  3.78s/it, loss=2.7, epoch=0.0334, learning_rate=2e-5] \u001b[A\n",
      "  3%|▎         | 143/4220 [09:01<4:16:56,  3.78s/it, loss=2.7, epoch=0.0334, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 143/4220 [09:01<4:16:56,  3.78s/it, loss=2.55, epoch=0.0336, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 144/4220 [09:05<4:16:58,  3.78s/it, loss=2.55, epoch=0.0336, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 144/4220 [09:05<4:16:58,  3.78s/it, loss=2.68, epoch=0.0339, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 145/4220 [09:09<4:16:53,  3.78s/it, loss=2.68, epoch=0.0339, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 145/4220 [09:09<4:16:53,  3.78s/it, loss=3.14, epoch=0.0341, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 146/4220 [09:13<4:16:41,  3.78s/it, loss=3.14, epoch=0.0341, learning_rate=2e-5]\u001b[A\n",
      "  3%|▎         | 146/4220 [09:13<4:16:41,  3.78s/it, loss=2.5, epoch=0.0344, learning_rate=1.99e-5]\u001b[A\n",
      "  3%|▎         | 147/4220 [09:16<4:16:31,  3.78s/it, loss=2.5, epoch=0.0344, learning_rate=1.99e-5]\u001b[A\n",
      "  3%|▎         | 147/4220 [09:16<4:16:31,  3.78s/it, loss=2.68, epoch=0.0346, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 148/4220 [09:20<4:16:35,  3.78s/it, loss=2.68, epoch=0.0346, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 148/4220 [09:20<4:16:35,  3.78s/it, loss=2.83, epoch=0.0348, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 149/4220 [09:24<4:16:26,  3.78s/it, loss=2.83, epoch=0.0348, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 149/4220 [09:24<4:16:26,  3.78s/it, loss=2.86, epoch=0.0351, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 150/4220 [09:28<4:16:30,  3.78s/it, loss=2.86, epoch=0.0351, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 150/4220 [09:28<4:16:30,  3.78s/it, loss=2.9, epoch=0.0353, learning_rate=1.99e-5] \u001b[A\n",
      "  4%|▎         | 151/4220 [09:31<4:16:31,  3.78s/it, loss=2.9, epoch=0.0353, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 151/4220 [09:31<4:16:31,  3.78s/it, loss=2.33, epoch=0.0355, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 152/4220 [09:35<4:16:35,  3.78s/it, loss=2.33, epoch=0.0355, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 152/4220 [09:35<4:16:35,  3.78s/it, loss=2.83, epoch=0.0358, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 153/4220 [09:39<4:16:37,  3.79s/it, loss=2.83, epoch=0.0358, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 153/4220 [09:39<4:16:37,  3.79s/it, loss=2.58, epoch=0.036, learning_rate=1.99e-5] \u001b[A\n",
      "  4%|▎         | 154/4220 [09:43<4:16:32,  3.79s/it, loss=2.58, epoch=0.036, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 154/4220 [09:43<4:16:32,  3.79s/it, loss=2.28, epoch=0.0363, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 155/4220 [09:47<4:16:28,  3.79s/it, loss=2.28, epoch=0.0363, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 155/4220 [09:47<4:16:28,  3.79s/it, loss=2.73, epoch=0.0365, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 156/4220 [09:50<4:16:16,  3.78s/it, loss=2.73, epoch=0.0365, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 156/4220 [09:50<4:16:16,  3.78s/it, loss=2.51, epoch=0.0367, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 157/4220 [09:54<4:16:15,  3.78s/it, loss=2.51, epoch=0.0367, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 157/4220 [09:54<4:16:15,  3.78s/it, loss=2.29, epoch=0.037, learning_rate=1.99e-5] \u001b[A\n",
      "  4%|▎         | 158/4220 [09:58<4:16:07,  3.78s/it, loss=2.29, epoch=0.037, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▎         | 158/4220 [09:58<4:16:07,  3.78s/it, loss=3.03, epoch=0.0372, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 159/4220 [10:02<4:15:52,  3.78s/it, loss=3.03, epoch=0.0372, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 159/4220 [10:02<4:15:52,  3.78s/it, loss=3.11, epoch=0.0374, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 160/4220 [10:06<4:15:50,  3.78s/it, loss=3.11, epoch=0.0374, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 160/4220 [10:06<4:15:50,  3.78s/it, loss=3.12, epoch=0.0377, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 161/4220 [10:09<4:15:49,  3.78s/it, loss=3.12, epoch=0.0377, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 161/4220 [10:09<4:15:49,  3.78s/it, loss=2.74, epoch=0.0379, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 162/4220 [10:13<4:15:46,  3.78s/it, loss=2.74, epoch=0.0379, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 162/4220 [10:13<4:15:46,  3.78s/it, loss=3.42, epoch=0.0382, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 163/4220 [10:17<4:15:44,  3.78s/it, loss=3.42, epoch=0.0382, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 163/4220 [10:17<4:15:44,  3.78s/it, loss=2.65, epoch=0.0384, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 164/4220 [10:21<4:15:45,  3.78s/it, loss=2.65, epoch=0.0384, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 164/4220 [10:21<4:15:45,  3.78s/it, loss=2.66, epoch=0.0386, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 165/4220 [10:24<4:15:32,  3.78s/it, loss=2.66, epoch=0.0386, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 165/4220 [10:24<4:15:32,  3.78s/it, loss=3.39, epoch=0.0389, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 166/4220 [10:28<4:15:23,  3.78s/it, loss=3.39, epoch=0.0389, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 166/4220 [10:28<4:15:23,  3.78s/it, loss=2.75, epoch=0.0391, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 167/4220 [10:32<4:15:21,  3.78s/it, loss=2.75, epoch=0.0391, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 167/4220 [10:32<4:15:21,  3.78s/it, loss=2.29, epoch=0.0393, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 168/4220 [10:36<4:15:24,  3.78s/it, loss=2.29, epoch=0.0393, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 168/4220 [10:36<4:15:24,  3.78s/it, loss=2.92, epoch=0.0396, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 169/4220 [10:40<4:15:25,  3.78s/it, loss=2.92, epoch=0.0396, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 169/4220 [10:40<4:15:25,  3.78s/it, loss=3.09, epoch=0.0398, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 170/4220 [10:43<4:15:17,  3.78s/it, loss=3.09, epoch=0.0398, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 170/4220 [10:43<4:15:17,  3.78s/it, loss=2.48, epoch=0.04, learning_rate=1.99e-5]  \u001b[A\n",
      "  4%|▍         | 171/4220 [10:47<4:15:19,  3.78s/it, loss=2.48, epoch=0.04, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 171/4220 [10:47<4:15:19,  3.78s/it, loss=2.5, epoch=0.0403, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 172/4220 [10:51<4:15:18,  3.78s/it, loss=2.5, epoch=0.0403, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 172/4220 [10:51<4:15:18,  3.78s/it, loss=2.89, epoch=0.0405, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 173/4220 [10:55<4:15:02,  3.78s/it, loss=2.89, epoch=0.0405, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 173/4220 [10:55<4:15:02,  3.78s/it, loss=2.81, epoch=0.0408, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 174/4220 [10:58<4:15:03,  3.78s/it, loss=2.81, epoch=0.0408, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 174/4220 [10:58<4:15:03,  3.78s/it, loss=2.81, epoch=0.041, learning_rate=1.99e-5] \u001b[A\n",
      "  4%|▍         | 175/4220 [11:02<4:14:58,  3.78s/it, loss=2.81, epoch=0.041, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 175/4220 [11:02<4:14:58,  3.78s/it, loss=2.97, epoch=0.0412, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 176/4220 [11:06<4:14:58,  3.78s/it, loss=2.97, epoch=0.0412, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 176/4220 [11:06<4:14:58,  3.78s/it, loss=2.31, epoch=0.0415, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 177/4220 [11:10<4:14:57,  3.78s/it, loss=2.31, epoch=0.0415, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 177/4220 [11:10<4:14:57,  3.78s/it, loss=2.68, epoch=0.0417, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 178/4220 [11:14<4:14:58,  3.78s/it, loss=2.68, epoch=0.0417, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 178/4220 [11:14<4:14:58,  3.78s/it, loss=2.51, epoch=0.0419, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 179/4220 [11:17<4:14:51,  3.78s/it, loss=2.51, epoch=0.0419, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 179/4220 [11:17<4:14:51,  3.78s/it, loss=2.69, epoch=0.0422, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 180/4220 [11:21<4:14:38,  3.78s/it, loss=2.69, epoch=0.0422, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 180/4220 [11:21<4:14:38,  3.78s/it, loss=2.45, epoch=0.0424, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 181/4220 [11:25<4:14:32,  3.78s/it, loss=2.45, epoch=0.0424, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 181/4220 [11:25<4:14:32,  3.78s/it, loss=2.92, epoch=0.0427, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 182/4220 [11:29<4:14:32,  3.78s/it, loss=2.92, epoch=0.0427, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 182/4220 [11:29<4:14:32,  3.78s/it, loss=2.5, epoch=0.0429, learning_rate=1.99e-5] \u001b[A\n",
      "  4%|▍         | 183/4220 [11:33<4:14:30,  3.78s/it, loss=2.5, epoch=0.0429, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 183/4220 [11:33<4:14:30,  3.78s/it, loss=3.02, epoch=0.0431, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 184/4220 [11:36<4:14:19,  3.78s/it, loss=3.02, epoch=0.0431, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 184/4220 [11:36<4:14:19,  3.78s/it, loss=2.84, epoch=0.0434, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 185/4220 [11:40<4:14:16,  3.78s/it, loss=2.84, epoch=0.0434, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 185/4220 [11:40<4:14:16,  3.78s/it, loss=3.09, epoch=0.0436, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 186/4220 [11:44<4:14:15,  3.78s/it, loss=3.09, epoch=0.0436, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 186/4220 [11:44<4:14:15,  3.78s/it, loss=2.52, epoch=0.0438, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 187/4220 [11:48<4:14:13,  3.78s/it, loss=2.52, epoch=0.0438, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 187/4220 [11:48<4:14:13,  3.78s/it, loss=2.64, epoch=0.0441, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 188/4220 [11:51<4:14:08,  3.78s/it, loss=2.64, epoch=0.0441, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 188/4220 [11:51<4:14:08,  3.78s/it, loss=3.13, epoch=0.0443, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 189/4220 [11:55<4:14:04,  3.78s/it, loss=3.13, epoch=0.0443, learning_rate=1.99e-5]\u001b[A\n",
      "  4%|▍         | 189/4220 [11:55<4:14:04,  3.78s/it, loss=2.47, epoch=0.0445, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 190/4220 [11:59<4:14:02,  3.78s/it, loss=2.47, epoch=0.0445, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 190/4220 [11:59<4:14:02,  3.78s/it, loss=3.33, epoch=0.0448, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 191/4220 [12:03<4:13:54,  3.78s/it, loss=3.33, epoch=0.0448, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 191/4220 [12:03<4:13:54,  3.78s/it, loss=2.8, epoch=0.045, learning_rate=1.99e-5]  \u001b[A\n",
      "  5%|▍         | 192/4220 [12:07<4:13:52,  3.78s/it, loss=2.8, epoch=0.045, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 192/4220 [12:07<4:13:52,  3.78s/it, loss=2.92, epoch=0.0453, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 193/4220 [12:10<4:13:51,  3.78s/it, loss=2.92, epoch=0.0453, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 193/4220 [12:10<4:13:51,  3.78s/it, loss=2.99, epoch=0.0455, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 194/4220 [12:14<4:15:59,  3.82s/it, loss=2.99, epoch=0.0455, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 194/4220 [12:14<4:15:59,  3.82s/it, loss=2.73, epoch=0.0457, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 195/4220 [12:18<4:15:13,  3.80s/it, loss=2.73, epoch=0.0457, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 195/4220 [12:18<4:15:13,  3.80s/it, loss=3.12, epoch=0.046, learning_rate=1.99e-5] \u001b[A\n",
      "  5%|▍         | 196/4220 [12:22<4:14:38,  3.80s/it, loss=3.12, epoch=0.046, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 196/4220 [12:22<4:14:38,  3.80s/it, loss=2.63, epoch=0.0462, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 197/4220 [12:26<4:14:23,  3.79s/it, loss=2.63, epoch=0.0462, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 197/4220 [12:26<4:14:23,  3.79s/it, loss=2.78, epoch=0.0464, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 198/4220 [12:29<4:14:06,  3.79s/it, loss=2.78, epoch=0.0464, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 198/4220 [12:29<4:14:06,  3.79s/it, loss=2.91, epoch=0.0467, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 199/4220 [12:33<4:13:55,  3.79s/it, loss=2.91, epoch=0.0467, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 199/4220 [12:33<4:13:55,  3.79s/it, loss=2.56, epoch=0.0469, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 200/4220 [12:37<4:13:50,  3.79s/it, loss=2.56, epoch=0.0469, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 200/4220 [12:37<4:13:50,  3.79s/it, loss=3.46, epoch=0.0472, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 201/4220 [12:41<4:13:34,  3.79s/it, loss=3.46, epoch=0.0472, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 201/4220 [12:41<4:13:34,  3.79s/it, loss=3.04, epoch=0.0474, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 202/4220 [12:45<4:13:27,  3.78s/it, loss=3.04, epoch=0.0474, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 202/4220 [12:45<4:13:27,  3.78s/it, loss=2.32, epoch=0.0476, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 203/4220 [12:48<4:13:21,  3.78s/it, loss=2.32, epoch=0.0476, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 203/4220 [12:48<4:13:21,  3.78s/it, loss=3.02, epoch=0.0479, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 204/4220 [12:52<4:13:10,  3.78s/it, loss=3.02, epoch=0.0479, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 204/4220 [12:52<4:13:10,  3.78s/it, loss=2.62, epoch=0.0481, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 205/4220 [12:56<4:13:05,  3.78s/it, loss=2.62, epoch=0.0481, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 205/4220 [12:56<4:13:05,  3.78s/it, loss=2.86, epoch=0.0483, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 206/4220 [13:00<4:13:04,  3.78s/it, loss=2.86, epoch=0.0483, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 206/4220 [13:00<4:13:04,  3.78s/it, loss=3.18, epoch=0.0486, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 207/4220 [13:03<4:13:08,  3.78s/it, loss=3.18, epoch=0.0486, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 207/4220 [13:03<4:13:08,  3.78s/it, loss=2.39, epoch=0.0488, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 208/4220 [13:07<4:13:04,  3.78s/it, loss=2.39, epoch=0.0488, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 208/4220 [13:07<4:13:04,  3.78s/it, loss=2.74, epoch=0.0491, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 209/4220 [13:11<4:13:06,  3.79s/it, loss=2.74, epoch=0.0491, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 209/4220 [13:11<4:13:06,  3.79s/it, loss=3.06, epoch=0.0493, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 210/4220 [13:15<4:13:03,  3.79s/it, loss=3.06, epoch=0.0493, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▍         | 210/4220 [13:15<4:13:03,  3.79s/it, loss=2.87, epoch=0.0495, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 211/4220 [13:19<4:12:52,  3.78s/it, loss=2.87, epoch=0.0495, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 211/4220 [13:19<4:12:52,  3.78s/it, loss=2.49, epoch=0.0498, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 212/4220 [13:22<4:12:52,  3.79s/it, loss=2.49, epoch=0.0498, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 212/4220 [13:22<4:12:52,  3.79s/it, loss=2.78, epoch=0.05, learning_rate=1.99e-5]  \u001b[A\n",
      "  5%|▌         | 213/4220 [13:26<4:12:40,  3.78s/it, loss=2.78, epoch=0.05, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 213/4220 [13:26<4:12:40,  3.78s/it, loss=2.37, epoch=0.0502, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 214/4220 [13:30<4:12:30,  3.78s/it, loss=2.37, epoch=0.0502, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 214/4220 [13:30<4:12:30,  3.78s/it, loss=2.53, epoch=0.0505, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 215/4220 [13:34<4:12:25,  3.78s/it, loss=2.53, epoch=0.0505, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 215/4220 [13:34<4:12:25,  3.78s/it, loss=3.27, epoch=0.0507, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 216/4220 [13:37<4:12:20,  3.78s/it, loss=3.27, epoch=0.0507, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 216/4220 [13:37<4:12:20,  3.78s/it, loss=2.81, epoch=0.0509, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 217/4220 [13:41<4:12:06,  3.78s/it, loss=2.81, epoch=0.0509, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 217/4220 [13:41<4:12:06,  3.78s/it, loss=2.67, epoch=0.0512, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 218/4220 [13:45<4:12:04,  3.78s/it, loss=2.67, epoch=0.0512, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 218/4220 [13:45<4:12:04,  3.78s/it, loss=3.05, epoch=0.0514, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 219/4220 [13:49<4:12:03,  3.78s/it, loss=3.05, epoch=0.0514, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 219/4220 [13:49<4:12:03,  3.78s/it, loss=2.41, epoch=0.0517, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 220/4220 [13:53<4:12:01,  3.78s/it, loss=2.41, epoch=0.0517, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 220/4220 [13:53<4:12:01,  3.78s/it, loss=3.14, epoch=0.0519, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 221/4220 [13:56<4:11:57,  3.78s/it, loss=3.14, epoch=0.0519, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 221/4220 [13:56<4:11:57,  3.78s/it, loss=2.7, epoch=0.0521, learning_rate=1.99e-5] \u001b[A\n",
      "  5%|▌         | 222/4220 [14:00<4:11:51,  3.78s/it, loss=2.7, epoch=0.0521, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 222/4220 [14:00<4:11:51,  3.78s/it, loss=2.67, epoch=0.0524, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 223/4220 [14:04<4:11:53,  3.78s/it, loss=2.67, epoch=0.0524, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 223/4220 [14:04<4:11:53,  3.78s/it, loss=3.15, epoch=0.0526, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 224/4220 [14:08<4:11:50,  3.78s/it, loss=3.15, epoch=0.0526, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 224/4220 [14:08<4:11:50,  3.78s/it, loss=2.61, epoch=0.0528, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 225/4220 [14:11<4:11:36,  3.78s/it, loss=2.61, epoch=0.0528, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 225/4220 [14:11<4:11:36,  3.78s/it, loss=2.64, epoch=0.0531, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 226/4220 [14:15<4:11:40,  3.78s/it, loss=2.64, epoch=0.0531, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 226/4220 [14:15<4:11:40,  3.78s/it, loss=2.69, epoch=0.0533, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 227/4220 [14:19<4:11:31,  3.78s/it, loss=2.69, epoch=0.0533, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 227/4220 [14:19<4:11:31,  3.78s/it, loss=3.03, epoch=0.0536, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 228/4220 [14:23<4:11:28,  3.78s/it, loss=3.03, epoch=0.0536, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 228/4220 [14:23<4:11:28,  3.78s/it, loss=2.91, epoch=0.0538, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 229/4220 [14:27<4:11:32,  3.78s/it, loss=2.91, epoch=0.0538, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 229/4220 [14:27<4:11:32,  3.78s/it, loss=3.56, epoch=0.054, learning_rate=1.99e-5] \u001b[A\n",
      "  5%|▌         | 230/4220 [14:30<4:11:28,  3.78s/it, loss=3.56, epoch=0.054, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 230/4220 [14:30<4:11:28,  3.78s/it, loss=2.65, epoch=0.0543, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 231/4220 [14:34<4:11:28,  3.78s/it, loss=2.65, epoch=0.0543, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 231/4220 [14:34<4:11:28,  3.78s/it, loss=2.66, epoch=0.0545, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 232/4220 [14:38<4:11:23,  3.78s/it, loss=2.66, epoch=0.0545, learning_rate=1.99e-5]\u001b[A\n",
      "  5%|▌         | 232/4220 [14:38<4:11:23,  3.78s/it, loss=2.74, epoch=0.0547, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 233/4220 [14:42<4:11:19,  3.78s/it, loss=2.74, epoch=0.0547, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 233/4220 [14:42<4:11:19,  3.78s/it, loss=2.74, epoch=0.055, learning_rate=1.99e-5] \u001b[A\n",
      "  6%|▌         | 234/4220 [14:46<4:11:16,  3.78s/it, loss=2.74, epoch=0.055, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 234/4220 [14:46<4:11:16,  3.78s/it, loss=2.59, epoch=0.0552, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 235/4220 [14:49<4:11:19,  3.78s/it, loss=2.59, epoch=0.0552, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 235/4220 [14:49<4:11:19,  3.78s/it, loss=2.74, epoch=0.0555, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 236/4220 [14:53<4:11:18,  3.78s/it, loss=2.74, epoch=0.0555, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 236/4220 [14:53<4:11:18,  3.78s/it, loss=2.5, epoch=0.0557, learning_rate=1.99e-5] \u001b[A\n",
      "  6%|▌         | 237/4220 [14:57<4:11:07,  3.78s/it, loss=2.5, epoch=0.0557, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 237/4220 [14:57<4:11:07,  3.78s/it, loss=2.98, epoch=0.0559, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 238/4220 [15:01<4:10:55,  3.78s/it, loss=2.98, epoch=0.0559, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 238/4220 [15:01<4:10:55,  3.78s/it, loss=2.79, epoch=0.0562, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 239/4220 [15:04<4:10:49,  3.78s/it, loss=2.79, epoch=0.0562, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 239/4220 [15:04<4:10:49,  3.78s/it, loss=2.88, epoch=0.0564, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 240/4220 [15:08<4:10:45,  3.78s/it, loss=2.88, epoch=0.0564, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 240/4220 [15:08<4:10:45,  3.78s/it, loss=2.83, epoch=0.0566, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 241/4220 [15:12<4:10:39,  3.78s/it, loss=2.83, epoch=0.0566, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 241/4220 [15:12<4:10:39,  3.78s/it, loss=2.78, epoch=0.0569, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 242/4220 [15:16<4:10:36,  3.78s/it, loss=2.78, epoch=0.0569, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 242/4220 [15:16<4:10:36,  3.78s/it, loss=3.06, epoch=0.0571, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 243/4220 [15:20<4:10:40,  3.78s/it, loss=3.06, epoch=0.0571, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 243/4220 [15:20<4:10:40,  3.78s/it, loss=2.57, epoch=0.0573, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 244/4220 [15:23<4:10:34,  3.78s/it, loss=2.57, epoch=0.0573, learning_rate=1.99e-5]\u001b[A\n",
      "  6%|▌         | 244/4220 [15:23<4:10:34,  3.78s/it, loss=2.51, epoch=0.0576, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 245/4220 [15:27<4:10:24,  3.78s/it, loss=2.51, epoch=0.0576, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 245/4220 [15:27<4:10:24,  3.78s/it, loss=2.81, epoch=0.0578, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 246/4220 [15:31<4:10:26,  3.78s/it, loss=2.81, epoch=0.0578, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 246/4220 [15:31<4:10:26,  3.78s/it, loss=2.79, epoch=0.0581, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 247/4220 [15:35<4:10:23,  3.78s/it, loss=2.79, epoch=0.0581, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 247/4220 [15:35<4:10:23,  3.78s/it, loss=3, epoch=0.0583, learning_rate=1.98e-5]   \u001b[A\n",
      "  6%|▌         | 248/4220 [15:38<4:10:23,  3.78s/it, loss=3, epoch=0.0583, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 248/4220 [15:38<4:10:23,  3.78s/it, loss=2.71, epoch=0.0585, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 249/4220 [15:42<4:10:16,  3.78s/it, loss=2.71, epoch=0.0585, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 249/4220 [15:42<4:10:16,  3.78s/it, loss=2.75, epoch=0.0588, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 250/4220 [15:46<4:10:06,  3.78s/it, loss=2.75, epoch=0.0588, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 250/4220 [15:46<4:10:06,  3.78s/it, loss=2.79, epoch=0.059, learning_rate=1.98e-5] \u001b[A\n",
      "  6%|▌         | 251/4220 [15:50<4:10:05,  3.78s/it, loss=2.79, epoch=0.059, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 251/4220 [15:50<4:10:05,  3.78s/it, loss=3.21, epoch=0.0592, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 252/4220 [15:54<4:10:07,  3.78s/it, loss=3.21, epoch=0.0592, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 252/4220 [15:54<4:10:07,  3.78s/it, loss=2.21, epoch=0.0595, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 253/4220 [15:57<4:10:06,  3.78s/it, loss=2.21, epoch=0.0595, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 253/4220 [15:57<4:10:06,  3.78s/it, loss=2.71, epoch=0.0597, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 254/4220 [16:01<4:09:53,  3.78s/it, loss=2.71, epoch=0.0597, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 254/4220 [16:01<4:09:53,  3.78s/it, loss=2.79, epoch=0.06, learning_rate=1.98e-5]  \u001b[A\n",
      "  6%|▌         | 255/4220 [16:05<4:09:53,  3.78s/it, loss=2.79, epoch=0.06, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 255/4220 [16:05<4:09:53,  3.78s/it, loss=2.68, epoch=0.0602, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 256/4220 [16:09<4:09:45,  3.78s/it, loss=2.68, epoch=0.0602, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 256/4220 [16:09<4:09:45,  3.78s/it, loss=3.5, epoch=0.0604, learning_rate=1.98e-5] \u001b[A\n",
      "  6%|▌         | 257/4220 [16:12<4:09:45,  3.78s/it, loss=3.5, epoch=0.0604, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 257/4220 [16:12<4:09:45,  3.78s/it, loss=2.67, epoch=0.0607, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 258/4220 [16:16<4:09:41,  3.78s/it, loss=2.67, epoch=0.0607, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 258/4220 [16:16<4:09:41,  3.78s/it, loss=2.84, epoch=0.0609, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 259/4220 [16:20<4:09:37,  3.78s/it, loss=2.84, epoch=0.0609, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 259/4220 [16:20<4:09:37,  3.78s/it, loss=2.94, epoch=0.0611, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 260/4220 [16:24<4:09:30,  3.78s/it, loss=2.94, epoch=0.0611, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 260/4220 [16:24<4:09:30,  3.78s/it, loss=2.84, epoch=0.0614, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 261/4220 [16:28<4:09:27,  3.78s/it, loss=2.84, epoch=0.0614, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 261/4220 [16:28<4:09:27,  3.78s/it, loss=2.34, epoch=0.0616, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 262/4220 [16:31<4:09:15,  3.78s/it, loss=2.34, epoch=0.0616, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 262/4220 [16:31<4:09:15,  3.78s/it, loss=2.68, epoch=0.0618, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 263/4220 [16:35<4:09:11,  3.78s/it, loss=2.68, epoch=0.0618, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▌         | 263/4220 [16:35<4:09:11,  3.78s/it, loss=2.63, epoch=0.0621, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 264/4220 [16:39<4:09:04,  3.78s/it, loss=2.63, epoch=0.0621, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 264/4220 [16:39<4:09:04,  3.78s/it, loss=2.6, epoch=0.0623, learning_rate=1.98e-5] \u001b[A\n",
      "  6%|▋         | 265/4220 [16:43<4:09:04,  3.78s/it, loss=2.6, epoch=0.0623, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 265/4220 [16:43<4:09:04,  3.78s/it, loss=2.91, epoch=0.0626, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 266/4220 [16:47<4:09:10,  3.78s/it, loss=2.91, epoch=0.0626, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 266/4220 [16:47<4:09:10,  3.78s/it, loss=2.97, epoch=0.0628, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 267/4220 [16:50<4:09:04,  3.78s/it, loss=2.97, epoch=0.0628, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 267/4220 [16:50<4:09:04,  3.78s/it, loss=2.43, epoch=0.063, learning_rate=1.98e-5] \u001b[A\n",
      "  6%|▋         | 268/4220 [16:54<4:09:09,  3.78s/it, loss=2.43, epoch=0.063, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 268/4220 [16:54<4:09:09,  3.78s/it, loss=2.4, epoch=0.0633, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 269/4220 [16:58<4:09:07,  3.78s/it, loss=2.4, epoch=0.0633, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 269/4220 [16:58<4:09:07,  3.78s/it, loss=2.6, epoch=0.0635, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 270/4220 [17:02<4:09:04,  3.78s/it, loss=2.6, epoch=0.0635, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 270/4220 [17:02<4:09:04,  3.78s/it, loss=2.99, epoch=0.0637, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 271/4220 [17:05<4:08:45,  3.78s/it, loss=2.99, epoch=0.0637, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 271/4220 [17:05<4:08:45,  3.78s/it, loss=2.3, epoch=0.064, learning_rate=1.98e-5]  \u001b[A\n",
      "  6%|▋         | 272/4220 [17:09<4:08:39,  3.78s/it, loss=2.3, epoch=0.064, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 272/4220 [17:09<4:08:39,  3.78s/it, loss=2.57, epoch=0.0642, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 273/4220 [17:13<4:08:29,  3.78s/it, loss=2.57, epoch=0.0642, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 273/4220 [17:13<4:08:29,  3.78s/it, loss=2.37, epoch=0.0645, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 274/4220 [17:17<4:09:32,  3.79s/it, loss=2.37, epoch=0.0645, learning_rate=1.98e-5]\u001b[A\n",
      "  6%|▋         | 274/4220 [17:17<4:09:32,  3.79s/it, loss=2.33, epoch=0.0647, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 275/4220 [17:21<4:09:11,  3.79s/it, loss=2.33, epoch=0.0647, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 275/4220 [17:21<4:09:11,  3.79s/it, loss=2.95, epoch=0.0649, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 276/4220 [17:24<4:08:57,  3.79s/it, loss=2.95, epoch=0.0649, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 276/4220 [17:24<4:08:57,  3.79s/it, loss=2.58, epoch=0.0652, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 277/4220 [17:28<4:08:47,  3.79s/it, loss=2.58, epoch=0.0652, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 277/4220 [17:28<4:08:47,  3.79s/it, loss=3.28, epoch=0.0654, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 278/4220 [17:32<4:08:33,  3.78s/it, loss=3.28, epoch=0.0654, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 278/4220 [17:32<4:08:33,  3.78s/it, loss=2.53, epoch=0.0656, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 279/4220 [17:36<4:08:28,  3.78s/it, loss=2.53, epoch=0.0656, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 279/4220 [17:36<4:08:28,  3.78s/it, loss=2.53, epoch=0.0659, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 280/4220 [17:39<4:08:20,  3.78s/it, loss=2.53, epoch=0.0659, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 280/4220 [17:39<4:08:20,  3.78s/it, loss=3, epoch=0.0661, learning_rate=1.98e-5]   \u001b[A\n",
      "  7%|▋         | 281/4220 [17:43<4:08:10,  3.78s/it, loss=3, epoch=0.0661, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 281/4220 [17:43<4:08:10,  3.78s/it, loss=3.27, epoch=0.0664, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 282/4220 [17:47<4:08:14,  3.78s/it, loss=3.27, epoch=0.0664, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 282/4220 [17:47<4:08:14,  3.78s/it, loss=2.87, epoch=0.0666, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 283/4220 [17:51<4:08:07,  3.78s/it, loss=2.87, epoch=0.0666, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 283/4220 [17:51<4:08:07,  3.78s/it, loss=3.17, epoch=0.0668, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 284/4220 [17:55<4:07:58,  3.78s/it, loss=3.17, epoch=0.0668, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 284/4220 [17:55<4:07:58,  3.78s/it, loss=2.93, epoch=0.0671, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 285/4220 [17:58<4:07:56,  3.78s/it, loss=2.93, epoch=0.0671, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 285/4220 [17:58<4:07:56,  3.78s/it, loss=2.83, epoch=0.0673, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 286/4220 [18:02<4:07:49,  3.78s/it, loss=2.83, epoch=0.0673, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 286/4220 [18:02<4:07:49,  3.78s/it, loss=2.76, epoch=0.0675, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 287/4220 [18:06<4:07:40,  3.78s/it, loss=2.76, epoch=0.0675, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 287/4220 [18:06<4:07:40,  3.78s/it, loss=2.47, epoch=0.0678, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 288/4220 [18:10<4:07:40,  3.78s/it, loss=2.47, epoch=0.0678, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 288/4220 [18:10<4:07:40,  3.78s/it, loss=2.5, epoch=0.068, learning_rate=1.98e-5]  \u001b[A\n",
      "  7%|▋         | 289/4220 [18:14<4:07:42,  3.78s/it, loss=2.5, epoch=0.068, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 289/4220 [18:14<4:07:42,  3.78s/it, loss=2.58, epoch=0.0682, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 290/4220 [18:17<4:07:31,  3.78s/it, loss=2.58, epoch=0.0682, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 290/4220 [18:17<4:07:31,  3.78s/it, loss=2.75, epoch=0.0685, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 291/4220 [18:21<4:07:24,  3.78s/it, loss=2.75, epoch=0.0685, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 291/4220 [18:21<4:07:24,  3.78s/it, loss=2.9, epoch=0.0687, learning_rate=1.98e-5] \u001b[A\n",
      "  7%|▋         | 292/4220 [18:25<4:07:23,  3.78s/it, loss=2.9, epoch=0.0687, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 292/4220 [18:25<4:07:23,  3.78s/it, loss=2.46, epoch=0.069, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 293/4220 [18:29<4:07:27,  3.78s/it, loss=2.46, epoch=0.069, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 293/4220 [18:29<4:07:27,  3.78s/it, loss=3.04, epoch=0.0692, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 294/4220 [18:32<4:07:22,  3.78s/it, loss=3.04, epoch=0.0692, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 294/4220 [18:32<4:07:22,  3.78s/it, loss=2.87, epoch=0.0694, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 295/4220 [18:36<4:07:20,  3.78s/it, loss=2.87, epoch=0.0694, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 295/4220 [18:36<4:07:20,  3.78s/it, loss=3.06, epoch=0.0697, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 296/4220 [18:40<4:07:09,  3.78s/it, loss=3.06, epoch=0.0697, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 296/4220 [18:40<4:07:09,  3.78s/it, loss=2.98, epoch=0.0699, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 297/4220 [18:44<4:07:15,  3.78s/it, loss=2.98, epoch=0.0699, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 297/4220 [18:44<4:07:15,  3.78s/it, loss=2.64, epoch=0.0701, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 298/4220 [18:48<4:07:14,  3.78s/it, loss=2.64, epoch=0.0701, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 298/4220 [18:48<4:07:14,  3.78s/it, loss=3.17, epoch=0.0704, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 299/4220 [18:51<4:07:04,  3.78s/it, loss=3.17, epoch=0.0704, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 299/4220 [18:51<4:07:04,  3.78s/it, loss=2.55, epoch=0.0706, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 300/4220 [18:55<4:07:01,  3.78s/it, loss=2.55, epoch=0.0706, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 300/4220 [18:55<4:07:01,  3.78s/it, loss=2.76, epoch=0.0709, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 301/4220 [18:59<4:07:01,  3.78s/it, loss=2.76, epoch=0.0709, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 301/4220 [18:59<4:07:01,  3.78s/it, loss=2.71, epoch=0.0711, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 302/4220 [19:03<4:06:56,  3.78s/it, loss=2.71, epoch=0.0711, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 302/4220 [19:03<4:06:56,  3.78s/it, loss=3.46, epoch=0.0713, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 303/4220 [19:06<4:06:54,  3.78s/it, loss=3.46, epoch=0.0713, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 303/4220 [19:06<4:06:54,  3.78s/it, loss=2.47, epoch=0.0716, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 304/4220 [19:10<4:06:48,  3.78s/it, loss=2.47, epoch=0.0716, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 304/4220 [19:10<4:06:48,  3.78s/it, loss=2.78, epoch=0.0718, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 305/4220 [19:14<4:06:43,  3.78s/it, loss=2.78, epoch=0.0718, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 305/4220 [19:14<4:06:43,  3.78s/it, loss=3.03, epoch=0.072, learning_rate=1.98e-5] \u001b[A\n",
      "  7%|▋         | 306/4220 [19:18<4:06:35,  3.78s/it, loss=3.03, epoch=0.072, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 306/4220 [19:18<4:06:35,  3.78s/it, loss=2.57, epoch=0.0723, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 307/4220 [19:22<4:06:36,  3.78s/it, loss=2.57, epoch=0.0723, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 307/4220 [19:22<4:06:36,  3.78s/it, loss=3.01, epoch=0.0725, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 308/4220 [19:25<4:06:27,  3.78s/it, loss=3.01, epoch=0.0725, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 308/4220 [19:25<4:06:27,  3.78s/it, loss=2.68, epoch=0.0727, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 309/4220 [19:29<4:06:29,  3.78s/it, loss=2.68, epoch=0.0727, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 309/4220 [19:29<4:06:29,  3.78s/it, loss=2, epoch=0.073, learning_rate=1.98e-5]    \u001b[A\n",
      "  7%|▋         | 310/4220 [19:33<4:06:16,  3.78s/it, loss=2, epoch=0.073, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 310/4220 [19:33<4:06:16,  3.78s/it, loss=2.95, epoch=0.0732, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 311/4220 [19:37<4:06:16,  3.78s/it, loss=2.95, epoch=0.0732, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 311/4220 [19:37<4:06:16,  3.78s/it, loss=2.98, epoch=0.0735, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 312/4220 [19:40<4:06:15,  3.78s/it, loss=2.98, epoch=0.0735, learning_rate=1.98e-5]\u001b[A\n",
      "  7%|▋         | 312/4220 [19:40<4:06:15,  3.78s/it, loss=2.72, epoch=0.0737, learning_rate=1.97e-5]\u001b[A\n",
      "  7%|▋         | 313/4220 [19:44<4:06:14,  3.78s/it, loss=2.72, epoch=0.0737, learning_rate=1.97e-5]\u001b[A\n",
      "  7%|▋         | 313/4220 [19:44<4:06:14,  3.78s/it, loss=3.4, epoch=0.0739, learning_rate=1.97e-5] \u001b[A\n",
      "  7%|▋         | 314/4220 [19:48<4:06:11,  3.78s/it, loss=3.4, epoch=0.0739, learning_rate=1.97e-5]\u001b[A\n",
      "  7%|▋         | 314/4220 [19:48<4:06:11,  3.78s/it, loss=3.43, epoch=0.0742, learning_rate=1.97e-5]\u001b[A\n",
      "  7%|▋         | 315/4220 [19:52<4:06:03,  3.78s/it, loss=3.43, epoch=0.0742, learning_rate=1.97e-5]\u001b[A\n",
      "  7%|▋         | 315/4220 [19:52<4:06:03,  3.78s/it, loss=2.98, epoch=0.0744, learning_rate=1.97e-5]\u001b[A\n",
      "  7%|▋         | 316/4220 [19:56<4:06:01,  3.78s/it, loss=2.98, epoch=0.0744, learning_rate=1.97e-5]\u001b[A\n",
      "  7%|▋         | 316/4220 [19:56<4:06:01,  3.78s/it, loss=2.97, epoch=0.0746, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 317/4220 [19:59<4:05:54,  3.78s/it, loss=2.97, epoch=0.0746, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 317/4220 [19:59<4:05:54,  3.78s/it, loss=3.18, epoch=0.0749, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 318/4220 [20:03<4:05:52,  3.78s/it, loss=3.18, epoch=0.0749, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 318/4220 [20:03<4:05:52,  3.78s/it, loss=2.36, epoch=0.0751, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 319/4220 [20:07<4:05:50,  3.78s/it, loss=2.36, epoch=0.0751, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 319/4220 [20:07<4:05:50,  3.78s/it, loss=2.86, epoch=0.0754, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 320/4220 [20:11<4:05:50,  3.78s/it, loss=2.86, epoch=0.0754, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 320/4220 [20:11<4:05:50,  3.78s/it, loss=3.39, epoch=0.0756, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 321/4220 [20:14<4:05:43,  3.78s/it, loss=3.39, epoch=0.0756, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 321/4220 [20:14<4:05:43,  3.78s/it, loss=2.73, epoch=0.0758, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 322/4220 [20:18<4:05:42,  3.78s/it, loss=2.73, epoch=0.0758, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 322/4220 [20:18<4:05:42,  3.78s/it, loss=2.4, epoch=0.0761, learning_rate=1.97e-5] \u001b[A\n",
      "  8%|▊         | 323/4220 [20:22<4:05:39,  3.78s/it, loss=2.4, epoch=0.0761, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 323/4220 [20:22<4:05:39,  3.78s/it, loss=2.95, epoch=0.0763, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 324/4220 [20:26<4:05:29,  3.78s/it, loss=2.95, epoch=0.0763, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 324/4220 [20:26<4:05:29,  3.78s/it, loss=3.39, epoch=0.0765, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 325/4220 [20:30<4:05:20,  3.78s/it, loss=3.39, epoch=0.0765, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 325/4220 [20:30<4:05:20,  3.78s/it, loss=2.62, epoch=0.0768, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 326/4220 [20:33<4:05:23,  3.78s/it, loss=2.62, epoch=0.0768, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 326/4220 [20:33<4:05:23,  3.78s/it, loss=3.32, epoch=0.077, learning_rate=1.97e-5] \u001b[A\n",
      "  8%|▊         | 327/4220 [20:37<4:05:15,  3.78s/it, loss=3.32, epoch=0.077, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 327/4220 [20:37<4:05:15,  3.78s/it, loss=3.05, epoch=0.0773, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 328/4220 [20:41<4:05:15,  3.78s/it, loss=3.05, epoch=0.0773, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 328/4220 [20:41<4:05:15,  3.78s/it, loss=3.54, epoch=0.0775, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 329/4220 [20:45<4:05:10,  3.78s/it, loss=3.54, epoch=0.0775, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 329/4220 [20:45<4:05:10,  3.78s/it, loss=3.05, epoch=0.0777, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 330/4220 [20:49<4:05:01,  3.78s/it, loss=3.05, epoch=0.0777, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 330/4220 [20:49<4:05:01,  3.78s/it, loss=2.97, epoch=0.078, learning_rate=1.97e-5] \u001b[A\n",
      "  8%|▊         | 331/4220 [20:52<4:04:59,  3.78s/it, loss=2.97, epoch=0.078, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 331/4220 [20:52<4:04:59,  3.78s/it, loss=2.75, epoch=0.0782, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 332/4220 [20:56<4:04:56,  3.78s/it, loss=2.75, epoch=0.0782, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 332/4220 [20:56<4:04:56,  3.78s/it, loss=2.8, epoch=0.0784, learning_rate=1.97e-5] \u001b[A\n",
      "  8%|▊         | 333/4220 [21:00<4:04:50,  3.78s/it, loss=2.8, epoch=0.0784, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 333/4220 [21:00<4:04:50,  3.78s/it, loss=2.91, epoch=0.0787, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 334/4220 [21:04<4:04:53,  3.78s/it, loss=2.91, epoch=0.0787, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 334/4220 [21:04<4:04:53,  3.78s/it, loss=2.86, epoch=0.0789, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 335/4220 [21:07<4:04:45,  3.78s/it, loss=2.86, epoch=0.0789, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 335/4220 [21:07<4:04:45,  3.78s/it, loss=2.97, epoch=0.0791, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 336/4220 [21:11<4:04:44,  3.78s/it, loss=2.97, epoch=0.0791, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 336/4220 [21:11<4:04:44,  3.78s/it, loss=2.52, epoch=0.0794, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 337/4220 [21:15<4:04:39,  3.78s/it, loss=2.52, epoch=0.0794, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 337/4220 [21:15<4:04:39,  3.78s/it, loss=2.44, epoch=0.0796, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 338/4220 [21:19<4:04:30,  3.78s/it, loss=2.44, epoch=0.0796, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 338/4220 [21:19<4:04:30,  3.78s/it, loss=2.92, epoch=0.0799, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 339/4220 [21:23<4:04:30,  3.78s/it, loss=2.92, epoch=0.0799, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 339/4220 [21:23<4:04:30,  3.78s/it, loss=3.04, epoch=0.0801, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 340/4220 [21:26<4:04:28,  3.78s/it, loss=3.04, epoch=0.0801, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 340/4220 [21:26<4:04:28,  3.78s/it, loss=3.06, epoch=0.0803, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 341/4220 [21:30<4:04:25,  3.78s/it, loss=3.06, epoch=0.0803, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 341/4220 [21:30<4:04:25,  3.78s/it, loss=2.84, epoch=0.0806, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 342/4220 [21:34<4:04:22,  3.78s/it, loss=2.84, epoch=0.0806, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 342/4220 [21:34<4:04:22,  3.78s/it, loss=2.64, epoch=0.0808, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 343/4220 [21:38<4:04:12,  3.78s/it, loss=2.64, epoch=0.0808, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 343/4220 [21:38<4:04:12,  3.78s/it, loss=3.48, epoch=0.081, learning_rate=1.97e-5] \u001b[A\n",
      "  8%|▊         | 344/4220 [21:41<4:04:06,  3.78s/it, loss=3.48, epoch=0.081, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 344/4220 [21:41<4:04:06,  3.78s/it, loss=2.09, epoch=0.0813, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 345/4220 [21:45<4:03:59,  3.78s/it, loss=2.09, epoch=0.0813, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 345/4220 [21:45<4:03:59,  3.78s/it, loss=2.96, epoch=0.0815, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 346/4220 [21:49<4:03:57,  3.78s/it, loss=2.96, epoch=0.0815, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 346/4220 [21:49<4:03:57,  3.78s/it, loss=2.5, epoch=0.0818, learning_rate=1.97e-5] \u001b[A\n",
      "  8%|▊         | 347/4220 [21:53<4:03:57,  3.78s/it, loss=2.5, epoch=0.0818, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 347/4220 [21:53<4:03:57,  3.78s/it, loss=2.67, epoch=0.082, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 348/4220 [21:57<4:03:58,  3.78s/it, loss=2.67, epoch=0.082, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 348/4220 [21:57<4:03:58,  3.78s/it, loss=3.06, epoch=0.0822, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 349/4220 [22:00<4:03:54,  3.78s/it, loss=3.06, epoch=0.0822, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 349/4220 [22:00<4:03:54,  3.78s/it, loss=2.99, epoch=0.0825, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 350/4220 [22:04<4:03:51,  3.78s/it, loss=2.99, epoch=0.0825, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 350/4220 [22:04<4:03:51,  3.78s/it, loss=3.01, epoch=0.0827, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 351/4220 [22:08<4:03:47,  3.78s/it, loss=3.01, epoch=0.0827, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 351/4220 [22:08<4:03:47,  3.78s/it, loss=3.2, epoch=0.0829, learning_rate=1.97e-5] \u001b[A\n",
      "  8%|▊         | 352/4220 [22:12<4:03:44,  3.78s/it, loss=3.2, epoch=0.0829, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 352/4220 [22:12<4:03:44,  3.78s/it, loss=2.85, epoch=0.0832, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 353/4220 [22:15<4:03:32,  3.78s/it, loss=2.85, epoch=0.0832, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 353/4220 [22:15<4:03:32,  3.78s/it, loss=3.16, epoch=0.0834, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 354/4220 [22:19<4:05:56,  3.82s/it, loss=3.16, epoch=0.0834, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 354/4220 [22:19<4:05:56,  3.82s/it, loss=2.64, epoch=0.0836, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 355/4220 [22:23<4:05:11,  3.81s/it, loss=2.64, epoch=0.0836, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 355/4220 [22:23<4:05:11,  3.81s/it, loss=3.47, epoch=0.0839, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 356/4220 [22:27<4:04:31,  3.80s/it, loss=3.47, epoch=0.0839, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 356/4220 [22:27<4:04:31,  3.80s/it, loss=3, epoch=0.0841, learning_rate=1.97e-5]   \u001b[A\n",
      "  8%|▊         | 357/4220 [22:31<4:04:09,  3.79s/it, loss=3, epoch=0.0841, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 357/4220 [22:31<4:04:09,  3.79s/it, loss=3.28, epoch=0.0844, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 358/4220 [22:34<4:03:52,  3.79s/it, loss=3.28, epoch=0.0844, learning_rate=1.97e-5]\u001b[A\n",
      "  8%|▊         | 358/4220 [22:34<4:03:52,  3.79s/it, loss=3.01, epoch=0.0846, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 359/4220 [22:38<4:03:44,  3.79s/it, loss=3.01, epoch=0.0846, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 359/4220 [22:38<4:03:44,  3.79s/it, loss=3, epoch=0.0848, learning_rate=1.97e-5]   \u001b[A\n",
      "  9%|▊         | 360/4220 [22:42<4:03:31,  3.79s/it, loss=3, epoch=0.0848, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 360/4220 [22:42<4:03:31,  3.79s/it, loss=3.1, epoch=0.0851, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 361/4220 [22:46<4:03:14,  3.78s/it, loss=3.1, epoch=0.0851, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 361/4220 [22:46<4:03:14,  3.78s/it, loss=2.73, epoch=0.0853, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 362/4220 [22:50<4:03:03,  3.78s/it, loss=2.73, epoch=0.0853, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 362/4220 [22:50<4:03:03,  3.78s/it, loss=3.25, epoch=0.0855, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 363/4220 [22:53<4:02:54,  3.78s/it, loss=3.25, epoch=0.0855, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 363/4220 [22:53<4:02:54,  3.78s/it, loss=2.86, epoch=0.0858, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 364/4220 [22:57<4:02:51,  3.78s/it, loss=2.86, epoch=0.0858, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 364/4220 [22:57<4:02:51,  3.78s/it, loss=2.56, epoch=0.086, learning_rate=1.97e-5] \u001b[A\n",
      "  9%|▊         | 365/4220 [23:01<4:02:51,  3.78s/it, loss=2.56, epoch=0.086, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 365/4220 [23:01<4:02:51,  3.78s/it, loss=2.85, epoch=0.0863, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 366/4220 [23:05<4:02:49,  3.78s/it, loss=2.85, epoch=0.0863, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 366/4220 [23:05<4:02:49,  3.78s/it, loss=3.16, epoch=0.0865, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 367/4220 [23:08<4:02:49,  3.78s/it, loss=3.16, epoch=0.0865, learning_rate=1.97e-5]\u001b[A\n",
      "  9%|▊         | 367/4220 [23:08<4:02:49,  3.78s/it, loss=2.73, epoch=0.0867, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▊         | 368/4220 [23:12<4:02:40,  3.78s/it, loss=2.73, epoch=0.0867, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▊         | 368/4220 [23:12<4:02:40,  3.78s/it, loss=2.88, epoch=0.087, learning_rate=1.96e-5] \u001b[A\n",
      "  9%|▊         | 369/4220 [23:16<4:02:36,  3.78s/it, loss=2.88, epoch=0.087, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▊         | 369/4220 [23:16<4:02:36,  3.78s/it, loss=2.61, epoch=0.0872, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 370/4220 [23:20<4:02:29,  3.78s/it, loss=2.61, epoch=0.0872, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 370/4220 [23:20<4:02:29,  3.78s/it, loss=2.66, epoch=0.0874, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 371/4220 [23:24<4:02:28,  3.78s/it, loss=2.66, epoch=0.0874, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 371/4220 [23:24<4:02:28,  3.78s/it, loss=3.31, epoch=0.0877, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 372/4220 [23:27<4:02:31,  3.78s/it, loss=3.31, epoch=0.0877, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 372/4220 [23:27<4:02:31,  3.78s/it, loss=3.3, epoch=0.0879, learning_rate=1.96e-5] \u001b[A\n",
      "  9%|▉         | 373/4220 [23:31<4:02:22,  3.78s/it, loss=3.3, epoch=0.0879, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 373/4220 [23:31<4:02:22,  3.78s/it, loss=2.87, epoch=0.0882, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 374/4220 [23:35<4:02:20,  3.78s/it, loss=2.87, epoch=0.0882, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 374/4220 [23:35<4:02:20,  3.78s/it, loss=2.52, epoch=0.0884, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 375/4220 [23:39<4:02:15,  3.78s/it, loss=2.52, epoch=0.0884, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 375/4220 [23:39<4:02:15,  3.78s/it, loss=2.77, epoch=0.0886, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 376/4220 [23:43<4:02:08,  3.78s/it, loss=2.77, epoch=0.0886, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 376/4220 [23:43<4:02:08,  3.78s/it, loss=2.71, epoch=0.0889, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 377/4220 [23:46<4:02:06,  3.78s/it, loss=2.71, epoch=0.0889, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 377/4220 [23:46<4:02:06,  3.78s/it, loss=3.19, epoch=0.0891, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 378/4220 [23:50<4:02:06,  3.78s/it, loss=3.19, epoch=0.0891, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 378/4220 [23:50<4:02:06,  3.78s/it, loss=2.9, epoch=0.0893, learning_rate=1.96e-5] \u001b[A\n",
      "  9%|▉         | 379/4220 [23:54<4:01:56,  3.78s/it, loss=2.9, epoch=0.0893, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 379/4220 [23:54<4:01:56,  3.78s/it, loss=2.99, epoch=0.0896, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 380/4220 [23:58<4:01:47,  3.78s/it, loss=2.99, epoch=0.0896, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 380/4220 [23:58<4:01:47,  3.78s/it, loss=2.71, epoch=0.0898, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 381/4220 [24:01<4:01:46,  3.78s/it, loss=2.71, epoch=0.0898, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 381/4220 [24:01<4:01:46,  3.78s/it, loss=2.96, epoch=0.09, learning_rate=1.96e-5]  \u001b[A\n",
      "  9%|▉         | 382/4220 [24:05<4:01:36,  3.78s/it, loss=2.96, epoch=0.09, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 382/4220 [24:05<4:01:36,  3.78s/it, loss=2.45, epoch=0.0903, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 383/4220 [24:09<4:01:38,  3.78s/it, loss=2.45, epoch=0.0903, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 383/4220 [24:09<4:01:38,  3.78s/it, loss=3.07, epoch=0.0905, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 384/4220 [24:13<4:01:38,  3.78s/it, loss=3.07, epoch=0.0905, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 384/4220 [24:13<4:01:38,  3.78s/it, loss=2.35, epoch=0.0908, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 385/4220 [24:17<4:01:37,  3.78s/it, loss=2.35, epoch=0.0908, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 385/4220 [24:17<4:01:37,  3.78s/it, loss=2.48, epoch=0.091, learning_rate=1.96e-5] \u001b[A\n",
      "  9%|▉         | 386/4220 [24:20<4:01:34,  3.78s/it, loss=2.48, epoch=0.091, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 386/4220 [24:20<4:01:34,  3.78s/it, loss=3.32, epoch=0.0912, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 387/4220 [24:24<4:01:29,  3.78s/it, loss=3.32, epoch=0.0912, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 387/4220 [24:24<4:01:29,  3.78s/it, loss=3.27, epoch=0.0915, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 388/4220 [24:28<4:01:25,  3.78s/it, loss=3.27, epoch=0.0915, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 388/4220 [24:28<4:01:25,  3.78s/it, loss=2.76, epoch=0.0917, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 389/4220 [24:32<4:01:20,  3.78s/it, loss=2.76, epoch=0.0917, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 389/4220 [24:32<4:01:20,  3.78s/it, loss=2.49, epoch=0.0919, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 390/4220 [24:35<4:01:07,  3.78s/it, loss=2.49, epoch=0.0919, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 390/4220 [24:35<4:01:07,  3.78s/it, loss=2.88, epoch=0.0922, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 391/4220 [24:39<4:01:14,  3.78s/it, loss=2.88, epoch=0.0922, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 391/4220 [24:39<4:01:14,  3.78s/it, loss=3.45, epoch=0.0924, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 392/4220 [24:43<4:01:11,  3.78s/it, loss=3.45, epoch=0.0924, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 392/4220 [24:43<4:01:11,  3.78s/it, loss=2.57, epoch=0.0927, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 393/4220 [24:47<4:01:08,  3.78s/it, loss=2.57, epoch=0.0927, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 393/4220 [24:47<4:01:08,  3.78s/it, loss=2.78, epoch=0.0929, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 394/4220 [24:51<4:01:05,  3.78s/it, loss=2.78, epoch=0.0929, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 394/4220 [24:51<4:01:05,  3.78s/it, loss=2.72, epoch=0.0931, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 395/4220 [24:54<4:01:01,  3.78s/it, loss=2.72, epoch=0.0931, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 395/4220 [24:54<4:01:01,  3.78s/it, loss=3.22, epoch=0.0934, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 396/4220 [24:58<4:00:55,  3.78s/it, loss=3.22, epoch=0.0934, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 396/4220 [24:58<4:00:55,  3.78s/it, loss=2.66, epoch=0.0936, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 397/4220 [25:02<4:00:44,  3.78s/it, loss=2.66, epoch=0.0936, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 397/4220 [25:02<4:00:44,  3.78s/it, loss=3.04, epoch=0.0938, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 398/4220 [25:06<4:00:45,  3.78s/it, loss=3.04, epoch=0.0938, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 398/4220 [25:06<4:00:45,  3.78s/it, loss=2.74, epoch=0.0941, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 399/4220 [25:09<4:00:43,  3.78s/it, loss=2.74, epoch=0.0941, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 399/4220 [25:09<4:00:43,  3.78s/it, loss=3.05, epoch=0.0943, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 400/4220 [25:13<4:00:39,  3.78s/it, loss=3.05, epoch=0.0943, learning_rate=1.96e-5]\u001b[A\n",
      "  9%|▉         | 400/4220 [25:13<4:00:39,  3.78s/it, loss=2.27, epoch=0.0945, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 401/4220 [25:17<4:00:39,  3.78s/it, loss=2.27, epoch=0.0945, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 401/4220 [25:17<4:00:39,  3.78s/it, loss=3.06, epoch=0.0948, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 402/4220 [25:21<4:00:34,  3.78s/it, loss=3.06, epoch=0.0948, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 402/4220 [25:21<4:00:34,  3.78s/it, loss=2.95, epoch=0.095, learning_rate=1.96e-5] \u001b[A\n",
      " 10%|▉         | 403/4220 [25:25<4:00:20,  3.78s/it, loss=2.95, epoch=0.095, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 403/4220 [25:25<4:00:20,  3.78s/it, loss=2.52, epoch=0.0953, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 404/4220 [25:28<4:00:21,  3.78s/it, loss=2.52, epoch=0.0953, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 404/4220 [25:28<4:00:21,  3.78s/it, loss=2.78, epoch=0.0955, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 405/4220 [25:32<4:00:16,  3.78s/it, loss=2.78, epoch=0.0955, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 405/4220 [25:32<4:00:16,  3.78s/it, loss=3.05, epoch=0.0957, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 406/4220 [25:36<4:00:12,  3.78s/it, loss=3.05, epoch=0.0957, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 406/4220 [25:36<4:00:12,  3.78s/it, loss=2.74, epoch=0.096, learning_rate=1.96e-5] \u001b[A\n",
      " 10%|▉         | 407/4220 [25:40<4:00:10,  3.78s/it, loss=2.74, epoch=0.096, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 407/4220 [25:40<4:00:10,  3.78s/it, loss=3.34, epoch=0.0962, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 408/4220 [25:43<4:00:09,  3.78s/it, loss=3.34, epoch=0.0962, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 408/4220 [25:43<4:00:09,  3.78s/it, loss=2.69, epoch=0.0964, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 409/4220 [25:47<4:00:07,  3.78s/it, loss=2.69, epoch=0.0964, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 409/4220 [25:47<4:00:07,  3.78s/it, loss=2.59, epoch=0.0967, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 410/4220 [25:51<4:00:05,  3.78s/it, loss=2.59, epoch=0.0967, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 410/4220 [25:51<4:00:05,  3.78s/it, loss=3.29, epoch=0.0969, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 411/4220 [25:55<4:00:03,  3.78s/it, loss=3.29, epoch=0.0969, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 411/4220 [25:55<4:00:03,  3.78s/it, loss=3.01, epoch=0.0972, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 412/4220 [25:59<4:00:01,  3.78s/it, loss=3.01, epoch=0.0972, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 412/4220 [25:59<4:00:01,  3.78s/it, loss=3.62, epoch=0.0974, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 413/4220 [26:02<3:59:56,  3.78s/it, loss=3.62, epoch=0.0974, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 413/4220 [26:02<3:59:56,  3.78s/it, loss=2.31, epoch=0.0976, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 414/4220 [26:06<3:59:42,  3.78s/it, loss=2.31, epoch=0.0976, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 414/4220 [26:06<3:59:42,  3.78s/it, loss=2.94, epoch=0.0979, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 415/4220 [26:10<3:59:38,  3.78s/it, loss=2.94, epoch=0.0979, learning_rate=1.96e-5]\u001b[A\n",
      " 10%|▉         | 415/4220 [26:10<3:59:38,  3.78s/it, loss=2.93, epoch=0.0981, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 416/4220 [26:14<3:59:34,  3.78s/it, loss=2.93, epoch=0.0981, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 416/4220 [26:14<3:59:34,  3.78s/it, loss=2.22, epoch=0.0983, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 417/4220 [26:17<3:59:30,  3.78s/it, loss=2.22, epoch=0.0983, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 417/4220 [26:17<3:59:30,  3.78s/it, loss=2.58, epoch=0.0986, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 418/4220 [26:21<3:59:32,  3.78s/it, loss=2.58, epoch=0.0986, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 418/4220 [26:21<3:59:32,  3.78s/it, loss=2.4, epoch=0.0988, learning_rate=1.95e-5] \u001b[A\n",
      " 10%|▉         | 419/4220 [26:25<3:59:26,  3.78s/it, loss=2.4, epoch=0.0988, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 419/4220 [26:25<3:59:26,  3.78s/it, loss=2.92, epoch=0.0991, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 420/4220 [26:29<3:59:29,  3.78s/it, loss=2.92, epoch=0.0991, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 420/4220 [26:29<3:59:29,  3.78s/it, loss=2.69, epoch=0.0993, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 421/4220 [26:33<3:59:25,  3.78s/it, loss=2.69, epoch=0.0993, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|▉         | 421/4220 [26:33<3:59:25,  3.78s/it, loss=2.55, epoch=0.0995, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 422/4220 [26:36<3:59:15,  3.78s/it, loss=2.55, epoch=0.0995, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 422/4220 [26:36<3:59:15,  3.78s/it, loss=2.8, epoch=0.0998, learning_rate=1.95e-5] \u001b[A\n",
      " 10%|█         | 423/4220 [26:40<3:59:11,  3.78s/it, loss=2.8, epoch=0.0998, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 423/4220 [26:40<3:59:11,  3.78s/it, loss=2.39, epoch=0.1, learning_rate=1.95e-5]  \u001b[A\n",
      " 10%|█         | 424/4220 [26:44<3:59:07,  3.78s/it, loss=2.39, epoch=0.1, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 424/4220 [26:44<3:59:07,  3.78s/it, loss=2.49, epoch=0.1, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 425/4220 [26:48<3:59:05,  3.78s/it, loss=2.49, epoch=0.1, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 425/4220 [26:48<3:59:05,  3.78s/it, loss=2.76, epoch=0.1, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 426/4220 [26:52<3:59:04,  3.78s/it, loss=2.76, epoch=0.1, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 426/4220 [26:52<3:59:04,  3.78s/it, loss=2.62, epoch=0.101, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 427/4220 [26:55<3:58:59,  3.78s/it, loss=2.62, epoch=0.101, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 427/4220 [26:55<3:58:59,  3.78s/it, loss=2.45, epoch=0.101, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 428/4220 [26:59<3:58:57,  3.78s/it, loss=2.45, epoch=0.101, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 428/4220 [26:59<3:58:57,  3.78s/it, loss=3.16, epoch=0.101, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 429/4220 [27:03<3:58:51,  3.78s/it, loss=3.16, epoch=0.101, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 429/4220 [27:03<3:58:51,  3.78s/it, loss=2.88, epoch=0.101, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 430/4220 [27:07<3:58:46,  3.78s/it, loss=2.88, epoch=0.101, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 430/4220 [27:07<3:58:46,  3.78s/it, loss=2.33, epoch=0.102, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 431/4220 [27:10<3:58:35,  3.78s/it, loss=2.33, epoch=0.102, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 431/4220 [27:10<3:58:35,  3.78s/it, loss=3.48, epoch=0.102, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 432/4220 [27:14<3:58:38,  3.78s/it, loss=3.48, epoch=0.102, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 432/4220 [27:14<3:58:38,  3.78s/it, loss=3.58, epoch=0.102, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 433/4220 [27:18<3:58:29,  3.78s/it, loss=3.58, epoch=0.102, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 433/4220 [27:18<3:58:29,  3.78s/it, loss=2.58, epoch=0.102, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 434/4220 [27:22<3:59:27,  3.79s/it, loss=2.58, epoch=0.102, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 434/4220 [27:22<3:59:27,  3.79s/it, loss=2.36, epoch=0.103, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 435/4220 [27:26<3:59:08,  3.79s/it, loss=2.36, epoch=0.103, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 435/4220 [27:26<3:59:08,  3.79s/it, loss=2.24, epoch=0.103, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 436/4220 [27:29<3:58:59,  3.79s/it, loss=2.24, epoch=0.103, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 436/4220 [27:29<3:58:59,  3.79s/it, loss=2.59, epoch=0.103, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 437/4220 [27:33<3:58:43,  3.79s/it, loss=2.59, epoch=0.103, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 437/4220 [27:33<3:58:43,  3.79s/it, loss=2.91, epoch=0.103, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 438/4220 [27:37<3:58:27,  3.78s/it, loss=2.91, epoch=0.103, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 438/4220 [27:37<3:58:27,  3.78s/it, loss=2.56, epoch=0.104, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 439/4220 [27:41<3:58:23,  3.78s/it, loss=2.56, epoch=0.104, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 439/4220 [27:41<3:58:23,  3.78s/it, loss=2.29, epoch=0.104, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 440/4220 [27:44<3:58:06,  3.78s/it, loss=2.29, epoch=0.104, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 440/4220 [27:44<3:58:06,  3.78s/it, loss=2.56, epoch=0.104, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 441/4220 [27:48<3:58:08,  3.78s/it, loss=2.56, epoch=0.104, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 441/4220 [27:48<3:58:08,  3.78s/it, loss=3.02, epoch=0.104, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 442/4220 [27:52<3:58:07,  3.78s/it, loss=3.02, epoch=0.104, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 442/4220 [27:52<3:58:07,  3.78s/it, loss=2.92, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 443/4220 [27:56<3:57:55,  3.78s/it, loss=2.92, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 10%|█         | 443/4220 [27:56<3:57:55,  3.78s/it, loss=2.75, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 444/4220 [28:00<3:57:53,  3.78s/it, loss=2.75, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 444/4220 [28:00<3:57:53,  3.78s/it, loss=3.27, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 445/4220 [28:03<3:57:54,  3.78s/it, loss=3.27, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 445/4220 [28:03<3:57:54,  3.78s/it, loss=2.95, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 446/4220 [28:07<3:57:52,  3.78s/it, loss=2.95, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 446/4220 [28:07<3:57:52,  3.78s/it, loss=3.24, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 447/4220 [28:11<3:57:50,  3.78s/it, loss=3.24, epoch=0.105, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 447/4220 [28:11<3:57:50,  3.78s/it, loss=3.32, epoch=0.106, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 448/4220 [28:15<3:57:44,  3.78s/it, loss=3.32, epoch=0.106, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 448/4220 [28:15<3:57:44,  3.78s/it, loss=3.3, epoch=0.106, learning_rate=1.95e-5] \u001b[A\n",
      " 11%|█         | 449/4220 [28:19<3:57:38,  3.78s/it, loss=3.3, epoch=0.106, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 449/4220 [28:19<3:57:38,  3.78s/it, loss=2.86, epoch=0.106, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 450/4220 [28:22<3:57:34,  3.78s/it, loss=2.86, epoch=0.106, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 450/4220 [28:22<3:57:34,  3.78s/it, loss=2.55, epoch=0.106, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 451/4220 [28:26<3:57:22,  3.78s/it, loss=2.55, epoch=0.106, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 451/4220 [28:26<3:57:22,  3.78s/it, loss=2.96, epoch=0.107, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 452/4220 [28:30<3:57:15,  3.78s/it, loss=2.96, epoch=0.107, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 452/4220 [28:30<3:57:15,  3.78s/it, loss=3.48, epoch=0.107, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 453/4220 [28:34<3:57:17,  3.78s/it, loss=3.48, epoch=0.107, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 453/4220 [28:34<3:57:17,  3.78s/it, loss=3.33, epoch=0.107, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 454/4220 [28:37<3:57:14,  3.78s/it, loss=3.33, epoch=0.107, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 454/4220 [28:37<3:57:14,  3.78s/it, loss=2.62, epoch=0.107, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 455/4220 [28:41<3:57:13,  3.78s/it, loss=2.62, epoch=0.107, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 455/4220 [28:41<3:57:13,  3.78s/it, loss=2.58, epoch=0.108, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 456/4220 [28:45<3:57:10,  3.78s/it, loss=2.58, epoch=0.108, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 456/4220 [28:45<3:57:10,  3.78s/it, loss=3.24, epoch=0.108, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 457/4220 [28:49<3:57:05,  3.78s/it, loss=3.24, epoch=0.108, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 457/4220 [28:49<3:57:05,  3.78s/it, loss=2.29, epoch=0.108, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 458/4220 [28:53<3:57:03,  3.78s/it, loss=2.29, epoch=0.108, learning_rate=1.95e-5]\u001b[A\n",
      " 11%|█         | 458/4220 [28:53<3:57:03,  3.78s/it, loss=3.03, epoch=0.108, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 459/4220 [28:56<3:57:01,  3.78s/it, loss=3.03, epoch=0.108, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 459/4220 [28:56<3:57:01,  3.78s/it, loss=2.88, epoch=0.109, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 460/4220 [29:00<3:56:53,  3.78s/it, loss=2.88, epoch=0.109, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 460/4220 [29:00<3:56:53,  3.78s/it, loss=2.91, epoch=0.109, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 461/4220 [29:04<3:56:53,  3.78s/it, loss=2.91, epoch=0.109, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 461/4220 [29:04<3:56:53,  3.78s/it, loss=3.07, epoch=0.109, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 462/4220 [29:08<3:56:51,  3.78s/it, loss=3.07, epoch=0.109, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 462/4220 [29:08<3:56:51,  3.78s/it, loss=2.8, epoch=0.109, learning_rate=1.94e-5] \u001b[A\n",
      " 11%|█         | 463/4220 [29:11<3:56:46,  3.78s/it, loss=2.8, epoch=0.109, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 463/4220 [29:11<3:56:46,  3.78s/it, loss=2.76, epoch=0.109, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 464/4220 [29:15<3:56:43,  3.78s/it, loss=2.76, epoch=0.109, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 464/4220 [29:15<3:56:43,  3.78s/it, loss=3.15, epoch=0.11, learning_rate=1.94e-5] \u001b[A\n",
      " 11%|█         | 465/4220 [29:19<3:56:33,  3.78s/it, loss=3.15, epoch=0.11, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 465/4220 [29:19<3:56:33,  3.78s/it, loss=2.43, epoch=0.11, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 466/4220 [29:23<3:56:32,  3.78s/it, loss=2.43, epoch=0.11, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 466/4220 [29:23<3:56:32,  3.78s/it, loss=3.49, epoch=0.11, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 467/4220 [29:27<3:56:27,  3.78s/it, loss=3.49, epoch=0.11, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 467/4220 [29:27<3:56:27,  3.78s/it, loss=2.7, epoch=0.11, learning_rate=1.94e-5] \u001b[A\n",
      " 11%|█         | 468/4220 [29:30<3:56:17,  3.78s/it, loss=2.7, epoch=0.11, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 468/4220 [29:30<3:56:17,  3.78s/it, loss=2.79, epoch=0.111, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 469/4220 [29:34<3:56:15,  3.78s/it, loss=2.79, epoch=0.111, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 469/4220 [29:34<3:56:15,  3.78s/it, loss=2.71, epoch=0.111, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 470/4220 [29:38<3:56:13,  3.78s/it, loss=2.71, epoch=0.111, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 470/4220 [29:38<3:56:13,  3.78s/it, loss=3.01, epoch=0.111, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 471/4220 [29:42<3:56:02,  3.78s/it, loss=3.01, epoch=0.111, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 471/4220 [29:42<3:56:02,  3.78s/it, loss=3.13, epoch=0.111, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 472/4220 [29:45<3:56:01,  3.78s/it, loss=3.13, epoch=0.111, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 472/4220 [29:45<3:56:01,  3.78s/it, loss=2.7, epoch=0.112, learning_rate=1.94e-5] \u001b[A\n",
      " 11%|█         | 473/4220 [29:49<3:56:01,  3.78s/it, loss=2.7, epoch=0.112, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 473/4220 [29:49<3:56:01,  3.78s/it, loss=2.33, epoch=0.112, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 474/4220 [29:53<3:55:58,  3.78s/it, loss=2.33, epoch=0.112, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█         | 474/4220 [29:53<3:55:58,  3.78s/it, loss=2.89, epoch=0.112, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 475/4220 [29:57<3:55:47,  3.78s/it, loss=2.89, epoch=0.112, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 475/4220 [29:57<3:55:47,  3.78s/it, loss=2.64, epoch=0.112, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 476/4220 [30:01<3:55:46,  3.78s/it, loss=2.64, epoch=0.112, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 476/4220 [30:01<3:55:46,  3.78s/it, loss=2.96, epoch=0.113, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 477/4220 [30:04<3:55:42,  3.78s/it, loss=2.96, epoch=0.113, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 477/4220 [30:04<3:55:42,  3.78s/it, loss=2.38, epoch=0.113, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 478/4220 [30:08<3:55:42,  3.78s/it, loss=2.38, epoch=0.113, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 478/4220 [30:08<3:55:42,  3.78s/it, loss=2.96, epoch=0.113, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 479/4220 [30:12<3:55:32,  3.78s/it, loss=2.96, epoch=0.113, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 479/4220 [30:12<3:55:32,  3.78s/it, loss=2.65, epoch=0.113, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 480/4220 [30:16<3:55:32,  3.78s/it, loss=2.65, epoch=0.113, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 480/4220 [30:16<3:55:32,  3.78s/it, loss=2.4, epoch=0.114, learning_rate=1.94e-5] \u001b[A\n",
      " 11%|█▏        | 481/4220 [30:19<3:55:35,  3.78s/it, loss=2.4, epoch=0.114, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 481/4220 [30:19<3:55:35,  3.78s/it, loss=2.62, epoch=0.114, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 482/4220 [30:23<3:55:35,  3.78s/it, loss=2.62, epoch=0.114, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 482/4220 [30:23<3:55:35,  3.78s/it, loss=3.19, epoch=0.114, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 483/4220 [30:27<3:55:30,  3.78s/it, loss=3.19, epoch=0.114, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 483/4220 [30:27<3:55:30,  3.78s/it, loss=2.75, epoch=0.114, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 484/4220 [30:31<3:55:25,  3.78s/it, loss=2.75, epoch=0.114, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 484/4220 [30:31<3:55:25,  3.78s/it, loss=2.57, epoch=0.114, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 485/4220 [30:35<3:55:15,  3.78s/it, loss=2.57, epoch=0.114, learning_rate=1.94e-5]\u001b[A\n",
      " 11%|█▏        | 485/4220 [30:35<3:55:15,  3.78s/it, loss=2.71, epoch=0.115, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 486/4220 [30:38<3:55:22,  3.78s/it, loss=2.71, epoch=0.115, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 486/4220 [30:38<3:55:22,  3.78s/it, loss=3.04, epoch=0.115, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 487/4220 [30:42<3:55:12,  3.78s/it, loss=3.04, epoch=0.115, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 487/4220 [30:42<3:55:12,  3.78s/it, loss=2.62, epoch=0.115, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 488/4220 [30:46<3:55:09,  3.78s/it, loss=2.62, epoch=0.115, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 488/4220 [30:46<3:55:09,  3.78s/it, loss=2.56, epoch=0.115, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 489/4220 [30:50<3:54:59,  3.78s/it, loss=2.56, epoch=0.115, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 489/4220 [30:50<3:54:59,  3.78s/it, loss=2.86, epoch=0.116, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 490/4220 [30:53<3:55:01,  3.78s/it, loss=2.86, epoch=0.116, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 490/4220 [30:53<3:55:01,  3.78s/it, loss=2.55, epoch=0.116, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 491/4220 [30:57<3:54:57,  3.78s/it, loss=2.55, epoch=0.116, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 491/4220 [30:57<3:54:57,  3.78s/it, loss=3.19, epoch=0.116, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 492/4220 [31:01<3:54:53,  3.78s/it, loss=3.19, epoch=0.116, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 492/4220 [31:01<3:54:53,  3.78s/it, loss=2.66, epoch=0.116, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 493/4220 [31:05<3:54:41,  3.78s/it, loss=2.66, epoch=0.116, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 493/4220 [31:05<3:54:41,  3.78s/it, loss=2.25, epoch=0.117, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 494/4220 [31:09<3:54:43,  3.78s/it, loss=2.25, epoch=0.117, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 494/4220 [31:09<3:54:43,  3.78s/it, loss=3.38, epoch=0.117, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 495/4220 [31:12<3:54:36,  3.78s/it, loss=3.38, epoch=0.117, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 495/4220 [31:12<3:54:36,  3.78s/it, loss=2.71, epoch=0.117, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 496/4220 [31:16<3:54:36,  3.78s/it, loss=2.71, epoch=0.117, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 496/4220 [31:16<3:54:36,  3.78s/it, loss=2.76, epoch=0.117, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 497/4220 [31:20<3:54:34,  3.78s/it, loss=2.76, epoch=0.117, learning_rate=1.94e-5]\u001b[A\n",
      " 12%|█▏        | 497/4220 [31:20<3:54:34,  3.78s/it, loss=2.64, epoch=0.118, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 498/4220 [31:24<3:54:37,  3.78s/it, loss=2.64, epoch=0.118, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 498/4220 [31:24<3:54:37,  3.78s/it, loss=2.79, epoch=0.118, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 499/4220 [31:28<3:54:30,  3.78s/it, loss=2.79, epoch=0.118, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 499/4220 [31:28<3:54:30,  3.78s/it, loss=2.65, epoch=0.118, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 500/4220 [31:31<3:54:19,  3.78s/it, loss=2.65, epoch=0.118, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 500/4220 [31:31<3:54:19,  3.78s/it, loss=2.64, epoch=0.118, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 501/4220 [31:35<3:54:18,  3.78s/it, loss=2.64, epoch=0.118, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 501/4220 [31:35<3:54:18,  3.78s/it, loss=3, epoch=0.118, learning_rate=1.93e-5]   \u001b[A\n",
      " 12%|█▏        | 502/4220 [31:39<3:54:16,  3.78s/it, loss=3, epoch=0.118, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 502/4220 [31:39<3:54:16,  3.78s/it, loss=2.67, epoch=0.119, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 503/4220 [31:43<3:54:03,  3.78s/it, loss=2.67, epoch=0.119, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 503/4220 [31:43<3:54:03,  3.78s/it, loss=2.65, epoch=0.119, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 504/4220 [31:46<3:53:59,  3.78s/it, loss=2.65, epoch=0.119, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 504/4220 [31:46<3:53:59,  3.78s/it, loss=2.83, epoch=0.119, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 505/4220 [31:50<3:53:55,  3.78s/it, loss=2.83, epoch=0.119, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 505/4220 [31:50<3:53:55,  3.78s/it, loss=2.58, epoch=0.119, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 506/4220 [31:54<3:53:56,  3.78s/it, loss=2.58, epoch=0.119, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 506/4220 [31:54<3:53:56,  3.78s/it, loss=2.85, epoch=0.12, learning_rate=1.93e-5] \u001b[A\n",
      " 12%|█▏        | 507/4220 [31:58<3:53:55,  3.78s/it, loss=2.85, epoch=0.12, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 507/4220 [31:58<3:53:55,  3.78s/it, loss=2.47, epoch=0.12, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 508/4220 [32:02<3:53:51,  3.78s/it, loss=2.47, epoch=0.12, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 508/4220 [32:02<3:53:51,  3.78s/it, loss=3.11, epoch=0.12, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 509/4220 [32:05<3:53:42,  3.78s/it, loss=3.11, epoch=0.12, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 509/4220 [32:05<3:53:42,  3.78s/it, loss=2.94, epoch=0.12, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 510/4220 [32:09<3:53:42,  3.78s/it, loss=2.94, epoch=0.12, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 510/4220 [32:09<3:53:42,  3.78s/it, loss=2.78, epoch=0.121, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 511/4220 [32:13<3:53:36,  3.78s/it, loss=2.78, epoch=0.121, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 511/4220 [32:13<3:53:36,  3.78s/it, loss=2.93, epoch=0.121, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 512/4220 [32:17<3:53:33,  3.78s/it, loss=2.93, epoch=0.121, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 512/4220 [32:17<3:53:33,  3.78s/it, loss=2.66, epoch=0.121, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 513/4220 [32:20<3:53:27,  3.78s/it, loss=2.66, epoch=0.121, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 513/4220 [32:20<3:53:27,  3.78s/it, loss=2.63, epoch=0.121, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 514/4220 [32:24<3:53:48,  3.79s/it, loss=2.63, epoch=0.121, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 514/4220 [32:24<3:53:48,  3.79s/it, loss=3.32, epoch=0.122, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 515/4220 [32:28<3:53:39,  3.78s/it, loss=3.32, epoch=0.122, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 515/4220 [32:28<3:53:39,  3.78s/it, loss=2.72, epoch=0.122, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 516/4220 [32:32<3:53:30,  3.78s/it, loss=2.72, epoch=0.122, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 516/4220 [32:32<3:53:30,  3.78s/it, loss=2.84, epoch=0.122, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 517/4220 [32:36<3:53:23,  3.78s/it, loss=2.84, epoch=0.122, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 517/4220 [32:36<3:53:23,  3.78s/it, loss=2.7, epoch=0.122, learning_rate=1.93e-5] \u001b[A\n",
      " 12%|█▏        | 518/4220 [32:39<3:53:15,  3.78s/it, loss=2.7, epoch=0.122, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 518/4220 [32:39<3:53:15,  3.78s/it, loss=2.78, epoch=0.123, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 519/4220 [32:43<3:53:08,  3.78s/it, loss=2.78, epoch=0.123, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 519/4220 [32:43<3:53:08,  3.78s/it, loss=2.25, epoch=0.123, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 520/4220 [32:47<3:53:06,  3.78s/it, loss=2.25, epoch=0.123, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 520/4220 [32:47<3:53:06,  3.78s/it, loss=2.99, epoch=0.123, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 521/4220 [32:51<3:53:00,  3.78s/it, loss=2.99, epoch=0.123, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 521/4220 [32:51<3:53:00,  3.78s/it, loss=3.2, epoch=0.123, learning_rate=1.93e-5] \u001b[A\n",
      " 12%|█▏        | 522/4220 [32:54<3:52:50,  3.78s/it, loss=3.2, epoch=0.123, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 522/4220 [32:54<3:52:50,  3.78s/it, loss=3.07, epoch=0.123, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 523/4220 [32:58<3:52:44,  3.78s/it, loss=3.07, epoch=0.123, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 523/4220 [32:58<3:52:44,  3.78s/it, loss=2.67, epoch=0.124, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 524/4220 [33:02<3:52:37,  3.78s/it, loss=2.67, epoch=0.124, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 524/4220 [33:02<3:52:37,  3.78s/it, loss=2.65, epoch=0.124, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 525/4220 [33:06<3:52:38,  3.78s/it, loss=2.65, epoch=0.124, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 525/4220 [33:06<3:52:38,  3.78s/it, loss=2.52, epoch=0.124, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 526/4220 [33:10<3:52:41,  3.78s/it, loss=2.52, epoch=0.124, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 526/4220 [33:10<3:52:41,  3.78s/it, loss=2.34, epoch=0.124, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 527/4220 [33:13<3:52:40,  3.78s/it, loss=2.34, epoch=0.124, learning_rate=1.93e-5]\u001b[A\n",
      " 12%|█▏        | 527/4220 [33:13<3:52:40,  3.78s/it, loss=3, epoch=0.125, learning_rate=1.93e-5]   \u001b[A\n",
      " 13%|█▎        | 528/4220 [33:17<3:52:40,  3.78s/it, loss=3, epoch=0.125, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 528/4220 [33:17<3:52:40,  3.78s/it, loss=2.95, epoch=0.125, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 529/4220 [33:21<3:52:39,  3.78s/it, loss=2.95, epoch=0.125, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 529/4220 [33:21<3:52:39,  3.78s/it, loss=3.24, epoch=0.125, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 530/4220 [33:25<3:52:29,  3.78s/it, loss=3.24, epoch=0.125, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 530/4220 [33:25<3:52:29,  3.78s/it, loss=2.89, epoch=0.125, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 531/4220 [33:28<3:52:29,  3.78s/it, loss=2.89, epoch=0.125, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 531/4220 [33:28<3:52:29,  3.78s/it, loss=3.27, epoch=0.126, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 532/4220 [33:32<3:52:23,  3.78s/it, loss=3.27, epoch=0.126, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 532/4220 [33:32<3:52:23,  3.78s/it, loss=2.88, epoch=0.126, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 533/4220 [33:36<3:52:16,  3.78s/it, loss=2.88, epoch=0.126, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 533/4220 [33:36<3:52:16,  3.78s/it, loss=2.11, epoch=0.126, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 534/4220 [33:40<3:52:10,  3.78s/it, loss=2.11, epoch=0.126, learning_rate=1.93e-5]\u001b[A\n",
      " 13%|█▎        | 534/4220 [33:40<3:52:10,  3.78s/it, loss=2.03, epoch=0.126, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 535/4220 [33:44<3:52:11,  3.78s/it, loss=2.03, epoch=0.126, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 535/4220 [33:44<3:52:11,  3.78s/it, loss=2.98, epoch=0.127, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 536/4220 [33:47<3:52:08,  3.78s/it, loss=2.98, epoch=0.127, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 536/4220 [33:47<3:52:08,  3.78s/it, loss=2.66, epoch=0.127, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 537/4220 [33:51<3:52:10,  3.78s/it, loss=2.66, epoch=0.127, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 537/4220 [33:51<3:52:10,  3.78s/it, loss=2.91, epoch=0.127, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 538/4220 [33:55<3:52:08,  3.78s/it, loss=2.91, epoch=0.127, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 538/4220 [33:55<3:52:08,  3.78s/it, loss=2.4, epoch=0.127, learning_rate=1.92e-5] \u001b[A\n",
      " 13%|█▎        | 539/4220 [33:59<3:52:00,  3.78s/it, loss=2.4, epoch=0.127, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 539/4220 [33:59<3:52:00,  3.78s/it, loss=2.62, epoch=0.127, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 540/4220 [34:02<3:51:54,  3.78s/it, loss=2.62, epoch=0.127, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 540/4220 [34:02<3:51:54,  3.78s/it, loss=3.66, epoch=0.128, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 541/4220 [34:06<3:51:46,  3.78s/it, loss=3.66, epoch=0.128, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 541/4220 [34:06<3:51:46,  3.78s/it, loss=2.76, epoch=0.128, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 542/4220 [34:10<3:51:45,  3.78s/it, loss=2.76, epoch=0.128, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 542/4220 [34:10<3:51:45,  3.78s/it, loss=2.53, epoch=0.128, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 543/4220 [34:14<3:51:42,  3.78s/it, loss=2.53, epoch=0.128, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 543/4220 [34:14<3:51:42,  3.78s/it, loss=2.79, epoch=0.128, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 544/4220 [34:18<3:51:37,  3.78s/it, loss=2.79, epoch=0.128, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 544/4220 [34:18<3:51:37,  3.78s/it, loss=2.85, epoch=0.129, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 545/4220 [34:21<3:51:29,  3.78s/it, loss=2.85, epoch=0.129, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 545/4220 [34:21<3:51:29,  3.78s/it, loss=2.73, epoch=0.129, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 546/4220 [34:25<3:51:28,  3.78s/it, loss=2.73, epoch=0.129, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 546/4220 [34:25<3:51:28,  3.78s/it, loss=3.2, epoch=0.129, learning_rate=1.92e-5] \u001b[A\n",
      " 13%|█▎        | 547/4220 [34:29<3:51:19,  3.78s/it, loss=3.2, epoch=0.129, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 547/4220 [34:29<3:51:19,  3.78s/it, loss=3.13, epoch=0.129, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 548/4220 [34:33<3:51:22,  3.78s/it, loss=3.13, epoch=0.129, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 548/4220 [34:33<3:51:22,  3.78s/it, loss=2.58, epoch=0.13, learning_rate=1.92e-5] \u001b[A\n",
      " 13%|█▎        | 549/4220 [34:37<3:51:22,  3.78s/it, loss=2.58, epoch=0.13, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 549/4220 [34:37<3:51:22,  3.78s/it, loss=2.71, epoch=0.13, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 550/4220 [34:40<3:51:14,  3.78s/it, loss=2.71, epoch=0.13, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 550/4220 [34:40<3:51:14,  3.78s/it, loss=3.11, epoch=0.13, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 551/4220 [34:44<3:51:12,  3.78s/it, loss=3.11, epoch=0.13, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 551/4220 [34:44<3:51:12,  3.78s/it, loss=2.92, epoch=0.13, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 552/4220 [34:48<3:51:07,  3.78s/it, loss=2.92, epoch=0.13, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 552/4220 [34:48<3:51:07,  3.78s/it, loss=2.14, epoch=0.131, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 553/4220 [34:52<3:51:02,  3.78s/it, loss=2.14, epoch=0.131, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 553/4220 [34:52<3:51:02,  3.78s/it, loss=2.67, epoch=0.131, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 554/4220 [34:55<3:50:54,  3.78s/it, loss=2.67, epoch=0.131, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 554/4220 [34:55<3:50:54,  3.78s/it, loss=3, epoch=0.131, learning_rate=1.92e-5]   \u001b[A\n",
      " 13%|█▎        | 555/4220 [34:59<3:50:54,  3.78s/it, loss=3, epoch=0.131, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 555/4220 [34:59<3:50:54,  3.78s/it, loss=2.78, epoch=0.131, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 556/4220 [35:03<3:50:48,  3.78s/it, loss=2.78, epoch=0.131, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 556/4220 [35:03<3:50:48,  3.78s/it, loss=2.68, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 557/4220 [35:07<3:50:39,  3.78s/it, loss=2.68, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 557/4220 [35:07<3:50:39,  3.78s/it, loss=2.69, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 558/4220 [35:11<3:50:41,  3.78s/it, loss=2.69, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 558/4220 [35:11<3:50:41,  3.78s/it, loss=3.04, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 559/4220 [35:14<3:50:33,  3.78s/it, loss=3.04, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 559/4220 [35:14<3:50:33,  3.78s/it, loss=2.64, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 560/4220 [35:18<3:50:29,  3.78s/it, loss=2.64, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 560/4220 [35:18<3:50:29,  3.78s/it, loss=2.38, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 561/4220 [35:22<3:50:28,  3.78s/it, loss=2.38, epoch=0.132, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 561/4220 [35:22<3:50:28,  3.78s/it, loss=2.94, epoch=0.133, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 562/4220 [35:26<3:50:24,  3.78s/it, loss=2.94, epoch=0.133, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 562/4220 [35:26<3:50:24,  3.78s/it, loss=2.93, epoch=0.133, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 563/4220 [35:29<3:50:24,  3.78s/it, loss=2.93, epoch=0.133, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 563/4220 [35:29<3:50:24,  3.78s/it, loss=3.37, epoch=0.133, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 564/4220 [35:33<3:50:09,  3.78s/it, loss=3.37, epoch=0.133, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 564/4220 [35:33<3:50:09,  3.78s/it, loss=2.82, epoch=0.133, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 565/4220 [35:37<3:50:10,  3.78s/it, loss=2.82, epoch=0.133, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 565/4220 [35:37<3:50:10,  3.78s/it, loss=2.76, epoch=0.134, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 566/4220 [35:41<3:50:03,  3.78s/it, loss=2.76, epoch=0.134, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 566/4220 [35:41<3:50:03,  3.78s/it, loss=2.91, epoch=0.134, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 567/4220 [35:45<3:50:04,  3.78s/it, loss=2.91, epoch=0.134, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 567/4220 [35:45<3:50:04,  3.78s/it, loss=3.15, epoch=0.134, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 568/4220 [35:48<3:50:05,  3.78s/it, loss=3.15, epoch=0.134, learning_rate=1.92e-5]\u001b[A\n",
      " 13%|█▎        | 568/4220 [35:48<3:50:05,  3.78s/it, loss=2.99, epoch=0.134, learning_rate=1.91e-5]\u001b[A\n",
      " 13%|█▎        | 569/4220 [35:52<3:50:02,  3.78s/it, loss=2.99, epoch=0.134, learning_rate=1.91e-5]\u001b[A\n",
      " 13%|█▎        | 569/4220 [35:52<3:50:02,  3.78s/it, loss=3.03, epoch=0.135, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 570/4220 [35:56<3:49:56,  3.78s/it, loss=3.03, epoch=0.135, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 570/4220 [35:56<3:49:56,  3.78s/it, loss=2.38, epoch=0.135, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 571/4220 [36:00<3:49:52,  3.78s/it, loss=2.38, epoch=0.135, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 571/4220 [36:00<3:49:52,  3.78s/it, loss=2.77, epoch=0.135, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 572/4220 [36:03<3:49:47,  3.78s/it, loss=2.77, epoch=0.135, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 572/4220 [36:03<3:49:47,  3.78s/it, loss=2.84, epoch=0.135, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 573/4220 [36:07<3:49:45,  3.78s/it, loss=2.84, epoch=0.135, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 573/4220 [36:07<3:49:45,  3.78s/it, loss=2.78, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 574/4220 [36:11<3:49:43,  3.78s/it, loss=2.78, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 574/4220 [36:11<3:49:43,  3.78s/it, loss=3.03, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 575/4220 [36:15<3:49:36,  3.78s/it, loss=3.03, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 575/4220 [36:15<3:49:36,  3.78s/it, loss=3.14, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 576/4220 [36:19<3:49:28,  3.78s/it, loss=3.14, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 576/4220 [36:19<3:49:28,  3.78s/it, loss=2.99, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 577/4220 [36:22<3:49:23,  3.78s/it, loss=2.99, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 577/4220 [36:22<3:49:23,  3.78s/it, loss=2.66, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 578/4220 [36:26<3:49:21,  3.78s/it, loss=2.66, epoch=0.136, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 578/4220 [36:26<3:49:21,  3.78s/it, loss=2.73, epoch=0.137, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 579/4220 [36:30<3:49:19,  3.78s/it, loss=2.73, epoch=0.137, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 579/4220 [36:30<3:49:19,  3.78s/it, loss=2.87, epoch=0.137, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 580/4220 [36:34<3:49:20,  3.78s/it, loss=2.87, epoch=0.137, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▎        | 580/4220 [36:34<3:49:20,  3.78s/it, loss=3.38, epoch=0.137, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 581/4220 [36:37<3:49:10,  3.78s/it, loss=3.38, epoch=0.137, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 581/4220 [36:37<3:49:10,  3.78s/it, loss=2.88, epoch=0.137, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 582/4220 [36:41<3:49:08,  3.78s/it, loss=2.88, epoch=0.137, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 582/4220 [36:41<3:49:08,  3.78s/it, loss=2.79, epoch=0.138, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 583/4220 [36:45<3:49:03,  3.78s/it, loss=2.79, epoch=0.138, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 583/4220 [36:45<3:49:03,  3.78s/it, loss=2.79, epoch=0.138, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 584/4220 [36:49<3:49:02,  3.78s/it, loss=2.79, epoch=0.138, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 584/4220 [36:49<3:49:02,  3.78s/it, loss=3.1, epoch=0.138, learning_rate=1.91e-5] \u001b[A\n",
      " 14%|█▍        | 585/4220 [36:53<3:48:59,  3.78s/it, loss=3.1, epoch=0.138, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 585/4220 [36:53<3:48:59,  3.78s/it, loss=2.89, epoch=0.138, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 586/4220 [36:56<3:48:55,  3.78s/it, loss=2.89, epoch=0.138, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 586/4220 [36:56<3:48:55,  3.78s/it, loss=2.72, epoch=0.139, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 587/4220 [37:00<3:48:54,  3.78s/it, loss=2.72, epoch=0.139, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 587/4220 [37:00<3:48:54,  3.78s/it, loss=2.93, epoch=0.139, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 588/4220 [37:04<3:48:53,  3.78s/it, loss=2.93, epoch=0.139, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 588/4220 [37:04<3:48:53,  3.78s/it, loss=3.09, epoch=0.139, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 589/4220 [37:08<3:48:45,  3.78s/it, loss=3.09, epoch=0.139, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 589/4220 [37:08<3:48:45,  3.78s/it, loss=3.2, epoch=0.139, learning_rate=1.91e-5] \u001b[A\n",
      " 14%|█▍        | 590/4220 [37:11<3:48:38,  3.78s/it, loss=3.2, epoch=0.139, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 590/4220 [37:11<3:48:38,  3.78s/it, loss=2.82, epoch=0.14, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 591/4220 [37:15<3:48:35,  3.78s/it, loss=2.82, epoch=0.14, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 591/4220 [37:15<3:48:35,  3.78s/it, loss=2.27, epoch=0.14, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 592/4220 [37:19<3:48:31,  3.78s/it, loss=2.27, epoch=0.14, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 592/4220 [37:19<3:48:31,  3.78s/it, loss=3.04, epoch=0.14, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 593/4220 [37:23<3:48:30,  3.78s/it, loss=3.04, epoch=0.14, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 593/4220 [37:23<3:48:30,  3.78s/it, loss=2.21, epoch=0.14, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 594/4220 [37:27<3:48:24,  3.78s/it, loss=2.21, epoch=0.14, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 594/4220 [37:27<3:48:24,  3.78s/it, loss=2.82, epoch=0.141, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 595/4220 [37:30<3:48:19,  3.78s/it, loss=2.82, epoch=0.141, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 595/4220 [37:30<3:48:19,  3.78s/it, loss=2.68, epoch=0.141, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 596/4220 [37:34<3:48:19,  3.78s/it, loss=2.68, epoch=0.141, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 596/4220 [37:34<3:48:19,  3.78s/it, loss=2.93, epoch=0.141, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 597/4220 [37:38<3:48:14,  3.78s/it, loss=2.93, epoch=0.141, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 597/4220 [37:38<3:48:14,  3.78s/it, loss=3.04, epoch=0.141, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 598/4220 [37:42<3:48:12,  3.78s/it, loss=3.04, epoch=0.141, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 598/4220 [37:42<3:48:12,  3.78s/it, loss=2.6, epoch=0.141, learning_rate=1.91e-5] \u001b[A\n",
      " 14%|█▍        | 599/4220 [37:45<3:48:12,  3.78s/it, loss=2.6, epoch=0.141, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 599/4220 [37:45<3:48:12,  3.78s/it, loss=3.24, epoch=0.142, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 600/4220 [37:49<3:48:02,  3.78s/it, loss=3.24, epoch=0.142, learning_rate=1.91e-5]\u001b[A\n",
      " 14%|█▍        | 600/4220 [37:49<3:48:02,  3.78s/it, loss=2.82, epoch=0.142, learning_rate=1.9e-5] \u001b[A\n",
      " 14%|█▍        | 601/4220 [37:53<3:48:00,  3.78s/it, loss=2.82, epoch=0.142, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 601/4220 [37:53<3:48:00,  3.78s/it, loss=2.78, epoch=0.142, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 602/4220 [37:57<3:47:53,  3.78s/it, loss=2.78, epoch=0.142, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 602/4220 [37:57<3:47:53,  3.78s/it, loss=2.74, epoch=0.142, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 603/4220 [38:01<3:47:48,  3.78s/it, loss=2.74, epoch=0.142, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 603/4220 [38:01<3:47:48,  3.78s/it, loss=3.39, epoch=0.143, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 604/4220 [38:04<3:47:48,  3.78s/it, loss=3.39, epoch=0.143, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 604/4220 [38:04<3:47:48,  3.78s/it, loss=3.15, epoch=0.143, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 605/4220 [38:08<3:47:47,  3.78s/it, loss=3.15, epoch=0.143, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 605/4220 [38:08<3:47:47,  3.78s/it, loss=2.76, epoch=0.143, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 606/4220 [38:12<3:47:33,  3.78s/it, loss=2.76, epoch=0.143, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 606/4220 [38:12<3:47:33,  3.78s/it, loss=2.24, epoch=0.143, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 607/4220 [38:16<3:47:34,  3.78s/it, loss=2.24, epoch=0.143, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 607/4220 [38:16<3:47:34,  3.78s/it, loss=3.12, epoch=0.144, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 608/4220 [38:20<3:47:34,  3.78s/it, loss=3.12, epoch=0.144, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 608/4220 [38:20<3:47:34,  3.78s/it, loss=2.85, epoch=0.144, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 609/4220 [38:23<3:47:30,  3.78s/it, loss=2.85, epoch=0.144, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 609/4220 [38:23<3:47:30,  3.78s/it, loss=3.47, epoch=0.144, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 610/4220 [38:27<3:47:27,  3.78s/it, loss=3.47, epoch=0.144, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 610/4220 [38:27<3:47:27,  3.78s/it, loss=3.06, epoch=0.144, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 611/4220 [38:31<3:47:19,  3.78s/it, loss=3.06, epoch=0.144, learning_rate=1.9e-5]\u001b[A\n",
      " 14%|█▍        | 611/4220 [38:31<3:47:19,  3.78s/it, loss=2.92, epoch=0.145, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 612/4220 [38:35<3:47:10,  3.78s/it, loss=2.92, epoch=0.145, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 612/4220 [38:35<3:47:10,  3.78s/it, loss=2.66, epoch=0.145, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 613/4220 [38:38<3:47:09,  3.78s/it, loss=2.66, epoch=0.145, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 613/4220 [38:38<3:47:09,  3.78s/it, loss=3.18, epoch=0.145, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 614/4220 [38:42<3:47:05,  3.78s/it, loss=3.18, epoch=0.145, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 614/4220 [38:42<3:47:05,  3.78s/it, loss=2.94, epoch=0.145, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 615/4220 [38:46<3:47:04,  3.78s/it, loss=2.94, epoch=0.145, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 615/4220 [38:46<3:47:04,  3.78s/it, loss=2.8, epoch=0.145, learning_rate=1.9e-5] \u001b[A\n",
      " 15%|█▍        | 616/4220 [38:50<3:46:58,  3.78s/it, loss=2.8, epoch=0.145, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 616/4220 [38:50<3:46:58,  3.78s/it, loss=2.32, epoch=0.146, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 617/4220 [38:54<3:46:54,  3.78s/it, loss=2.32, epoch=0.146, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 617/4220 [38:54<3:46:54,  3.78s/it, loss=3.29, epoch=0.146, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 618/4220 [38:57<3:46:53,  3.78s/it, loss=3.29, epoch=0.146, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 618/4220 [38:57<3:46:53,  3.78s/it, loss=2.76, epoch=0.146, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 619/4220 [39:01<3:46:47,  3.78s/it, loss=2.76, epoch=0.146, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 619/4220 [39:01<3:46:47,  3.78s/it, loss=2.94, epoch=0.146, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 620/4220 [39:05<3:46:44,  3.78s/it, loss=2.94, epoch=0.146, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 620/4220 [39:05<3:46:44,  3.78s/it, loss=2.55, epoch=0.147, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 621/4220 [39:09<3:46:42,  3.78s/it, loss=2.55, epoch=0.147, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 621/4220 [39:09<3:46:42,  3.78s/it, loss=3.01, epoch=0.147, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 622/4220 [39:12<3:46:35,  3.78s/it, loss=3.01, epoch=0.147, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 622/4220 [39:12<3:46:35,  3.78s/it, loss=2.69, epoch=0.147, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 623/4220 [39:16<3:46:31,  3.78s/it, loss=2.69, epoch=0.147, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 623/4220 [39:16<3:46:31,  3.78s/it, loss=2.68, epoch=0.147, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 624/4220 [39:20<3:46:25,  3.78s/it, loss=2.68, epoch=0.147, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 624/4220 [39:20<3:46:25,  3.78s/it, loss=2.93, epoch=0.148, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 625/4220 [39:24<3:46:25,  3.78s/it, loss=2.93, epoch=0.148, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 625/4220 [39:24<3:46:25,  3.78s/it, loss=2.84, epoch=0.148, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 626/4220 [39:28<3:46:23,  3.78s/it, loss=2.84, epoch=0.148, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 626/4220 [39:28<3:46:23,  3.78s/it, loss=2.79, epoch=0.148, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 627/4220 [39:31<3:46:20,  3.78s/it, loss=2.79, epoch=0.148, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 627/4220 [39:31<3:46:20,  3.78s/it, loss=2.88, epoch=0.148, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 628/4220 [39:35<3:46:15,  3.78s/it, loss=2.88, epoch=0.148, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 628/4220 [39:35<3:46:15,  3.78s/it, loss=2.86, epoch=0.149, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 629/4220 [39:39<3:46:08,  3.78s/it, loss=2.86, epoch=0.149, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 629/4220 [39:39<3:46:08,  3.78s/it, loss=2.78, epoch=0.149, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 630/4220 [39:43<3:46:11,  3.78s/it, loss=2.78, epoch=0.149, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 630/4220 [39:43<3:46:11,  3.78s/it, loss=3.29, epoch=0.149, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 631/4220 [39:46<3:46:07,  3.78s/it, loss=3.29, epoch=0.149, learning_rate=1.9e-5]\u001b[A\n",
      " 15%|█▍        | 631/4220 [39:46<3:46:07,  3.78s/it, loss=2.72, epoch=0.149, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▍        | 632/4220 [39:50<3:46:05,  3.78s/it, loss=2.72, epoch=0.149, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▍        | 632/4220 [39:50<3:46:05,  3.78s/it, loss=3.08, epoch=0.15, learning_rate=1.89e-5] \u001b[A\n",
      " 15%|█▌        | 633/4220 [39:54<3:46:05,  3.78s/it, loss=3.08, epoch=0.15, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 633/4220 [39:54<3:46:05,  3.78s/it, loss=2.67, epoch=0.15, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 634/4220 [39:58<3:45:59,  3.78s/it, loss=2.67, epoch=0.15, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 634/4220 [39:58<3:45:59,  3.78s/it, loss=2.37, epoch=0.15, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 635/4220 [40:02<3:45:53,  3.78s/it, loss=2.37, epoch=0.15, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 635/4220 [40:02<3:45:53,  3.78s/it, loss=2.75, epoch=0.15, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 636/4220 [40:05<3:45:48,  3.78s/it, loss=2.75, epoch=0.15, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 636/4220 [40:05<3:45:48,  3.78s/it, loss=3.15, epoch=0.15, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 637/4220 [40:09<3:45:45,  3.78s/it, loss=3.15, epoch=0.15, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 637/4220 [40:09<3:45:45,  3.78s/it, loss=3.07, epoch=0.151, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 638/4220 [40:13<3:45:34,  3.78s/it, loss=3.07, epoch=0.151, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 638/4220 [40:13<3:45:34,  3.78s/it, loss=2.8, epoch=0.151, learning_rate=1.89e-5] \u001b[A\n",
      " 15%|█▌        | 639/4220 [40:17<3:45:33,  3.78s/it, loss=2.8, epoch=0.151, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 639/4220 [40:17<3:45:33,  3.78s/it, loss=2.59, epoch=0.151, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 640/4220 [40:20<3:45:25,  3.78s/it, loss=2.59, epoch=0.151, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 640/4220 [40:20<3:45:25,  3.78s/it, loss=2.63, epoch=0.151, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 641/4220 [40:24<3:45:21,  3.78s/it, loss=2.63, epoch=0.151, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 641/4220 [40:24<3:45:21,  3.78s/it, loss=2.41, epoch=0.152, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 642/4220 [40:28<3:45:08,  3.78s/it, loss=2.41, epoch=0.152, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 642/4220 [40:28<3:45:08,  3.78s/it, loss=2.71, epoch=0.152, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 643/4220 [40:32<3:45:11,  3.78s/it, loss=2.71, epoch=0.152, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 643/4220 [40:32<3:45:11,  3.78s/it, loss=3.19, epoch=0.152, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 644/4220 [40:36<3:45:08,  3.78s/it, loss=3.19, epoch=0.152, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 644/4220 [40:36<3:45:08,  3.78s/it, loss=2.51, epoch=0.152, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 645/4220 [40:39<3:45:05,  3.78s/it, loss=2.51, epoch=0.152, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 645/4220 [40:39<3:45:05,  3.78s/it, loss=2.46, epoch=0.153, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 646/4220 [40:43<3:45:07,  3.78s/it, loss=2.46, epoch=0.153, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 646/4220 [40:43<3:45:07,  3.78s/it, loss=2.51, epoch=0.153, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 647/4220 [40:47<3:44:56,  3.78s/it, loss=2.51, epoch=0.153, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 647/4220 [40:47<3:44:56,  3.78s/it, loss=2.77, epoch=0.153, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 648/4220 [40:51<3:44:56,  3.78s/it, loss=2.77, epoch=0.153, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 648/4220 [40:51<3:44:56,  3.78s/it, loss=3.11, epoch=0.153, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 649/4220 [40:54<3:44:55,  3.78s/it, loss=3.11, epoch=0.153, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 649/4220 [40:54<3:44:55,  3.78s/it, loss=3.15, epoch=0.154, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 650/4220 [40:58<3:44:55,  3.78s/it, loss=3.15, epoch=0.154, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 650/4220 [40:58<3:44:55,  3.78s/it, loss=2.83, epoch=0.154, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 651/4220 [41:02<3:44:49,  3.78s/it, loss=2.83, epoch=0.154, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 651/4220 [41:02<3:44:49,  3.78s/it, loss=2.7, epoch=0.154, learning_rate=1.89e-5] \u001b[A\n",
      " 15%|█▌        | 652/4220 [41:06<3:44:48,  3.78s/it, loss=2.7, epoch=0.154, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 652/4220 [41:06<3:44:48,  3.78s/it, loss=2.97, epoch=0.154, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 653/4220 [41:10<3:44:47,  3.78s/it, loss=2.97, epoch=0.154, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 653/4220 [41:10<3:44:47,  3.78s/it, loss=2.95, epoch=0.155, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 654/4220 [41:13<3:44:38,  3.78s/it, loss=2.95, epoch=0.155, learning_rate=1.89e-5]\u001b[A\n",
      " 15%|█▌        | 654/4220 [41:13<3:44:38,  3.78s/it, loss=2.83, epoch=0.155, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 655/4220 [41:17<3:44:26,  3.78s/it, loss=2.83, epoch=0.155, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 655/4220 [41:17<3:44:26,  3.78s/it, loss=3.15, epoch=0.155, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 656/4220 [41:21<3:44:24,  3.78s/it, loss=3.15, epoch=0.155, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 656/4220 [41:21<3:44:24,  3.78s/it, loss=2.44, epoch=0.155, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 657/4220 [41:25<3:44:16,  3.78s/it, loss=2.44, epoch=0.155, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 657/4220 [41:25<3:44:16,  3.78s/it, loss=3, epoch=0.155, learning_rate=1.89e-5]   \u001b[A\n",
      " 16%|█▌        | 658/4220 [41:28<3:44:14,  3.78s/it, loss=3, epoch=0.155, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 658/4220 [41:28<3:44:14,  3.78s/it, loss=2.84, epoch=0.156, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 659/4220 [41:32<3:44:19,  3.78s/it, loss=2.84, epoch=0.156, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 659/4220 [41:32<3:44:19,  3.78s/it, loss=3.16, epoch=0.156, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 660/4220 [41:36<3:44:13,  3.78s/it, loss=3.16, epoch=0.156, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 660/4220 [41:36<3:44:13,  3.78s/it, loss=2.68, epoch=0.156, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 661/4220 [41:40<3:44:06,  3.78s/it, loss=2.68, epoch=0.156, learning_rate=1.89e-5]\u001b[A\n",
      " 16%|█▌        | 661/4220 [41:40<3:44:06,  3.78s/it, loss=2.59, epoch=0.156, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 662/4220 [41:44<3:44:05,  3.78s/it, loss=2.59, epoch=0.156, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 662/4220 [41:44<3:44:05,  3.78s/it, loss=3.11, epoch=0.157, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 663/4220 [41:47<3:44:05,  3.78s/it, loss=3.11, epoch=0.157, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 663/4220 [41:47<3:44:05,  3.78s/it, loss=3.03, epoch=0.157, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 664/4220 [41:51<3:44:07,  3.78s/it, loss=3.03, epoch=0.157, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 664/4220 [41:51<3:44:07,  3.78s/it, loss=2.87, epoch=0.157, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 665/4220 [41:55<3:43:53,  3.78s/it, loss=2.87, epoch=0.157, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 665/4220 [41:55<3:43:53,  3.78s/it, loss=2.82, epoch=0.157, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 666/4220 [41:59<3:43:47,  3.78s/it, loss=2.82, epoch=0.157, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 666/4220 [41:59<3:43:47,  3.78s/it, loss=2.35, epoch=0.158, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 667/4220 [42:02<3:43:46,  3.78s/it, loss=2.35, epoch=0.158, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 667/4220 [42:02<3:43:46,  3.78s/it, loss=2.94, epoch=0.158, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 668/4220 [42:06<3:43:39,  3.78s/it, loss=2.94, epoch=0.158, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 668/4220 [42:06<3:43:39,  3.78s/it, loss=2.43, epoch=0.158, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 669/4220 [42:10<3:43:37,  3.78s/it, loss=2.43, epoch=0.158, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 669/4220 [42:10<3:43:37,  3.78s/it, loss=2.7, epoch=0.158, learning_rate=1.88e-5] \u001b[A\n",
      " 16%|█▌        | 670/4220 [42:14<3:43:40,  3.78s/it, loss=2.7, epoch=0.158, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 670/4220 [42:14<3:43:40,  3.78s/it, loss=2.71, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 671/4220 [42:18<3:43:37,  3.78s/it, loss=2.71, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 671/4220 [42:18<3:43:37,  3.78s/it, loss=2.93, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 672/4220 [42:21<3:43:34,  3.78s/it, loss=2.93, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 672/4220 [42:21<3:43:34,  3.78s/it, loss=3.12, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 673/4220 [42:25<3:43:26,  3.78s/it, loss=3.12, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 673/4220 [42:25<3:43:26,  3.78s/it, loss=2.74, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 674/4220 [42:29<3:43:26,  3.78s/it, loss=2.74, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 674/4220 [42:29<3:43:26,  3.78s/it, loss=3.32, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 675/4220 [42:33<3:43:24,  3.78s/it, loss=3.32, epoch=0.159, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 675/4220 [42:33<3:43:24,  3.78s/it, loss=2.89, epoch=0.16, learning_rate=1.88e-5] \u001b[A\n",
      " 16%|█▌        | 676/4220 [42:36<3:43:21,  3.78s/it, loss=2.89, epoch=0.16, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 676/4220 [42:36<3:43:21,  3.78s/it, loss=2.78, epoch=0.16, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 677/4220 [42:40<3:43:10,  3.78s/it, loss=2.78, epoch=0.16, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 677/4220 [42:40<3:43:10,  3.78s/it, loss=2.37, epoch=0.16, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 678/4220 [42:44<3:43:07,  3.78s/it, loss=2.37, epoch=0.16, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 678/4220 [42:44<3:43:07,  3.78s/it, loss=2.88, epoch=0.16, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 679/4220 [42:48<3:43:01,  3.78s/it, loss=2.88, epoch=0.16, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 679/4220 [42:48<3:43:01,  3.78s/it, loss=3.26, epoch=0.161, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 680/4220 [42:52<3:42:52,  3.78s/it, loss=3.26, epoch=0.161, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 680/4220 [42:52<3:42:52,  3.78s/it, loss=3.08, epoch=0.161, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 681/4220 [42:55<3:42:52,  3.78s/it, loss=3.08, epoch=0.161, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 681/4220 [42:55<3:42:52,  3.78s/it, loss=2.31, epoch=0.161, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 682/4220 [42:59<3:42:45,  3.78s/it, loss=2.31, epoch=0.161, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 682/4220 [42:59<3:42:45,  3.78s/it, loss=2.57, epoch=0.161, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 683/4220 [43:03<3:42:44,  3.78s/it, loss=2.57, epoch=0.161, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 683/4220 [43:03<3:42:44,  3.78s/it, loss=2.65, epoch=0.162, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 684/4220 [43:07<3:42:40,  3.78s/it, loss=2.65, epoch=0.162, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 684/4220 [43:07<3:42:40,  3.78s/it, loss=2.37, epoch=0.162, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 685/4220 [43:10<3:42:34,  3.78s/it, loss=2.37, epoch=0.162, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▌        | 685/4220 [43:10<3:42:34,  3.78s/it, loss=2.7, epoch=0.162, learning_rate=1.88e-5] \u001b[A\n",
      " 16%|█▋        | 686/4220 [43:14<3:42:35,  3.78s/it, loss=2.7, epoch=0.162, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▋        | 686/4220 [43:14<3:42:35,  3.78s/it, loss=2.86, epoch=0.162, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▋        | 687/4220 [43:18<3:42:35,  3.78s/it, loss=2.86, epoch=0.162, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▋        | 687/4220 [43:18<3:42:35,  3.78s/it, loss=3.16, epoch=0.163, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▋        | 688/4220 [43:22<3:42:30,  3.78s/it, loss=3.16, epoch=0.163, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▋        | 688/4220 [43:22<3:42:30,  3.78s/it, loss=3.16, epoch=0.163, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▋        | 689/4220 [43:26<3:42:25,  3.78s/it, loss=3.16, epoch=0.163, learning_rate=1.88e-5]\u001b[A\n",
      " 16%|█▋        | 689/4220 [43:26<3:42:25,  3.78s/it, loss=2.9, epoch=0.163, learning_rate=1.87e-5] \u001b[A\n",
      " 16%|█▋        | 690/4220 [43:29<3:42:23,  3.78s/it, loss=2.9, epoch=0.163, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 690/4220 [43:29<3:42:23,  3.78s/it, loss=2.89, epoch=0.163, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 691/4220 [43:33<3:42:19,  3.78s/it, loss=2.89, epoch=0.163, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 691/4220 [43:33<3:42:19,  3.78s/it, loss=3.11, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 692/4220 [43:37<3:42:15,  3.78s/it, loss=3.11, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 692/4220 [43:37<3:42:15,  3.78s/it, loss=2.81, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 693/4220 [43:41<3:42:07,  3.78s/it, loss=2.81, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 693/4220 [43:41<3:42:07,  3.78s/it, loss=2.27, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 694/4220 [43:45<3:42:08,  3.78s/it, loss=2.27, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 694/4220 [43:45<3:42:08,  3.78s/it, loss=3.27, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 695/4220 [43:48<3:42:04,  3.78s/it, loss=3.27, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 695/4220 [43:48<3:42:04,  3.78s/it, loss=2.45, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 696/4220 [43:52<3:41:59,  3.78s/it, loss=2.45, epoch=0.164, learning_rate=1.87e-5]\u001b[A\n",
      " 16%|█▋        | 696/4220 [43:52<3:41:59,  3.78s/it, loss=2.82, epoch=0.165, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 697/4220 [43:56<3:41:56,  3.78s/it, loss=2.82, epoch=0.165, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 697/4220 [43:56<3:41:56,  3.78s/it, loss=2.48, epoch=0.165, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 698/4220 [44:00<3:41:50,  3.78s/it, loss=2.48, epoch=0.165, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 698/4220 [44:00<3:41:50,  3.78s/it, loss=2.76, epoch=0.165, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 699/4220 [44:03<3:41:50,  3.78s/it, loss=2.76, epoch=0.165, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 699/4220 [44:03<3:41:50,  3.78s/it, loss=3.43, epoch=0.165, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 700/4220 [44:07<3:41:39,  3.78s/it, loss=3.43, epoch=0.165, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 700/4220 [44:07<3:41:39,  3.78s/it, loss=2.38, epoch=0.166, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 701/4220 [44:11<3:41:41,  3.78s/it, loss=2.38, epoch=0.166, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 701/4220 [44:11<3:41:41,  3.78s/it, loss=2.81, epoch=0.166, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 702/4220 [44:15<3:41:32,  3.78s/it, loss=2.81, epoch=0.166, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 702/4220 [44:15<3:41:32,  3.78s/it, loss=2.67, epoch=0.166, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 703/4220 [44:19<3:41:24,  3.78s/it, loss=2.67, epoch=0.166, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 703/4220 [44:19<3:41:24,  3.78s/it, loss=2.9, epoch=0.166, learning_rate=1.87e-5] \u001b[A\n",
      " 17%|█▋        | 704/4220 [44:22<3:41:24,  3.78s/it, loss=2.9, epoch=0.166, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 704/4220 [44:22<3:41:24,  3.78s/it, loss=2.77, epoch=0.167, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 705/4220 [44:26<3:41:23,  3.78s/it, loss=2.77, epoch=0.167, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 705/4220 [44:26<3:41:23,  3.78s/it, loss=2.67, epoch=0.167, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 706/4220 [44:30<3:41:11,  3.78s/it, loss=2.67, epoch=0.167, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 706/4220 [44:30<3:41:11,  3.78s/it, loss=3.08, epoch=0.167, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 707/4220 [44:34<3:41:18,  3.78s/it, loss=3.08, epoch=0.167, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 707/4220 [44:34<3:41:18,  3.78s/it, loss=2.62, epoch=0.167, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 708/4220 [44:37<3:41:15,  3.78s/it, loss=2.62, epoch=0.167, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 708/4220 [44:37<3:41:15,  3.78s/it, loss=2.52, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 709/4220 [44:41<3:41:08,  3.78s/it, loss=2.52, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 709/4220 [44:41<3:41:08,  3.78s/it, loss=2.85, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 710/4220 [44:45<3:41:05,  3.78s/it, loss=2.85, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 710/4220 [44:45<3:41:05,  3.78s/it, loss=3.26, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 711/4220 [44:49<3:41:02,  3.78s/it, loss=3.26, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 711/4220 [44:49<3:41:02,  3.78s/it, loss=2.35, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 712/4220 [44:53<3:40:57,  3.78s/it, loss=2.35, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 712/4220 [44:53<3:40:57,  3.78s/it, loss=2.98, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 713/4220 [44:56<3:40:55,  3.78s/it, loss=2.98, epoch=0.168, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 713/4220 [44:56<3:40:55,  3.78s/it, loss=3.14, epoch=0.169, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 714/4220 [45:00<3:40:51,  3.78s/it, loss=3.14, epoch=0.169, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 714/4220 [45:00<3:40:51,  3.78s/it, loss=2.61, epoch=0.169, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 715/4220 [45:04<3:40:45,  3.78s/it, loss=2.61, epoch=0.169, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 715/4220 [45:04<3:40:45,  3.78s/it, loss=3.35, epoch=0.169, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 716/4220 [45:08<3:40:44,  3.78s/it, loss=3.35, epoch=0.169, learning_rate=1.87e-5]\u001b[A\n",
      " 17%|█▋        | 716/4220 [45:08<3:40:44,  3.78s/it, loss=2.81, epoch=0.169, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 717/4220 [45:11<3:40:42,  3.78s/it, loss=2.81, epoch=0.169, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 717/4220 [45:11<3:40:42,  3.78s/it, loss=2.91, epoch=0.17, learning_rate=1.86e-5] \u001b[A\n",
      " 17%|█▋        | 718/4220 [45:15<3:40:39,  3.78s/it, loss=2.91, epoch=0.17, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 718/4220 [45:15<3:40:39,  3.78s/it, loss=2.39, epoch=0.17, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 719/4220 [45:19<3:40:38,  3.78s/it, loss=2.39, epoch=0.17, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 719/4220 [45:19<3:40:38,  3.78s/it, loss=3.19, epoch=0.17, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 720/4220 [45:23<3:40:35,  3.78s/it, loss=3.19, epoch=0.17, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 720/4220 [45:23<3:40:35,  3.78s/it, loss=2.6, epoch=0.17, learning_rate=1.86e-5] \u001b[A\n",
      " 17%|█▋        | 721/4220 [45:27<3:40:26,  3.78s/it, loss=2.6, epoch=0.17, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 721/4220 [45:27<3:40:26,  3.78s/it, loss=2.38, epoch=0.171, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 722/4220 [45:30<3:40:20,  3.78s/it, loss=2.38, epoch=0.171, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 722/4220 [45:30<3:40:20,  3.78s/it, loss=3.36, epoch=0.171, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 723/4220 [45:34<3:40:19,  3.78s/it, loss=3.36, epoch=0.171, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 723/4220 [45:34<3:40:19,  3.78s/it, loss=2.64, epoch=0.171, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 724/4220 [45:38<3:40:20,  3.78s/it, loss=2.64, epoch=0.171, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 724/4220 [45:38<3:40:20,  3.78s/it, loss=3.19, epoch=0.171, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 725/4220 [45:42<3:40:16,  3.78s/it, loss=3.19, epoch=0.171, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 725/4220 [45:42<3:40:16,  3.78s/it, loss=2.77, epoch=0.172, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 726/4220 [45:45<3:40:06,  3.78s/it, loss=2.77, epoch=0.172, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 726/4220 [45:45<3:40:06,  3.78s/it, loss=2.76, epoch=0.172, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 727/4220 [45:49<3:40:03,  3.78s/it, loss=2.76, epoch=0.172, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 727/4220 [45:49<3:40:03,  3.78s/it, loss=2.54, epoch=0.172, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 728/4220 [45:53<3:39:57,  3.78s/it, loss=2.54, epoch=0.172, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 728/4220 [45:53<3:39:57,  3.78s/it, loss=2.45, epoch=0.172, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 729/4220 [45:57<3:39:53,  3.78s/it, loss=2.45, epoch=0.172, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 729/4220 [45:57<3:39:53,  3.78s/it, loss=2.83, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 730/4220 [46:01<3:39:48,  3.78s/it, loss=2.83, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 730/4220 [46:01<3:39:48,  3.78s/it, loss=2.85, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 731/4220 [46:04<3:39:48,  3.78s/it, loss=2.85, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 731/4220 [46:04<3:39:48,  3.78s/it, loss=2.88, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 732/4220 [46:08<3:39:43,  3.78s/it, loss=2.88, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 732/4220 [46:08<3:39:43,  3.78s/it, loss=2.92, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 733/4220 [46:12<3:39:37,  3.78s/it, loss=2.92, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 733/4220 [46:12<3:39:37,  3.78s/it, loss=2.72, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 734/4220 [46:16<3:39:32,  3.78s/it, loss=2.72, epoch=0.173, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 734/4220 [46:16<3:39:32,  3.78s/it, loss=3.07, epoch=0.174, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 735/4220 [46:19<3:39:33,  3.78s/it, loss=3.07, epoch=0.174, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 735/4220 [46:19<3:39:33,  3.78s/it, loss=2.63, epoch=0.174, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 736/4220 [46:23<3:39:29,  3.78s/it, loss=2.63, epoch=0.174, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 736/4220 [46:23<3:39:29,  3.78s/it, loss=2.96, epoch=0.174, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 737/4220 [46:27<3:39:25,  3.78s/it, loss=2.96, epoch=0.174, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 737/4220 [46:27<3:39:25,  3.78s/it, loss=2.28, epoch=0.174, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 738/4220 [46:31<3:39:18,  3.78s/it, loss=2.28, epoch=0.174, learning_rate=1.86e-5]\u001b[A\n",
      " 17%|█▋        | 738/4220 [46:31<3:39:18,  3.78s/it, loss=2.61, epoch=0.175, learning_rate=1.86e-5]\u001b[A\n",
      " 18%|█▊        | 739/4220 [46:35<3:39:18,  3.78s/it, loss=2.61, epoch=0.175, learning_rate=1.86e-5]\u001b[A\n",
      " 18%|█▊        | 739/4220 [46:35<3:39:18,  3.78s/it, loss=2.63, epoch=0.175, learning_rate=1.86e-5]\u001b[A\n",
      " 18%|█▊        | 740/4220 [46:38<3:39:13,  3.78s/it, loss=2.63, epoch=0.175, learning_rate=1.86e-5]\u001b[A\n",
      " 18%|█▊        | 740/4220 [46:38<3:39:13,  3.78s/it, loss=2.97, epoch=0.175, learning_rate=1.86e-5]\u001b[A\n",
      " 18%|█▊        | 741/4220 [46:42<3:38:59,  3.78s/it, loss=2.97, epoch=0.175, learning_rate=1.86e-5]\u001b[A\n",
      " 18%|█▊        | 741/4220 [46:42<3:38:59,  3.78s/it, loss=2.68, epoch=0.175, learning_rate=1.86e-5]\u001b[A\n",
      " 18%|█▊        | 742/4220 [46:46<3:39:01,  3.78s/it, loss=2.68, epoch=0.175, learning_rate=1.86e-5]\u001b[A\n",
      " 18%|█▊        | 742/4220 [46:46<3:39:01,  3.78s/it, loss=2.81, epoch=0.176, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 743/4220 [46:50<3:38:59,  3.78s/it, loss=2.81, epoch=0.176, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 743/4220 [46:50<3:38:59,  3.78s/it, loss=2.57, epoch=0.176, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 744/4220 [46:53<3:38:55,  3.78s/it, loss=2.57, epoch=0.176, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 744/4220 [46:53<3:38:55,  3.78s/it, loss=2.94, epoch=0.176, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 745/4220 [46:57<3:38:58,  3.78s/it, loss=2.94, epoch=0.176, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 745/4220 [46:57<3:38:58,  3.78s/it, loss=2.76, epoch=0.176, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 746/4220 [47:01<3:38:56,  3.78s/it, loss=2.76, epoch=0.176, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 746/4220 [47:01<3:38:56,  3.78s/it, loss=3.18, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 747/4220 [47:05<3:38:53,  3.78s/it, loss=3.18, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 747/4220 [47:05<3:38:53,  3.78s/it, loss=2.82, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 748/4220 [47:09<3:38:48,  3.78s/it, loss=2.82, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 748/4220 [47:09<3:38:48,  3.78s/it, loss=2.93, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 749/4220 [47:12<3:38:41,  3.78s/it, loss=2.93, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 749/4220 [47:12<3:38:41,  3.78s/it, loss=2.67, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 750/4220 [47:16<3:38:35,  3.78s/it, loss=2.67, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 750/4220 [47:16<3:38:35,  3.78s/it, loss=2.62, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 751/4220 [47:20<3:38:38,  3.78s/it, loss=2.62, epoch=0.177, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 751/4220 [47:20<3:38:38,  3.78s/it, loss=2.72, epoch=0.178, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 752/4220 [47:24<3:38:28,  3.78s/it, loss=2.72, epoch=0.178, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 752/4220 [47:24<3:38:28,  3.78s/it, loss=2.15, epoch=0.178, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 753/4220 [47:28<3:38:23,  3.78s/it, loss=2.15, epoch=0.178, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 753/4220 [47:28<3:38:23,  3.78s/it, loss=2.25, epoch=0.178, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 754/4220 [47:31<3:38:22,  3.78s/it, loss=2.25, epoch=0.178, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 754/4220 [47:31<3:38:22,  3.78s/it, loss=2.98, epoch=0.178, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 755/4220 [47:35<3:38:17,  3.78s/it, loss=2.98, epoch=0.178, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 755/4220 [47:35<3:38:17,  3.78s/it, loss=3.01, epoch=0.179, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 756/4220 [47:39<3:38:11,  3.78s/it, loss=3.01, epoch=0.179, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 756/4220 [47:39<3:38:11,  3.78s/it, loss=2.53, epoch=0.179, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 757/4220 [47:43<3:38:04,  3.78s/it, loss=2.53, epoch=0.179, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 757/4220 [47:43<3:38:04,  3.78s/it, loss=2.4, epoch=0.179, learning_rate=1.85e-5] \u001b[A\n",
      " 18%|█▊        | 758/4220 [47:46<3:38:01,  3.78s/it, loss=2.4, epoch=0.179, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 758/4220 [47:46<3:38:01,  3.78s/it, loss=2.89, epoch=0.179, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 759/4220 [47:50<3:38:03,  3.78s/it, loss=2.89, epoch=0.179, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 759/4220 [47:50<3:38:03,  3.78s/it, loss=2.42, epoch=0.18, learning_rate=1.85e-5] \u001b[A\n",
      " 18%|█▊        | 760/4220 [47:54<3:38:00,  3.78s/it, loss=2.42, epoch=0.18, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 760/4220 [47:54<3:38:00,  3.78s/it, loss=2.98, epoch=0.18, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 761/4220 [47:58<3:37:54,  3.78s/it, loss=2.98, epoch=0.18, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 761/4220 [47:58<3:37:54,  3.78s/it, loss=2.79, epoch=0.18, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 762/4220 [48:02<3:37:54,  3.78s/it, loss=2.79, epoch=0.18, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 762/4220 [48:02<3:37:54,  3.78s/it, loss=2.91, epoch=0.18, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 763/4220 [48:05<3:37:49,  3.78s/it, loss=2.91, epoch=0.18, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 763/4220 [48:05<3:37:49,  3.78s/it, loss=2.82, epoch=0.181, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 764/4220 [48:09<3:37:43,  3.78s/it, loss=2.82, epoch=0.181, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 764/4220 [48:09<3:37:43,  3.78s/it, loss=2.98, epoch=0.181, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 765/4220 [48:13<3:37:41,  3.78s/it, loss=2.98, epoch=0.181, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 765/4220 [48:13<3:37:41,  3.78s/it, loss=2.82, epoch=0.181, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 766/4220 [48:17<3:37:39,  3.78s/it, loss=2.82, epoch=0.181, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 766/4220 [48:17<3:37:39,  3.78s/it, loss=2.77, epoch=0.181, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 767/4220 [48:20<3:37:35,  3.78s/it, loss=2.77, epoch=0.181, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 767/4220 [48:20<3:37:35,  3.78s/it, loss=2.82, epoch=0.182, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 768/4220 [48:24<3:37:31,  3.78s/it, loss=2.82, epoch=0.182, learning_rate=1.85e-5]\u001b[A\n",
      " 18%|█▊        | 768/4220 [48:24<3:37:31,  3.78s/it, loss=2.72, epoch=0.182, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 769/4220 [48:28<3:37:29,  3.78s/it, loss=2.72, epoch=0.182, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 769/4220 [48:28<3:37:29,  3.78s/it, loss=2.84, epoch=0.182, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 770/4220 [48:32<3:37:23,  3.78s/it, loss=2.84, epoch=0.182, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 770/4220 [48:32<3:37:23,  3.78s/it, loss=3.26, epoch=0.182, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 771/4220 [48:36<3:37:13,  3.78s/it, loss=3.26, epoch=0.182, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 771/4220 [48:36<3:37:13,  3.78s/it, loss=2.94, epoch=0.182, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 772/4220 [48:39<3:37:05,  3.78s/it, loss=2.94, epoch=0.182, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 772/4220 [48:39<3:37:05,  3.78s/it, loss=2.67, epoch=0.183, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 773/4220 [48:43<3:36:57,  3.78s/it, loss=2.67, epoch=0.183, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 773/4220 [48:43<3:36:57,  3.78s/it, loss=2.86, epoch=0.183, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 774/4220 [48:47<3:36:58,  3.78s/it, loss=2.86, epoch=0.183, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 774/4220 [48:47<3:36:58,  3.78s/it, loss=2.69, epoch=0.183, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 775/4220 [48:51<3:36:59,  3.78s/it, loss=2.69, epoch=0.183, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 775/4220 [48:51<3:36:59,  3.78s/it, loss=2.93, epoch=0.183, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 776/4220 [48:54<3:36:57,  3.78s/it, loss=2.93, epoch=0.183, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 776/4220 [48:54<3:36:57,  3.78s/it, loss=3.11, epoch=0.184, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 777/4220 [48:58<3:36:50,  3.78s/it, loss=3.11, epoch=0.184, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 777/4220 [48:58<3:36:50,  3.78s/it, loss=3.17, epoch=0.184, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 778/4220 [49:02<3:36:47,  3.78s/it, loss=3.17, epoch=0.184, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 778/4220 [49:02<3:36:47,  3.78s/it, loss=2.85, epoch=0.184, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 779/4220 [49:06<3:36:44,  3.78s/it, loss=2.85, epoch=0.184, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 779/4220 [49:06<3:36:44,  3.78s/it, loss=2.61, epoch=0.184, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 780/4220 [49:10<3:36:37,  3.78s/it, loss=2.61, epoch=0.184, learning_rate=1.84e-5]\u001b[A\n",
      " 18%|█▊        | 780/4220 [49:10<3:36:37,  3.78s/it, loss=2.96, epoch=0.185, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 781/4220 [49:13<3:36:40,  3.78s/it, loss=2.96, epoch=0.185, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 781/4220 [49:13<3:36:40,  3.78s/it, loss=3.03, epoch=0.185, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 782/4220 [49:17<3:36:35,  3.78s/it, loss=3.03, epoch=0.185, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 782/4220 [49:17<3:36:35,  3.78s/it, loss=2.63, epoch=0.185, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 783/4220 [49:21<3:36:28,  3.78s/it, loss=2.63, epoch=0.185, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 783/4220 [49:21<3:36:28,  3.78s/it, loss=2.75, epoch=0.185, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 784/4220 [49:25<3:36:27,  3.78s/it, loss=2.75, epoch=0.185, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 784/4220 [49:25<3:36:27,  3.78s/it, loss=2.54, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 785/4220 [49:28<3:36:27,  3.78s/it, loss=2.54, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 785/4220 [49:28<3:36:27,  3.78s/it, loss=2.65, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 786/4220 [49:32<3:36:23,  3.78s/it, loss=2.65, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 786/4220 [49:32<3:36:23,  3.78s/it, loss=2.83, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 787/4220 [49:36<3:36:12,  3.78s/it, loss=2.83, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 787/4220 [49:36<3:36:12,  3.78s/it, loss=2.74, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 788/4220 [49:40<3:36:06,  3.78s/it, loss=2.74, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 788/4220 [49:40<3:36:06,  3.78s/it, loss=2.91, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 789/4220 [49:44<3:35:57,  3.78s/it, loss=2.91, epoch=0.186, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 789/4220 [49:44<3:35:57,  3.78s/it, loss=3.12, epoch=0.187, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 790/4220 [49:47<3:35:53,  3.78s/it, loss=3.12, epoch=0.187, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 790/4220 [49:47<3:35:53,  3.78s/it, loss=3.21, epoch=0.187, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 791/4220 [49:51<3:35:56,  3.78s/it, loss=3.21, epoch=0.187, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▊        | 791/4220 [49:51<3:35:56,  3.78s/it, loss=2.98, epoch=0.187, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▉        | 792/4220 [49:55<3:35:50,  3.78s/it, loss=2.98, epoch=0.187, learning_rate=1.84e-5]\u001b[A\n",
      " 19%|█▉        | 792/4220 [49:55<3:35:50,  3.78s/it, loss=3.1, epoch=0.187, learning_rate=1.83e-5] \u001b[A\n",
      " 19%|█▉        | 793/4220 [49:59<3:35:50,  3.78s/it, loss=3.1, epoch=0.187, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 793/4220 [49:59<3:35:50,  3.78s/it, loss=2.82, epoch=0.188, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 794/4220 [50:02<3:35:47,  3.78s/it, loss=2.82, epoch=0.188, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 794/4220 [50:02<3:35:47,  3.78s/it, loss=2.66, epoch=0.188, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 795/4220 [50:06<3:35:43,  3.78s/it, loss=2.66, epoch=0.188, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 795/4220 [50:06<3:35:43,  3.78s/it, loss=2.65, epoch=0.188, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 796/4220 [50:10<3:35:36,  3.78s/it, loss=2.65, epoch=0.188, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 796/4220 [50:10<3:35:36,  3.78s/it, loss=2.74, epoch=0.188, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 797/4220 [50:14<3:35:33,  3.78s/it, loss=2.74, epoch=0.188, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 797/4220 [50:14<3:35:33,  3.78s/it, loss=3.19, epoch=0.189, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 798/4220 [50:18<3:35:25,  3.78s/it, loss=3.19, epoch=0.189, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 798/4220 [50:18<3:35:25,  3.78s/it, loss=2.44, epoch=0.189, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 799/4220 [50:21<3:35:17,  3.78s/it, loss=2.44, epoch=0.189, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 799/4220 [50:21<3:35:17,  3.78s/it, loss=2.62, epoch=0.189, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 800/4220 [50:25<3:35:17,  3.78s/it, loss=2.62, epoch=0.189, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 800/4220 [50:25<3:35:17,  3.78s/it, loss=3.18, epoch=0.189, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 801/4220 [50:29<3:35:16,  3.78s/it, loss=3.18, epoch=0.189, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 801/4220 [50:29<3:35:16,  3.78s/it, loss=3.35, epoch=0.19, learning_rate=1.83e-5] \u001b[A\n",
      " 19%|█▉        | 802/4220 [50:33<3:35:13,  3.78s/it, loss=3.35, epoch=0.19, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 802/4220 [50:33<3:35:13,  3.78s/it, loss=2.82, epoch=0.19, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 803/4220 [50:36<3:35:09,  3.78s/it, loss=2.82, epoch=0.19, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 803/4220 [50:36<3:35:09,  3.78s/it, loss=2.7, epoch=0.19, learning_rate=1.83e-5] \u001b[A\n",
      " 19%|█▉        | 804/4220 [50:40<3:35:11,  3.78s/it, loss=2.7, epoch=0.19, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 804/4220 [50:40<3:35:11,  3.78s/it, loss=2.62, epoch=0.19, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 805/4220 [50:44<3:35:09,  3.78s/it, loss=2.62, epoch=0.19, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 805/4220 [50:44<3:35:09,  3.78s/it, loss=2.5, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 806/4220 [50:48<3:35:05,  3.78s/it, loss=2.5, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 806/4220 [50:48<3:35:05,  3.78s/it, loss=3.07, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 807/4220 [50:52<3:34:56,  3.78s/it, loss=3.07, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 807/4220 [50:52<3:34:56,  3.78s/it, loss=2.73, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 808/4220 [50:55<3:34:52,  3.78s/it, loss=2.73, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 808/4220 [50:55<3:34:52,  3.78s/it, loss=2.27, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 809/4220 [50:59<3:34:45,  3.78s/it, loss=2.27, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 809/4220 [50:59<3:34:45,  3.78s/it, loss=2.89, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 810/4220 [51:03<3:34:48,  3.78s/it, loss=2.89, epoch=0.191, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 810/4220 [51:03<3:34:48,  3.78s/it, loss=2.89, epoch=0.192, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 811/4220 [51:07<3:34:47,  3.78s/it, loss=2.89, epoch=0.192, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 811/4220 [51:07<3:34:47,  3.78s/it, loss=2.74, epoch=0.192, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 812/4220 [51:10<3:34:42,  3.78s/it, loss=2.74, epoch=0.192, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 812/4220 [51:10<3:34:42,  3.78s/it, loss=2.76, epoch=0.192, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 813/4220 [51:14<3:34:31,  3.78s/it, loss=2.76, epoch=0.192, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 813/4220 [51:14<3:34:31,  3.78s/it, loss=3.42, epoch=0.192, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 814/4220 [51:18<3:35:59,  3.80s/it, loss=3.42, epoch=0.192, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 814/4220 [51:18<3:35:59,  3.80s/it, loss=3, epoch=0.193, learning_rate=1.83e-5]   \u001b[A\n",
      " 19%|█▉        | 815/4220 [51:22<3:35:23,  3.80s/it, loss=3, epoch=0.193, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 815/4220 [51:22<3:35:23,  3.80s/it, loss=2.61, epoch=0.193, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 816/4220 [51:26<3:35:06,  3.79s/it, loss=2.61, epoch=0.193, learning_rate=1.83e-5]\u001b[A\n",
      " 19%|█▉        | 816/4220 [51:26<3:35:06,  3.79s/it, loss=2.71, epoch=0.193, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 817/4220 [51:29<3:34:55,  3.79s/it, loss=2.71, epoch=0.193, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 817/4220 [51:29<3:34:55,  3.79s/it, loss=2.52, epoch=0.193, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 818/4220 [51:33<3:34:37,  3.79s/it, loss=2.52, epoch=0.193, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 818/4220 [51:33<3:34:37,  3.79s/it, loss=3.19, epoch=0.194, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 819/4220 [51:37<3:34:27,  3.78s/it, loss=3.19, epoch=0.194, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 819/4220 [51:37<3:34:27,  3.78s/it, loss=2.7, epoch=0.194, learning_rate=1.82e-5] \u001b[A\n",
      " 19%|█▉        | 820/4220 [51:41<3:34:20,  3.78s/it, loss=2.7, epoch=0.194, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 820/4220 [51:41<3:34:20,  3.78s/it, loss=2.62, epoch=0.194, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 821/4220 [51:45<3:34:13,  3.78s/it, loss=2.62, epoch=0.194, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 821/4220 [51:45<3:34:13,  3.78s/it, loss=2.54, epoch=0.194, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 822/4220 [51:48<3:34:07,  3.78s/it, loss=2.54, epoch=0.194, learning_rate=1.82e-5]\u001b[A\n",
      " 19%|█▉        | 822/4220 [51:48<3:34:07,  3.78s/it, loss=2.71, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 823/4220 [51:52<3:34:10,  3.78s/it, loss=2.71, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 823/4220 [51:52<3:34:10,  3.78s/it, loss=2.79, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 824/4220 [51:56<3:34:07,  3.78s/it, loss=2.79, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 824/4220 [51:56<3:34:07,  3.78s/it, loss=3.05, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 825/4220 [52:00<3:34:00,  3.78s/it, loss=3.05, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 825/4220 [52:00<3:34:00,  3.78s/it, loss=2.68, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 826/4220 [52:03<3:33:55,  3.78s/it, loss=2.68, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 826/4220 [52:03<3:33:55,  3.78s/it, loss=2.64, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 827/4220 [52:07<3:33:49,  3.78s/it, loss=2.64, epoch=0.195, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 827/4220 [52:07<3:33:49,  3.78s/it, loss=2.65, epoch=0.196, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 828/4220 [52:11<3:33:47,  3.78s/it, loss=2.65, epoch=0.196, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 828/4220 [52:11<3:33:47,  3.78s/it, loss=3.44, epoch=0.196, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 829/4220 [52:15<3:33:37,  3.78s/it, loss=3.44, epoch=0.196, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 829/4220 [52:15<3:33:37,  3.78s/it, loss=2.36, epoch=0.196, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 830/4220 [52:19<3:33:36,  3.78s/it, loss=2.36, epoch=0.196, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 830/4220 [52:19<3:33:36,  3.78s/it, loss=2.66, epoch=0.196, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 831/4220 [52:22<3:33:23,  3.78s/it, loss=2.66, epoch=0.196, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 831/4220 [52:22<3:33:23,  3.78s/it, loss=2.81, epoch=0.197, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 832/4220 [52:26<3:33:27,  3.78s/it, loss=2.81, epoch=0.197, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 832/4220 [52:26<3:33:27,  3.78s/it, loss=2.81, epoch=0.197, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 833/4220 [52:30<3:33:26,  3.78s/it, loss=2.81, epoch=0.197, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 833/4220 [52:30<3:33:26,  3.78s/it, loss=2.79, epoch=0.197, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 834/4220 [52:34<3:33:16,  3.78s/it, loss=2.79, epoch=0.197, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 834/4220 [52:34<3:33:16,  3.78s/it, loss=2.36, epoch=0.197, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 835/4220 [52:38<3:33:14,  3.78s/it, loss=2.36, epoch=0.197, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 835/4220 [52:38<3:33:14,  3.78s/it, loss=2.48, epoch=0.198, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 836/4220 [52:41<3:33:11,  3.78s/it, loss=2.48, epoch=0.198, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 836/4220 [52:41<3:33:11,  3.78s/it, loss=2.85, epoch=0.198, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 837/4220 [52:45<3:33:04,  3.78s/it, loss=2.85, epoch=0.198, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 837/4220 [52:45<3:33:04,  3.78s/it, loss=2.9, epoch=0.198, learning_rate=1.82e-5] \u001b[A\n",
      " 20%|█▉        | 838/4220 [52:49<3:33:00,  3.78s/it, loss=2.9, epoch=0.198, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 838/4220 [52:49<3:33:00,  3.78s/it, loss=2.85, epoch=0.198, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 839/4220 [52:53<3:33:00,  3.78s/it, loss=2.85, epoch=0.198, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 839/4220 [52:53<3:33:00,  3.78s/it, loss=2.85, epoch=0.199, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 840/4220 [52:56<3:33:02,  3.78s/it, loss=2.85, epoch=0.199, learning_rate=1.82e-5]\u001b[A\n",
      " 20%|█▉        | 840/4220 [52:56<3:33:02,  3.78s/it, loss=3.05, epoch=0.199, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|█▉        | 841/4220 [53:00<3:32:57,  3.78s/it, loss=3.05, epoch=0.199, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|█▉        | 841/4220 [53:00<3:32:57,  3.78s/it, loss=2.91, epoch=0.199, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|█▉        | 842/4220 [53:04<3:32:50,  3.78s/it, loss=2.91, epoch=0.199, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|█▉        | 842/4220 [53:04<3:32:50,  3.78s/it, loss=3.19, epoch=0.199, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|█▉        | 843/4220 [53:08<3:32:42,  3.78s/it, loss=3.19, epoch=0.199, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|█▉        | 843/4220 [53:08<3:32:42,  3.78s/it, loss=3.15, epoch=0.2, learning_rate=1.81e-5]  \u001b[A\n",
      " 20%|██        | 844/4220 [53:12<3:32:36,  3.78s/it, loss=3.15, epoch=0.2, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 844/4220 [53:12<3:32:36,  3.78s/it, loss=2.95, epoch=0.2, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 845/4220 [53:15<3:32:31,  3.78s/it, loss=2.95, epoch=0.2, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 845/4220 [53:15<3:32:31,  3.78s/it, loss=2.69, epoch=0.2, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 846/4220 [53:19<3:32:28,  3.78s/it, loss=2.69, epoch=0.2, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 846/4220 [53:19<3:32:28,  3.78s/it, loss=3.11, epoch=0.2, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 847/4220 [53:23<3:32:27,  3.78s/it, loss=3.11, epoch=0.2, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 847/4220 [53:23<3:32:27,  3.78s/it, loss=2.44, epoch=0.2, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 848/4220 [53:27<3:32:26,  3.78s/it, loss=2.44, epoch=0.2, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 848/4220 [53:27<3:32:26,  3.78s/it, loss=2.22, epoch=0.201, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 849/4220 [53:30<3:32:24,  3.78s/it, loss=2.22, epoch=0.201, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 849/4220 [53:30<3:32:24,  3.78s/it, loss=2.96, epoch=0.201, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 850/4220 [53:34<3:32:19,  3.78s/it, loss=2.96, epoch=0.201, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 850/4220 [53:34<3:32:19,  3.78s/it, loss=3.3, epoch=0.201, learning_rate=1.81e-5] \u001b[A\n",
      " 20%|██        | 851/4220 [53:38<3:32:20,  3.78s/it, loss=3.3, epoch=0.201, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 851/4220 [53:38<3:32:20,  3.78s/it, loss=3.11, epoch=0.201, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 852/4220 [53:42<3:32:06,  3.78s/it, loss=3.11, epoch=0.201, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 852/4220 [53:42<3:32:06,  3.78s/it, loss=2.92, epoch=0.202, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 853/4220 [53:46<3:32:04,  3.78s/it, loss=2.92, epoch=0.202, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 853/4220 [53:46<3:32:04,  3.78s/it, loss=2.68, epoch=0.202, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 854/4220 [53:49<3:32:01,  3.78s/it, loss=2.68, epoch=0.202, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 854/4220 [53:49<3:32:01,  3.78s/it, loss=2.68, epoch=0.202, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 855/4220 [53:53<3:31:56,  3.78s/it, loss=2.68, epoch=0.202, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 855/4220 [53:53<3:31:56,  3.78s/it, loss=2.47, epoch=0.202, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 856/4220 [53:57<3:31:52,  3.78s/it, loss=2.47, epoch=0.202, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 856/4220 [53:57<3:31:52,  3.78s/it, loss=2.42, epoch=0.203, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 857/4220 [54:01<3:31:47,  3.78s/it, loss=2.42, epoch=0.203, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 857/4220 [54:01<3:31:47,  3.78s/it, loss=2.89, epoch=0.203, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 858/4220 [54:04<3:31:44,  3.78s/it, loss=2.89, epoch=0.203, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 858/4220 [54:04<3:31:44,  3.78s/it, loss=2.38, epoch=0.203, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 859/4220 [54:08<3:31:43,  3.78s/it, loss=2.38, epoch=0.203, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 859/4220 [54:08<3:31:43,  3.78s/it, loss=2.87, epoch=0.203, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 860/4220 [54:12<3:31:34,  3.78s/it, loss=2.87, epoch=0.203, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 860/4220 [54:12<3:31:34,  3.78s/it, loss=2.93, epoch=0.204, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 861/4220 [54:16<3:31:38,  3.78s/it, loss=2.93, epoch=0.204, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 861/4220 [54:16<3:31:38,  3.78s/it, loss=2.9, epoch=0.204, learning_rate=1.81e-5] \u001b[A\n",
      " 20%|██        | 862/4220 [54:20<3:31:31,  3.78s/it, loss=2.9, epoch=0.204, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 862/4220 [54:20<3:31:31,  3.78s/it, loss=2.42, epoch=0.204, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 863/4220 [54:23<3:31:22,  3.78s/it, loss=2.42, epoch=0.204, learning_rate=1.81e-5]\u001b[A\n",
      " 20%|██        | 863/4220 [54:23<3:31:22,  3.78s/it, loss=3, epoch=0.204, learning_rate=1.8e-5]    \u001b[A\n",
      " 20%|██        | 864/4220 [54:27<3:31:21,  3.78s/it, loss=3, epoch=0.204, learning_rate=1.8e-5]\u001b[A\n",
      " 20%|██        | 864/4220 [54:27<3:31:21,  3.78s/it, loss=2.74, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 20%|██        | 865/4220 [54:31<3:31:19,  3.78s/it, loss=2.74, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 20%|██        | 865/4220 [54:31<3:31:19,  3.78s/it, loss=2.96, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 866/4220 [54:35<3:31:14,  3.78s/it, loss=2.96, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 866/4220 [54:35<3:31:14,  3.78s/it, loss=2.57, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 867/4220 [54:38<3:31:18,  3.78s/it, loss=2.57, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 867/4220 [54:38<3:31:18,  3.78s/it, loss=2.91, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 868/4220 [54:42<3:31:14,  3.78s/it, loss=2.91, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 868/4220 [54:42<3:31:14,  3.78s/it, loss=2.97, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 869/4220 [54:46<3:31:13,  3.78s/it, loss=2.97, epoch=0.205, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 869/4220 [54:46<3:31:13,  3.78s/it, loss=2.28, epoch=0.206, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 870/4220 [54:50<3:31:07,  3.78s/it, loss=2.28, epoch=0.206, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 870/4220 [54:50<3:31:07,  3.78s/it, loss=2.54, epoch=0.206, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 871/4220 [54:54<3:31:02,  3.78s/it, loss=2.54, epoch=0.206, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 871/4220 [54:54<3:31:02,  3.78s/it, loss=2.88, epoch=0.206, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 872/4220 [54:57<3:30:53,  3.78s/it, loss=2.88, epoch=0.206, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 872/4220 [54:57<3:30:53,  3.78s/it, loss=3.09, epoch=0.206, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 873/4220 [55:01<3:30:50,  3.78s/it, loss=3.09, epoch=0.206, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 873/4220 [55:01<3:30:50,  3.78s/it, loss=2.8, epoch=0.207, learning_rate=1.8e-5] \u001b[A\n",
      " 21%|██        | 874/4220 [55:05<3:30:46,  3.78s/it, loss=2.8, epoch=0.207, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 874/4220 [55:05<3:30:46,  3.78s/it, loss=2.85, epoch=0.207, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 875/4220 [55:09<3:30:44,  3.78s/it, loss=2.85, epoch=0.207, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 875/4220 [55:09<3:30:44,  3.78s/it, loss=3.15, epoch=0.207, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 876/4220 [55:12<3:30:38,  3.78s/it, loss=3.15, epoch=0.207, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 876/4220 [55:12<3:30:38,  3.78s/it, loss=2.99, epoch=0.207, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 877/4220 [55:16<3:30:31,  3.78s/it, loss=2.99, epoch=0.207, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 877/4220 [55:16<3:30:31,  3.78s/it, loss=2.69, epoch=0.208, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 878/4220 [55:20<3:30:25,  3.78s/it, loss=2.69, epoch=0.208, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 878/4220 [55:20<3:30:25,  3.78s/it, loss=2.53, epoch=0.208, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 879/4220 [55:24<3:30:23,  3.78s/it, loss=2.53, epoch=0.208, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 879/4220 [55:24<3:30:23,  3.78s/it, loss=2.85, epoch=0.208, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 880/4220 [55:28<3:30:19,  3.78s/it, loss=2.85, epoch=0.208, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 880/4220 [55:28<3:30:19,  3.78s/it, loss=2.35, epoch=0.208, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 881/4220 [55:31<3:30:12,  3.78s/it, loss=2.35, epoch=0.208, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 881/4220 [55:31<3:30:12,  3.78s/it, loss=3.03, epoch=0.209, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 882/4220 [55:35<3:30:11,  3.78s/it, loss=3.03, epoch=0.209, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 882/4220 [55:35<3:30:11,  3.78s/it, loss=2.91, epoch=0.209, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 883/4220 [55:39<3:30:09,  3.78s/it, loss=2.91, epoch=0.209, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 883/4220 [55:39<3:30:09,  3.78s/it, loss=2.86, epoch=0.209, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 884/4220 [55:43<3:30:01,  3.78s/it, loss=2.86, epoch=0.209, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 884/4220 [55:43<3:30:01,  3.78s/it, loss=2.48, epoch=0.209, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 885/4220 [55:46<3:30:04,  3.78s/it, loss=2.48, epoch=0.209, learning_rate=1.8e-5]\u001b[A\n",
      " 21%|██        | 885/4220 [55:46<3:30:04,  3.78s/it, loss=2.89, epoch=0.209, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 886/4220 [55:50<3:30:02,  3.78s/it, loss=2.89, epoch=0.209, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 886/4220 [55:50<3:30:02,  3.78s/it, loss=2.59, epoch=0.21, learning_rate=1.79e-5] \u001b[A\n",
      " 21%|██        | 887/4220 [55:54<3:29:54,  3.78s/it, loss=2.59, epoch=0.21, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 887/4220 [55:54<3:29:54,  3.78s/it, loss=3.33, epoch=0.21, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 888/4220 [55:58<3:29:51,  3.78s/it, loss=3.33, epoch=0.21, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 888/4220 [55:58<3:29:51,  3.78s/it, loss=2.92, epoch=0.21, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 889/4220 [56:02<3:29:42,  3.78s/it, loss=2.92, epoch=0.21, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 889/4220 [56:02<3:29:42,  3.78s/it, loss=2.44, epoch=0.21, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 890/4220 [56:05<3:29:41,  3.78s/it, loss=2.44, epoch=0.21, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 890/4220 [56:05<3:29:41,  3.78s/it, loss=2.85, epoch=0.211, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 891/4220 [56:09<3:29:40,  3.78s/it, loss=2.85, epoch=0.211, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 891/4220 [56:09<3:29:40,  3.78s/it, loss=2.73, epoch=0.211, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 892/4220 [56:13<3:29:30,  3.78s/it, loss=2.73, epoch=0.211, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 892/4220 [56:13<3:29:30,  3.78s/it, loss=2.64, epoch=0.211, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 893/4220 [56:17<3:29:28,  3.78s/it, loss=2.64, epoch=0.211, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 893/4220 [56:17<3:29:28,  3.78s/it, loss=2.78, epoch=0.211, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 894/4220 [56:20<3:29:26,  3.78s/it, loss=2.78, epoch=0.211, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 894/4220 [56:20<3:29:26,  3.78s/it, loss=2.61, epoch=0.212, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 895/4220 [56:24<3:29:24,  3.78s/it, loss=2.61, epoch=0.212, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 895/4220 [56:24<3:29:24,  3.78s/it, loss=3.23, epoch=0.212, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 896/4220 [56:28<3:29:21,  3.78s/it, loss=3.23, epoch=0.212, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██        | 896/4220 [56:28<3:29:21,  3.78s/it, loss=2.8, epoch=0.212, learning_rate=1.79e-5] \u001b[A\n",
      " 21%|██▏       | 897/4220 [56:32<3:29:22,  3.78s/it, loss=2.8, epoch=0.212, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 897/4220 [56:32<3:29:22,  3.78s/it, loss=2.68, epoch=0.212, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 898/4220 [56:36<3:29:14,  3.78s/it, loss=2.68, epoch=0.212, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 898/4220 [56:36<3:29:14,  3.78s/it, loss=2.98, epoch=0.213, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 899/4220 [56:39<3:29:06,  3.78s/it, loss=2.98, epoch=0.213, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 899/4220 [56:39<3:29:06,  3.78s/it, loss=2.58, epoch=0.213, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 900/4220 [56:43<3:29:04,  3.78s/it, loss=2.58, epoch=0.213, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 900/4220 [56:43<3:29:04,  3.78s/it, loss=2.98, epoch=0.213, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 901/4220 [56:47<3:28:56,  3.78s/it, loss=2.98, epoch=0.213, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 901/4220 [56:47<3:28:56,  3.78s/it, loss=2.68, epoch=0.213, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 902/4220 [56:51<3:28:56,  3.78s/it, loss=2.68, epoch=0.213, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 902/4220 [56:51<3:28:56,  3.78s/it, loss=2.85, epoch=0.214, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 903/4220 [56:54<3:28:43,  3.78s/it, loss=2.85, epoch=0.214, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 903/4220 [56:54<3:28:43,  3.78s/it, loss=2.93, epoch=0.214, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 904/4220 [56:58<3:28:42,  3.78s/it, loss=2.93, epoch=0.214, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 904/4220 [56:58<3:28:42,  3.78s/it, loss=2.43, epoch=0.214, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 905/4220 [57:02<3:28:39,  3.78s/it, loss=2.43, epoch=0.214, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 905/4220 [57:02<3:28:39,  3.78s/it, loss=2.51, epoch=0.214, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 906/4220 [57:06<3:28:41,  3.78s/it, loss=2.51, epoch=0.214, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 906/4220 [57:06<3:28:41,  3.78s/it, loss=2.9, epoch=0.214, learning_rate=1.79e-5] \u001b[A\n",
      " 21%|██▏       | 907/4220 [57:10<3:28:38,  3.78s/it, loss=2.9, epoch=0.214, learning_rate=1.79e-5]\u001b[A\n",
      " 21%|██▏       | 907/4220 [57:10<3:28:38,  3.78s/it, loss=2.49, epoch=0.215, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 908/4220 [57:13<3:28:35,  3.78s/it, loss=2.49, epoch=0.215, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 908/4220 [57:13<3:28:35,  3.78s/it, loss=2.88, epoch=0.215, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 909/4220 [57:17<3:28:33,  3.78s/it, loss=2.88, epoch=0.215, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 909/4220 [57:17<3:28:33,  3.78s/it, loss=2.86, epoch=0.215, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 910/4220 [57:21<3:28:29,  3.78s/it, loss=2.86, epoch=0.215, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 910/4220 [57:21<3:28:29,  3.78s/it, loss=3.57, epoch=0.215, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 911/4220 [57:25<3:28:23,  3.78s/it, loss=3.57, epoch=0.215, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 911/4220 [57:25<3:28:23,  3.78s/it, loss=3.04, epoch=0.216, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 912/4220 [57:28<3:28:21,  3.78s/it, loss=3.04, epoch=0.216, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 912/4220 [57:28<3:28:21,  3.78s/it, loss=2.75, epoch=0.216, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 913/4220 [57:32<3:28:19,  3.78s/it, loss=2.75, epoch=0.216, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 913/4220 [57:32<3:28:19,  3.78s/it, loss=3.1, epoch=0.216, learning_rate=1.78e-5] \u001b[A\n",
      " 22%|██▏       | 914/4220 [57:36<3:28:08,  3.78s/it, loss=3.1, epoch=0.216, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 914/4220 [57:36<3:28:08,  3.78s/it, loss=2.64, epoch=0.216, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 915/4220 [57:40<3:28:00,  3.78s/it, loss=2.64, epoch=0.216, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 915/4220 [57:40<3:28:00,  3.78s/it, loss=3.17, epoch=0.217, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 916/4220 [57:44<3:27:54,  3.78s/it, loss=3.17, epoch=0.217, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 916/4220 [57:44<3:27:54,  3.78s/it, loss=2.88, epoch=0.217, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 917/4220 [57:47<3:27:49,  3.78s/it, loss=2.88, epoch=0.217, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 917/4220 [57:47<3:27:49,  3.78s/it, loss=2.65, epoch=0.217, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 918/4220 [57:51<3:27:51,  3.78s/it, loss=2.65, epoch=0.217, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 918/4220 [57:51<3:27:51,  3.78s/it, loss=2.67, epoch=0.217, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 919/4220 [57:55<3:27:51,  3.78s/it, loss=2.67, epoch=0.217, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 919/4220 [57:55<3:27:51,  3.78s/it, loss=2.33, epoch=0.218, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 920/4220 [57:59<3:27:48,  3.78s/it, loss=2.33, epoch=0.218, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 920/4220 [57:59<3:27:48,  3.78s/it, loss=2.97, epoch=0.218, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 921/4220 [58:02<3:27:44,  3.78s/it, loss=2.97, epoch=0.218, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 921/4220 [58:02<3:27:44,  3.78s/it, loss=2.7, epoch=0.218, learning_rate=1.78e-5] \u001b[A\n",
      " 22%|██▏       | 922/4220 [58:06<3:27:40,  3.78s/it, loss=2.7, epoch=0.218, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 922/4220 [58:06<3:27:40,  3.78s/it, loss=2.74, epoch=0.218, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 923/4220 [58:10<3:27:34,  3.78s/it, loss=2.74, epoch=0.218, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 923/4220 [58:10<3:27:34,  3.78s/it, loss=2.88, epoch=0.218, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 924/4220 [58:14<3:27:27,  3.78s/it, loss=2.88, epoch=0.218, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 924/4220 [58:14<3:27:27,  3.78s/it, loss=3.04, epoch=0.219, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 925/4220 [58:18<3:27:28,  3.78s/it, loss=3.04, epoch=0.219, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 925/4220 [58:18<3:27:28,  3.78s/it, loss=3.23, epoch=0.219, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 926/4220 [58:21<3:27:24,  3.78s/it, loss=3.23, epoch=0.219, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 926/4220 [58:21<3:27:24,  3.78s/it, loss=2.7, epoch=0.219, learning_rate=1.78e-5] \u001b[A\n",
      " 22%|██▏       | 927/4220 [58:25<3:27:21,  3.78s/it, loss=2.7, epoch=0.219, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 927/4220 [58:25<3:27:21,  3.78s/it, loss=2.37, epoch=0.219, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 928/4220 [58:29<3:27:20,  3.78s/it, loss=2.37, epoch=0.219, learning_rate=1.78e-5]\u001b[A\n",
      " 22%|██▏       | 928/4220 [58:29<3:27:20,  3.78s/it, loss=2.46, epoch=0.22, learning_rate=1.77e-5] \u001b[A\n",
      " 22%|██▏       | 929/4220 [58:33<3:27:14,  3.78s/it, loss=2.46, epoch=0.22, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 929/4220 [58:33<3:27:14,  3.78s/it, loss=2.53, epoch=0.22, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 930/4220 [58:36<3:27:09,  3.78s/it, loss=2.53, epoch=0.22, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 930/4220 [58:36<3:27:09,  3.78s/it, loss=2.93, epoch=0.22, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 931/4220 [58:40<3:27:08,  3.78s/it, loss=2.93, epoch=0.22, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 931/4220 [58:40<3:27:08,  3.78s/it, loss=3.07, epoch=0.22, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 932/4220 [58:44<3:26:59,  3.78s/it, loss=3.07, epoch=0.22, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 932/4220 [58:44<3:26:59,  3.78s/it, loss=2.97, epoch=0.221, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 933/4220 [58:48<3:26:52,  3.78s/it, loss=2.97, epoch=0.221, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 933/4220 [58:48<3:26:52,  3.78s/it, loss=2.67, epoch=0.221, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 934/4220 [58:52<3:26:53,  3.78s/it, loss=2.67, epoch=0.221, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 934/4220 [58:52<3:26:53,  3.78s/it, loss=2.46, epoch=0.221, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 935/4220 [58:55<3:26:51,  3.78s/it, loss=2.46, epoch=0.221, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 935/4220 [58:55<3:26:51,  3.78s/it, loss=3.08, epoch=0.221, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 936/4220 [58:59<3:26:48,  3.78s/it, loss=3.08, epoch=0.221, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 936/4220 [58:59<3:26:48,  3.78s/it, loss=2.31, epoch=0.222, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 937/4220 [59:03<3:26:47,  3.78s/it, loss=2.31, epoch=0.222, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 937/4220 [59:03<3:26:47,  3.78s/it, loss=2.52, epoch=0.222, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 938/4220 [59:07<3:26:38,  3.78s/it, loss=2.52, epoch=0.222, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 938/4220 [59:07<3:26:38,  3.78s/it, loss=3.3, epoch=0.222, learning_rate=1.77e-5] \u001b[A\n",
      " 22%|██▏       | 939/4220 [59:10<3:26:33,  3.78s/it, loss=3.3, epoch=0.222, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 939/4220 [59:10<3:26:33,  3.78s/it, loss=2.56, epoch=0.222, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 940/4220 [59:14<3:26:29,  3.78s/it, loss=2.56, epoch=0.222, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 940/4220 [59:14<3:26:29,  3.78s/it, loss=2.81, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 941/4220 [59:18<3:26:28,  3.78s/it, loss=2.81, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 941/4220 [59:18<3:26:28,  3.78s/it, loss=2.79, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 942/4220 [59:22<3:26:24,  3.78s/it, loss=2.79, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 942/4220 [59:22<3:26:24,  3.78s/it, loss=2.53, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 943/4220 [59:26<3:26:26,  3.78s/it, loss=2.53, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 943/4220 [59:26<3:26:26,  3.78s/it, loss=2.89, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 944/4220 [59:29<3:26:24,  3.78s/it, loss=2.89, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 944/4220 [59:29<3:26:24,  3.78s/it, loss=2.34, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 945/4220 [59:33<3:26:22,  3.78s/it, loss=2.34, epoch=0.223, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 945/4220 [59:33<3:26:22,  3.78s/it, loss=2.7, epoch=0.224, learning_rate=1.77e-5] \u001b[A\n",
      " 22%|██▏       | 946/4220 [59:37<3:26:14,  3.78s/it, loss=2.7, epoch=0.224, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 946/4220 [59:37<3:26:14,  3.78s/it, loss=3.03, epoch=0.224, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 947/4220 [59:41<3:26:10,  3.78s/it, loss=3.03, epoch=0.224, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 947/4220 [59:41<3:26:10,  3.78s/it, loss=2.71, epoch=0.224, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 948/4220 [59:45<3:26:02,  3.78s/it, loss=2.71, epoch=0.224, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 948/4220 [59:45<3:26:02,  3.78s/it, loss=3.06, epoch=0.224, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 949/4220 [59:48<3:26:00,  3.78s/it, loss=3.06, epoch=0.224, learning_rate=1.77e-5]\u001b[A\n",
      " 22%|██▏       | 949/4220 [59:48<3:26:00,  3.78s/it, loss=2.93, epoch=0.225, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 950/4220 [59:52<3:25:53,  3.78s/it, loss=2.93, epoch=0.225, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 950/4220 [59:52<3:25:53,  3.78s/it, loss=2.94, epoch=0.225, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 951/4220 [59:56<3:25:46,  3.78s/it, loss=2.94, epoch=0.225, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 951/4220 [59:56<3:25:46,  3.78s/it, loss=3.1, epoch=0.225, learning_rate=1.76e-5] \u001b[A\n",
      " 23%|██▎       | 952/4220 [1:00:00<3:25:46,  3.78s/it, loss=3.1, epoch=0.225, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 952/4220 [1:00:00<3:25:46,  3.78s/it, loss=2.96, epoch=0.225, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 953/4220 [1:00:03<3:25:43,  3.78s/it, loss=2.96, epoch=0.225, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 953/4220 [1:00:03<3:25:43,  3.78s/it, loss=2.97, epoch=0.226, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 954/4220 [1:00:07<3:25:42,  3.78s/it, loss=2.97, epoch=0.226, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 954/4220 [1:00:07<3:25:42,  3.78s/it, loss=2.76, epoch=0.226, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 955/4220 [1:00:11<3:25:41,  3.78s/it, loss=2.76, epoch=0.226, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 955/4220 [1:00:11<3:25:41,  3.78s/it, loss=2.77, epoch=0.226, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 956/4220 [1:00:15<3:25:37,  3.78s/it, loss=2.77, epoch=0.226, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 956/4220 [1:00:15<3:25:37,  3.78s/it, loss=2.51, epoch=0.226, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 957/4220 [1:00:19<3:25:35,  3.78s/it, loss=2.51, epoch=0.226, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 957/4220 [1:00:19<3:25:35,  3.78s/it, loss=3.33, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 958/4220 [1:00:22<3:25:24,  3.78s/it, loss=3.33, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 958/4220 [1:00:22<3:25:24,  3.78s/it, loss=2.59, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 959/4220 [1:00:26<3:25:18,  3.78s/it, loss=2.59, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 959/4220 [1:00:26<3:25:18,  3.78s/it, loss=2.77, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 960/4220 [1:00:30<3:25:14,  3.78s/it, loss=2.77, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 960/4220 [1:00:30<3:25:14,  3.78s/it, loss=2.56, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 961/4220 [1:00:34<3:25:13,  3.78s/it, loss=2.56, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 961/4220 [1:00:34<3:25:13,  3.78s/it, loss=3.41, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 962/4220 [1:00:37<3:25:06,  3.78s/it, loss=3.41, epoch=0.227, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 962/4220 [1:00:37<3:25:06,  3.78s/it, loss=2.65, epoch=0.228, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 963/4220 [1:00:41<3:25:08,  3.78s/it, loss=2.65, epoch=0.228, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 963/4220 [1:00:41<3:25:08,  3.78s/it, loss=3.16, epoch=0.228, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 964/4220 [1:00:45<3:25:05,  3.78s/it, loss=3.16, epoch=0.228, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 964/4220 [1:00:45<3:25:05,  3.78s/it, loss=2.89, epoch=0.228, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 965/4220 [1:00:49<3:24:54,  3.78s/it, loss=2.89, epoch=0.228, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 965/4220 [1:00:49<3:24:54,  3.78s/it, loss=2.65, epoch=0.228, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 966/4220 [1:00:53<3:24:55,  3.78s/it, loss=2.65, epoch=0.228, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 966/4220 [1:00:53<3:24:55,  3.78s/it, loss=2.89, epoch=0.229, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 967/4220 [1:00:56<3:24:53,  3.78s/it, loss=2.89, epoch=0.229, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 967/4220 [1:00:56<3:24:53,  3.78s/it, loss=3.09, epoch=0.229, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 968/4220 [1:01:00<3:24:47,  3.78s/it, loss=3.09, epoch=0.229, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 968/4220 [1:01:00<3:24:47,  3.78s/it, loss=3.12, epoch=0.229, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 969/4220 [1:01:04<3:24:41,  3.78s/it, loss=3.12, epoch=0.229, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 969/4220 [1:01:04<3:24:41,  3.78s/it, loss=3.21, epoch=0.229, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 970/4220 [1:01:08<3:24:32,  3.78s/it, loss=3.21, epoch=0.229, learning_rate=1.76e-5]\u001b[A\n",
      " 23%|██▎       | 970/4220 [1:01:08<3:24:32,  3.78s/it, loss=2.92, epoch=0.23, learning_rate=1.75e-5] \u001b[A\n",
      " 23%|██▎       | 971/4220 [1:01:11<3:24:33,  3.78s/it, loss=2.92, epoch=0.23, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 971/4220 [1:01:11<3:24:33,  3.78s/it, loss=2.8, epoch=0.23, learning_rate=1.75e-5] \u001b[A\n",
      " 23%|██▎       | 972/4220 [1:01:15<3:24:30,  3.78s/it, loss=2.8, epoch=0.23, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 972/4220 [1:01:15<3:24:30,  3.78s/it, loss=2.63, epoch=0.23, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 973/4220 [1:01:19<3:24:29,  3.78s/it, loss=2.63, epoch=0.23, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 973/4220 [1:01:19<3:24:29,  3.78s/it, loss=3.47, epoch=0.23, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 974/4220 [1:01:23<3:24:22,  3.78s/it, loss=3.47, epoch=0.23, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 974/4220 [1:01:23<3:24:22,  3.78s/it, loss=2.74, epoch=0.231, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 975/4220 [1:01:27<3:24:21,  3.78s/it, loss=2.74, epoch=0.231, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 975/4220 [1:01:27<3:24:21,  3.78s/it, loss=3.32, epoch=0.231, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 976/4220 [1:01:30<3:24:16,  3.78s/it, loss=3.32, epoch=0.231, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 976/4220 [1:01:30<3:24:16,  3.78s/it, loss=2.8, epoch=0.231, learning_rate=1.75e-5] \u001b[A\n",
      " 23%|██▎       | 977/4220 [1:01:34<3:24:18,  3.78s/it, loss=2.8, epoch=0.231, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 977/4220 [1:01:34<3:24:18,  3.78s/it, loss=2.75, epoch=0.231, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 978/4220 [1:01:38<3:24:09,  3.78s/it, loss=2.75, epoch=0.231, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 978/4220 [1:01:38<3:24:09,  3.78s/it, loss=2.81, epoch=0.232, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 979/4220 [1:01:42<3:24:10,  3.78s/it, loss=2.81, epoch=0.232, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 979/4220 [1:01:42<3:24:10,  3.78s/it, loss=2.44, epoch=0.232, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 980/4220 [1:01:45<3:24:09,  3.78s/it, loss=2.44, epoch=0.232, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 980/4220 [1:01:45<3:24:09,  3.78s/it, loss=2.9, epoch=0.232, learning_rate=1.75e-5] \u001b[A\n",
      " 23%|██▎       | 981/4220 [1:01:49<3:24:05,  3.78s/it, loss=2.9, epoch=0.232, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 981/4220 [1:01:49<3:24:05,  3.78s/it, loss=2.96, epoch=0.232, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 982/4220 [1:01:53<3:23:59,  3.78s/it, loss=2.96, epoch=0.232, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 982/4220 [1:01:53<3:23:59,  3.78s/it, loss=2.78, epoch=0.232, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 983/4220 [1:01:57<3:23:54,  3.78s/it, loss=2.78, epoch=0.232, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 983/4220 [1:01:57<3:23:54,  3.78s/it, loss=3.25, epoch=0.233, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 984/4220 [1:02:01<3:23:50,  3.78s/it, loss=3.25, epoch=0.233, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 984/4220 [1:02:01<3:23:50,  3.78s/it, loss=2.95, epoch=0.233, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 985/4220 [1:02:04<3:23:45,  3.78s/it, loss=2.95, epoch=0.233, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 985/4220 [1:02:04<3:23:45,  3.78s/it, loss=2.74, epoch=0.233, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 986/4220 [1:02:08<3:23:38,  3.78s/it, loss=2.74, epoch=0.233, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 986/4220 [1:02:08<3:23:38,  3.78s/it, loss=2.73, epoch=0.233, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 987/4220 [1:02:12<3:23:32,  3.78s/it, loss=2.73, epoch=0.233, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 987/4220 [1:02:12<3:23:32,  3.78s/it, loss=2.63, epoch=0.234, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 988/4220 [1:02:16<3:23:26,  3.78s/it, loss=2.63, epoch=0.234, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 988/4220 [1:02:16<3:23:26,  3.78s/it, loss=2.89, epoch=0.234, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 989/4220 [1:02:19<3:23:26,  3.78s/it, loss=2.89, epoch=0.234, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 989/4220 [1:02:19<3:23:26,  3.78s/it, loss=2.91, epoch=0.234, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 990/4220 [1:02:23<3:23:24,  3.78s/it, loss=2.91, epoch=0.234, learning_rate=1.75e-5]\u001b[A\n",
      " 23%|██▎       | 990/4220 [1:02:23<3:23:24,  3.78s/it, loss=3.26, epoch=0.234, learning_rate=1.74e-5]\u001b[A\n",
      " 23%|██▎       | 991/4220 [1:02:27<3:23:16,  3.78s/it, loss=3.26, epoch=0.234, learning_rate=1.74e-5]\u001b[A\n",
      " 23%|██▎       | 991/4220 [1:02:27<3:23:16,  3.78s/it, loss=2.4, epoch=0.235, learning_rate=1.74e-5] \u001b[A\n",
      " 24%|██▎       | 992/4220 [1:02:31<3:23:14,  3.78s/it, loss=2.4, epoch=0.235, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 992/4220 [1:02:31<3:23:14,  3.78s/it, loss=2.55, epoch=0.235, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 993/4220 [1:02:35<3:23:11,  3.78s/it, loss=2.55, epoch=0.235, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 993/4220 [1:02:35<3:23:11,  3.78s/it, loss=2.61, epoch=0.235, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 994/4220 [1:02:38<3:23:10,  3.78s/it, loss=2.61, epoch=0.235, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 994/4220 [1:02:38<3:23:10,  3.78s/it, loss=3.14, epoch=0.235, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 995/4220 [1:02:42<3:23:07,  3.78s/it, loss=3.14, epoch=0.235, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 995/4220 [1:02:42<3:23:07,  3.78s/it, loss=3.3, epoch=0.236, learning_rate=1.74e-5] \u001b[A\n",
      " 24%|██▎       | 996/4220 [1:02:46<3:23:02,  3.78s/it, loss=3.3, epoch=0.236, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 996/4220 [1:02:46<3:23:02,  3.78s/it, loss=2.82, epoch=0.236, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 997/4220 [1:02:50<3:22:59,  3.78s/it, loss=2.82, epoch=0.236, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 997/4220 [1:02:50<3:22:59,  3.78s/it, loss=2.93, epoch=0.236, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 998/4220 [1:02:53<3:22:52,  3.78s/it, loss=2.93, epoch=0.236, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 998/4220 [1:02:53<3:22:52,  3.78s/it, loss=2.31, epoch=0.236, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 999/4220 [1:02:57<3:22:50,  3.78s/it, loss=2.31, epoch=0.236, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 999/4220 [1:02:57<3:22:50,  3.78s/it, loss=2.77, epoch=0.236, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 1000/4220 [1:03:01<3:22:44,  3.78s/it, loss=2.77, epoch=0.236, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 1000/4220 [1:03:01<3:22:44,  3.78s/it, loss=3, epoch=0.237, learning_rate=1.74e-5]   \u001b[ARemoved shared tensor {'model.unembed.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "\n",
      " 24%|██▎       | 1001/4220 [1:04:10<20:54:23, 23.38s/it, loss=3, epoch=0.237, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 1001/4220 [1:04:10<20:54:23, 23.38s/it, loss=2.99, epoch=0.237, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 1002/4220 [1:04:14<15:37:56, 17.49s/it, loss=2.99, epoch=0.237, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▎       | 1002/4220 [1:04:14<15:37:56, 17.49s/it, loss=2.9, epoch=0.237, learning_rate=1.74e-5] \u001b[A\n",
      " 24%|██▍       | 1003/4220 [1:04:18<11:56:40, 13.37s/it, loss=2.9, epoch=0.237, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1003/4220 [1:04:18<11:56:40, 13.37s/it, loss=2.45, epoch=0.237, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1004/4220 [1:04:21<9:21:43, 10.48s/it, loss=2.45, epoch=0.237, learning_rate=1.74e-5] \u001b[A\n",
      " 24%|██▍       | 1004/4220 [1:04:21<9:21:43, 10.48s/it, loss=3.03, epoch=0.238, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1005/4220 [1:04:25<7:33:22,  8.46s/it, loss=3.03, epoch=0.238, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1005/4220 [1:04:25<7:33:22,  8.46s/it, loss=2.84, epoch=0.238, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1006/4220 [1:04:29<6:17:32,  7.05s/it, loss=2.84, epoch=0.238, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1006/4220 [1:04:29<6:17:32,  7.05s/it, loss=2.9, epoch=0.238, learning_rate=1.74e-5] \u001b[A\n",
      " 24%|██▍       | 1007/4220 [1:04:33<5:24:28,  6.06s/it, loss=2.9, epoch=0.238, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1007/4220 [1:04:33<5:24:28,  6.06s/it, loss=2.76, epoch=0.238, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1008/4220 [1:04:36<4:47:24,  5.37s/it, loss=2.76, epoch=0.238, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1008/4220 [1:04:36<4:47:24,  5.37s/it, loss=2.68, epoch=0.239, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1009/4220 [1:04:40<4:21:30,  4.89s/it, loss=2.68, epoch=0.239, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1009/4220 [1:04:40<4:21:30,  4.89s/it, loss=2.58, epoch=0.239, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1010/4220 [1:04:44<4:03:24,  4.55s/it, loss=2.58, epoch=0.239, learning_rate=1.74e-5]\u001b[A\n",
      " 24%|██▍       | 1010/4220 [1:04:44<4:03:24,  4.55s/it, loss=2.92, epoch=0.239, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1011/4220 [1:04:48<3:50:49,  4.32s/it, loss=2.92, epoch=0.239, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1011/4220 [1:04:48<3:50:49,  4.32s/it, loss=2.91, epoch=0.239, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1012/4220 [1:04:51<3:41:49,  4.15s/it, loss=2.91, epoch=0.239, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1012/4220 [1:04:51<3:41:49,  4.15s/it, loss=2.64, epoch=0.24, learning_rate=1.73e-5] \u001b[A\n",
      " 24%|██▍       | 1013/4220 [1:04:55<3:35:32,  4.03s/it, loss=2.64, epoch=0.24, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1013/4220 [1:04:55<3:35:32,  4.03s/it, loss=2.61, epoch=0.24, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1014/4220 [1:04:59<3:31:10,  3.95s/it, loss=2.61, epoch=0.24, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1014/4220 [1:04:59<3:31:10,  3.95s/it, loss=2.96, epoch=0.24, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1015/4220 [1:05:03<3:28:09,  3.90s/it, loss=2.96, epoch=0.24, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1015/4220 [1:05:03<3:28:09,  3.90s/it, loss=2.87, epoch=0.24, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1016/4220 [1:05:06<3:26:06,  3.86s/it, loss=2.87, epoch=0.24, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1016/4220 [1:05:06<3:26:06,  3.86s/it, loss=2.43, epoch=0.241, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1017/4220 [1:05:10<3:24:33,  3.83s/it, loss=2.43, epoch=0.241, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1017/4220 [1:05:10<3:24:33,  3.83s/it, loss=2.28, epoch=0.241, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1018/4220 [1:05:14<3:23:31,  3.81s/it, loss=2.28, epoch=0.241, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1018/4220 [1:05:14<3:23:31,  3.81s/it, loss=2.5, epoch=0.241, learning_rate=1.73e-5] \u001b[A\n",
      " 24%|██▍       | 1019/4220 [1:05:18<3:22:42,  3.80s/it, loss=2.5, epoch=0.241, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1019/4220 [1:05:18<3:22:42,  3.80s/it, loss=2.97, epoch=0.241, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1020/4220 [1:05:22<3:22:07,  3.79s/it, loss=2.97, epoch=0.241, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1020/4220 [1:05:22<3:22:07,  3.79s/it, loss=2.58, epoch=0.241, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1021/4220 [1:05:25<3:21:44,  3.78s/it, loss=2.58, epoch=0.241, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1021/4220 [1:05:25<3:21:44,  3.78s/it, loss=2.13, epoch=0.242, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1022/4220 [1:05:29<3:21:28,  3.78s/it, loss=2.13, epoch=0.242, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1022/4220 [1:05:29<3:21:28,  3.78s/it, loss=2.48, epoch=0.242, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1023/4220 [1:05:33<3:21:15,  3.78s/it, loss=2.48, epoch=0.242, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1023/4220 [1:05:33<3:21:15,  3.78s/it, loss=3, epoch=0.242, learning_rate=1.73e-5]   \u001b[A\n",
      " 24%|██▍       | 1024/4220 [1:05:37<3:21:05,  3.78s/it, loss=3, epoch=0.242, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1024/4220 [1:05:37<3:21:05,  3.78s/it, loss=2.6, epoch=0.242, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1025/4220 [1:05:40<3:20:56,  3.77s/it, loss=2.6, epoch=0.242, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1025/4220 [1:05:40<3:20:56,  3.77s/it, loss=2.82, epoch=0.243, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1026/4220 [1:05:44<3:20:55,  3.77s/it, loss=2.82, epoch=0.243, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1026/4220 [1:05:44<3:20:55,  3.77s/it, loss=2.65, epoch=0.243, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1027/4220 [1:05:48<3:20:51,  3.77s/it, loss=2.65, epoch=0.243, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1027/4220 [1:05:48<3:20:51,  3.77s/it, loss=2.53, epoch=0.243, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1028/4220 [1:05:52<3:20:44,  3.77s/it, loss=2.53, epoch=0.243, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1028/4220 [1:05:52<3:20:44,  3.77s/it, loss=2.36, epoch=0.243, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1029/4220 [1:05:55<3:20:45,  3.77s/it, loss=2.36, epoch=0.243, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1029/4220 [1:05:55<3:20:45,  3.77s/it, loss=2.66, epoch=0.244, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1030/4220 [1:05:59<3:20:37,  3.77s/it, loss=2.66, epoch=0.244, learning_rate=1.73e-5]\u001b[A\n",
      " 24%|██▍       | 1030/4220 [1:05:59<3:20:37,  3.77s/it, loss=2.51, epoch=0.244, learning_rate=1.72e-5]\u001b[A\n",
      " 24%|██▍       | 1031/4220 [1:06:03<3:20:34,  3.77s/it, loss=2.51, epoch=0.244, learning_rate=1.72e-5]\u001b[A\n",
      " 24%|██▍       | 1031/4220 [1:06:03<3:20:34,  3.77s/it, loss=2.67, epoch=0.244, learning_rate=1.72e-5]\u001b[A\n",
      " 24%|██▍       | 1032/4220 [1:06:07<3:20:33,  3.77s/it, loss=2.67, epoch=0.244, learning_rate=1.72e-5]\u001b[A\n",
      " 24%|██▍       | 1032/4220 [1:06:07<3:20:33,  3.77s/it, loss=3.37, epoch=0.244, learning_rate=1.72e-5]\u001b[A\n",
      " 24%|██▍       | 1033/4220 [1:06:11<3:20:27,  3.77s/it, loss=3.37, epoch=0.244, learning_rate=1.72e-5]\u001b[A\n",
      " 24%|██▍       | 1033/4220 [1:06:11<3:20:27,  3.77s/it, loss=2.25, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1034/4220 [1:06:14<3:20:28,  3.78s/it, loss=2.25, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1034/4220 [1:06:14<3:20:28,  3.78s/it, loss=3.05, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1035/4220 [1:06:18<3:20:25,  3.78s/it, loss=3.05, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1035/4220 [1:06:18<3:20:25,  3.78s/it, loss=2.67, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1036/4220 [1:06:22<3:20:18,  3.77s/it, loss=2.67, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1036/4220 [1:06:22<3:20:18,  3.77s/it, loss=2.93, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1037/4220 [1:06:26<3:20:21,  3.78s/it, loss=2.93, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1037/4220 [1:06:26<3:20:21,  3.78s/it, loss=2.71, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1038/4220 [1:06:29<3:20:18,  3.78s/it, loss=2.71, epoch=0.245, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1038/4220 [1:06:29<3:20:18,  3.78s/it, loss=3.17, epoch=0.246, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1039/4220 [1:06:33<3:20:10,  3.78s/it, loss=3.17, epoch=0.246, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1039/4220 [1:06:33<3:20:10,  3.78s/it, loss=3.02, epoch=0.246, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1040/4220 [1:06:37<3:20:03,  3.77s/it, loss=3.02, epoch=0.246, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1040/4220 [1:06:37<3:20:03,  3.77s/it, loss=2.69, epoch=0.246, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1041/4220 [1:06:41<3:19:57,  3.77s/it, loss=2.69, epoch=0.246, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1041/4220 [1:06:41<3:19:57,  3.77s/it, loss=2.69, epoch=0.246, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1042/4220 [1:06:45<3:19:52,  3.77s/it, loss=2.69, epoch=0.246, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1042/4220 [1:06:45<3:19:52,  3.77s/it, loss=2.85, epoch=0.247, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1043/4220 [1:06:48<3:19:49,  3.77s/it, loss=2.85, epoch=0.247, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1043/4220 [1:06:48<3:19:49,  3.77s/it, loss=2.83, epoch=0.247, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1044/4220 [1:06:52<3:19:51,  3.78s/it, loss=2.83, epoch=0.247, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1044/4220 [1:06:52<3:19:51,  3.78s/it, loss=2.84, epoch=0.247, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1045/4220 [1:06:56<3:19:48,  3.78s/it, loss=2.84, epoch=0.247, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1045/4220 [1:06:56<3:19:48,  3.78s/it, loss=2.62, epoch=0.247, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1046/4220 [1:07:00<3:19:44,  3.78s/it, loss=2.62, epoch=0.247, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1046/4220 [1:07:00<3:19:44,  3.78s/it, loss=2.39, epoch=0.248, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1047/4220 [1:07:03<3:19:39,  3.78s/it, loss=2.39, epoch=0.248, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1047/4220 [1:07:03<3:19:39,  3.78s/it, loss=2.69, epoch=0.248, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1048/4220 [1:07:07<3:19:35,  3.78s/it, loss=2.69, epoch=0.248, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1048/4220 [1:07:07<3:19:35,  3.78s/it, loss=2.74, epoch=0.248, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1049/4220 [1:07:11<3:19:34,  3.78s/it, loss=2.74, epoch=0.248, learning_rate=1.72e-5]\u001b[A\n",
      " 25%|██▍       | 1049/4220 [1:07:11<3:19:34,  3.78s/it, loss=2.79, epoch=0.248, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1050/4220 [1:07:15<3:19:28,  3.78s/it, loss=2.79, epoch=0.248, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1050/4220 [1:07:15<3:19:28,  3.78s/it, loss=2.84, epoch=0.249, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1051/4220 [1:07:19<3:19:27,  3.78s/it, loss=2.84, epoch=0.249, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1051/4220 [1:07:19<3:19:27,  3.78s/it, loss=3.06, epoch=0.249, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1052/4220 [1:07:22<3:19:20,  3.78s/it, loss=3.06, epoch=0.249, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1052/4220 [1:07:22<3:19:20,  3.78s/it, loss=2.53, epoch=0.249, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1053/4220 [1:07:26<3:19:18,  3.78s/it, loss=2.53, epoch=0.249, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1053/4220 [1:07:26<3:19:18,  3.78s/it, loss=3.33, epoch=0.249, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1054/4220 [1:07:30<3:19:14,  3.78s/it, loss=3.33, epoch=0.249, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▍       | 1054/4220 [1:07:30<3:19:14,  3.78s/it, loss=2.89, epoch=0.25, learning_rate=1.71e-5] \u001b[A\n",
      " 25%|██▌       | 1055/4220 [1:07:34<3:19:11,  3.78s/it, loss=2.89, epoch=0.25, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1055/4220 [1:07:34<3:19:11,  3.78s/it, loss=2.79, epoch=0.25, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1056/4220 [1:07:37<3:19:11,  3.78s/it, loss=2.79, epoch=0.25, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1056/4220 [1:07:37<3:19:11,  3.78s/it, loss=2.78, epoch=0.25, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1057/4220 [1:07:41<3:19:00,  3.77s/it, loss=2.78, epoch=0.25, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1057/4220 [1:07:41<3:19:00,  3.77s/it, loss=2.6, epoch=0.25, learning_rate=1.71e-5] \u001b[A\n",
      " 25%|██▌       | 1058/4220 [1:07:45<3:18:58,  3.78s/it, loss=2.6, epoch=0.25, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1058/4220 [1:07:45<3:18:58,  3.78s/it, loss=2.5, epoch=0.25, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1059/4220 [1:07:49<3:18:56,  3.78s/it, loss=2.5, epoch=0.25, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1059/4220 [1:07:49<3:18:56,  3.78s/it, loss=3.05, epoch=0.251, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1060/4220 [1:07:53<3:18:54,  3.78s/it, loss=3.05, epoch=0.251, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1060/4220 [1:07:53<3:18:54,  3.78s/it, loss=2.59, epoch=0.251, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1061/4220 [1:07:56<3:18:55,  3.78s/it, loss=2.59, epoch=0.251, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1061/4220 [1:07:56<3:18:55,  3.78s/it, loss=2.74, epoch=0.251, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1062/4220 [1:08:00<3:18:52,  3.78s/it, loss=2.74, epoch=0.251, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1062/4220 [1:08:00<3:18:52,  3.78s/it, loss=2.52, epoch=0.251, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1063/4220 [1:08:04<3:18:44,  3.78s/it, loss=2.52, epoch=0.251, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1063/4220 [1:08:04<3:18:44,  3.78s/it, loss=3.05, epoch=0.252, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1064/4220 [1:08:08<3:18:42,  3.78s/it, loss=3.05, epoch=0.252, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1064/4220 [1:08:08<3:18:42,  3.78s/it, loss=2.8, epoch=0.252, learning_rate=1.71e-5] \u001b[A\n",
      " 25%|██▌       | 1065/4220 [1:08:11<3:18:34,  3.78s/it, loss=2.8, epoch=0.252, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1065/4220 [1:08:11<3:18:34,  3.78s/it, loss=2.76, epoch=0.252, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1066/4220 [1:08:15<3:18:32,  3.78s/it, loss=2.76, epoch=0.252, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1066/4220 [1:08:15<3:18:32,  3.78s/it, loss=3.05, epoch=0.252, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1067/4220 [1:08:19<3:18:27,  3.78s/it, loss=3.05, epoch=0.252, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1067/4220 [1:08:19<3:18:27,  3.78s/it, loss=2.71, epoch=0.253, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1068/4220 [1:08:23<3:18:26,  3.78s/it, loss=2.71, epoch=0.253, learning_rate=1.71e-5]\u001b[A\n",
      " 25%|██▌       | 1068/4220 [1:08:23<3:18:26,  3.78s/it, loss=2.81, epoch=0.253, learning_rate=1.7e-5] \u001b[A\n",
      " 25%|██▌       | 1069/4220 [1:08:27<3:18:26,  3.78s/it, loss=2.81, epoch=0.253, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1069/4220 [1:08:27<3:18:26,  3.78s/it, loss=3.16, epoch=0.253, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1070/4220 [1:08:30<3:18:21,  3.78s/it, loss=3.16, epoch=0.253, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1070/4220 [1:08:30<3:18:21,  3.78s/it, loss=3.11, epoch=0.253, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1071/4220 [1:08:34<3:18:17,  3.78s/it, loss=3.11, epoch=0.253, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1071/4220 [1:08:34<3:18:17,  3.78s/it, loss=2.58, epoch=0.254, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1072/4220 [1:08:38<3:18:13,  3.78s/it, loss=2.58, epoch=0.254, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1072/4220 [1:08:38<3:18:13,  3.78s/it, loss=2.54, epoch=0.254, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1073/4220 [1:08:42<3:18:05,  3.78s/it, loss=2.54, epoch=0.254, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1073/4220 [1:08:42<3:18:05,  3.78s/it, loss=3.13, epoch=0.254, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1074/4220 [1:08:45<3:18:05,  3.78s/it, loss=3.13, epoch=0.254, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1074/4220 [1:08:45<3:18:05,  3.78s/it, loss=2.88, epoch=0.254, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1075/4220 [1:08:49<3:18:07,  3.78s/it, loss=2.88, epoch=0.254, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1075/4220 [1:08:49<3:18:07,  3.78s/it, loss=2.68, epoch=0.255, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1076/4220 [1:08:53<3:17:58,  3.78s/it, loss=2.68, epoch=0.255, learning_rate=1.7e-5]\u001b[A\n",
      " 25%|██▌       | 1076/4220 [1:08:53<3:17:58,  3.78s/it, loss=2.38, epoch=0.255, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1077/4220 [1:08:57<3:17:51,  3.78s/it, loss=2.38, epoch=0.255, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1077/4220 [1:08:57<3:17:51,  3.78s/it, loss=2.23, epoch=0.255, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1078/4220 [1:09:01<3:17:42,  3.78s/it, loss=2.23, epoch=0.255, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1078/4220 [1:09:01<3:17:42,  3.78s/it, loss=2.76, epoch=0.255, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1079/4220 [1:09:04<3:17:42,  3.78s/it, loss=2.76, epoch=0.255, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1079/4220 [1:09:04<3:17:42,  3.78s/it, loss=2.8, epoch=0.255, learning_rate=1.7e-5] \u001b[A\n",
      " 26%|██▌       | 1080/4220 [1:09:08<3:17:41,  3.78s/it, loss=2.8, epoch=0.255, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1080/4220 [1:09:08<3:17:41,  3.78s/it, loss=2.18, epoch=0.256, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1081/4220 [1:09:12<3:17:38,  3.78s/it, loss=2.18, epoch=0.256, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1081/4220 [1:09:12<3:17:38,  3.78s/it, loss=3.14, epoch=0.256, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1082/4220 [1:09:16<3:17:34,  3.78s/it, loss=3.14, epoch=0.256, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1082/4220 [1:09:16<3:17:34,  3.78s/it, loss=2.97, epoch=0.256, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1083/4220 [1:09:19<3:17:32,  3.78s/it, loss=2.97, epoch=0.256, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1083/4220 [1:09:19<3:17:32,  3.78s/it, loss=2.55, epoch=0.256, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1084/4220 [1:09:23<3:17:27,  3.78s/it, loss=2.55, epoch=0.256, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1084/4220 [1:09:23<3:17:27,  3.78s/it, loss=3.13, epoch=0.257, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1085/4220 [1:09:27<3:17:27,  3.78s/it, loss=3.13, epoch=0.257, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1085/4220 [1:09:27<3:17:27,  3.78s/it, loss=3.07, epoch=0.257, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1086/4220 [1:09:31<3:17:20,  3.78s/it, loss=3.07, epoch=0.257, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1086/4220 [1:09:31<3:17:20,  3.78s/it, loss=2.57, epoch=0.257, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1087/4220 [1:09:35<3:17:17,  3.78s/it, loss=2.57, epoch=0.257, learning_rate=1.7e-5]\u001b[A\n",
      " 26%|██▌       | 1087/4220 [1:09:35<3:17:17,  3.78s/it, loss=3.12, epoch=0.257, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1088/4220 [1:09:38<3:17:09,  3.78s/it, loss=3.12, epoch=0.257, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1088/4220 [1:09:38<3:17:09,  3.78s/it, loss=2.89, epoch=0.258, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1089/4220 [1:09:42<3:17:09,  3.78s/it, loss=2.89, epoch=0.258, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1089/4220 [1:09:42<3:17:09,  3.78s/it, loss=2.86, epoch=0.258, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1090/4220 [1:09:46<3:17:12,  3.78s/it, loss=2.86, epoch=0.258, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1090/4220 [1:09:46<3:17:12,  3.78s/it, loss=2.99, epoch=0.258, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1091/4220 [1:09:50<3:17:06,  3.78s/it, loss=2.99, epoch=0.258, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1091/4220 [1:09:50<3:17:06,  3.78s/it, loss=2.61, epoch=0.258, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1092/4220 [1:09:53<3:16:56,  3.78s/it, loss=2.61, epoch=0.258, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1092/4220 [1:09:53<3:16:56,  3.78s/it, loss=2.27, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1093/4220 [1:09:57<3:16:54,  3.78s/it, loss=2.27, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1093/4220 [1:09:57<3:16:54,  3.78s/it, loss=2.44, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1094/4220 [1:10:01<3:16:45,  3.78s/it, loss=2.44, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1094/4220 [1:10:01<3:16:45,  3.78s/it, loss=2.62, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1095/4220 [1:10:05<3:16:40,  3.78s/it, loss=2.62, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1095/4220 [1:10:05<3:16:40,  3.78s/it, loss=3.14, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1096/4220 [1:10:09<3:16:40,  3.78s/it, loss=3.14, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1096/4220 [1:10:09<3:16:40,  3.78s/it, loss=2.62, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1097/4220 [1:10:12<3:16:34,  3.78s/it, loss=2.62, epoch=0.259, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1097/4220 [1:10:12<3:16:34,  3.78s/it, loss=3.18, epoch=0.26, learning_rate=1.69e-5] \u001b[A\n",
      " 26%|██▌       | 1098/4220 [1:10:16<3:16:33,  3.78s/it, loss=3.18, epoch=0.26, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1098/4220 [1:10:16<3:16:33,  3.78s/it, loss=2.53, epoch=0.26, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1099/4220 [1:10:20<3:16:34,  3.78s/it, loss=2.53, epoch=0.26, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1099/4220 [1:10:20<3:16:34,  3.78s/it, loss=3, epoch=0.26, learning_rate=1.69e-5]   \u001b[A\n",
      " 26%|██▌       | 1100/4220 [1:10:24<3:16:28,  3.78s/it, loss=3, epoch=0.26, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1100/4220 [1:10:24<3:16:28,  3.78s/it, loss=2.55, epoch=0.26, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1101/4220 [1:10:27<3:16:27,  3.78s/it, loss=2.55, epoch=0.26, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1101/4220 [1:10:27<3:16:27,  3.78s/it, loss=2.71, epoch=0.261, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1102/4220 [1:10:31<3:16:20,  3.78s/it, loss=2.71, epoch=0.261, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1102/4220 [1:10:31<3:16:20,  3.78s/it, loss=2.4, epoch=0.261, learning_rate=1.69e-5] \u001b[A\n",
      " 26%|██▌       | 1103/4220 [1:10:35<3:16:16,  3.78s/it, loss=2.4, epoch=0.261, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1103/4220 [1:10:35<3:16:16,  3.78s/it, loss=3.18, epoch=0.261, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1104/4220 [1:10:39<3:16:06,  3.78s/it, loss=3.18, epoch=0.261, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1104/4220 [1:10:39<3:16:06,  3.78s/it, loss=2.74, epoch=0.261, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1105/4220 [1:10:43<3:16:06,  3.78s/it, loss=2.74, epoch=0.261, learning_rate=1.69e-5]\u001b[A\n",
      " 26%|██▌       | 1105/4220 [1:10:43<3:16:06,  3.78s/it, loss=2.49, epoch=0.262, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▌       | 1106/4220 [1:10:46<3:16:02,  3.78s/it, loss=2.49, epoch=0.262, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▌       | 1106/4220 [1:10:46<3:16:02,  3.78s/it, loss=2.56, epoch=0.262, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▌       | 1107/4220 [1:10:50<3:16:01,  3.78s/it, loss=2.56, epoch=0.262, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▌       | 1107/4220 [1:10:50<3:16:01,  3.78s/it, loss=2.8, epoch=0.262, learning_rate=1.68e-5] \u001b[A\n",
      " 26%|██▋       | 1108/4220 [1:10:54<3:15:54,  3.78s/it, loss=2.8, epoch=0.262, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1108/4220 [1:10:54<3:15:54,  3.78s/it, loss=2.8, epoch=0.262, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1109/4220 [1:10:58<3:15:54,  3.78s/it, loss=2.8, epoch=0.262, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1109/4220 [1:10:58<3:15:54,  3.78s/it, loss=2.71, epoch=0.263, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1110/4220 [1:11:01<3:15:54,  3.78s/it, loss=2.71, epoch=0.263, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1110/4220 [1:11:01<3:15:54,  3.78s/it, loss=3.09, epoch=0.263, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1111/4220 [1:11:05<3:15:44,  3.78s/it, loss=3.09, epoch=0.263, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1111/4220 [1:11:05<3:15:44,  3.78s/it, loss=2.83, epoch=0.263, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1112/4220 [1:11:09<3:15:41,  3.78s/it, loss=2.83, epoch=0.263, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1112/4220 [1:11:09<3:15:41,  3.78s/it, loss=3.31, epoch=0.263, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1113/4220 [1:11:13<3:15:39,  3.78s/it, loss=3.31, epoch=0.263, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1113/4220 [1:11:13<3:15:39,  3.78s/it, loss=2.9, epoch=0.264, learning_rate=1.68e-5] \u001b[A\n",
      " 26%|██▋       | 1114/4220 [1:11:17<3:15:34,  3.78s/it, loss=2.9, epoch=0.264, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1114/4220 [1:11:17<3:15:34,  3.78s/it, loss=2.87, epoch=0.264, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1115/4220 [1:11:20<3:15:36,  3.78s/it, loss=2.87, epoch=0.264, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1115/4220 [1:11:20<3:15:36,  3.78s/it, loss=2.59, epoch=0.264, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1116/4220 [1:11:24<3:15:35,  3.78s/it, loss=2.59, epoch=0.264, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1116/4220 [1:11:24<3:15:35,  3.78s/it, loss=3.31, epoch=0.264, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1117/4220 [1:11:28<3:15:25,  3.78s/it, loss=3.31, epoch=0.264, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1117/4220 [1:11:28<3:15:25,  3.78s/it, loss=2.68, epoch=0.264, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1118/4220 [1:11:32<3:15:24,  3.78s/it, loss=2.68, epoch=0.264, learning_rate=1.68e-5]\u001b[A\n",
      " 26%|██▋       | 1118/4220 [1:11:32<3:15:24,  3.78s/it, loss=2.53, epoch=0.265, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1119/4220 [1:11:35<3:15:25,  3.78s/it, loss=2.53, epoch=0.265, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1119/4220 [1:11:35<3:15:25,  3.78s/it, loss=3.04, epoch=0.265, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1120/4220 [1:11:39<3:15:14,  3.78s/it, loss=3.04, epoch=0.265, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1120/4220 [1:11:39<3:15:14,  3.78s/it, loss=2.73, epoch=0.265, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1121/4220 [1:11:43<3:15:12,  3.78s/it, loss=2.73, epoch=0.265, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1121/4220 [1:11:43<3:15:12,  3.78s/it, loss=3.19, epoch=0.265, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1122/4220 [1:11:47<3:15:06,  3.78s/it, loss=3.19, epoch=0.265, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1122/4220 [1:11:47<3:15:06,  3.78s/it, loss=3.43, epoch=0.266, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1123/4220 [1:11:51<3:15:05,  3.78s/it, loss=3.43, epoch=0.266, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1123/4220 [1:11:51<3:15:05,  3.78s/it, loss=2.2, epoch=0.266, learning_rate=1.68e-5] \u001b[A\n",
      " 27%|██▋       | 1124/4220 [1:11:54<3:15:03,  3.78s/it, loss=2.2, epoch=0.266, learning_rate=1.68e-5]\u001b[A\n",
      " 27%|██▋       | 1124/4220 [1:11:54<3:15:03,  3.78s/it, loss=3.78, epoch=0.266, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1125/4220 [1:11:58<3:15:01,  3.78s/it, loss=3.78, epoch=0.266, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1125/4220 [1:11:58<3:15:01,  3.78s/it, loss=3.13, epoch=0.266, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1126/4220 [1:12:02<3:14:58,  3.78s/it, loss=3.13, epoch=0.266, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1126/4220 [1:12:02<3:14:58,  3.78s/it, loss=2.72, epoch=0.267, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1127/4220 [1:12:06<3:14:49,  3.78s/it, loss=2.72, epoch=0.267, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1127/4220 [1:12:06<3:14:49,  3.78s/it, loss=2.66, epoch=0.267, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1128/4220 [1:12:09<3:14:43,  3.78s/it, loss=2.66, epoch=0.267, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1128/4220 [1:12:09<3:14:43,  3.78s/it, loss=2.9, epoch=0.267, learning_rate=1.67e-5] \u001b[A\n",
      " 27%|██▋       | 1129/4220 [1:12:13<3:14:42,  3.78s/it, loss=2.9, epoch=0.267, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1129/4220 [1:12:13<3:14:42,  3.78s/it, loss=2.76, epoch=0.267, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1130/4220 [1:12:17<3:14:36,  3.78s/it, loss=2.76, epoch=0.267, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1130/4220 [1:12:17<3:14:36,  3.78s/it, loss=2.85, epoch=0.268, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1131/4220 [1:12:21<3:14:30,  3.78s/it, loss=2.85, epoch=0.268, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1131/4220 [1:12:21<3:14:30,  3.78s/it, loss=2.9, epoch=0.268, learning_rate=1.67e-5] \u001b[A\n",
      " 27%|██▋       | 1132/4220 [1:12:25<3:14:25,  3.78s/it, loss=2.9, epoch=0.268, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1132/4220 [1:12:25<3:14:25,  3.78s/it, loss=2.35, epoch=0.268, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1133/4220 [1:12:28<3:14:21,  3.78s/it, loss=2.35, epoch=0.268, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1133/4220 [1:12:28<3:14:21,  3.78s/it, loss=2.94, epoch=0.268, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1134/4220 [1:12:32<3:14:23,  3.78s/it, loss=2.94, epoch=0.268, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1134/4220 [1:12:32<3:14:23,  3.78s/it, loss=2.52, epoch=0.268, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1135/4220 [1:12:36<3:14:18,  3.78s/it, loss=2.52, epoch=0.268, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1135/4220 [1:12:36<3:14:18,  3.78s/it, loss=3.09, epoch=0.269, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1136/4220 [1:12:40<3:14:10,  3.78s/it, loss=3.09, epoch=0.269, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1136/4220 [1:12:40<3:14:10,  3.78s/it, loss=2.34, epoch=0.269, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1137/4220 [1:12:43<3:14:07,  3.78s/it, loss=2.34, epoch=0.269, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1137/4220 [1:12:43<3:14:07,  3.78s/it, loss=2.4, epoch=0.269, learning_rate=1.67e-5] \u001b[A\n",
      " 27%|██▋       | 1138/4220 [1:12:47<3:14:05,  3.78s/it, loss=2.4, epoch=0.269, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1138/4220 [1:12:47<3:14:05,  3.78s/it, loss=2.67, epoch=0.269, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1139/4220 [1:12:51<3:14:05,  3.78s/it, loss=2.67, epoch=0.269, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1139/4220 [1:12:51<3:14:05,  3.78s/it, loss=2.79, epoch=0.27, learning_rate=1.67e-5] \u001b[A\n",
      " 27%|██▋       | 1140/4220 [1:12:55<3:14:00,  3.78s/it, loss=2.79, epoch=0.27, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1140/4220 [1:12:55<3:14:00,  3.78s/it, loss=2.73, epoch=0.27, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1141/4220 [1:12:59<3:13:56,  3.78s/it, loss=2.73, epoch=0.27, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1141/4220 [1:12:59<3:13:56,  3.78s/it, loss=2.79, epoch=0.27, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1142/4220 [1:13:02<3:13:53,  3.78s/it, loss=2.79, epoch=0.27, learning_rate=1.67e-5]\u001b[A\n",
      " 27%|██▋       | 1142/4220 [1:13:02<3:13:53,  3.78s/it, loss=2.9, epoch=0.27, learning_rate=1.66e-5] \u001b[A\n",
      " 27%|██▋       | 1143/4220 [1:13:06<3:13:53,  3.78s/it, loss=2.9, epoch=0.27, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1143/4220 [1:13:06<3:13:53,  3.78s/it, loss=3, epoch=0.271, learning_rate=1.66e-5] \u001b[A\n",
      " 27%|██▋       | 1144/4220 [1:13:10<3:13:50,  3.78s/it, loss=3, epoch=0.271, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1144/4220 [1:13:10<3:13:50,  3.78s/it, loss=2.37, epoch=0.271, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1145/4220 [1:13:14<3:13:43,  3.78s/it, loss=2.37, epoch=0.271, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1145/4220 [1:13:14<3:13:43,  3.78s/it, loss=3.23, epoch=0.271, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1146/4220 [1:13:17<3:13:37,  3.78s/it, loss=3.23, epoch=0.271, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1146/4220 [1:13:17<3:13:37,  3.78s/it, loss=2.85, epoch=0.271, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1147/4220 [1:13:21<3:13:35,  3.78s/it, loss=2.85, epoch=0.271, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1147/4220 [1:13:21<3:13:35,  3.78s/it, loss=2.66, epoch=0.272, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1148/4220 [1:13:25<3:13:28,  3.78s/it, loss=2.66, epoch=0.272, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1148/4220 [1:13:25<3:13:28,  3.78s/it, loss=2.72, epoch=0.272, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1149/4220 [1:13:29<3:13:23,  3.78s/it, loss=2.72, epoch=0.272, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1149/4220 [1:13:29<3:13:23,  3.78s/it, loss=2.13, epoch=0.272, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1150/4220 [1:13:33<3:13:17,  3.78s/it, loss=2.13, epoch=0.272, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1150/4220 [1:13:33<3:13:17,  3.78s/it, loss=2.73, epoch=0.272, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1151/4220 [1:13:36<3:13:13,  3.78s/it, loss=2.73, epoch=0.272, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1151/4220 [1:13:36<3:13:13,  3.78s/it, loss=2.55, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1152/4220 [1:13:40<3:13:06,  3.78s/it, loss=2.55, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1152/4220 [1:13:40<3:13:06,  3.78s/it, loss=2.64, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1153/4220 [1:13:44<3:13:06,  3.78s/it, loss=2.64, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1153/4220 [1:13:44<3:13:06,  3.78s/it, loss=2.69, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1154/4220 [1:13:48<3:13:00,  3.78s/it, loss=2.69, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1154/4220 [1:13:48<3:13:00,  3.78s/it, loss=3.02, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1155/4220 [1:13:51<3:12:59,  3.78s/it, loss=3.02, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1155/4220 [1:13:51<3:12:59,  3.78s/it, loss=2.93, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1156/4220 [1:13:55<3:12:51,  3.78s/it, loss=2.93, epoch=0.273, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1156/4220 [1:13:55<3:12:51,  3.78s/it, loss=2.61, epoch=0.274, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1157/4220 [1:13:59<3:12:53,  3.78s/it, loss=2.61, epoch=0.274, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1157/4220 [1:13:59<3:12:53,  3.78s/it, loss=2.86, epoch=0.274, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1158/4220 [1:14:03<3:12:47,  3.78s/it, loss=2.86, epoch=0.274, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1158/4220 [1:14:03<3:12:47,  3.78s/it, loss=3.25, epoch=0.274, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1159/4220 [1:14:07<3:12:49,  3.78s/it, loss=3.25, epoch=0.274, learning_rate=1.66e-5]\u001b[A\n",
      " 27%|██▋       | 1159/4220 [1:14:07<3:12:49,  3.78s/it, loss=3.02, epoch=0.274, learning_rate=1.65e-5]\u001b[A\n",
      " 27%|██▋       | 1160/4220 [1:14:10<3:12:47,  3.78s/it, loss=3.02, epoch=0.274, learning_rate=1.65e-5]\u001b[A\n",
      " 27%|██▋       | 1160/4220 [1:14:10<3:12:47,  3.78s/it, loss=2.62, epoch=0.275, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1161/4220 [1:14:14<3:12:45,  3.78s/it, loss=2.62, epoch=0.275, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1161/4220 [1:14:14<3:12:45,  3.78s/it, loss=2.78, epoch=0.275, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1162/4220 [1:14:18<3:12:41,  3.78s/it, loss=2.78, epoch=0.275, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1162/4220 [1:14:18<3:12:41,  3.78s/it, loss=2.61, epoch=0.275, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1163/4220 [1:14:22<3:12:33,  3.78s/it, loss=2.61, epoch=0.275, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1163/4220 [1:14:22<3:12:33,  3.78s/it, loss=3.07, epoch=0.275, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1164/4220 [1:14:26<3:12:27,  3.78s/it, loss=3.07, epoch=0.275, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1164/4220 [1:14:26<3:12:27,  3.78s/it, loss=3.12, epoch=0.276, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1165/4220 [1:14:29<3:12:22,  3.78s/it, loss=3.12, epoch=0.276, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1165/4220 [1:14:29<3:12:22,  3.78s/it, loss=2.9, epoch=0.276, learning_rate=1.65e-5] \u001b[A\n",
      " 28%|██▊       | 1166/4220 [1:14:33<3:12:21,  3.78s/it, loss=2.9, epoch=0.276, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1166/4220 [1:14:33<3:12:21,  3.78s/it, loss=2.85, epoch=0.276, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1167/4220 [1:14:37<3:12:19,  3.78s/it, loss=2.85, epoch=0.276, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1167/4220 [1:14:37<3:12:19,  3.78s/it, loss=2.66, epoch=0.276, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1168/4220 [1:14:41<3:12:14,  3.78s/it, loss=2.66, epoch=0.276, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1168/4220 [1:14:41<3:12:14,  3.78s/it, loss=3.14, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1169/4220 [1:14:44<3:12:10,  3.78s/it, loss=3.14, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1169/4220 [1:14:44<3:12:10,  3.78s/it, loss=2.36, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1170/4220 [1:14:48<3:12:10,  3.78s/it, loss=2.36, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1170/4220 [1:14:48<3:12:10,  3.78s/it, loss=2.95, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1171/4220 [1:14:52<3:12:10,  3.78s/it, loss=2.95, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1171/4220 [1:14:52<3:12:10,  3.78s/it, loss=2.63, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1172/4220 [1:14:56<3:11:59,  3.78s/it, loss=2.63, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1172/4220 [1:14:56<3:11:59,  3.78s/it, loss=2.84, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1173/4220 [1:15:00<3:11:59,  3.78s/it, loss=2.84, epoch=0.277, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1173/4220 [1:15:00<3:11:59,  3.78s/it, loss=2.86, epoch=0.278, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1174/4220 [1:15:03<3:11:46,  3.78s/it, loss=2.86, epoch=0.278, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1174/4220 [1:15:03<3:11:46,  3.78s/it, loss=2.57, epoch=0.278, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1175/4220 [1:15:07<3:11:48,  3.78s/it, loss=2.57, epoch=0.278, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1175/4220 [1:15:07<3:11:48,  3.78s/it, loss=2.74, epoch=0.278, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1176/4220 [1:15:11<3:11:42,  3.78s/it, loss=2.74, epoch=0.278, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1176/4220 [1:15:11<3:11:42,  3.78s/it, loss=2.68, epoch=0.278, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1177/4220 [1:15:15<3:11:37,  3.78s/it, loss=2.68, epoch=0.278, learning_rate=1.65e-5]\u001b[A\n",
      " 28%|██▊       | 1177/4220 [1:15:15<3:11:37,  3.78s/it, loss=2.74, epoch=0.279, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1178/4220 [1:15:18<3:11:32,  3.78s/it, loss=2.74, epoch=0.279, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1178/4220 [1:15:18<3:11:32,  3.78s/it, loss=2.95, epoch=0.279, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1179/4220 [1:15:22<3:11:32,  3.78s/it, loss=2.95, epoch=0.279, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1179/4220 [1:15:22<3:11:32,  3.78s/it, loss=3.42, epoch=0.279, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1180/4220 [1:15:26<3:11:28,  3.78s/it, loss=3.42, epoch=0.279, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1180/4220 [1:15:26<3:11:28,  3.78s/it, loss=2.9, epoch=0.279, learning_rate=1.64e-5] \u001b[A\n",
      " 28%|██▊       | 1181/4220 [1:15:30<3:11:21,  3.78s/it, loss=2.9, epoch=0.279, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1181/4220 [1:15:30<3:11:21,  3.78s/it, loss=3.13, epoch=0.28, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1182/4220 [1:15:34<3:11:15,  3.78s/it, loss=3.13, epoch=0.28, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1182/4220 [1:15:34<3:11:15,  3.78s/it, loss=2.76, epoch=0.28, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1183/4220 [1:15:37<3:11:09,  3.78s/it, loss=2.76, epoch=0.28, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1183/4220 [1:15:37<3:11:09,  3.78s/it, loss=3.03, epoch=0.28, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1184/4220 [1:15:41<3:11:01,  3.78s/it, loss=3.03, epoch=0.28, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1184/4220 [1:15:41<3:11:01,  3.78s/it, loss=2.75, epoch=0.28, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1185/4220 [1:15:45<3:10:57,  3.78s/it, loss=2.75, epoch=0.28, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1185/4220 [1:15:45<3:10:57,  3.78s/it, loss=2.8, epoch=0.281, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1186/4220 [1:15:49<3:10:58,  3.78s/it, loss=2.8, epoch=0.281, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1186/4220 [1:15:49<3:10:58,  3.78s/it, loss=2.85, epoch=0.281, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1187/4220 [1:15:52<3:10:56,  3.78s/it, loss=2.85, epoch=0.281, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1187/4220 [1:15:52<3:10:56,  3.78s/it, loss=3.04, epoch=0.281, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1188/4220 [1:15:56<3:10:47,  3.78s/it, loss=3.04, epoch=0.281, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1188/4220 [1:15:56<3:10:47,  3.78s/it, loss=2.74, epoch=0.281, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1189/4220 [1:16:00<3:10:49,  3.78s/it, loss=2.74, epoch=0.281, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1189/4220 [1:16:00<3:10:49,  3.78s/it, loss=2.55, epoch=0.282, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1190/4220 [1:16:04<3:10:48,  3.78s/it, loss=2.55, epoch=0.282, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1190/4220 [1:16:04<3:10:48,  3.78s/it, loss=2.57, epoch=0.282, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1191/4220 [1:16:08<3:10:44,  3.78s/it, loss=2.57, epoch=0.282, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1191/4220 [1:16:08<3:10:44,  3.78s/it, loss=3.11, epoch=0.282, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1192/4220 [1:16:11<3:10:41,  3.78s/it, loss=3.11, epoch=0.282, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1192/4220 [1:16:11<3:10:41,  3.78s/it, loss=3.1, epoch=0.282, learning_rate=1.64e-5] \u001b[A\n",
      " 28%|██▊       | 1193/4220 [1:16:15<3:10:32,  3.78s/it, loss=3.1, epoch=0.282, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1193/4220 [1:16:15<3:10:32,  3.78s/it, loss=2.72, epoch=0.282, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1194/4220 [1:16:19<3:10:32,  3.78s/it, loss=2.72, epoch=0.282, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1194/4220 [1:16:19<3:10:32,  3.78s/it, loss=2.92, epoch=0.283, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1195/4220 [1:16:23<3:10:31,  3.78s/it, loss=2.92, epoch=0.283, learning_rate=1.64e-5]\u001b[A\n",
      " 28%|██▊       | 1195/4220 [1:16:23<3:10:31,  3.78s/it, loss=2.38, epoch=0.283, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1196/4220 [1:16:26<3:10:26,  3.78s/it, loss=2.38, epoch=0.283, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1196/4220 [1:16:26<3:10:26,  3.78s/it, loss=3.04, epoch=0.283, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1197/4220 [1:16:30<3:10:24,  3.78s/it, loss=3.04, epoch=0.283, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1197/4220 [1:16:30<3:10:24,  3.78s/it, loss=2.35, epoch=0.283, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1198/4220 [1:16:34<3:10:17,  3.78s/it, loss=2.35, epoch=0.283, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1198/4220 [1:16:34<3:10:17,  3.78s/it, loss=2.86, epoch=0.284, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1199/4220 [1:16:38<3:10:14,  3.78s/it, loss=2.86, epoch=0.284, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1199/4220 [1:16:38<3:10:14,  3.78s/it, loss=3.09, epoch=0.284, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1200/4220 [1:16:42<3:10:11,  3.78s/it, loss=3.09, epoch=0.284, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1200/4220 [1:16:42<3:10:11,  3.78s/it, loss=2.67, epoch=0.284, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1201/4220 [1:16:45<3:10:04,  3.78s/it, loss=2.67, epoch=0.284, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1201/4220 [1:16:45<3:10:04,  3.78s/it, loss=3.01, epoch=0.284, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1202/4220 [1:16:49<3:10:02,  3.78s/it, loss=3.01, epoch=0.284, learning_rate=1.63e-5]\u001b[A\n",
      " 28%|██▊       | 1202/4220 [1:16:49<3:10:02,  3.78s/it, loss=2.58, epoch=0.285, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1203/4220 [1:16:53<3:09:57,  3.78s/it, loss=2.58, epoch=0.285, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1203/4220 [1:16:53<3:09:57,  3.78s/it, loss=2.69, epoch=0.285, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1204/4220 [1:16:57<3:09:48,  3.78s/it, loss=2.69, epoch=0.285, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1204/4220 [1:16:57<3:09:48,  3.78s/it, loss=2.51, epoch=0.285, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1205/4220 [1:17:00<3:09:50,  3.78s/it, loss=2.51, epoch=0.285, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1205/4220 [1:17:00<3:09:50,  3.78s/it, loss=3.34, epoch=0.285, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1206/4220 [1:17:04<3:11:00,  3.80s/it, loss=3.34, epoch=0.285, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1206/4220 [1:17:04<3:11:00,  3.80s/it, loss=3.13, epoch=0.286, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1207/4220 [1:17:08<3:10:30,  3.79s/it, loss=3.13, epoch=0.286, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1207/4220 [1:17:08<3:10:30,  3.79s/it, loss=3.21, epoch=0.286, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1208/4220 [1:17:12<3:10:14,  3.79s/it, loss=3.21, epoch=0.286, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1208/4220 [1:17:12<3:10:14,  3.79s/it, loss=3.22, epoch=0.286, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1209/4220 [1:17:16<3:09:58,  3.79s/it, loss=3.22, epoch=0.286, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1209/4220 [1:17:16<3:09:58,  3.79s/it, loss=2.51, epoch=0.286, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1210/4220 [1:17:19<3:09:46,  3.78s/it, loss=2.51, epoch=0.286, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1210/4220 [1:17:19<3:09:46,  3.78s/it, loss=2.6, epoch=0.286, learning_rate=1.63e-5] \u001b[A\n",
      " 29%|██▊       | 1211/4220 [1:17:23<3:09:33,  3.78s/it, loss=2.6, epoch=0.286, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1211/4220 [1:17:23<3:09:33,  3.78s/it, loss=2.79, epoch=0.287, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1212/4220 [1:17:27<3:09:32,  3.78s/it, loss=2.79, epoch=0.287, learning_rate=1.63e-5]\u001b[A\n",
      " 29%|██▊       | 1212/4220 [1:17:27<3:09:32,  3.78s/it, loss=2.91, epoch=0.287, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▊       | 1213/4220 [1:17:31<3:09:27,  3.78s/it, loss=2.91, epoch=0.287, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▊       | 1213/4220 [1:17:31<3:09:27,  3.78s/it, loss=2.68, epoch=0.287, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1214/4220 [1:17:34<3:09:21,  3.78s/it, loss=2.68, epoch=0.287, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1214/4220 [1:17:34<3:09:21,  3.78s/it, loss=2.72, epoch=0.287, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1215/4220 [1:17:38<3:09:14,  3.78s/it, loss=2.72, epoch=0.287, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1215/4220 [1:17:38<3:09:14,  3.78s/it, loss=2.82, epoch=0.288, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1216/4220 [1:17:42<3:09:12,  3.78s/it, loss=2.82, epoch=0.288, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1216/4220 [1:17:42<3:09:12,  3.78s/it, loss=2.87, epoch=0.288, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1217/4220 [1:17:46<3:09:00,  3.78s/it, loss=2.87, epoch=0.288, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1217/4220 [1:17:46<3:09:00,  3.78s/it, loss=3.02, epoch=0.288, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1218/4220 [1:17:50<3:09:03,  3.78s/it, loss=3.02, epoch=0.288, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1218/4220 [1:17:50<3:09:03,  3.78s/it, loss=2.96, epoch=0.288, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1219/4220 [1:17:53<3:09:02,  3.78s/it, loss=2.96, epoch=0.288, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1219/4220 [1:17:53<3:09:02,  3.78s/it, loss=2.66, epoch=0.289, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1220/4220 [1:17:57<3:08:51,  3.78s/it, loss=2.66, epoch=0.289, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1220/4220 [1:17:57<3:08:51,  3.78s/it, loss=2.71, epoch=0.289, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1221/4220 [1:18:01<3:08:50,  3.78s/it, loss=2.71, epoch=0.289, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1221/4220 [1:18:01<3:08:50,  3.78s/it, loss=3.1, epoch=0.289, learning_rate=1.62e-5] \u001b[A\n",
      " 29%|██▉       | 1222/4220 [1:18:05<3:08:44,  3.78s/it, loss=3.1, epoch=0.289, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1222/4220 [1:18:05<3:08:44,  3.78s/it, loss=3.03, epoch=0.289, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1223/4220 [1:18:08<3:08:43,  3.78s/it, loss=3.03, epoch=0.289, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1223/4220 [1:18:08<3:08:43,  3.78s/it, loss=2.76, epoch=0.29, learning_rate=1.62e-5] \u001b[A\n",
      " 29%|██▉       | 1224/4220 [1:18:12<3:08:38,  3.78s/it, loss=2.76, epoch=0.29, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1224/4220 [1:18:12<3:08:38,  3.78s/it, loss=2.77, epoch=0.29, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1225/4220 [1:18:16<3:08:32,  3.78s/it, loss=2.77, epoch=0.29, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1225/4220 [1:18:16<3:08:32,  3.78s/it, loss=2.6, epoch=0.29, learning_rate=1.62e-5] \u001b[A\n",
      " 29%|██▉       | 1226/4220 [1:18:20<3:08:31,  3.78s/it, loss=2.6, epoch=0.29, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1226/4220 [1:18:20<3:08:31,  3.78s/it, loss=2.89, epoch=0.29, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1227/4220 [1:18:24<3:08:29,  3.78s/it, loss=2.89, epoch=0.29, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1227/4220 [1:18:24<3:08:29,  3.78s/it, loss=2.84, epoch=0.291, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1228/4220 [1:18:27<3:08:27,  3.78s/it, loss=2.84, epoch=0.291, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1228/4220 [1:18:27<3:08:27,  3.78s/it, loss=2.67, epoch=0.291, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1229/4220 [1:18:31<3:08:22,  3.78s/it, loss=2.67, epoch=0.291, learning_rate=1.62e-5]\u001b[A\n",
      " 29%|██▉       | 1229/4220 [1:18:31<3:08:22,  3.78s/it, loss=3.17, epoch=0.291, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1230/4220 [1:18:35<3:08:20,  3.78s/it, loss=3.17, epoch=0.291, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1230/4220 [1:18:35<3:08:20,  3.78s/it, loss=2.84, epoch=0.291, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1231/4220 [1:18:39<3:08:16,  3.78s/it, loss=2.84, epoch=0.291, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1231/4220 [1:18:39<3:08:16,  3.78s/it, loss=3.11, epoch=0.291, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1232/4220 [1:18:42<3:08:10,  3.78s/it, loss=3.11, epoch=0.291, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1232/4220 [1:18:42<3:08:10,  3.78s/it, loss=2.51, epoch=0.292, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1233/4220 [1:18:46<3:08:12,  3.78s/it, loss=2.51, epoch=0.292, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1233/4220 [1:18:46<3:08:12,  3.78s/it, loss=3.21, epoch=0.292, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1234/4220 [1:18:50<3:08:10,  3.78s/it, loss=3.21, epoch=0.292, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1234/4220 [1:18:50<3:08:10,  3.78s/it, loss=2.92, epoch=0.292, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1235/4220 [1:18:54<3:08:00,  3.78s/it, loss=2.92, epoch=0.292, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1235/4220 [1:18:54<3:08:00,  3.78s/it, loss=2.77, epoch=0.292, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1236/4220 [1:18:58<3:07:56,  3.78s/it, loss=2.77, epoch=0.292, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1236/4220 [1:18:58<3:07:56,  3.78s/it, loss=2.69, epoch=0.293, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1237/4220 [1:19:01<3:07:51,  3.78s/it, loss=2.69, epoch=0.293, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1237/4220 [1:19:01<3:07:51,  3.78s/it, loss=3.07, epoch=0.293, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1238/4220 [1:19:05<3:07:43,  3.78s/it, loss=3.07, epoch=0.293, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1238/4220 [1:19:05<3:07:43,  3.78s/it, loss=3.05, epoch=0.293, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1239/4220 [1:19:09<3:07:41,  3.78s/it, loss=3.05, epoch=0.293, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1239/4220 [1:19:09<3:07:41,  3.78s/it, loss=2.53, epoch=0.293, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1240/4220 [1:19:13<3:07:36,  3.78s/it, loss=2.53, epoch=0.293, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1240/4220 [1:19:13<3:07:36,  3.78s/it, loss=2.76, epoch=0.294, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1241/4220 [1:19:17<3:07:33,  3.78s/it, loss=2.76, epoch=0.294, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1241/4220 [1:19:17<3:07:33,  3.78s/it, loss=2.88, epoch=0.294, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1242/4220 [1:19:20<3:07:30,  3.78s/it, loss=2.88, epoch=0.294, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1242/4220 [1:19:20<3:07:30,  3.78s/it, loss=3.47, epoch=0.294, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1243/4220 [1:19:24<3:07:25,  3.78s/it, loss=3.47, epoch=0.294, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1243/4220 [1:19:24<3:07:25,  3.78s/it, loss=3.12, epoch=0.294, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1244/4220 [1:19:28<3:07:24,  3.78s/it, loss=3.12, epoch=0.294, learning_rate=1.61e-5]\u001b[A\n",
      " 29%|██▉       | 1244/4220 [1:19:28<3:07:24,  3.78s/it, loss=2.41, epoch=0.295, learning_rate=1.61e-5]\u001b[A\n",
      " 30%|██▉       | 1245/4220 [1:19:32<3:07:20,  3.78s/it, loss=2.41, epoch=0.295, learning_rate=1.61e-5]\u001b[A\n",
      " 30%|██▉       | 1245/4220 [1:19:32<3:07:20,  3.78s/it, loss=2.28, epoch=0.295, learning_rate=1.61e-5]\u001b[A\n",
      " 30%|██▉       | 1246/4220 [1:19:35<3:07:18,  3.78s/it, loss=2.28, epoch=0.295, learning_rate=1.61e-5]\u001b[A\n",
      " 30%|██▉       | 1246/4220 [1:19:35<3:07:18,  3.78s/it, loss=3.12, epoch=0.295, learning_rate=1.6e-5] \u001b[A\n",
      " 30%|██▉       | 1247/4220 [1:19:39<3:07:11,  3.78s/it, loss=3.12, epoch=0.295, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1247/4220 [1:19:39<3:07:11,  3.78s/it, loss=2.52, epoch=0.295, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1248/4220 [1:19:43<3:07:09,  3.78s/it, loss=2.52, epoch=0.295, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1248/4220 [1:19:43<3:07:09,  3.78s/it, loss=2.62, epoch=0.295, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1249/4220 [1:19:47<3:07:07,  3.78s/it, loss=2.62, epoch=0.295, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1249/4220 [1:19:47<3:07:07,  3.78s/it, loss=2.58, epoch=0.296, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1250/4220 [1:19:51<3:06:57,  3.78s/it, loss=2.58, epoch=0.296, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1250/4220 [1:19:51<3:06:57,  3.78s/it, loss=2.71, epoch=0.296, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1251/4220 [1:19:54<3:06:56,  3.78s/it, loss=2.71, epoch=0.296, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1251/4220 [1:19:54<3:06:56,  3.78s/it, loss=3.6, epoch=0.296, learning_rate=1.6e-5] \u001b[A\n",
      " 30%|██▉       | 1252/4220 [1:19:58<3:06:53,  3.78s/it, loss=3.6, epoch=0.296, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1252/4220 [1:19:58<3:06:53,  3.78s/it, loss=3.18, epoch=0.296, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1253/4220 [1:20:02<3:06:49,  3.78s/it, loss=3.18, epoch=0.296, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1253/4220 [1:20:02<3:06:49,  3.78s/it, loss=2.94, epoch=0.297, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1254/4220 [1:20:06<3:06:43,  3.78s/it, loss=2.94, epoch=0.297, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1254/4220 [1:20:06<3:06:43,  3.78s/it, loss=3, epoch=0.297, learning_rate=1.6e-5]   \u001b[A\n",
      " 30%|██▉       | 1255/4220 [1:20:09<3:06:37,  3.78s/it, loss=3, epoch=0.297, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1255/4220 [1:20:09<3:06:37,  3.78s/it, loss=2.8, epoch=0.297, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1256/4220 [1:20:13<3:06:35,  3.78s/it, loss=2.8, epoch=0.297, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1256/4220 [1:20:13<3:06:35,  3.78s/it, loss=2.79, epoch=0.297, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1257/4220 [1:20:17<3:06:28,  3.78s/it, loss=2.79, epoch=0.297, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1257/4220 [1:20:17<3:06:28,  3.78s/it, loss=2.3, epoch=0.298, learning_rate=1.6e-5] \u001b[A\n",
      " 30%|██▉       | 1258/4220 [1:20:21<3:06:31,  3.78s/it, loss=2.3, epoch=0.298, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1258/4220 [1:20:21<3:06:31,  3.78s/it, loss=2.57, epoch=0.298, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1259/4220 [1:20:25<3:06:29,  3.78s/it, loss=2.57, epoch=0.298, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1259/4220 [1:20:25<3:06:29,  3.78s/it, loss=3.05, epoch=0.298, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1260/4220 [1:20:28<3:06:27,  3.78s/it, loss=3.05, epoch=0.298, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1260/4220 [1:20:28<3:06:27,  3.78s/it, loss=2.64, epoch=0.298, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1261/4220 [1:20:32<3:06:22,  3.78s/it, loss=2.64, epoch=0.298, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1261/4220 [1:20:32<3:06:22,  3.78s/it, loss=3.22, epoch=0.299, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1262/4220 [1:20:36<3:06:17,  3.78s/it, loss=3.22, epoch=0.299, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1262/4220 [1:20:36<3:06:17,  3.78s/it, loss=2.38, epoch=0.299, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1263/4220 [1:20:40<3:06:14,  3.78s/it, loss=2.38, epoch=0.299, learning_rate=1.6e-5]\u001b[A\n",
      " 30%|██▉       | 1263/4220 [1:20:40<3:06:14,  3.78s/it, loss=2.68, epoch=0.299, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|██▉       | 1264/4220 [1:20:43<3:06:10,  3.78s/it, loss=2.68, epoch=0.299, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|██▉       | 1264/4220 [1:20:43<3:06:10,  3.78s/it, loss=2.76, epoch=0.299, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|██▉       | 1265/4220 [1:20:47<3:06:05,  3.78s/it, loss=2.76, epoch=0.299, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|██▉       | 1265/4220 [1:20:47<3:06:05,  3.78s/it, loss=2.9, epoch=0.3, learning_rate=1.59e-5]   \u001b[A\n",
      " 30%|███       | 1266/4220 [1:20:51<3:05:56,  3.78s/it, loss=2.9, epoch=0.3, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1266/4220 [1:20:51<3:05:56,  3.78s/it, loss=2.85, epoch=0.3, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1267/4220 [1:20:55<3:05:52,  3.78s/it, loss=2.85, epoch=0.3, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1267/4220 [1:20:55<3:05:52,  3.78s/it, loss=2.96, epoch=0.3, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1268/4220 [1:20:59<3:05:50,  3.78s/it, loss=2.96, epoch=0.3, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1268/4220 [1:20:59<3:05:50,  3.78s/it, loss=3.26, epoch=0.3, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1269/4220 [1:21:02<3:05:41,  3.78s/it, loss=3.26, epoch=0.3, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1269/4220 [1:21:02<3:05:41,  3.78s/it, loss=2.91, epoch=0.3, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1270/4220 [1:21:06<3:05:43,  3.78s/it, loss=2.91, epoch=0.3, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1270/4220 [1:21:06<3:05:43,  3.78s/it, loss=2.73, epoch=0.301, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1271/4220 [1:21:10<3:05:40,  3.78s/it, loss=2.73, epoch=0.301, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1271/4220 [1:21:10<3:05:40,  3.78s/it, loss=3.17, epoch=0.301, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1272/4220 [1:21:14<3:05:34,  3.78s/it, loss=3.17, epoch=0.301, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1272/4220 [1:21:14<3:05:34,  3.78s/it, loss=2.63, epoch=0.301, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1273/4220 [1:21:17<3:05:28,  3.78s/it, loss=2.63, epoch=0.301, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1273/4220 [1:21:17<3:05:28,  3.78s/it, loss=2.74, epoch=0.301, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1274/4220 [1:21:21<3:05:23,  3.78s/it, loss=2.74, epoch=0.301, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1274/4220 [1:21:21<3:05:23,  3.78s/it, loss=2.61, epoch=0.302, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1275/4220 [1:21:25<3:05:22,  3.78s/it, loss=2.61, epoch=0.302, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1275/4220 [1:21:25<3:05:22,  3.78s/it, loss=2.9, epoch=0.302, learning_rate=1.59e-5] \u001b[A\n",
      " 30%|███       | 1276/4220 [1:21:29<3:05:21,  3.78s/it, loss=2.9, epoch=0.302, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1276/4220 [1:21:29<3:05:21,  3.78s/it, loss=2.62, epoch=0.302, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1277/4220 [1:21:32<3:05:16,  3.78s/it, loss=2.62, epoch=0.302, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1277/4220 [1:21:32<3:05:16,  3.78s/it, loss=3.26, epoch=0.302, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1278/4220 [1:21:36<3:05:11,  3.78s/it, loss=3.26, epoch=0.302, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1278/4220 [1:21:36<3:05:11,  3.78s/it, loss=2.73, epoch=0.303, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1279/4220 [1:21:40<3:05:04,  3.78s/it, loss=2.73, epoch=0.303, learning_rate=1.59e-5]\u001b[A\n",
      " 30%|███       | 1279/4220 [1:21:40<3:05:04,  3.78s/it, loss=2.6, epoch=0.303, learning_rate=1.58e-5] \u001b[A\n",
      " 30%|███       | 1280/4220 [1:21:44<3:05:02,  3.78s/it, loss=2.6, epoch=0.303, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1280/4220 [1:21:44<3:05:02,  3.78s/it, loss=2.56, epoch=0.303, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1281/4220 [1:21:48<3:04:55,  3.78s/it, loss=2.56, epoch=0.303, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1281/4220 [1:21:48<3:04:55,  3.78s/it, loss=2.54, epoch=0.303, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1282/4220 [1:21:51<3:04:54,  3.78s/it, loss=2.54, epoch=0.303, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1282/4220 [1:21:51<3:04:54,  3.78s/it, loss=2.87, epoch=0.304, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1283/4220 [1:21:55<3:04:54,  3.78s/it, loss=2.87, epoch=0.304, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1283/4220 [1:21:55<3:04:54,  3.78s/it, loss=3.05, epoch=0.304, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1284/4220 [1:21:59<3:04:53,  3.78s/it, loss=3.05, epoch=0.304, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1284/4220 [1:21:59<3:04:53,  3.78s/it, loss=3.05, epoch=0.304, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1285/4220 [1:22:03<3:04:48,  3.78s/it, loss=3.05, epoch=0.304, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1285/4220 [1:22:03<3:04:48,  3.78s/it, loss=2.69, epoch=0.304, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1286/4220 [1:22:07<3:05:56,  3.80s/it, loss=2.69, epoch=0.304, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1286/4220 [1:22:07<3:05:56,  3.80s/it, loss=2.63, epoch=0.305, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1287/4220 [1:22:10<3:05:27,  3.79s/it, loss=2.63, epoch=0.305, learning_rate=1.58e-5]\u001b[A\n",
      " 30%|███       | 1287/4220 [1:22:10<3:05:27,  3.79s/it, loss=2.51, epoch=0.305, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1288/4220 [1:22:14<3:05:11,  3.79s/it, loss=2.51, epoch=0.305, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1288/4220 [1:22:14<3:05:11,  3.79s/it, loss=2.98, epoch=0.305, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1289/4220 [1:22:18<3:04:58,  3.79s/it, loss=2.98, epoch=0.305, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1289/4220 [1:22:18<3:04:58,  3.79s/it, loss=2.51, epoch=0.305, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1290/4220 [1:22:22<3:04:44,  3.78s/it, loss=2.51, epoch=0.305, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1290/4220 [1:22:22<3:04:44,  3.78s/it, loss=2.8, epoch=0.305, learning_rate=1.58e-5] \u001b[A\n",
      " 31%|███       | 1291/4220 [1:22:25<3:04:37,  3.78s/it, loss=2.8, epoch=0.305, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1291/4220 [1:22:25<3:04:37,  3.78s/it, loss=3.09, epoch=0.306, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1292/4220 [1:22:29<3:04:29,  3.78s/it, loss=3.09, epoch=0.306, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1292/4220 [1:22:29<3:04:29,  3.78s/it, loss=3.51, epoch=0.306, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1293/4220 [1:22:33<3:04:22,  3.78s/it, loss=3.51, epoch=0.306, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1293/4220 [1:22:33<3:04:22,  3.78s/it, loss=2.78, epoch=0.306, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1294/4220 [1:22:37<3:04:14,  3.78s/it, loss=2.78, epoch=0.306, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1294/4220 [1:22:37<3:04:14,  3.78s/it, loss=2.81, epoch=0.306, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1295/4220 [1:22:41<3:04:13,  3.78s/it, loss=2.81, epoch=0.306, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1295/4220 [1:22:41<3:04:13,  3.78s/it, loss=2.83, epoch=0.307, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1296/4220 [1:22:44<3:04:11,  3.78s/it, loss=2.83, epoch=0.307, learning_rate=1.58e-5]\u001b[A\n",
      " 31%|███       | 1296/4220 [1:22:44<3:04:11,  3.78s/it, loss=2.25, epoch=0.307, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1297/4220 [1:22:48<3:04:04,  3.78s/it, loss=2.25, epoch=0.307, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1297/4220 [1:22:48<3:04:04,  3.78s/it, loss=2.98, epoch=0.307, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1298/4220 [1:22:52<3:04:04,  3.78s/it, loss=2.98, epoch=0.307, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1298/4220 [1:22:52<3:04:04,  3.78s/it, loss=2.81, epoch=0.307, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1299/4220 [1:22:56<3:03:56,  3.78s/it, loss=2.81, epoch=0.307, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1299/4220 [1:22:56<3:03:56,  3.78s/it, loss=2.8, epoch=0.308, learning_rate=1.57e-5] \u001b[A\n",
      " 31%|███       | 1300/4220 [1:22:59<3:03:55,  3.78s/it, loss=2.8, epoch=0.308, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1300/4220 [1:22:59<3:03:55,  3.78s/it, loss=2.81, epoch=0.308, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1301/4220 [1:23:03<3:03:52,  3.78s/it, loss=2.81, epoch=0.308, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1301/4220 [1:23:03<3:03:52,  3.78s/it, loss=3.54, epoch=0.308, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1302/4220 [1:23:07<3:03:44,  3.78s/it, loss=3.54, epoch=0.308, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1302/4220 [1:23:07<3:03:44,  3.78s/it, loss=2.79, epoch=0.308, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1303/4220 [1:23:11<3:03:43,  3.78s/it, loss=2.79, epoch=0.308, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1303/4220 [1:23:11<3:03:43,  3.78s/it, loss=3.24, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1304/4220 [1:23:15<3:03:41,  3.78s/it, loss=3.24, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1304/4220 [1:23:15<3:03:41,  3.78s/it, loss=3.04, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1305/4220 [1:23:18<3:03:38,  3.78s/it, loss=3.04, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1305/4220 [1:23:18<3:03:38,  3.78s/it, loss=3.11, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1306/4220 [1:23:22<3:03:30,  3.78s/it, loss=3.11, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1306/4220 [1:23:22<3:03:30,  3.78s/it, loss=2.38, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1307/4220 [1:23:26<3:03:28,  3.78s/it, loss=2.38, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1307/4220 [1:23:26<3:03:28,  3.78s/it, loss=2.89, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1308/4220 [1:23:30<3:03:22,  3.78s/it, loss=2.89, epoch=0.309, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1308/4220 [1:23:30<3:03:22,  3.78s/it, loss=3.32, epoch=0.31, learning_rate=1.57e-5] \u001b[A\n",
      " 31%|███       | 1309/4220 [1:23:33<3:03:22,  3.78s/it, loss=3.32, epoch=0.31, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1309/4220 [1:23:33<3:03:22,  3.78s/it, loss=2.9, epoch=0.31, learning_rate=1.57e-5] \u001b[A\n",
      " 31%|███       | 1310/4220 [1:23:37<3:03:19,  3.78s/it, loss=2.9, epoch=0.31, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1310/4220 [1:23:37<3:03:19,  3.78s/it, loss=2.65, epoch=0.31, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1311/4220 [1:23:41<3:03:19,  3.78s/it, loss=2.65, epoch=0.31, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1311/4220 [1:23:41<3:03:19,  3.78s/it, loss=2.72, epoch=0.31, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1312/4220 [1:23:45<3:03:16,  3.78s/it, loss=2.72, epoch=0.31, learning_rate=1.57e-5]\u001b[A\n",
      " 31%|███       | 1312/4220 [1:23:45<3:03:16,  3.78s/it, loss=2.63, epoch=0.311, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1313/4220 [1:23:49<3:03:13,  3.78s/it, loss=2.63, epoch=0.311, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1313/4220 [1:23:49<3:03:13,  3.78s/it, loss=2.91, epoch=0.311, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1314/4220 [1:23:52<3:03:01,  3.78s/it, loss=2.91, epoch=0.311, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1314/4220 [1:23:52<3:03:01,  3.78s/it, loss=3.14, epoch=0.311, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1315/4220 [1:23:56<3:03:03,  3.78s/it, loss=3.14, epoch=0.311, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1315/4220 [1:23:56<3:03:03,  3.78s/it, loss=3.11, epoch=0.311, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1316/4220 [1:24:00<3:03:01,  3.78s/it, loss=3.11, epoch=0.311, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1316/4220 [1:24:00<3:03:01,  3.78s/it, loss=3.32, epoch=0.312, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1317/4220 [1:24:04<3:02:50,  3.78s/it, loss=3.32, epoch=0.312, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1317/4220 [1:24:04<3:02:50,  3.78s/it, loss=2.52, epoch=0.312, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1318/4220 [1:24:08<3:02:47,  3.78s/it, loss=2.52, epoch=0.312, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███       | 1318/4220 [1:24:08<3:02:47,  3.78s/it, loss=2.82, epoch=0.312, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1319/4220 [1:24:11<3:02:42,  3.78s/it, loss=2.82, epoch=0.312, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1319/4220 [1:24:11<3:02:42,  3.78s/it, loss=3.09, epoch=0.312, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1320/4220 [1:24:15<3:02:40,  3.78s/it, loss=3.09, epoch=0.312, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1320/4220 [1:24:15<3:02:40,  3.78s/it, loss=2.69, epoch=0.313, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1321/4220 [1:24:19<3:02:37,  3.78s/it, loss=2.69, epoch=0.313, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1321/4220 [1:24:19<3:02:37,  3.78s/it, loss=3.01, epoch=0.313, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1322/4220 [1:24:23<3:02:36,  3.78s/it, loss=3.01, epoch=0.313, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1322/4220 [1:24:23<3:02:36,  3.78s/it, loss=3.08, epoch=0.313, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1323/4220 [1:24:26<3:02:30,  3.78s/it, loss=3.08, epoch=0.313, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1323/4220 [1:24:26<3:02:30,  3.78s/it, loss=2.75, epoch=0.313, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1324/4220 [1:24:30<3:02:23,  3.78s/it, loss=2.75, epoch=0.313, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1324/4220 [1:24:30<3:02:23,  3.78s/it, loss=2.8, epoch=0.314, learning_rate=1.56e-5] \u001b[A\n",
      " 31%|███▏      | 1325/4220 [1:24:34<3:02:21,  3.78s/it, loss=2.8, epoch=0.314, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1325/4220 [1:24:34<3:02:21,  3.78s/it, loss=2.98, epoch=0.314, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1326/4220 [1:24:38<3:02:20,  3.78s/it, loss=2.98, epoch=0.314, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1326/4220 [1:24:38<3:02:20,  3.78s/it, loss=3.09, epoch=0.314, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1327/4220 [1:24:42<3:02:10,  3.78s/it, loss=3.09, epoch=0.314, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1327/4220 [1:24:42<3:02:10,  3.78s/it, loss=2.59, epoch=0.314, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1328/4220 [1:24:45<3:02:05,  3.78s/it, loss=2.59, epoch=0.314, learning_rate=1.56e-5]\u001b[A\n",
      " 31%|███▏      | 1328/4220 [1:24:45<3:02:05,  3.78s/it, loss=3.09, epoch=0.314, learning_rate=1.55e-5]\u001b[A\n",
      " 31%|███▏      | 1329/4220 [1:24:49<3:02:02,  3.78s/it, loss=3.09, epoch=0.314, learning_rate=1.55e-5]\u001b[A\n",
      " 31%|███▏      | 1329/4220 [1:24:49<3:02:02,  3.78s/it, loss=2.91, epoch=0.315, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1330/4220 [1:24:53<3:02:03,  3.78s/it, loss=2.91, epoch=0.315, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1330/4220 [1:24:53<3:02:03,  3.78s/it, loss=2.89, epoch=0.315, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1331/4220 [1:24:57<3:02:01,  3.78s/it, loss=2.89, epoch=0.315, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1331/4220 [1:24:57<3:02:01,  3.78s/it, loss=2.72, epoch=0.315, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1332/4220 [1:25:00<3:01:57,  3.78s/it, loss=2.72, epoch=0.315, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1332/4220 [1:25:00<3:01:57,  3.78s/it, loss=3.08, epoch=0.315, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1333/4220 [1:25:04<3:01:48,  3.78s/it, loss=3.08, epoch=0.315, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1333/4220 [1:25:04<3:01:48,  3.78s/it, loss=3.33, epoch=0.316, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1334/4220 [1:25:08<3:01:47,  3.78s/it, loss=3.33, epoch=0.316, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1334/4220 [1:25:08<3:01:47,  3.78s/it, loss=2.58, epoch=0.316, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1335/4220 [1:25:12<3:01:38,  3.78s/it, loss=2.58, epoch=0.316, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1335/4220 [1:25:12<3:01:38,  3.78s/it, loss=2.79, epoch=0.316, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1336/4220 [1:25:16<3:01:37,  3.78s/it, loss=2.79, epoch=0.316, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1336/4220 [1:25:16<3:01:37,  3.78s/it, loss=2.86, epoch=0.316, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1337/4220 [1:25:19<3:01:26,  3.78s/it, loss=2.86, epoch=0.316, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1337/4220 [1:25:19<3:01:26,  3.78s/it, loss=2.7, epoch=0.317, learning_rate=1.55e-5] \u001b[A\n",
      " 32%|███▏      | 1338/4220 [1:25:23<3:01:28,  3.78s/it, loss=2.7, epoch=0.317, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1338/4220 [1:25:23<3:01:28,  3.78s/it, loss=2.93, epoch=0.317, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1339/4220 [1:25:27<3:01:24,  3.78s/it, loss=2.93, epoch=0.317, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1339/4220 [1:25:27<3:01:24,  3.78s/it, loss=2.94, epoch=0.317, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1340/4220 [1:25:31<3:01:18,  3.78s/it, loss=2.94, epoch=0.317, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1340/4220 [1:25:31<3:01:18,  3.78s/it, loss=2.69, epoch=0.317, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1341/4220 [1:25:34<3:01:20,  3.78s/it, loss=2.69, epoch=0.317, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1341/4220 [1:25:34<3:01:20,  3.78s/it, loss=2.66, epoch=0.318, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1342/4220 [1:25:38<3:01:15,  3.78s/it, loss=2.66, epoch=0.318, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1342/4220 [1:25:38<3:01:15,  3.78s/it, loss=2, epoch=0.318, learning_rate=1.55e-5]   \u001b[A\n",
      " 32%|███▏      | 1343/4220 [1:25:42<3:01:08,  3.78s/it, loss=2, epoch=0.318, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1343/4220 [1:25:42<3:01:08,  3.78s/it, loss=2.92, epoch=0.318, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1344/4220 [1:25:46<3:01:07,  3.78s/it, loss=2.92, epoch=0.318, learning_rate=1.55e-5]\u001b[A\n",
      " 32%|███▏      | 1344/4220 [1:25:46<3:01:07,  3.78s/it, loss=3.12, epoch=0.318, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1345/4220 [1:25:50<3:01:00,  3.78s/it, loss=3.12, epoch=0.318, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1345/4220 [1:25:50<3:01:00,  3.78s/it, loss=2.93, epoch=0.318, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1346/4220 [1:25:53<3:00:56,  3.78s/it, loss=2.93, epoch=0.318, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1346/4220 [1:25:53<3:00:56,  3.78s/it, loss=2.64, epoch=0.319, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1347/4220 [1:25:57<3:00:52,  3.78s/it, loss=2.64, epoch=0.319, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1347/4220 [1:25:57<3:00:52,  3.78s/it, loss=2.52, epoch=0.319, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1348/4220 [1:26:01<3:00:45,  3.78s/it, loss=2.52, epoch=0.319, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1348/4220 [1:26:01<3:00:45,  3.78s/it, loss=2.64, epoch=0.319, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1349/4220 [1:26:05<3:00:44,  3.78s/it, loss=2.64, epoch=0.319, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1349/4220 [1:26:05<3:00:44,  3.78s/it, loss=3.1, epoch=0.319, learning_rate=1.54e-5] \u001b[A\n",
      " 32%|███▏      | 1350/4220 [1:26:08<3:00:40,  3.78s/it, loss=3.1, epoch=0.319, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1350/4220 [1:26:08<3:00:40,  3.78s/it, loss=2.98, epoch=0.32, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1351/4220 [1:26:12<3:00:35,  3.78s/it, loss=2.98, epoch=0.32, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1351/4220 [1:26:12<3:00:35,  3.78s/it, loss=3.18, epoch=0.32, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1352/4220 [1:26:16<3:00:32,  3.78s/it, loss=3.18, epoch=0.32, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1352/4220 [1:26:16<3:00:32,  3.78s/it, loss=2.63, epoch=0.32, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1353/4220 [1:26:20<3:00:30,  3.78s/it, loss=2.63, epoch=0.32, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1353/4220 [1:26:20<3:00:30,  3.78s/it, loss=2.73, epoch=0.32, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1354/4220 [1:26:24<3:00:26,  3.78s/it, loss=2.73, epoch=0.32, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1354/4220 [1:26:24<3:00:26,  3.78s/it, loss=2.94, epoch=0.321, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1355/4220 [1:26:27<3:00:21,  3.78s/it, loss=2.94, epoch=0.321, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1355/4220 [1:26:27<3:00:21,  3.78s/it, loss=2.07, epoch=0.321, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1356/4220 [1:26:31<3:00:21,  3.78s/it, loss=2.07, epoch=0.321, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1356/4220 [1:26:31<3:00:21,  3.78s/it, loss=2.4, epoch=0.321, learning_rate=1.54e-5] \u001b[A\n",
      " 32%|███▏      | 1357/4220 [1:26:35<3:00:13,  3.78s/it, loss=2.4, epoch=0.321, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1357/4220 [1:26:35<3:00:13,  3.78s/it, loss=2.94, epoch=0.321, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1358/4220 [1:26:39<3:00:14,  3.78s/it, loss=2.94, epoch=0.321, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1358/4220 [1:26:39<3:00:14,  3.78s/it, loss=2.94, epoch=0.322, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1359/4220 [1:26:42<3:00:09,  3.78s/it, loss=2.94, epoch=0.322, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1359/4220 [1:26:42<3:00:09,  3.78s/it, loss=3.4, epoch=0.322, learning_rate=1.54e-5] \u001b[A\n",
      " 32%|███▏      | 1360/4220 [1:26:46<3:00:05,  3.78s/it, loss=3.4, epoch=0.322, learning_rate=1.54e-5]\u001b[A\n",
      " 32%|███▏      | 1360/4220 [1:26:46<3:00:05,  3.78s/it, loss=2.72, epoch=0.322, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1361/4220 [1:26:50<3:00:00,  3.78s/it, loss=2.72, epoch=0.322, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1361/4220 [1:26:50<3:00:00,  3.78s/it, loss=2.2, epoch=0.322, learning_rate=1.53e-5] \u001b[A\n",
      " 32%|███▏      | 1362/4220 [1:26:54<2:59:55,  3.78s/it, loss=2.2, epoch=0.322, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1362/4220 [1:26:54<2:59:55,  3.78s/it, loss=3.17, epoch=0.323, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1363/4220 [1:26:58<2:59:54,  3.78s/it, loss=3.17, epoch=0.323, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1363/4220 [1:26:58<2:59:54,  3.78s/it, loss=2.47, epoch=0.323, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1364/4220 [1:27:01<2:59:49,  3.78s/it, loss=2.47, epoch=0.323, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1364/4220 [1:27:01<2:59:49,  3.78s/it, loss=3, epoch=0.323, learning_rate=1.53e-5]   \u001b[A\n",
      " 32%|███▏      | 1365/4220 [1:27:05<2:59:40,  3.78s/it, loss=3, epoch=0.323, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1365/4220 [1:27:05<2:59:40,  3.78s/it, loss=2.85, epoch=0.323, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1366/4220 [1:27:09<2:59:39,  3.78s/it, loss=2.85, epoch=0.323, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1366/4220 [1:27:09<2:59:39,  3.78s/it, loss=2.79, epoch=0.323, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1367/4220 [1:27:13<2:59:38,  3.78s/it, loss=2.79, epoch=0.323, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1367/4220 [1:27:13<2:59:38,  3.78s/it, loss=3.26, epoch=0.324, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1368/4220 [1:27:16<2:59:35,  3.78s/it, loss=3.26, epoch=0.324, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1368/4220 [1:27:16<2:59:35,  3.78s/it, loss=3.08, epoch=0.324, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1369/4220 [1:27:20<2:59:35,  3.78s/it, loss=3.08, epoch=0.324, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1369/4220 [1:27:20<2:59:35,  3.78s/it, loss=2.64, epoch=0.324, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1370/4220 [1:27:24<2:59:22,  3.78s/it, loss=2.64, epoch=0.324, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1370/4220 [1:27:24<2:59:22,  3.78s/it, loss=2.56, epoch=0.324, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1371/4220 [1:27:28<2:59:20,  3.78s/it, loss=2.56, epoch=0.324, learning_rate=1.53e-5]\u001b[A\n",
      " 32%|███▏      | 1371/4220 [1:27:28<2:59:20,  3.78s/it, loss=3.13, epoch=0.325, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1372/4220 [1:27:32<2:59:19,  3.78s/it, loss=3.13, epoch=0.325, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1372/4220 [1:27:32<2:59:19,  3.78s/it, loss=2.59, epoch=0.325, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1373/4220 [1:27:35<2:59:17,  3.78s/it, loss=2.59, epoch=0.325, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1373/4220 [1:27:35<2:59:17,  3.78s/it, loss=3.01, epoch=0.325, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1374/4220 [1:27:39<2:59:10,  3.78s/it, loss=3.01, epoch=0.325, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1374/4220 [1:27:39<2:59:10,  3.78s/it, loss=2.57, epoch=0.325, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1375/4220 [1:27:43<2:59:07,  3.78s/it, loss=2.57, epoch=0.325, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1375/4220 [1:27:43<2:59:07,  3.78s/it, loss=2.67, epoch=0.326, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1376/4220 [1:27:47<2:59:07,  3.78s/it, loss=2.67, epoch=0.326, learning_rate=1.53e-5]\u001b[A\n",
      " 33%|███▎      | 1376/4220 [1:27:47<2:59:07,  3.78s/it, loss=3.1, epoch=0.326, learning_rate=1.52e-5] \u001b[A\n",
      " 33%|███▎      | 1377/4220 [1:27:50<2:58:59,  3.78s/it, loss=3.1, epoch=0.326, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1377/4220 [1:27:50<2:58:59,  3.78s/it, loss=2.57, epoch=0.326, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1378/4220 [1:27:54<2:58:54,  3.78s/it, loss=2.57, epoch=0.326, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1378/4220 [1:27:54<2:58:54,  3.78s/it, loss=3.05, epoch=0.326, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1379/4220 [1:27:58<2:58:55,  3.78s/it, loss=3.05, epoch=0.326, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1379/4220 [1:27:58<2:58:55,  3.78s/it, loss=3.27, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1380/4220 [1:28:02<2:58:50,  3.78s/it, loss=3.27, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1380/4220 [1:28:02<2:58:50,  3.78s/it, loss=3.21, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1381/4220 [1:28:06<2:58:46,  3.78s/it, loss=3.21, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1381/4220 [1:28:06<2:58:46,  3.78s/it, loss=3.22, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1382/4220 [1:28:09<2:58:39,  3.78s/it, loss=3.22, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1382/4220 [1:28:09<2:58:39,  3.78s/it, loss=2.81, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1383/4220 [1:28:13<2:58:36,  3.78s/it, loss=2.81, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1383/4220 [1:28:13<2:58:36,  3.78s/it, loss=3.29, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1384/4220 [1:28:17<2:58:31,  3.78s/it, loss=3.29, epoch=0.327, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1384/4220 [1:28:17<2:58:31,  3.78s/it, loss=3.05, epoch=0.328, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1385/4220 [1:28:21<2:58:31,  3.78s/it, loss=3.05, epoch=0.328, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1385/4220 [1:28:21<2:58:31,  3.78s/it, loss=3.39, epoch=0.328, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1386/4220 [1:28:24<2:58:23,  3.78s/it, loss=3.39, epoch=0.328, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1386/4220 [1:28:24<2:58:23,  3.78s/it, loss=3.25, epoch=0.328, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1387/4220 [1:28:28<2:58:26,  3.78s/it, loss=3.25, epoch=0.328, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1387/4220 [1:28:28<2:58:26,  3.78s/it, loss=2.92, epoch=0.328, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1388/4220 [1:28:32<2:58:20,  3.78s/it, loss=2.92, epoch=0.328, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1388/4220 [1:28:32<2:58:20,  3.78s/it, loss=2.76, epoch=0.329, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1389/4220 [1:28:36<2:58:11,  3.78s/it, loss=2.76, epoch=0.329, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1389/4220 [1:28:36<2:58:11,  3.78s/it, loss=2.77, epoch=0.329, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1390/4220 [1:28:40<2:58:09,  3.78s/it, loss=2.77, epoch=0.329, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1390/4220 [1:28:40<2:58:09,  3.78s/it, loss=3.22, epoch=0.329, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1391/4220 [1:28:43<2:58:05,  3.78s/it, loss=3.22, epoch=0.329, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1391/4220 [1:28:43<2:58:05,  3.78s/it, loss=2.68, epoch=0.329, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1392/4220 [1:28:47<2:58:06,  3.78s/it, loss=2.68, epoch=0.329, learning_rate=1.52e-5]\u001b[A\n",
      " 33%|███▎      | 1392/4220 [1:28:47<2:58:06,  3.78s/it, loss=2.69, epoch=0.33, learning_rate=1.51e-5] \u001b[A\n",
      " 33%|███▎      | 1393/4220 [1:28:51<2:58:04,  3.78s/it, loss=2.69, epoch=0.33, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1393/4220 [1:28:51<2:58:04,  3.78s/it, loss=2.79, epoch=0.33, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1394/4220 [1:28:55<2:58:04,  3.78s/it, loss=2.79, epoch=0.33, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1394/4220 [1:28:55<2:58:04,  3.78s/it, loss=2.51, epoch=0.33, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1395/4220 [1:28:58<2:58:02,  3.78s/it, loss=2.51, epoch=0.33, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1395/4220 [1:28:58<2:58:02,  3.78s/it, loss=3.34, epoch=0.33, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1396/4220 [1:29:02<2:57:57,  3.78s/it, loss=3.34, epoch=0.33, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1396/4220 [1:29:02<2:57:57,  3.78s/it, loss=2.59, epoch=0.331, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1397/4220 [1:29:06<2:57:50,  3.78s/it, loss=2.59, epoch=0.331, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1397/4220 [1:29:06<2:57:50,  3.78s/it, loss=2.78, epoch=0.331, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1398/4220 [1:29:10<2:57:42,  3.78s/it, loss=2.78, epoch=0.331, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1398/4220 [1:29:10<2:57:42,  3.78s/it, loss=2.91, epoch=0.331, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1399/4220 [1:29:14<2:57:41,  3.78s/it, loss=2.91, epoch=0.331, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1399/4220 [1:29:14<2:57:41,  3.78s/it, loss=2.7, epoch=0.331, learning_rate=1.51e-5] \u001b[A\n",
      " 33%|███▎      | 1400/4220 [1:29:17<2:57:39,  3.78s/it, loss=2.7, epoch=0.331, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1400/4220 [1:29:17<2:57:39,  3.78s/it, loss=2.58, epoch=0.332, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1401/4220 [1:29:21<2:57:36,  3.78s/it, loss=2.58, epoch=0.332, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1401/4220 [1:29:21<2:57:36,  3.78s/it, loss=2.6, epoch=0.332, learning_rate=1.51e-5] \u001b[A\n",
      " 33%|███▎      | 1402/4220 [1:29:25<2:57:26,  3.78s/it, loss=2.6, epoch=0.332, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1402/4220 [1:29:25<2:57:26,  3.78s/it, loss=2.55, epoch=0.332, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1403/4220 [1:29:29<2:57:30,  3.78s/it, loss=2.55, epoch=0.332, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1403/4220 [1:29:29<2:57:30,  3.78s/it, loss=2.89, epoch=0.332, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1404/4220 [1:29:32<2:57:26,  3.78s/it, loss=2.89, epoch=0.332, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1404/4220 [1:29:32<2:57:26,  3.78s/it, loss=2.25, epoch=0.332, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1405/4220 [1:29:36<2:57:16,  3.78s/it, loss=2.25, epoch=0.332, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1405/4220 [1:29:36<2:57:16,  3.78s/it, loss=2.8, epoch=0.333, learning_rate=1.51e-5] \u001b[A\n",
      " 33%|███▎      | 1406/4220 [1:29:40<2:57:14,  3.78s/it, loss=2.8, epoch=0.333, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1406/4220 [1:29:40<2:57:14,  3.78s/it, loss=2.53, epoch=0.333, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1407/4220 [1:29:44<2:57:06,  3.78s/it, loss=2.53, epoch=0.333, learning_rate=1.51e-5]\u001b[A\n",
      " 33%|███▎      | 1407/4220 [1:29:44<2:57:06,  3.78s/it, loss=2.77, epoch=0.333, learning_rate=1.5e-5] \u001b[A\n",
      " 33%|███▎      | 1408/4220 [1:29:48<2:57:05,  3.78s/it, loss=2.77, epoch=0.333, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1408/4220 [1:29:48<2:57:05,  3.78s/it, loss=2.73, epoch=0.333, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1409/4220 [1:29:51<2:57:05,  3.78s/it, loss=2.73, epoch=0.333, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1409/4220 [1:29:51<2:57:05,  3.78s/it, loss=2.86, epoch=0.334, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1410/4220 [1:29:55<2:57:05,  3.78s/it, loss=2.86, epoch=0.334, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1410/4220 [1:29:55<2:57:05,  3.78s/it, loss=2.69, epoch=0.334, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1411/4220 [1:29:59<2:56:56,  3.78s/it, loss=2.69, epoch=0.334, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1411/4220 [1:29:59<2:56:56,  3.78s/it, loss=3.17, epoch=0.334, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1412/4220 [1:30:03<2:56:49,  3.78s/it, loss=3.17, epoch=0.334, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1412/4220 [1:30:03<2:56:49,  3.78s/it, loss=2.92, epoch=0.334, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1413/4220 [1:30:06<2:56:46,  3.78s/it, loss=2.92, epoch=0.334, learning_rate=1.5e-5]\u001b[A\n",
      " 33%|███▎      | 1413/4220 [1:30:06<2:56:46,  3.78s/it, loss=2.65, epoch=0.335, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1414/4220 [1:30:10<2:56:35,  3.78s/it, loss=2.65, epoch=0.335, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1414/4220 [1:30:10<2:56:35,  3.78s/it, loss=2.73, epoch=0.335, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1415/4220 [1:30:14<2:56:35,  3.78s/it, loss=2.73, epoch=0.335, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1415/4220 [1:30:14<2:56:35,  3.78s/it, loss=2.87, epoch=0.335, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1416/4220 [1:30:18<2:56:32,  3.78s/it, loss=2.87, epoch=0.335, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1416/4220 [1:30:18<2:56:32,  3.78s/it, loss=2.37, epoch=0.335, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1417/4220 [1:30:22<2:56:30,  3.78s/it, loss=2.37, epoch=0.335, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1417/4220 [1:30:22<2:56:30,  3.78s/it, loss=2.95, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1418/4220 [1:30:25<2:56:32,  3.78s/it, loss=2.95, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1418/4220 [1:30:25<2:56:32,  3.78s/it, loss=3.25, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1419/4220 [1:30:29<2:56:31,  3.78s/it, loss=3.25, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1419/4220 [1:30:29<2:56:31,  3.78s/it, loss=2.74, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1420/4220 [1:30:33<2:56:25,  3.78s/it, loss=2.74, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1420/4220 [1:30:33<2:56:25,  3.78s/it, loss=3.15, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1421/4220 [1:30:37<2:56:16,  3.78s/it, loss=3.15, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1421/4220 [1:30:37<2:56:16,  3.78s/it, loss=2.69, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1422/4220 [1:30:40<2:56:14,  3.78s/it, loss=2.69, epoch=0.336, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1422/4220 [1:30:40<2:56:14,  3.78s/it, loss=2.69, epoch=0.337, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1423/4220 [1:30:44<2:56:06,  3.78s/it, loss=2.69, epoch=0.337, learning_rate=1.5e-5]\u001b[A\n",
      " 34%|███▎      | 1423/4220 [1:30:44<2:56:06,  3.78s/it, loss=3.43, epoch=0.337, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▎      | 1424/4220 [1:30:48<2:56:07,  3.78s/it, loss=3.43, epoch=0.337, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▎      | 1424/4220 [1:30:48<2:56:07,  3.78s/it, loss=3.04, epoch=0.337, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1425/4220 [1:30:52<2:56:03,  3.78s/it, loss=3.04, epoch=0.337, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1425/4220 [1:30:52<2:56:03,  3.78s/it, loss=2.72, epoch=0.337, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1426/4220 [1:30:56<2:55:55,  3.78s/it, loss=2.72, epoch=0.337, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1426/4220 [1:30:56<2:55:55,  3.78s/it, loss=2.48, epoch=0.338, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1427/4220 [1:30:59<2:55:53,  3.78s/it, loss=2.48, epoch=0.338, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1427/4220 [1:30:59<2:55:53,  3.78s/it, loss=2.81, epoch=0.338, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1428/4220 [1:31:03<2:55:50,  3.78s/it, loss=2.81, epoch=0.338, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1428/4220 [1:31:03<2:55:50,  3.78s/it, loss=2.99, epoch=0.338, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1429/4220 [1:31:07<2:55:45,  3.78s/it, loss=2.99, epoch=0.338, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1429/4220 [1:31:07<2:55:45,  3.78s/it, loss=2.92, epoch=0.338, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1430/4220 [1:31:11<2:55:42,  3.78s/it, loss=2.92, epoch=0.338, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1430/4220 [1:31:11<2:55:42,  3.78s/it, loss=3.26, epoch=0.339, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1431/4220 [1:31:14<2:55:39,  3.78s/it, loss=3.26, epoch=0.339, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1431/4220 [1:31:14<2:55:39,  3.78s/it, loss=2.53, epoch=0.339, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1432/4220 [1:31:18<2:55:36,  3.78s/it, loss=2.53, epoch=0.339, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1432/4220 [1:31:18<2:55:36,  3.78s/it, loss=2.4, epoch=0.339, learning_rate=1.49e-5] \u001b[A\n",
      " 34%|███▍      | 1433/4220 [1:31:22<2:55:32,  3.78s/it, loss=2.4, epoch=0.339, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1433/4220 [1:31:22<2:55:32,  3.78s/it, loss=3.02, epoch=0.339, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1434/4220 [1:31:26<2:55:25,  3.78s/it, loss=3.02, epoch=0.339, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1434/4220 [1:31:26<2:55:25,  3.78s/it, loss=2.76, epoch=0.34, learning_rate=1.49e-5] \u001b[A\n",
      " 34%|███▍      | 1435/4220 [1:31:30<2:55:20,  3.78s/it, loss=2.76, epoch=0.34, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1435/4220 [1:31:30<2:55:20,  3.78s/it, loss=2.39, epoch=0.34, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1436/4220 [1:31:33<2:55:20,  3.78s/it, loss=2.39, epoch=0.34, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1436/4220 [1:31:33<2:55:20,  3.78s/it, loss=3.15, epoch=0.34, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1437/4220 [1:31:37<2:55:17,  3.78s/it, loss=3.15, epoch=0.34, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1437/4220 [1:31:37<2:55:17,  3.78s/it, loss=2.93, epoch=0.34, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1438/4220 [1:31:41<2:55:15,  3.78s/it, loss=2.93, epoch=0.34, learning_rate=1.49e-5]\u001b[A\n",
      " 34%|███▍      | 1438/4220 [1:31:41<2:55:15,  3.78s/it, loss=3.27, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1439/4220 [1:31:45<2:55:13,  3.78s/it, loss=3.27, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1439/4220 [1:31:45<2:55:13,  3.78s/it, loss=2.78, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1440/4220 [1:31:48<2:55:10,  3.78s/it, loss=2.78, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1440/4220 [1:31:48<2:55:10,  3.78s/it, loss=2.57, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1441/4220 [1:31:52<2:55:04,  3.78s/it, loss=2.57, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1441/4220 [1:31:52<2:55:04,  3.78s/it, loss=2.71, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1442/4220 [1:31:56<2:55:02,  3.78s/it, loss=2.71, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1442/4220 [1:31:56<2:55:02,  3.78s/it, loss=2.52, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1443/4220 [1:32:00<2:54:53,  3.78s/it, loss=2.52, epoch=0.341, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1443/4220 [1:32:00<2:54:53,  3.78s/it, loss=2.5, epoch=0.342, learning_rate=1.48e-5] \u001b[A\n",
      " 34%|███▍      | 1444/4220 [1:32:04<2:54:53,  3.78s/it, loss=2.5, epoch=0.342, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1444/4220 [1:32:04<2:54:53,  3.78s/it, loss=2.61, epoch=0.342, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1445/4220 [1:32:07<2:54:48,  3.78s/it, loss=2.61, epoch=0.342, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1445/4220 [1:32:07<2:54:48,  3.78s/it, loss=3.03, epoch=0.342, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1446/4220 [1:32:11<2:54:41,  3.78s/it, loss=3.03, epoch=0.342, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1446/4220 [1:32:11<2:54:41,  3.78s/it, loss=2.72, epoch=0.342, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1447/4220 [1:32:15<2:54:38,  3.78s/it, loss=2.72, epoch=0.342, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1447/4220 [1:32:15<2:54:38,  3.78s/it, loss=2.28, epoch=0.343, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1448/4220 [1:32:19<2:54:38,  3.78s/it, loss=2.28, epoch=0.343, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1448/4220 [1:32:19<2:54:38,  3.78s/it, loss=2.67, epoch=0.343, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1449/4220 [1:32:22<2:54:30,  3.78s/it, loss=2.67, epoch=0.343, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1449/4220 [1:32:22<2:54:30,  3.78s/it, loss=2.68, epoch=0.343, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1450/4220 [1:32:26<2:54:26,  3.78s/it, loss=2.68, epoch=0.343, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1450/4220 [1:32:26<2:54:26,  3.78s/it, loss=2.8, epoch=0.343, learning_rate=1.48e-5] \u001b[A\n",
      " 34%|███▍      | 1451/4220 [1:32:30<2:54:26,  3.78s/it, loss=2.8, epoch=0.343, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1451/4220 [1:32:30<2:54:26,  3.78s/it, loss=2.83, epoch=0.344, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1452/4220 [1:32:34<2:54:19,  3.78s/it, loss=2.83, epoch=0.344, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1452/4220 [1:32:34<2:54:19,  3.78s/it, loss=2.91, epoch=0.344, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1453/4220 [1:32:38<2:54:14,  3.78s/it, loss=2.91, epoch=0.344, learning_rate=1.48e-5]\u001b[A\n",
      " 34%|███▍      | 1453/4220 [1:32:38<2:54:14,  3.78s/it, loss=2.85, epoch=0.344, learning_rate=1.47e-5]\u001b[A\n",
      " 34%|███▍      | 1454/4220 [1:32:41<2:54:10,  3.78s/it, loss=2.85, epoch=0.344, learning_rate=1.47e-5]\u001b[A\n",
      " 34%|███▍      | 1454/4220 [1:32:41<2:54:10,  3.78s/it, loss=2.79, epoch=0.344, learning_rate=1.47e-5]\u001b[A\n",
      " 34%|███▍      | 1455/4220 [1:32:45<2:54:08,  3.78s/it, loss=2.79, epoch=0.344, learning_rate=1.47e-5]\u001b[A\n",
      " 34%|███▍      | 1455/4220 [1:32:45<2:54:08,  3.78s/it, loss=3.29, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1456/4220 [1:32:49<2:54:04,  3.78s/it, loss=3.29, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1456/4220 [1:32:49<2:54:04,  3.78s/it, loss=2.66, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1457/4220 [1:32:53<2:54:05,  3.78s/it, loss=2.66, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1457/4220 [1:32:53<2:54:05,  3.78s/it, loss=3.28, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1458/4220 [1:32:57<2:54:01,  3.78s/it, loss=3.28, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1458/4220 [1:32:57<2:54:01,  3.78s/it, loss=2.75, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1459/4220 [1:33:00<2:53:52,  3.78s/it, loss=2.75, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1459/4220 [1:33:00<2:53:52,  3.78s/it, loss=3.12, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1460/4220 [1:33:04<2:53:47,  3.78s/it, loss=3.12, epoch=0.345, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1460/4220 [1:33:04<2:53:47,  3.78s/it, loss=2.87, epoch=0.346, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1461/4220 [1:33:08<2:53:45,  3.78s/it, loss=2.87, epoch=0.346, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1461/4220 [1:33:08<2:53:45,  3.78s/it, loss=2.94, epoch=0.346, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1462/4220 [1:33:12<2:53:40,  3.78s/it, loss=2.94, epoch=0.346, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1462/4220 [1:33:12<2:53:40,  3.78s/it, loss=3.21, epoch=0.346, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1463/4220 [1:33:15<2:53:34,  3.78s/it, loss=3.21, epoch=0.346, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1463/4220 [1:33:15<2:53:34,  3.78s/it, loss=2.93, epoch=0.346, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1464/4220 [1:33:19<2:53:33,  3.78s/it, loss=2.93, epoch=0.346, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1464/4220 [1:33:19<2:53:33,  3.78s/it, loss=3.33, epoch=0.347, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1465/4220 [1:33:23<2:53:26,  3.78s/it, loss=3.33, epoch=0.347, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1465/4220 [1:33:23<2:53:26,  3.78s/it, loss=2.79, epoch=0.347, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1466/4220 [1:33:27<2:53:21,  3.78s/it, loss=2.79, epoch=0.347, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1466/4220 [1:33:27<2:53:21,  3.78s/it, loss=2.78, epoch=0.347, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1467/4220 [1:33:31<2:53:22,  3.78s/it, loss=2.78, epoch=0.347, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1467/4220 [1:33:31<2:53:22,  3.78s/it, loss=2.63, epoch=0.347, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1468/4220 [1:33:34<2:53:18,  3.78s/it, loss=2.63, epoch=0.347, learning_rate=1.47e-5]\u001b[A\n",
      " 35%|███▍      | 1468/4220 [1:33:34<2:53:18,  3.78s/it, loss=2.91, epoch=0.348, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1469/4220 [1:33:38<2:53:11,  3.78s/it, loss=2.91, epoch=0.348, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1469/4220 [1:33:38<2:53:11,  3.78s/it, loss=3.09, epoch=0.348, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1470/4220 [1:33:42<2:53:08,  3.78s/it, loss=3.09, epoch=0.348, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1470/4220 [1:33:42<2:53:08,  3.78s/it, loss=3.36, epoch=0.348, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1471/4220 [1:33:46<2:53:02,  3.78s/it, loss=3.36, epoch=0.348, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1471/4220 [1:33:46<2:53:02,  3.78s/it, loss=2.69, epoch=0.348, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1472/4220 [1:33:49<2:53:03,  3.78s/it, loss=2.69, epoch=0.348, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1472/4220 [1:33:49<2:53:03,  3.78s/it, loss=3.38, epoch=0.349, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1473/4220 [1:33:53<2:53:00,  3.78s/it, loss=3.38, epoch=0.349, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1473/4220 [1:33:53<2:53:00,  3.78s/it, loss=2.87, epoch=0.349, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1474/4220 [1:33:57<2:52:57,  3.78s/it, loss=2.87, epoch=0.349, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1474/4220 [1:33:57<2:52:57,  3.78s/it, loss=2.84, epoch=0.349, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1475/4220 [1:34:01<2:52:50,  3.78s/it, loss=2.84, epoch=0.349, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1475/4220 [1:34:01<2:52:50,  3.78s/it, loss=2.89, epoch=0.349, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1476/4220 [1:34:05<2:52:49,  3.78s/it, loss=2.89, epoch=0.349, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▍      | 1476/4220 [1:34:05<2:52:49,  3.78s/it, loss=3.09, epoch=0.35, learning_rate=1.46e-5] \u001b[A\n",
      " 35%|███▌      | 1477/4220 [1:34:08<2:52:42,  3.78s/it, loss=3.09, epoch=0.35, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1477/4220 [1:34:08<2:52:42,  3.78s/it, loss=3.07, epoch=0.35, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1478/4220 [1:34:12<2:52:41,  3.78s/it, loss=3.07, epoch=0.35, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1478/4220 [1:34:12<2:52:41,  3.78s/it, loss=3.06, epoch=0.35, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1479/4220 [1:34:16<2:52:37,  3.78s/it, loss=3.06, epoch=0.35, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1479/4220 [1:34:16<2:52:37,  3.78s/it, loss=3.13, epoch=0.35, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1480/4220 [1:34:20<2:52:35,  3.78s/it, loss=3.13, epoch=0.35, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1480/4220 [1:34:20<2:52:35,  3.78s/it, loss=3.37, epoch=0.35, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1481/4220 [1:34:23<2:52:32,  3.78s/it, loss=3.37, epoch=0.35, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1481/4220 [1:34:23<2:52:32,  3.78s/it, loss=2.61, epoch=0.351, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1482/4220 [1:34:27<2:52:29,  3.78s/it, loss=2.61, epoch=0.351, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1482/4220 [1:34:27<2:52:29,  3.78s/it, loss=2.83, epoch=0.351, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1483/4220 [1:34:31<2:52:22,  3.78s/it, loss=2.83, epoch=0.351, learning_rate=1.46e-5]\u001b[A\n",
      " 35%|███▌      | 1483/4220 [1:34:31<2:52:22,  3.78s/it, loss=3.06, epoch=0.351, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1484/4220 [1:34:35<2:52:18,  3.78s/it, loss=3.06, epoch=0.351, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1484/4220 [1:34:35<2:52:18,  3.78s/it, loss=2.46, epoch=0.351, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1485/4220 [1:34:39<2:52:17,  3.78s/it, loss=2.46, epoch=0.351, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1485/4220 [1:34:39<2:52:17,  3.78s/it, loss=2.94, epoch=0.352, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1486/4220 [1:34:42<2:52:11,  3.78s/it, loss=2.94, epoch=0.352, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1486/4220 [1:34:42<2:52:11,  3.78s/it, loss=2.88, epoch=0.352, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1487/4220 [1:34:46<2:52:08,  3.78s/it, loss=2.88, epoch=0.352, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1487/4220 [1:34:46<2:52:08,  3.78s/it, loss=2.51, epoch=0.352, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1488/4220 [1:34:50<2:52:02,  3.78s/it, loss=2.51, epoch=0.352, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1488/4220 [1:34:50<2:52:02,  3.78s/it, loss=2.9, epoch=0.352, learning_rate=1.45e-5] \u001b[A\n",
      " 35%|███▌      | 1489/4220 [1:34:54<2:52:00,  3.78s/it, loss=2.9, epoch=0.352, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1489/4220 [1:34:54<2:52:00,  3.78s/it, loss=2.3, epoch=0.353, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1490/4220 [1:34:57<2:51:56,  3.78s/it, loss=2.3, epoch=0.353, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1490/4220 [1:34:57<2:51:56,  3.78s/it, loss=2.94, epoch=0.353, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1491/4220 [1:35:01<2:51:46,  3.78s/it, loss=2.94, epoch=0.353, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1491/4220 [1:35:01<2:51:46,  3.78s/it, loss=2.42, epoch=0.353, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1492/4220 [1:35:05<2:51:46,  3.78s/it, loss=2.42, epoch=0.353, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1492/4220 [1:35:05<2:51:46,  3.78s/it, loss=2.98, epoch=0.353, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1493/4220 [1:35:09<2:51:38,  3.78s/it, loss=2.98, epoch=0.353, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1493/4220 [1:35:09<2:51:38,  3.78s/it, loss=2.31, epoch=0.354, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1494/4220 [1:35:13<2:51:37,  3.78s/it, loss=2.31, epoch=0.354, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1494/4220 [1:35:13<2:51:37,  3.78s/it, loss=2.89, epoch=0.354, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1495/4220 [1:35:16<2:51:33,  3.78s/it, loss=2.89, epoch=0.354, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1495/4220 [1:35:16<2:51:33,  3.78s/it, loss=3.29, epoch=0.354, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1496/4220 [1:35:20<2:51:33,  3.78s/it, loss=3.29, epoch=0.354, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1496/4220 [1:35:20<2:51:33,  3.78s/it, loss=2.86, epoch=0.354, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1497/4220 [1:35:24<2:51:28,  3.78s/it, loss=2.86, epoch=0.354, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1497/4220 [1:35:24<2:51:28,  3.78s/it, loss=2.11, epoch=0.355, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1498/4220 [1:35:28<2:51:29,  3.78s/it, loss=2.11, epoch=0.355, learning_rate=1.45e-5]\u001b[A\n",
      " 35%|███▌      | 1498/4220 [1:35:28<2:51:29,  3.78s/it, loss=3.01, epoch=0.355, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1499/4220 [1:35:31<2:51:23,  3.78s/it, loss=3.01, epoch=0.355, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1499/4220 [1:35:31<2:51:23,  3.78s/it, loss=2.83, epoch=0.355, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1500/4220 [1:35:35<2:51:18,  3.78s/it, loss=2.83, epoch=0.355, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1500/4220 [1:35:35<2:51:18,  3.78s/it, loss=2.42, epoch=0.355, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1501/4220 [1:35:39<2:51:12,  3.78s/it, loss=2.42, epoch=0.355, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1501/4220 [1:35:39<2:51:12,  3.78s/it, loss=3.07, epoch=0.355, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1502/4220 [1:35:43<2:51:11,  3.78s/it, loss=3.07, epoch=0.355, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1502/4220 [1:35:43<2:51:11,  3.78s/it, loss=3.08, epoch=0.356, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1503/4220 [1:35:47<2:51:12,  3.78s/it, loss=3.08, epoch=0.356, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1503/4220 [1:35:47<2:51:12,  3.78s/it, loss=2.78, epoch=0.356, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1504/4220 [1:35:50<2:51:08,  3.78s/it, loss=2.78, epoch=0.356, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1504/4220 [1:35:50<2:51:08,  3.78s/it, loss=2.79, epoch=0.356, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1505/4220 [1:35:54<2:51:02,  3.78s/it, loss=2.79, epoch=0.356, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1505/4220 [1:35:54<2:51:02,  3.78s/it, loss=2.99, epoch=0.356, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1506/4220 [1:35:58<2:50:56,  3.78s/it, loss=2.99, epoch=0.356, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1506/4220 [1:35:58<2:50:56,  3.78s/it, loss=2.49, epoch=0.357, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1507/4220 [1:36:02<2:50:51,  3.78s/it, loss=2.49, epoch=0.357, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1507/4220 [1:36:02<2:50:51,  3.78s/it, loss=3.08, epoch=0.357, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1508/4220 [1:36:05<2:50:51,  3.78s/it, loss=3.08, epoch=0.357, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1508/4220 [1:36:05<2:50:51,  3.78s/it, loss=3.03, epoch=0.357, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1509/4220 [1:36:09<2:50:48,  3.78s/it, loss=3.03, epoch=0.357, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1509/4220 [1:36:09<2:50:48,  3.78s/it, loss=2.71, epoch=0.357, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1510/4220 [1:36:13<2:50:44,  3.78s/it, loss=2.71, epoch=0.357, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1510/4220 [1:36:13<2:50:44,  3.78s/it, loss=3.06, epoch=0.358, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1511/4220 [1:36:17<2:50:40,  3.78s/it, loss=3.06, epoch=0.358, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1511/4220 [1:36:17<2:50:40,  3.78s/it, loss=2.81, epoch=0.358, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1512/4220 [1:36:21<2:50:33,  3.78s/it, loss=2.81, epoch=0.358, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1512/4220 [1:36:21<2:50:33,  3.78s/it, loss=2.81, epoch=0.358, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1513/4220 [1:36:24<2:50:27,  3.78s/it, loss=2.81, epoch=0.358, learning_rate=1.44e-5]\u001b[A\n",
      " 36%|███▌      | 1513/4220 [1:36:24<2:50:27,  3.78s/it, loss=2.28, epoch=0.358, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1514/4220 [1:36:28<2:50:26,  3.78s/it, loss=2.28, epoch=0.358, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1514/4220 [1:36:28<2:50:26,  3.78s/it, loss=3.35, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1515/4220 [1:36:32<2:50:23,  3.78s/it, loss=3.35, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1515/4220 [1:36:32<2:50:23,  3.78s/it, loss=3.14, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1516/4220 [1:36:36<2:50:22,  3.78s/it, loss=3.14, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1516/4220 [1:36:36<2:50:22,  3.78s/it, loss=2.73, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1517/4220 [1:36:39<2:50:14,  3.78s/it, loss=2.73, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1517/4220 [1:36:39<2:50:14,  3.78s/it, loss=2.49, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1518/4220 [1:36:43<2:50:10,  3.78s/it, loss=2.49, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1518/4220 [1:36:43<2:50:10,  3.78s/it, loss=2.88, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1519/4220 [1:36:47<2:50:02,  3.78s/it, loss=2.88, epoch=0.359, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1519/4220 [1:36:47<2:50:02,  3.78s/it, loss=2.88, epoch=0.36, learning_rate=1.43e-5] \u001b[A\n",
      " 36%|███▌      | 1520/4220 [1:36:51<2:50:02,  3.78s/it, loss=2.88, epoch=0.36, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1520/4220 [1:36:51<2:50:02,  3.78s/it, loss=2.98, epoch=0.36, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1521/4220 [1:36:55<2:49:58,  3.78s/it, loss=2.98, epoch=0.36, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1521/4220 [1:36:55<2:49:58,  3.78s/it, loss=3.05, epoch=0.36, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1522/4220 [1:36:58<2:49:55,  3.78s/it, loss=3.05, epoch=0.36, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1522/4220 [1:36:58<2:49:55,  3.78s/it, loss=2.8, epoch=0.36, learning_rate=1.43e-5] \u001b[A\n",
      " 36%|███▌      | 1523/4220 [1:37:02<2:49:53,  3.78s/it, loss=2.8, epoch=0.36, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1523/4220 [1:37:02<2:49:53,  3.78s/it, loss=2.57, epoch=0.361, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1524/4220 [1:37:06<2:49:47,  3.78s/it, loss=2.57, epoch=0.361, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1524/4220 [1:37:06<2:49:47,  3.78s/it, loss=2.76, epoch=0.361, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1525/4220 [1:37:10<2:49:40,  3.78s/it, loss=2.76, epoch=0.361, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1525/4220 [1:37:10<2:49:40,  3.78s/it, loss=2.9, epoch=0.361, learning_rate=1.43e-5] \u001b[A\n",
      " 36%|███▌      | 1526/4220 [1:37:13<2:49:39,  3.78s/it, loss=2.9, epoch=0.361, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1526/4220 [1:37:13<2:49:39,  3.78s/it, loss=2.8, epoch=0.361, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1527/4220 [1:37:17<2:49:35,  3.78s/it, loss=2.8, epoch=0.361, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1527/4220 [1:37:17<2:49:35,  3.78s/it, loss=2.76, epoch=0.362, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1528/4220 [1:37:21<2:49:32,  3.78s/it, loss=2.76, epoch=0.362, learning_rate=1.43e-5]\u001b[A\n",
      " 36%|███▌      | 1528/4220 [1:37:21<2:49:32,  3.78s/it, loss=3.22, epoch=0.362, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▌      | 1529/4220 [1:37:25<2:49:29,  3.78s/it, loss=3.22, epoch=0.362, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▌      | 1529/4220 [1:37:25<2:49:29,  3.78s/it, loss=2.56, epoch=0.362, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1530/4220 [1:37:29<2:49:20,  3.78s/it, loss=2.56, epoch=0.362, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1530/4220 [1:37:29<2:49:20,  3.78s/it, loss=2.38, epoch=0.362, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1531/4220 [1:37:32<2:49:21,  3.78s/it, loss=2.38, epoch=0.362, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1531/4220 [1:37:32<2:49:21,  3.78s/it, loss=2.62, epoch=0.363, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1532/4220 [1:37:36<2:49:18,  3.78s/it, loss=2.62, epoch=0.363, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1532/4220 [1:37:36<2:49:18,  3.78s/it, loss=3.03, epoch=0.363, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1533/4220 [1:37:40<2:49:14,  3.78s/it, loss=3.03, epoch=0.363, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1533/4220 [1:37:40<2:49:14,  3.78s/it, loss=3.27, epoch=0.363, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1534/4220 [1:37:44<2:49:09,  3.78s/it, loss=3.27, epoch=0.363, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1534/4220 [1:37:44<2:49:09,  3.78s/it, loss=2.55, epoch=0.363, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1535/4220 [1:37:47<2:49:07,  3.78s/it, loss=2.55, epoch=0.363, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1535/4220 [1:37:47<2:49:07,  3.78s/it, loss=3.1, epoch=0.364, learning_rate=1.42e-5] \u001b[A\n",
      " 36%|███▋      | 1536/4220 [1:37:51<2:49:02,  3.78s/it, loss=3.1, epoch=0.364, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1536/4220 [1:37:51<2:49:02,  3.78s/it, loss=2.8, epoch=0.364, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1537/4220 [1:37:55<2:48:58,  3.78s/it, loss=2.8, epoch=0.364, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1537/4220 [1:37:55<2:48:58,  3.78s/it, loss=2.68, epoch=0.364, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1538/4220 [1:37:59<2:48:56,  3.78s/it, loss=2.68, epoch=0.364, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1538/4220 [1:37:59<2:48:56,  3.78s/it, loss=2.74, epoch=0.364, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1539/4220 [1:38:03<2:48:48,  3.78s/it, loss=2.74, epoch=0.364, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1539/4220 [1:38:03<2:48:48,  3.78s/it, loss=3.5, epoch=0.364, learning_rate=1.42e-5] \u001b[A\n",
      " 36%|███▋      | 1540/4220 [1:38:06<2:48:49,  3.78s/it, loss=3.5, epoch=0.364, learning_rate=1.42e-5]\u001b[A\n",
      " 36%|███▋      | 1540/4220 [1:38:06<2:48:49,  3.78s/it, loss=2.84, epoch=0.365, learning_rate=1.42e-5]\u001b[A\n",
      " 37%|███▋      | 1541/4220 [1:38:10<2:48:43,  3.78s/it, loss=2.84, epoch=0.365, learning_rate=1.42e-5]\u001b[A\n",
      " 37%|███▋      | 1541/4220 [1:38:10<2:48:43,  3.78s/it, loss=2.94, epoch=0.365, learning_rate=1.42e-5]\u001b[A\n",
      " 37%|███▋      | 1542/4220 [1:38:14<2:48:35,  3.78s/it, loss=2.94, epoch=0.365, learning_rate=1.42e-5]\u001b[A\n",
      " 37%|███▋      | 1542/4220 [1:38:14<2:48:35,  3.78s/it, loss=2.75, epoch=0.365, learning_rate=1.42e-5]\u001b[A\n",
      " 37%|███▋      | 1543/4220 [1:38:18<2:48:36,  3.78s/it, loss=2.75, epoch=0.365, learning_rate=1.42e-5]\u001b[A\n",
      " 37%|███▋      | 1543/4220 [1:38:18<2:48:36,  3.78s/it, loss=2.79, epoch=0.365, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1544/4220 [1:38:21<2:48:31,  3.78s/it, loss=2.79, epoch=0.365, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1544/4220 [1:38:21<2:48:31,  3.78s/it, loss=3.09, epoch=0.366, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1545/4220 [1:38:25<2:48:25,  3.78s/it, loss=3.09, epoch=0.366, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1545/4220 [1:38:25<2:48:25,  3.78s/it, loss=2.79, epoch=0.366, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1546/4220 [1:38:29<2:48:26,  3.78s/it, loss=2.79, epoch=0.366, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1546/4220 [1:38:29<2:48:26,  3.78s/it, loss=2.89, epoch=0.366, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1547/4220 [1:38:33<2:48:24,  3.78s/it, loss=2.89, epoch=0.366, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1547/4220 [1:38:33<2:48:24,  3.78s/it, loss=2.54, epoch=0.366, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1548/4220 [1:38:37<2:48:14,  3.78s/it, loss=2.54, epoch=0.366, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1548/4220 [1:38:37<2:48:14,  3.78s/it, loss=2.84, epoch=0.367, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1549/4220 [1:38:40<2:48:13,  3.78s/it, loss=2.84, epoch=0.367, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1549/4220 [1:38:40<2:48:13,  3.78s/it, loss=3.02, epoch=0.367, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1550/4220 [1:38:44<2:48:06,  3.78s/it, loss=3.02, epoch=0.367, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1550/4220 [1:38:44<2:48:06,  3.78s/it, loss=2.8, epoch=0.367, learning_rate=1.41e-5] \u001b[A\n",
      " 37%|███▋      | 1551/4220 [1:38:48<2:48:04,  3.78s/it, loss=2.8, epoch=0.367, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1551/4220 [1:38:48<2:48:04,  3.78s/it, loss=2.96, epoch=0.367, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1552/4220 [1:38:52<2:47:59,  3.78s/it, loss=2.96, epoch=0.367, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1552/4220 [1:38:52<2:47:59,  3.78s/it, loss=2.52, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1553/4220 [1:38:55<2:47:56,  3.78s/it, loss=2.52, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1553/4220 [1:38:55<2:47:56,  3.78s/it, loss=2.37, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1554/4220 [1:38:59<2:47:53,  3.78s/it, loss=2.37, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1554/4220 [1:38:59<2:47:53,  3.78s/it, loss=2.66, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1555/4220 [1:39:03<2:47:49,  3.78s/it, loss=2.66, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1555/4220 [1:39:03<2:47:49,  3.78s/it, loss=2.61, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1556/4220 [1:39:07<2:47:45,  3.78s/it, loss=2.61, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1556/4220 [1:39:07<2:47:45,  3.78s/it, loss=2.63, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1557/4220 [1:39:11<2:47:39,  3.78s/it, loss=2.63, epoch=0.368, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1557/4220 [1:39:11<2:47:39,  3.78s/it, loss=2.64, epoch=0.369, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1558/4220 [1:39:14<2:47:39,  3.78s/it, loss=2.64, epoch=0.369, learning_rate=1.41e-5]\u001b[A\n",
      " 37%|███▋      | 1558/4220 [1:39:14<2:47:39,  3.78s/it, loss=3.08, epoch=0.369, learning_rate=1.4e-5] \u001b[A\n",
      " 37%|███▋      | 1559/4220 [1:39:18<2:47:35,  3.78s/it, loss=3.08, epoch=0.369, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1559/4220 [1:39:18<2:47:35,  3.78s/it, loss=2.98, epoch=0.369, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1560/4220 [1:39:22<2:47:30,  3.78s/it, loss=2.98, epoch=0.369, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1560/4220 [1:39:22<2:47:30,  3.78s/it, loss=2.87, epoch=0.369, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1561/4220 [1:39:26<2:47:27,  3.78s/it, loss=2.87, epoch=0.369, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1561/4220 [1:39:26<2:47:27,  3.78s/it, loss=3.11, epoch=0.37, learning_rate=1.4e-5] \u001b[A\n",
      " 37%|███▋      | 1562/4220 [1:39:29<2:47:26,  3.78s/it, loss=3.11, epoch=0.37, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1562/4220 [1:39:29<2:47:26,  3.78s/it, loss=2.69, epoch=0.37, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1563/4220 [1:39:33<2:47:19,  3.78s/it, loss=2.69, epoch=0.37, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1563/4220 [1:39:33<2:47:19,  3.78s/it, loss=2.76, epoch=0.37, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1564/4220 [1:39:37<2:47:17,  3.78s/it, loss=2.76, epoch=0.37, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1564/4220 [1:39:37<2:47:17,  3.78s/it, loss=3.26, epoch=0.37, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1565/4220 [1:39:41<2:47:14,  3.78s/it, loss=3.26, epoch=0.37, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1565/4220 [1:39:41<2:47:14,  3.78s/it, loss=2.42, epoch=0.371, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1566/4220 [1:39:45<2:47:07,  3.78s/it, loss=2.42, epoch=0.371, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1566/4220 [1:39:45<2:47:07,  3.78s/it, loss=2.88, epoch=0.371, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1567/4220 [1:39:48<2:47:07,  3.78s/it, loss=2.88, epoch=0.371, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1567/4220 [1:39:48<2:47:07,  3.78s/it, loss=3.06, epoch=0.371, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1568/4220 [1:39:52<2:46:58,  3.78s/it, loss=3.06, epoch=0.371, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1568/4220 [1:39:52<2:46:58,  3.78s/it, loss=2.94, epoch=0.371, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1569/4220 [1:39:56<2:46:54,  3.78s/it, loss=2.94, epoch=0.371, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1569/4220 [1:39:56<2:46:54,  3.78s/it, loss=2.98, epoch=0.372, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1570/4220 [1:40:00<2:46:49,  3.78s/it, loss=2.98, epoch=0.372, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1570/4220 [1:40:00<2:46:49,  3.78s/it, loss=2.69, epoch=0.372, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1571/4220 [1:40:03<2:46:46,  3.78s/it, loss=2.69, epoch=0.372, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1571/4220 [1:40:03<2:46:46,  3.78s/it, loss=3.15, epoch=0.372, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1572/4220 [1:40:07<2:46:44,  3.78s/it, loss=3.15, epoch=0.372, learning_rate=1.4e-5]\u001b[A\n",
      " 37%|███▋      | 1572/4220 [1:40:07<2:46:44,  3.78s/it, loss=2.66, epoch=0.372, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1573/4220 [1:40:11<2:46:41,  3.78s/it, loss=2.66, epoch=0.372, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1573/4220 [1:40:11<2:46:41,  3.78s/it, loss=2.58, epoch=0.373, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1574/4220 [1:40:15<2:46:38,  3.78s/it, loss=2.58, epoch=0.373, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1574/4220 [1:40:15<2:46:38,  3.78s/it, loss=2.72, epoch=0.373, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1575/4220 [1:40:19<2:46:36,  3.78s/it, loss=2.72, epoch=0.373, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1575/4220 [1:40:19<2:46:36,  3.78s/it, loss=2.35, epoch=0.373, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1576/4220 [1:40:22<2:46:31,  3.78s/it, loss=2.35, epoch=0.373, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1576/4220 [1:40:22<2:46:31,  3.78s/it, loss=2.6, epoch=0.373, learning_rate=1.39e-5] \u001b[A\n",
      " 37%|███▋      | 1577/4220 [1:40:26<2:46:30,  3.78s/it, loss=2.6, epoch=0.373, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1577/4220 [1:40:26<2:46:30,  3.78s/it, loss=2.92, epoch=0.373, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1578/4220 [1:40:30<2:46:24,  3.78s/it, loss=2.92, epoch=0.373, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1578/4220 [1:40:30<2:46:24,  3.78s/it, loss=2.37, epoch=0.374, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1579/4220 [1:40:34<2:46:18,  3.78s/it, loss=2.37, epoch=0.374, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1579/4220 [1:40:34<2:46:18,  3.78s/it, loss=2.58, epoch=0.374, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1580/4220 [1:40:38<2:46:14,  3.78s/it, loss=2.58, epoch=0.374, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1580/4220 [1:40:38<2:46:14,  3.78s/it, loss=3.04, epoch=0.374, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1581/4220 [1:40:41<2:46:15,  3.78s/it, loss=3.04, epoch=0.374, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1581/4220 [1:40:41<2:46:15,  3.78s/it, loss=2.68, epoch=0.374, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1582/4220 [1:40:45<2:46:12,  3.78s/it, loss=2.68, epoch=0.374, learning_rate=1.39e-5]\u001b[A\n",
      " 37%|███▋      | 1582/4220 [1:40:45<2:46:12,  3.78s/it, loss=2.94, epoch=0.375, learning_rate=1.39e-5]\u001b[A\n",
      " 38%|███▊      | 1583/4220 [1:40:49<2:46:11,  3.78s/it, loss=2.94, epoch=0.375, learning_rate=1.39e-5]\u001b[A\n",
      " 38%|███▊      | 1583/4220 [1:40:49<2:46:11,  3.78s/it, loss=3.24, epoch=0.375, learning_rate=1.39e-5]\u001b[A\n",
      " 38%|███▊      | 1584/4220 [1:40:53<2:46:04,  3.78s/it, loss=3.24, epoch=0.375, learning_rate=1.39e-5]\u001b[A\n",
      " 38%|███▊      | 1584/4220 [1:40:53<2:46:04,  3.78s/it, loss=3.05, epoch=0.375, learning_rate=1.39e-5]\u001b[A\n",
      " 38%|███▊      | 1585/4220 [1:40:56<2:45:58,  3.78s/it, loss=3.05, epoch=0.375, learning_rate=1.39e-5]\u001b[A\n",
      " 38%|███▊      | 1585/4220 [1:40:56<2:45:58,  3.78s/it, loss=3.05, epoch=0.375, learning_rate=1.39e-5]\u001b[A\n",
      " 38%|███▊      | 1586/4220 [1:41:00<2:45:55,  3.78s/it, loss=3.05, epoch=0.375, learning_rate=1.39e-5]\u001b[A\n",
      " 38%|███▊      | 1586/4220 [1:41:00<2:45:55,  3.78s/it, loss=2.5, epoch=0.376, learning_rate=1.39e-5] \u001b[A\n",
      " 38%|███▊      | 1587/4220 [1:41:04<2:45:52,  3.78s/it, loss=2.5, epoch=0.376, learning_rate=1.39e-5]\u001b[A\n",
      " 38%|███▊      | 1587/4220 [1:41:04<2:45:52,  3.78s/it, loss=2.93, epoch=0.376, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1588/4220 [1:41:08<2:45:48,  3.78s/it, loss=2.93, epoch=0.376, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1588/4220 [1:41:08<2:45:48,  3.78s/it, loss=2.39, epoch=0.376, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1589/4220 [1:41:12<2:45:43,  3.78s/it, loss=2.39, epoch=0.376, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1589/4220 [1:41:12<2:45:43,  3.78s/it, loss=2.52, epoch=0.376, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1590/4220 [1:41:15<2:45:38,  3.78s/it, loss=2.52, epoch=0.376, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1590/4220 [1:41:15<2:45:38,  3.78s/it, loss=3.12, epoch=0.377, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1591/4220 [1:41:19<2:45:29,  3.78s/it, loss=3.12, epoch=0.377, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1591/4220 [1:41:19<2:45:29,  3.78s/it, loss=2.74, epoch=0.377, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1592/4220 [1:41:23<2:45:31,  3.78s/it, loss=2.74, epoch=0.377, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1592/4220 [1:41:23<2:45:31,  3.78s/it, loss=2.95, epoch=0.377, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1593/4220 [1:41:27<2:45:27,  3.78s/it, loss=2.95, epoch=0.377, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1593/4220 [1:41:27<2:45:27,  3.78s/it, loss=2.66, epoch=0.377, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1594/4220 [1:41:30<2:45:21,  3.78s/it, loss=2.66, epoch=0.377, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1594/4220 [1:41:30<2:45:21,  3.78s/it, loss=2.7, epoch=0.377, learning_rate=1.38e-5] \u001b[A\n",
      " 38%|███▊      | 1595/4220 [1:41:34<2:45:13,  3.78s/it, loss=2.7, epoch=0.377, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1595/4220 [1:41:34<2:45:13,  3.78s/it, loss=3.09, epoch=0.378, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1596/4220 [1:41:38<2:45:06,  3.78s/it, loss=3.09, epoch=0.378, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1596/4220 [1:41:38<2:45:06,  3.78s/it, loss=2.84, epoch=0.378, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1597/4220 [1:41:42<2:45:04,  3.78s/it, loss=2.84, epoch=0.378, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1597/4220 [1:41:42<2:45:04,  3.78s/it, loss=3.41, epoch=0.378, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1598/4220 [1:41:46<2:45:02,  3.78s/it, loss=3.41, epoch=0.378, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1598/4220 [1:41:46<2:45:02,  3.78s/it, loss=3.13, epoch=0.378, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1599/4220 [1:41:49<2:44:58,  3.78s/it, loss=3.13, epoch=0.378, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1599/4220 [1:41:49<2:44:58,  3.78s/it, loss=2.42, epoch=0.379, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1600/4220 [1:41:53<2:44:58,  3.78s/it, loss=2.42, epoch=0.379, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1600/4220 [1:41:53<2:44:58,  3.78s/it, loss=2.88, epoch=0.379, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1601/4220 [1:41:57<2:44:50,  3.78s/it, loss=2.88, epoch=0.379, learning_rate=1.38e-5]\u001b[A\n",
      " 38%|███▊      | 1601/4220 [1:41:57<2:44:50,  3.78s/it, loss=2.49, epoch=0.379, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1602/4220 [1:42:01<2:44:48,  3.78s/it, loss=2.49, epoch=0.379, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1602/4220 [1:42:01<2:44:48,  3.78s/it, loss=2.69, epoch=0.379, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1603/4220 [1:42:04<2:44:46,  3.78s/it, loss=2.69, epoch=0.379, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1603/4220 [1:42:04<2:44:46,  3.78s/it, loss=2.33, epoch=0.38, learning_rate=1.37e-5] \u001b[A\n",
      " 38%|███▊      | 1604/4220 [1:42:08<2:44:40,  3.78s/it, loss=2.33, epoch=0.38, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1604/4220 [1:42:08<2:44:40,  3.78s/it, loss=2.44, epoch=0.38, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1605/4220 [1:42:12<2:44:34,  3.78s/it, loss=2.44, epoch=0.38, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1605/4220 [1:42:12<2:44:34,  3.78s/it, loss=3, epoch=0.38, learning_rate=1.37e-5]   \u001b[A\n",
      " 38%|███▊      | 1606/4220 [1:42:16<2:44:33,  3.78s/it, loss=3, epoch=0.38, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1606/4220 [1:42:16<2:44:33,  3.78s/it, loss=3.27, epoch=0.38, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1607/4220 [1:42:20<2:44:31,  3.78s/it, loss=3.27, epoch=0.38, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1607/4220 [1:42:20<2:44:31,  3.78s/it, loss=2.81, epoch=0.381, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1608/4220 [1:42:23<2:44:28,  3.78s/it, loss=2.81, epoch=0.381, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1608/4220 [1:42:23<2:44:28,  3.78s/it, loss=2.63, epoch=0.381, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1609/4220 [1:42:27<2:44:24,  3.78s/it, loss=2.63, epoch=0.381, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1609/4220 [1:42:27<2:44:24,  3.78s/it, loss=2.8, epoch=0.381, learning_rate=1.37e-5] \u001b[A\n",
      " 38%|███▊      | 1610/4220 [1:42:31<2:44:19,  3.78s/it, loss=2.8, epoch=0.381, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1610/4220 [1:42:31<2:44:19,  3.78s/it, loss=2.98, epoch=0.381, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1611/4220 [1:42:35<2:44:17,  3.78s/it, loss=2.98, epoch=0.381, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1611/4220 [1:42:35<2:44:17,  3.78s/it, loss=2.79, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1612/4220 [1:42:38<2:44:10,  3.78s/it, loss=2.79, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1612/4220 [1:42:38<2:44:10,  3.78s/it, loss=3.03, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1613/4220 [1:42:42<2:44:04,  3.78s/it, loss=3.03, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1613/4220 [1:42:42<2:44:04,  3.78s/it, loss=3.42, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1614/4220 [1:42:46<2:44:04,  3.78s/it, loss=3.42, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1614/4220 [1:42:46<2:44:04,  3.78s/it, loss=2.96, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1615/4220 [1:42:50<2:44:00,  3.78s/it, loss=2.96, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1615/4220 [1:42:50<2:44:00,  3.78s/it, loss=2.76, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1616/4220 [1:42:54<2:43:59,  3.78s/it, loss=2.76, epoch=0.382, learning_rate=1.37e-5]\u001b[A\n",
      " 38%|███▊      | 1616/4220 [1:42:54<2:43:59,  3.78s/it, loss=2.34, epoch=0.383, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1617/4220 [1:42:57<2:43:58,  3.78s/it, loss=2.34, epoch=0.383, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1617/4220 [1:42:57<2:43:58,  3.78s/it, loss=2.64, epoch=0.383, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1618/4220 [1:43:01<2:43:51,  3.78s/it, loss=2.64, epoch=0.383, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1618/4220 [1:43:01<2:43:51,  3.78s/it, loss=2.75, epoch=0.383, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1619/4220 [1:43:05<2:43:46,  3.78s/it, loss=2.75, epoch=0.383, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1619/4220 [1:43:05<2:43:46,  3.78s/it, loss=2.74, epoch=0.383, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1620/4220 [1:43:09<2:43:39,  3.78s/it, loss=2.74, epoch=0.383, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1620/4220 [1:43:09<2:43:39,  3.78s/it, loss=2.27, epoch=0.384, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1621/4220 [1:43:12<2:43:43,  3.78s/it, loss=2.27, epoch=0.384, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1621/4220 [1:43:12<2:43:43,  3.78s/it, loss=3.33, epoch=0.384, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1622/4220 [1:43:16<2:43:40,  3.78s/it, loss=3.33, epoch=0.384, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1622/4220 [1:43:16<2:43:40,  3.78s/it, loss=3.43, epoch=0.384, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1623/4220 [1:43:20<2:43:34,  3.78s/it, loss=3.43, epoch=0.384, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1623/4220 [1:43:20<2:43:34,  3.78s/it, loss=3.04, epoch=0.384, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1624/4220 [1:43:24<2:43:30,  3.78s/it, loss=3.04, epoch=0.384, learning_rate=1.36e-5]\u001b[A\n",
      " 38%|███▊      | 1624/4220 [1:43:24<2:43:30,  3.78s/it, loss=2.92, epoch=0.385, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1625/4220 [1:43:28<2:43:30,  3.78s/it, loss=2.92, epoch=0.385, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1625/4220 [1:43:28<2:43:30,  3.78s/it, loss=3.28, epoch=0.385, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1626/4220 [1:43:31<2:43:29,  3.78s/it, loss=3.28, epoch=0.385, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1626/4220 [1:43:31<2:43:29,  3.78s/it, loss=2.83, epoch=0.385, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1627/4220 [1:43:35<2:43:24,  3.78s/it, loss=2.83, epoch=0.385, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1627/4220 [1:43:35<2:43:24,  3.78s/it, loss=2.72, epoch=0.385, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1628/4220 [1:43:39<2:43:21,  3.78s/it, loss=2.72, epoch=0.385, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1628/4220 [1:43:39<2:43:21,  3.78s/it, loss=2.33, epoch=0.386, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1629/4220 [1:43:43<2:43:14,  3.78s/it, loss=2.33, epoch=0.386, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1629/4220 [1:43:43<2:43:14,  3.78s/it, loss=2.54, epoch=0.386, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1630/4220 [1:43:46<2:43:11,  3.78s/it, loss=2.54, epoch=0.386, learning_rate=1.36e-5]\u001b[A\n",
      " 39%|███▊      | 1630/4220 [1:43:46<2:43:11,  3.78s/it, loss=2.82, epoch=0.386, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1631/4220 [1:43:50<2:43:03,  3.78s/it, loss=2.82, epoch=0.386, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1631/4220 [1:43:50<2:43:03,  3.78s/it, loss=2.68, epoch=0.386, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1632/4220 [1:43:54<2:42:56,  3.78s/it, loss=2.68, epoch=0.386, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1632/4220 [1:43:54<2:42:56,  3.78s/it, loss=2.71, epoch=0.386, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1633/4220 [1:43:58<2:42:52,  3.78s/it, loss=2.71, epoch=0.386, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1633/4220 [1:43:58<2:42:52,  3.78s/it, loss=2.91, epoch=0.387, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1634/4220 [1:44:02<2:42:51,  3.78s/it, loss=2.91, epoch=0.387, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1634/4220 [1:44:02<2:42:51,  3.78s/it, loss=2.36, epoch=0.387, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1635/4220 [1:44:05<2:42:50,  3.78s/it, loss=2.36, epoch=0.387, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▊      | 1635/4220 [1:44:05<2:42:50,  3.78s/it, loss=2.76, epoch=0.387, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1636/4220 [1:44:09<2:42:44,  3.78s/it, loss=2.76, epoch=0.387, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1636/4220 [1:44:09<2:42:44,  3.78s/it, loss=2.98, epoch=0.387, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1637/4220 [1:44:13<2:42:42,  3.78s/it, loss=2.98, epoch=0.387, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1637/4220 [1:44:13<2:42:42,  3.78s/it, loss=2.38, epoch=0.388, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1638/4220 [1:44:17<2:42:34,  3.78s/it, loss=2.38, epoch=0.388, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1638/4220 [1:44:17<2:42:34,  3.78s/it, loss=2.73, epoch=0.388, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1639/4220 [1:44:20<2:42:32,  3.78s/it, loss=2.73, epoch=0.388, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1639/4220 [1:44:20<2:42:32,  3.78s/it, loss=2.47, epoch=0.388, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1640/4220 [1:44:24<2:42:25,  3.78s/it, loss=2.47, epoch=0.388, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1640/4220 [1:44:24<2:42:25,  3.78s/it, loss=2.44, epoch=0.388, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1641/4220 [1:44:28<2:42:26,  3.78s/it, loss=2.44, epoch=0.388, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1641/4220 [1:44:28<2:42:26,  3.78s/it, loss=2.96, epoch=0.389, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1642/4220 [1:44:32<2:42:21,  3.78s/it, loss=2.96, epoch=0.389, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1642/4220 [1:44:32<2:42:21,  3.78s/it, loss=2.94, epoch=0.389, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1643/4220 [1:44:36<2:42:18,  3.78s/it, loss=2.94, epoch=0.389, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1643/4220 [1:44:36<2:42:18,  3.78s/it, loss=2.88, epoch=0.389, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1644/4220 [1:44:39<2:42:13,  3.78s/it, loss=2.88, epoch=0.389, learning_rate=1.35e-5]\u001b[A\n",
      " 39%|███▉      | 1644/4220 [1:44:39<2:42:13,  3.78s/it, loss=3.05, epoch=0.389, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1645/4220 [1:44:43<2:42:11,  3.78s/it, loss=3.05, epoch=0.389, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1645/4220 [1:44:43<2:42:11,  3.78s/it, loss=3.01, epoch=0.39, learning_rate=1.34e-5] \u001b[A\n",
      " 39%|███▉      | 1646/4220 [1:44:47<2:42:07,  3.78s/it, loss=3.01, epoch=0.39, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1646/4220 [1:44:47<2:42:07,  3.78s/it, loss=2.46, epoch=0.39, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1647/4220 [1:44:51<2:42:01,  3.78s/it, loss=2.46, epoch=0.39, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1647/4220 [1:44:51<2:42:01,  3.78s/it, loss=2.92, epoch=0.39, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1648/4220 [1:44:54<2:41:57,  3.78s/it, loss=2.92, epoch=0.39, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1648/4220 [1:44:54<2:41:57,  3.78s/it, loss=3.18, epoch=0.39, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1649/4220 [1:44:58<2:41:57,  3.78s/it, loss=3.18, epoch=0.39, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1649/4220 [1:44:58<2:41:57,  3.78s/it, loss=2.72, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1650/4220 [1:45:02<2:41:51,  3.78s/it, loss=2.72, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1650/4220 [1:45:02<2:41:51,  3.78s/it, loss=3.11, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1651/4220 [1:45:06<2:41:49,  3.78s/it, loss=3.11, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1651/4220 [1:45:06<2:41:49,  3.78s/it, loss=3.02, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1652/4220 [1:45:10<2:41:47,  3.78s/it, loss=3.02, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1652/4220 [1:45:10<2:41:47,  3.78s/it, loss=1.97, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1653/4220 [1:45:13<2:41:46,  3.78s/it, loss=1.97, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1653/4220 [1:45:13<2:41:46,  3.78s/it, loss=2.87, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1654/4220 [1:45:17<2:41:42,  3.78s/it, loss=2.87, epoch=0.391, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1654/4220 [1:45:17<2:41:42,  3.78s/it, loss=3.17, epoch=0.392, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1655/4220 [1:45:21<2:41:34,  3.78s/it, loss=3.17, epoch=0.392, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1655/4220 [1:45:21<2:41:34,  3.78s/it, loss=2.84, epoch=0.392, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1656/4220 [1:45:25<2:41:30,  3.78s/it, loss=2.84, epoch=0.392, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1656/4220 [1:45:25<2:41:30,  3.78s/it, loss=2.82, epoch=0.392, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1657/4220 [1:45:28<2:41:24,  3.78s/it, loss=2.82, epoch=0.392, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1657/4220 [1:45:28<2:41:24,  3.78s/it, loss=2.52, epoch=0.392, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1658/4220 [1:45:32<2:41:24,  3.78s/it, loss=2.52, epoch=0.392, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1658/4220 [1:45:32<2:41:24,  3.78s/it, loss=3.05, epoch=0.393, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1659/4220 [1:45:36<2:41:23,  3.78s/it, loss=3.05, epoch=0.393, learning_rate=1.34e-5]\u001b[A\n",
      " 39%|███▉      | 1659/4220 [1:45:36<2:41:23,  3.78s/it, loss=2.44, epoch=0.393, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1660/4220 [1:45:40<2:41:18,  3.78s/it, loss=2.44, epoch=0.393, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1660/4220 [1:45:40<2:41:18,  3.78s/it, loss=3.43, epoch=0.393, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1661/4220 [1:45:44<2:41:13,  3.78s/it, loss=3.43, epoch=0.393, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1661/4220 [1:45:44<2:41:13,  3.78s/it, loss=2.52, epoch=0.393, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1662/4220 [1:45:47<2:41:06,  3.78s/it, loss=2.52, epoch=0.393, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1662/4220 [1:45:47<2:41:06,  3.78s/it, loss=2.71, epoch=0.394, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1663/4220 [1:45:51<2:41:04,  3.78s/it, loss=2.71, epoch=0.394, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1663/4220 [1:45:51<2:41:04,  3.78s/it, loss=3.06, epoch=0.394, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1664/4220 [1:45:55<2:41:02,  3.78s/it, loss=3.06, epoch=0.394, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1664/4220 [1:45:55<2:41:02,  3.78s/it, loss=2.85, epoch=0.394, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1665/4220 [1:45:59<2:40:54,  3.78s/it, loss=2.85, epoch=0.394, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1665/4220 [1:45:59<2:40:54,  3.78s/it, loss=2.68, epoch=0.394, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1666/4220 [1:46:02<2:40:51,  3.78s/it, loss=2.68, epoch=0.394, learning_rate=1.33e-5]\u001b[A\n",
      " 39%|███▉      | 1666/4220 [1:46:02<2:40:51,  3.78s/it, loss=2.64, epoch=0.395, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1667/4220 [1:46:06<2:40:47,  3.78s/it, loss=2.64, epoch=0.395, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1667/4220 [1:46:06<2:40:47,  3.78s/it, loss=2.8, epoch=0.395, learning_rate=1.33e-5] \u001b[A\n",
      " 40%|███▉      | 1668/4220 [1:46:10<2:40:46,  3.78s/it, loss=2.8, epoch=0.395, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1668/4220 [1:46:10<2:40:46,  3.78s/it, loss=2.42, epoch=0.395, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1669/4220 [1:46:14<2:40:48,  3.78s/it, loss=2.42, epoch=0.395, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1669/4220 [1:46:14<2:40:48,  3.78s/it, loss=2.63, epoch=0.395, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1670/4220 [1:46:18<2:40:39,  3.78s/it, loss=2.63, epoch=0.395, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1670/4220 [1:46:18<2:40:39,  3.78s/it, loss=2.83, epoch=0.395, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1671/4220 [1:46:21<2:40:35,  3.78s/it, loss=2.83, epoch=0.395, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1671/4220 [1:46:21<2:40:35,  3.78s/it, loss=2.86, epoch=0.396, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1672/4220 [1:46:25<2:40:32,  3.78s/it, loss=2.86, epoch=0.396, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1672/4220 [1:46:25<2:40:32,  3.78s/it, loss=3, epoch=0.396, learning_rate=1.33e-5]   \u001b[A\n",
      " 40%|███▉      | 1673/4220 [1:46:29<2:40:24,  3.78s/it, loss=3, epoch=0.396, learning_rate=1.33e-5]\u001b[A\n",
      " 40%|███▉      | 1673/4220 [1:46:29<2:40:24,  3.78s/it, loss=2.32, epoch=0.396, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1674/4220 [1:46:33<2:40:26,  3.78s/it, loss=2.32, epoch=0.396, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1674/4220 [1:46:33<2:40:26,  3.78s/it, loss=2.99, epoch=0.396, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1675/4220 [1:46:37<2:40:20,  3.78s/it, loss=2.99, epoch=0.396, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1675/4220 [1:46:37<2:40:20,  3.78s/it, loss=3.07, epoch=0.397, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1676/4220 [1:46:40<2:40:17,  3.78s/it, loss=3.07, epoch=0.397, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1676/4220 [1:46:40<2:40:17,  3.78s/it, loss=2.86, epoch=0.397, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1677/4220 [1:46:44<2:40:14,  3.78s/it, loss=2.86, epoch=0.397, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1677/4220 [1:46:44<2:40:14,  3.78s/it, loss=2.56, epoch=0.397, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1678/4220 [1:46:48<2:40:09,  3.78s/it, loss=2.56, epoch=0.397, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1678/4220 [1:46:48<2:40:09,  3.78s/it, loss=2.9, epoch=0.397, learning_rate=1.32e-5] \u001b[A\n",
      " 40%|███▉      | 1679/4220 [1:46:52<2:40:05,  3.78s/it, loss=2.9, epoch=0.397, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1679/4220 [1:46:52<2:40:05,  3.78s/it, loss=3.03, epoch=0.398, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1680/4220 [1:46:55<2:39:59,  3.78s/it, loss=3.03, epoch=0.398, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1680/4220 [1:46:55<2:39:59,  3.78s/it, loss=2.48, epoch=0.398, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1681/4220 [1:46:59<2:39:57,  3.78s/it, loss=2.48, epoch=0.398, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1681/4220 [1:46:59<2:39:57,  3.78s/it, loss=3.25, epoch=0.398, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1682/4220 [1:47:03<2:39:56,  3.78s/it, loss=3.25, epoch=0.398, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1682/4220 [1:47:03<2:39:56,  3.78s/it, loss=3.07, epoch=0.398, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1683/4220 [1:47:07<2:39:51,  3.78s/it, loss=3.07, epoch=0.398, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1683/4220 [1:47:07<2:39:51,  3.78s/it, loss=2.67, epoch=0.399, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1684/4220 [1:47:11<2:39:47,  3.78s/it, loss=2.67, epoch=0.399, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1684/4220 [1:47:11<2:39:47,  3.78s/it, loss=2.67, epoch=0.399, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1685/4220 [1:47:14<2:39:43,  3.78s/it, loss=2.67, epoch=0.399, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1685/4220 [1:47:14<2:39:43,  3.78s/it, loss=2.73, epoch=0.399, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1686/4220 [1:47:18<2:39:39,  3.78s/it, loss=2.73, epoch=0.399, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1686/4220 [1:47:18<2:39:39,  3.78s/it, loss=3.4, epoch=0.399, learning_rate=1.32e-5] \u001b[A\n",
      " 40%|███▉      | 1687/4220 [1:47:22<2:39:32,  3.78s/it, loss=3.4, epoch=0.399, learning_rate=1.32e-5]\u001b[A\n",
      " 40%|███▉      | 1687/4220 [1:47:22<2:39:32,  3.78s/it, loss=2.96, epoch=0.4, learning_rate=1.31e-5] \u001b[A\n",
      " 40%|████      | 1688/4220 [1:47:26<2:39:29,  3.78s/it, loss=2.96, epoch=0.4, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1688/4220 [1:47:26<2:39:29,  3.78s/it, loss=2.95, epoch=0.4, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1689/4220 [1:47:29<2:39:30,  3.78s/it, loss=2.95, epoch=0.4, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1689/4220 [1:47:29<2:39:30,  3.78s/it, loss=2.52, epoch=0.4, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1690/4220 [1:47:33<2:39:25,  3.78s/it, loss=2.52, epoch=0.4, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1690/4220 [1:47:33<2:39:25,  3.78s/it, loss=3.05, epoch=0.4, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1691/4220 [1:47:37<2:39:18,  3.78s/it, loss=3.05, epoch=0.4, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1691/4220 [1:47:37<2:39:18,  3.78s/it, loss=2.5, epoch=0.4, learning_rate=1.31e-5] \u001b[A\n",
      " 40%|████      | 1692/4220 [1:47:41<2:39:15,  3.78s/it, loss=2.5, epoch=0.4, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1692/4220 [1:47:41<2:39:15,  3.78s/it, loss=2.49, epoch=0.401, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1693/4220 [1:47:45<2:39:11,  3.78s/it, loss=2.49, epoch=0.401, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1693/4220 [1:47:45<2:39:11,  3.78s/it, loss=2.99, epoch=0.401, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1694/4220 [1:47:48<2:39:08,  3.78s/it, loss=2.99, epoch=0.401, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1694/4220 [1:47:48<2:39:08,  3.78s/it, loss=3.02, epoch=0.401, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1695/4220 [1:47:52<2:39:08,  3.78s/it, loss=3.02, epoch=0.401, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1695/4220 [1:47:52<2:39:08,  3.78s/it, loss=3.02, epoch=0.401, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1696/4220 [1:47:56<2:39:02,  3.78s/it, loss=3.02, epoch=0.401, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1696/4220 [1:47:56<2:39:02,  3.78s/it, loss=3.08, epoch=0.402, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1697/4220 [1:48:00<2:38:56,  3.78s/it, loss=3.08, epoch=0.402, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1697/4220 [1:48:00<2:38:56,  3.78s/it, loss=2.96, epoch=0.402, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1698/4220 [1:48:03<2:38:53,  3.78s/it, loss=2.96, epoch=0.402, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1698/4220 [1:48:03<2:38:53,  3.78s/it, loss=3.09, epoch=0.402, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1699/4220 [1:48:07<2:38:48,  3.78s/it, loss=3.09, epoch=0.402, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1699/4220 [1:48:07<2:38:48,  3.78s/it, loss=2.58, epoch=0.402, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1700/4220 [1:48:11<2:38:44,  3.78s/it, loss=2.58, epoch=0.402, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1700/4220 [1:48:11<2:38:44,  3.78s/it, loss=2.96, epoch=0.403, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1701/4220 [1:48:15<2:38:41,  3.78s/it, loss=2.96, epoch=0.403, learning_rate=1.31e-5]\u001b[A\n",
      " 40%|████      | 1701/4220 [1:48:15<2:38:41,  3.78s/it, loss=2.46, epoch=0.403, learning_rate=1.3e-5] \u001b[A\n",
      " 40%|████      | 1702/4220 [1:48:19<2:38:35,  3.78s/it, loss=2.46, epoch=0.403, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1702/4220 [1:48:19<2:38:35,  3.78s/it, loss=2.84, epoch=0.403, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1703/4220 [1:48:22<2:38:29,  3.78s/it, loss=2.84, epoch=0.403, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1703/4220 [1:48:22<2:38:29,  3.78s/it, loss=2.55, epoch=0.403, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1704/4220 [1:48:26<2:38:27,  3.78s/it, loss=2.55, epoch=0.403, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1704/4220 [1:48:26<2:38:27,  3.78s/it, loss=2.53, epoch=0.404, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1705/4220 [1:48:30<2:38:27,  3.78s/it, loss=2.53, epoch=0.404, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1705/4220 [1:48:30<2:38:27,  3.78s/it, loss=3.13, epoch=0.404, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1706/4220 [1:48:34<2:38:23,  3.78s/it, loss=3.13, epoch=0.404, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1706/4220 [1:48:34<2:38:23,  3.78s/it, loss=3.02, epoch=0.404, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1707/4220 [1:48:37<2:38:20,  3.78s/it, loss=3.02, epoch=0.404, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1707/4220 [1:48:37<2:38:20,  3.78s/it, loss=2.59, epoch=0.404, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1708/4220 [1:48:41<2:38:15,  3.78s/it, loss=2.59, epoch=0.404, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1708/4220 [1:48:41<2:38:15,  3.78s/it, loss=2.57, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1709/4220 [1:48:45<2:38:11,  3.78s/it, loss=2.57, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 40%|████      | 1709/4220 [1:48:45<2:38:11,  3.78s/it, loss=2.76, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1710/4220 [1:48:49<2:38:07,  3.78s/it, loss=2.76, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1710/4220 [1:48:49<2:38:07,  3.78s/it, loss=2.54, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1711/4220 [1:48:53<2:38:08,  3.78s/it, loss=2.54, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1711/4220 [1:48:53<2:38:08,  3.78s/it, loss=2.79, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1712/4220 [1:48:56<2:38:01,  3.78s/it, loss=2.79, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1712/4220 [1:48:56<2:38:01,  3.78s/it, loss=3.03, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1713/4220 [1:49:00<2:37:58,  3.78s/it, loss=3.03, epoch=0.405, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1713/4220 [1:49:00<2:37:58,  3.78s/it, loss=3.18, epoch=0.406, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1714/4220 [1:49:04<2:37:53,  3.78s/it, loss=3.18, epoch=0.406, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1714/4220 [1:49:04<2:37:53,  3.78s/it, loss=3.04, epoch=0.406, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1715/4220 [1:49:08<2:37:52,  3.78s/it, loss=3.04, epoch=0.406, learning_rate=1.3e-5]\u001b[A\n",
      " 41%|████      | 1715/4220 [1:49:08<2:37:52,  3.78s/it, loss=2.62, epoch=0.406, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1716/4220 [1:49:11<2:37:45,  3.78s/it, loss=2.62, epoch=0.406, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1716/4220 [1:49:11<2:37:45,  3.78s/it, loss=2.77, epoch=0.406, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1717/4220 [1:49:15<2:37:42,  3.78s/it, loss=2.77, epoch=0.406, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1717/4220 [1:49:15<2:37:42,  3.78s/it, loss=2.26, epoch=0.407, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1718/4220 [1:49:19<2:37:37,  3.78s/it, loss=2.26, epoch=0.407, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1718/4220 [1:49:19<2:37:37,  3.78s/it, loss=3.15, epoch=0.407, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1719/4220 [1:49:23<2:37:34,  3.78s/it, loss=3.15, epoch=0.407, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1719/4220 [1:49:23<2:37:34,  3.78s/it, loss=2.71, epoch=0.407, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1720/4220 [1:49:27<2:37:28,  3.78s/it, loss=2.71, epoch=0.407, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1720/4220 [1:49:27<2:37:28,  3.78s/it, loss=3.17, epoch=0.407, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1721/4220 [1:49:30<2:37:23,  3.78s/it, loss=3.17, epoch=0.407, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1721/4220 [1:49:30<2:37:23,  3.78s/it, loss=2.62, epoch=0.408, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1722/4220 [1:49:34<2:37:21,  3.78s/it, loss=2.62, epoch=0.408, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1722/4220 [1:49:34<2:37:21,  3.78s/it, loss=2.83, epoch=0.408, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1723/4220 [1:49:38<2:37:20,  3.78s/it, loss=2.83, epoch=0.408, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1723/4220 [1:49:38<2:37:20,  3.78s/it, loss=3.19, epoch=0.408, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1724/4220 [1:49:42<2:37:16,  3.78s/it, loss=3.19, epoch=0.408, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1724/4220 [1:49:42<2:37:16,  3.78s/it, loss=3.26, epoch=0.408, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1725/4220 [1:49:46<2:37:13,  3.78s/it, loss=3.26, epoch=0.408, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1725/4220 [1:49:46<2:37:13,  3.78s/it, loss=2.66, epoch=0.409, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1726/4220 [1:49:49<2:37:08,  3.78s/it, loss=2.66, epoch=0.409, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1726/4220 [1:49:49<2:37:08,  3.78s/it, loss=2.82, epoch=0.409, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1727/4220 [1:49:53<2:36:58,  3.78s/it, loss=2.82, epoch=0.409, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1727/4220 [1:49:53<2:36:58,  3.78s/it, loss=2.39, epoch=0.409, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1728/4220 [1:49:57<2:36:57,  3.78s/it, loss=2.39, epoch=0.409, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1728/4220 [1:49:57<2:36:57,  3.78s/it, loss=3.05, epoch=0.409, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1729/4220 [1:50:01<2:36:54,  3.78s/it, loss=3.05, epoch=0.409, learning_rate=1.29e-5]\u001b[A\n",
      " 41%|████      | 1729/4220 [1:50:01<2:36:54,  3.78s/it, loss=2.27, epoch=0.409, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1730/4220 [1:50:04<2:36:50,  3.78s/it, loss=2.27, epoch=0.409, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1730/4220 [1:50:04<2:36:50,  3.78s/it, loss=3.24, epoch=0.41, learning_rate=1.28e-5] \u001b[A\n",
      " 41%|████      | 1731/4220 [1:50:08<2:36:50,  3.78s/it, loss=3.24, epoch=0.41, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1731/4220 [1:50:08<2:36:50,  3.78s/it, loss=2.63, epoch=0.41, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1732/4220 [1:50:12<2:36:47,  3.78s/it, loss=2.63, epoch=0.41, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1732/4220 [1:50:12<2:36:47,  3.78s/it, loss=2.61, epoch=0.41, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1733/4220 [1:50:16<2:36:41,  3.78s/it, loss=2.61, epoch=0.41, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1733/4220 [1:50:16<2:36:41,  3.78s/it, loss=2.4, epoch=0.41, learning_rate=1.28e-5] \u001b[A\n",
      " 41%|████      | 1734/4220 [1:50:20<2:36:37,  3.78s/it, loss=2.4, epoch=0.41, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1734/4220 [1:50:20<2:36:37,  3.78s/it, loss=2.58, epoch=0.411, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1735/4220 [1:50:23<2:36:36,  3.78s/it, loss=2.58, epoch=0.411, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1735/4220 [1:50:23<2:36:36,  3.78s/it, loss=2.9, epoch=0.411, learning_rate=1.28e-5] \u001b[A\n",
      " 41%|████      | 1736/4220 [1:50:27<2:36:32,  3.78s/it, loss=2.9, epoch=0.411, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1736/4220 [1:50:27<2:36:32,  3.78s/it, loss=3.03, epoch=0.411, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1737/4220 [1:50:31<2:36:23,  3.78s/it, loss=3.03, epoch=0.411, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1737/4220 [1:50:31<2:36:23,  3.78s/it, loss=2.74, epoch=0.411, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1738/4220 [1:50:35<2:36:17,  3.78s/it, loss=2.74, epoch=0.411, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1738/4220 [1:50:35<2:36:17,  3.78s/it, loss=2.9, epoch=0.412, learning_rate=1.28e-5] \u001b[A\n",
      " 41%|████      | 1739/4220 [1:50:38<2:36:16,  3.78s/it, loss=2.9, epoch=0.412, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1739/4220 [1:50:38<2:36:16,  3.78s/it, loss=3.38, epoch=0.412, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1740/4220 [1:50:42<2:36:10,  3.78s/it, loss=3.38, epoch=0.412, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████      | 1740/4220 [1:50:42<2:36:10,  3.78s/it, loss=2.97, epoch=0.412, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████▏     | 1741/4220 [1:50:46<2:36:09,  3.78s/it, loss=2.97, epoch=0.412, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████▏     | 1741/4220 [1:50:46<2:36:09,  3.78s/it, loss=3.12, epoch=0.412, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████▏     | 1742/4220 [1:50:50<2:36:05,  3.78s/it, loss=3.12, epoch=0.412, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████▏     | 1742/4220 [1:50:50<2:36:05,  3.78s/it, loss=2.68, epoch=0.413, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████▏     | 1743/4220 [1:50:54<2:36:01,  3.78s/it, loss=2.68, epoch=0.413, learning_rate=1.28e-5]\u001b[A\n",
      " 41%|████▏     | 1743/4220 [1:50:54<2:36:01,  3.78s/it, loss=3.61, epoch=0.413, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1744/4220 [1:50:57<2:35:56,  3.78s/it, loss=3.61, epoch=0.413, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1744/4220 [1:50:57<2:35:56,  3.78s/it, loss=2.52, epoch=0.413, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1745/4220 [1:51:01<2:35:52,  3.78s/it, loss=2.52, epoch=0.413, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1745/4220 [1:51:01<2:35:52,  3.78s/it, loss=3.08, epoch=0.413, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1746/4220 [1:51:05<2:35:44,  3.78s/it, loss=3.08, epoch=0.413, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1746/4220 [1:51:05<2:35:44,  3.78s/it, loss=2.71, epoch=0.414, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1747/4220 [1:51:09<2:35:47,  3.78s/it, loss=2.71, epoch=0.414, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1747/4220 [1:51:09<2:35:47,  3.78s/it, loss=2.75, epoch=0.414, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1748/4220 [1:51:12<2:35:46,  3.78s/it, loss=2.75, epoch=0.414, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1748/4220 [1:51:12<2:35:46,  3.78s/it, loss=3.27, epoch=0.414, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1749/4220 [1:51:16<2:35:43,  3.78s/it, loss=3.27, epoch=0.414, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1749/4220 [1:51:16<2:35:43,  3.78s/it, loss=2.6, epoch=0.414, learning_rate=1.27e-5] \u001b[A\n",
      " 41%|████▏     | 1750/4220 [1:51:20<2:35:41,  3.78s/it, loss=2.6, epoch=0.414, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1750/4220 [1:51:20<2:35:41,  3.78s/it, loss=3.02, epoch=0.414, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1751/4220 [1:51:24<2:35:35,  3.78s/it, loss=3.02, epoch=0.414, learning_rate=1.27e-5]\u001b[A\n",
      " 41%|████▏     | 1751/4220 [1:51:24<2:35:35,  3.78s/it, loss=2.95, epoch=0.415, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1752/4220 [1:51:28<2:35:30,  3.78s/it, loss=2.95, epoch=0.415, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1752/4220 [1:51:28<2:35:30,  3.78s/it, loss=2.47, epoch=0.415, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1753/4220 [1:51:31<2:35:24,  3.78s/it, loss=2.47, epoch=0.415, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1753/4220 [1:51:31<2:35:24,  3.78s/it, loss=2.84, epoch=0.415, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1754/4220 [1:51:35<2:35:21,  3.78s/it, loss=2.84, epoch=0.415, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1754/4220 [1:51:35<2:35:21,  3.78s/it, loss=2.66, epoch=0.415, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1755/4220 [1:51:39<2:35:16,  3.78s/it, loss=2.66, epoch=0.415, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1755/4220 [1:51:39<2:35:16,  3.78s/it, loss=2.53, epoch=0.416, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1756/4220 [1:51:43<2:35:11,  3.78s/it, loss=2.53, epoch=0.416, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1756/4220 [1:51:43<2:35:11,  3.78s/it, loss=2.79, epoch=0.416, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1757/4220 [1:51:46<2:35:13,  3.78s/it, loss=2.79, epoch=0.416, learning_rate=1.27e-5]\u001b[A\n",
      " 42%|████▏     | 1757/4220 [1:51:46<2:35:13,  3.78s/it, loss=2.81, epoch=0.416, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1758/4220 [1:51:50<2:35:04,  3.78s/it, loss=2.81, epoch=0.416, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1758/4220 [1:51:50<2:35:04,  3.78s/it, loss=2.56, epoch=0.416, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1759/4220 [1:51:54<2:34:59,  3.78s/it, loss=2.56, epoch=0.416, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1759/4220 [1:51:54<2:34:59,  3.78s/it, loss=3.14, epoch=0.417, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1760/4220 [1:51:58<2:34:56,  3.78s/it, loss=3.14, epoch=0.417, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1760/4220 [1:51:58<2:34:56,  3.78s/it, loss=2.94, epoch=0.417, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1761/4220 [1:52:02<2:34:50,  3.78s/it, loss=2.94, epoch=0.417, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1761/4220 [1:52:02<2:34:50,  3.78s/it, loss=2.55, epoch=0.417, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1762/4220 [1:52:05<2:34:48,  3.78s/it, loss=2.55, epoch=0.417, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1762/4220 [1:52:05<2:34:48,  3.78s/it, loss=2.72, epoch=0.417, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1763/4220 [1:52:09<2:34:42,  3.78s/it, loss=2.72, epoch=0.417, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1763/4220 [1:52:09<2:34:42,  3.78s/it, loss=3.15, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1764/4220 [1:52:13<2:34:41,  3.78s/it, loss=3.15, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1764/4220 [1:52:13<2:34:41,  3.78s/it, loss=2.82, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1765/4220 [1:52:17<2:34:36,  3.78s/it, loss=2.82, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1765/4220 [1:52:17<2:34:36,  3.78s/it, loss=2.89, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1766/4220 [1:52:20<2:34:31,  3.78s/it, loss=2.89, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1766/4220 [1:52:20<2:34:31,  3.78s/it, loss=3.02, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1767/4220 [1:52:24<2:34:29,  3.78s/it, loss=3.02, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1767/4220 [1:52:24<2:34:29,  3.78s/it, loss=2.57, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1768/4220 [1:52:28<2:34:25,  3.78s/it, loss=2.57, epoch=0.418, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1768/4220 [1:52:28<2:34:25,  3.78s/it, loss=2.81, epoch=0.419, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1769/4220 [1:52:32<2:34:21,  3.78s/it, loss=2.81, epoch=0.419, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1769/4220 [1:52:32<2:34:21,  3.78s/it, loss=2.49, epoch=0.419, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1770/4220 [1:52:36<2:34:20,  3.78s/it, loss=2.49, epoch=0.419, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1770/4220 [1:52:36<2:34:20,  3.78s/it, loss=2.74, epoch=0.419, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1771/4220 [1:52:39<2:34:18,  3.78s/it, loss=2.74, epoch=0.419, learning_rate=1.26e-5]\u001b[A\n",
      " 42%|████▏     | 1771/4220 [1:52:39<2:34:18,  3.78s/it, loss=3.25, epoch=0.419, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1772/4220 [1:52:43<2:34:15,  3.78s/it, loss=3.25, epoch=0.419, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1772/4220 [1:52:43<2:34:15,  3.78s/it, loss=2.89, epoch=0.42, learning_rate=1.25e-5] \u001b[A\n",
      " 42%|████▏     | 1773/4220 [1:52:47<2:34:11,  3.78s/it, loss=2.89, epoch=0.42, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1773/4220 [1:52:47<2:34:11,  3.78s/it, loss=2.75, epoch=0.42, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1774/4220 [1:52:51<2:34:03,  3.78s/it, loss=2.75, epoch=0.42, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1774/4220 [1:52:51<2:34:03,  3.78s/it, loss=3, epoch=0.42, learning_rate=1.25e-5]   \u001b[A\n",
      " 42%|████▏     | 1775/4220 [1:52:54<2:34:02,  3.78s/it, loss=3, epoch=0.42, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1775/4220 [1:52:54<2:34:02,  3.78s/it, loss=2.71, epoch=0.42, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1776/4220 [1:52:58<2:33:55,  3.78s/it, loss=2.71, epoch=0.42, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1776/4220 [1:52:58<2:33:55,  3.78s/it, loss=2.92, epoch=0.421, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1777/4220 [1:53:02<2:33:53,  3.78s/it, loss=2.92, epoch=0.421, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1777/4220 [1:53:02<2:33:53,  3.78s/it, loss=2.85, epoch=0.421, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1778/4220 [1:53:06<2:33:50,  3.78s/it, loss=2.85, epoch=0.421, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1778/4220 [1:53:06<2:33:50,  3.78s/it, loss=2.79, epoch=0.421, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1779/4220 [1:53:10<2:33:47,  3.78s/it, loss=2.79, epoch=0.421, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1779/4220 [1:53:10<2:33:47,  3.78s/it, loss=3.06, epoch=0.421, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1780/4220 [1:53:13<2:33:41,  3.78s/it, loss=3.06, epoch=0.421, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1780/4220 [1:53:13<2:33:41,  3.78s/it, loss=2.83, epoch=0.422, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1781/4220 [1:53:17<2:33:38,  3.78s/it, loss=2.83, epoch=0.422, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1781/4220 [1:53:17<2:33:38,  3.78s/it, loss=2.76, epoch=0.422, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1782/4220 [1:53:21<2:33:33,  3.78s/it, loss=2.76, epoch=0.422, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1782/4220 [1:53:21<2:33:33,  3.78s/it, loss=3.08, epoch=0.422, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1783/4220 [1:53:25<2:33:32,  3.78s/it, loss=3.08, epoch=0.422, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1783/4220 [1:53:25<2:33:32,  3.78s/it, loss=2.81, epoch=0.422, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1784/4220 [1:53:29<2:33:29,  3.78s/it, loss=2.81, epoch=0.422, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1784/4220 [1:53:29<2:33:29,  3.78s/it, loss=2.46, epoch=0.423, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1785/4220 [1:53:32<2:33:27,  3.78s/it, loss=2.46, epoch=0.423, learning_rate=1.25e-5]\u001b[A\n",
      " 42%|████▏     | 1785/4220 [1:53:32<2:33:27,  3.78s/it, loss=2.25, epoch=0.423, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1786/4220 [1:53:36<2:33:21,  3.78s/it, loss=2.25, epoch=0.423, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1786/4220 [1:53:36<2:33:21,  3.78s/it, loss=3.05, epoch=0.423, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1787/4220 [1:53:40<2:33:17,  3.78s/it, loss=3.05, epoch=0.423, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1787/4220 [1:53:40<2:33:17,  3.78s/it, loss=2.47, epoch=0.423, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1788/4220 [1:53:44<2:33:15,  3.78s/it, loss=2.47, epoch=0.423, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1788/4220 [1:53:44<2:33:15,  3.78s/it, loss=2.56, epoch=0.423, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1789/4220 [1:53:47<2:33:10,  3.78s/it, loss=2.56, epoch=0.423, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1789/4220 [1:53:47<2:33:10,  3.78s/it, loss=2.44, epoch=0.424, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1790/4220 [1:53:51<2:33:05,  3.78s/it, loss=2.44, epoch=0.424, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1790/4220 [1:53:51<2:33:05,  3.78s/it, loss=2.48, epoch=0.424, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1791/4220 [1:53:55<2:33:02,  3.78s/it, loss=2.48, epoch=0.424, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1791/4220 [1:53:55<2:33:02,  3.78s/it, loss=2.92, epoch=0.424, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1792/4220 [1:53:59<2:32:56,  3.78s/it, loss=2.92, epoch=0.424, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1792/4220 [1:53:59<2:32:56,  3.78s/it, loss=2.71, epoch=0.424, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1793/4220 [1:54:03<2:32:54,  3.78s/it, loss=2.71, epoch=0.424, learning_rate=1.24e-5]\u001b[A\n",
      " 42%|████▏     | 1793/4220 [1:54:03<2:32:54,  3.78s/it, loss=2.71, epoch=0.425, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1794/4220 [1:54:09<3:10:28,  4.71s/it, loss=2.71, epoch=0.425, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1794/4220 [1:54:09<3:10:28,  4.71s/it, loss=3.28, epoch=0.425, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1795/4220 [1:54:13<2:59:29,  4.44s/it, loss=3.28, epoch=0.425, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1795/4220 [1:54:13<2:59:29,  4.44s/it, loss=2.81, epoch=0.425, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1796/4220 [1:54:17<2:51:19,  4.24s/it, loss=2.81, epoch=0.425, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1796/4220 [1:54:17<2:51:19,  4.24s/it, loss=2.82, epoch=0.425, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1797/4220 [1:54:21<2:45:32,  4.10s/it, loss=2.82, epoch=0.425, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1797/4220 [1:54:21<2:45:32,  4.10s/it, loss=2.89, epoch=0.426, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1798/4220 [1:54:25<2:41:31,  4.00s/it, loss=2.89, epoch=0.426, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1798/4220 [1:54:25<2:41:31,  4.00s/it, loss=2.44, epoch=0.426, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1799/4220 [1:54:28<2:38:43,  3.93s/it, loss=2.44, epoch=0.426, learning_rate=1.24e-5]\u001b[A\n",
      " 43%|████▎     | 1799/4220 [1:54:28<2:38:43,  3.93s/it, loss=2.95, epoch=0.426, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1800/4220 [1:54:32<2:36:44,  3.89s/it, loss=2.95, epoch=0.426, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1800/4220 [1:54:32<2:36:44,  3.89s/it, loss=2.89, epoch=0.426, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1801/4220 [1:54:36<2:35:21,  3.85s/it, loss=2.89, epoch=0.426, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1801/4220 [1:54:36<2:35:21,  3.85s/it, loss=3.15, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1802/4220 [1:54:40<2:34:18,  3.83s/it, loss=3.15, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1802/4220 [1:54:40<2:34:18,  3.83s/it, loss=3.22, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1803/4220 [1:54:43<2:33:38,  3.81s/it, loss=3.22, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1803/4220 [1:54:43<2:33:38,  3.81s/it, loss=2.56, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1804/4220 [1:54:47<2:33:02,  3.80s/it, loss=2.56, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1804/4220 [1:54:47<2:33:02,  3.80s/it, loss=2.28, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1805/4220 [1:54:51<2:32:43,  3.79s/it, loss=2.28, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1805/4220 [1:54:51<2:32:43,  3.79s/it, loss=2.89, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1806/4220 [1:54:55<2:32:29,  3.79s/it, loss=2.89, epoch=0.427, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1806/4220 [1:54:55<2:32:29,  3.79s/it, loss=2.95, epoch=0.428, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1807/4220 [1:54:59<2:32:17,  3.79s/it, loss=2.95, epoch=0.428, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1807/4220 [1:54:59<2:32:17,  3.79s/it, loss=2.9, epoch=0.428, learning_rate=1.23e-5] \u001b[A\n",
      " 43%|████▎     | 1808/4220 [1:55:02<2:32:08,  3.78s/it, loss=2.9, epoch=0.428, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1808/4220 [1:55:02<2:32:08,  3.78s/it, loss=3.08, epoch=0.428, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1809/4220 [1:55:06<2:31:59,  3.78s/it, loss=3.08, epoch=0.428, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1809/4220 [1:55:06<2:31:59,  3.78s/it, loss=2.62, epoch=0.428, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1810/4220 [1:55:10<2:31:53,  3.78s/it, loss=2.62, epoch=0.428, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1810/4220 [1:55:10<2:31:53,  3.78s/it, loss=2.58, epoch=0.429, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1811/4220 [1:55:14<2:31:46,  3.78s/it, loss=2.58, epoch=0.429, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1811/4220 [1:55:14<2:31:46,  3.78s/it, loss=3.36, epoch=0.429, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1812/4220 [1:55:17<2:31:44,  3.78s/it, loss=3.36, epoch=0.429, learning_rate=1.23e-5]\u001b[A\n",
      " 43%|████▎     | 1812/4220 [1:55:17<2:31:44,  3.78s/it, loss=3.23, epoch=0.429, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1813/4220 [1:55:21<2:31:40,  3.78s/it, loss=3.23, epoch=0.429, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1813/4220 [1:55:21<2:31:40,  3.78s/it, loss=2.66, epoch=0.429, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1814/4220 [1:55:25<2:31:35,  3.78s/it, loss=2.66, epoch=0.429, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1814/4220 [1:55:25<2:31:35,  3.78s/it, loss=2.99, epoch=0.43, learning_rate=1.22e-5] \u001b[A\n",
      " 43%|████▎     | 1815/4220 [1:55:29<2:31:27,  3.78s/it, loss=2.99, epoch=0.43, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1815/4220 [1:55:29<2:31:27,  3.78s/it, loss=2.78, epoch=0.43, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1816/4220 [1:55:33<2:31:21,  3.78s/it, loss=2.78, epoch=0.43, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1816/4220 [1:55:33<2:31:21,  3.78s/it, loss=2.97, epoch=0.43, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1817/4220 [1:55:36<2:31:18,  3.78s/it, loss=2.97, epoch=0.43, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1817/4220 [1:55:36<2:31:18,  3.78s/it, loss=2.86, epoch=0.43, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1818/4220 [1:55:40<2:31:14,  3.78s/it, loss=2.86, epoch=0.43, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1818/4220 [1:55:40<2:31:14,  3.78s/it, loss=2.6, epoch=0.431, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1819/4220 [1:55:44<2:31:09,  3.78s/it, loss=2.6, epoch=0.431, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1819/4220 [1:55:44<2:31:09,  3.78s/it, loss=2.5, epoch=0.431, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1820/4220 [1:55:48<2:31:05,  3.78s/it, loss=2.5, epoch=0.431, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1820/4220 [1:55:48<2:31:05,  3.78s/it, loss=2.79, epoch=0.431, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1821/4220 [1:55:51<2:30:57,  3.78s/it, loss=2.79, epoch=0.431, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1821/4220 [1:55:51<2:30:57,  3.78s/it, loss=3.13, epoch=0.431, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1822/4220 [1:55:55<2:30:58,  3.78s/it, loss=3.13, epoch=0.431, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1822/4220 [1:55:55<2:30:58,  3.78s/it, loss=2.72, epoch=0.432, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1823/4220 [1:55:59<2:30:56,  3.78s/it, loss=2.72, epoch=0.432, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1823/4220 [1:55:59<2:30:56,  3.78s/it, loss=2.5, epoch=0.432, learning_rate=1.22e-5] \u001b[A\n",
      " 43%|████▎     | 1824/4220 [1:56:03<2:30:52,  3.78s/it, loss=2.5, epoch=0.432, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1824/4220 [1:56:03<2:30:52,  3.78s/it, loss=3.52, epoch=0.432, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1825/4220 [1:56:07<2:30:48,  3.78s/it, loss=3.52, epoch=0.432, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1825/4220 [1:56:07<2:30:48,  3.78s/it, loss=3.12, epoch=0.432, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1826/4220 [1:56:10<2:30:42,  3.78s/it, loss=3.12, epoch=0.432, learning_rate=1.22e-5]\u001b[A\n",
      " 43%|████▎     | 1826/4220 [1:56:10<2:30:42,  3.78s/it, loss=3.27, epoch=0.432, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1827/4220 [1:56:14<2:30:37,  3.78s/it, loss=3.27, epoch=0.432, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1827/4220 [1:56:14<2:30:37,  3.78s/it, loss=2.46, epoch=0.433, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1828/4220 [1:56:18<2:30:34,  3.78s/it, loss=2.46, epoch=0.433, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1828/4220 [1:56:18<2:30:34,  3.78s/it, loss=2.82, epoch=0.433, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1829/4220 [1:56:22<2:30:32,  3.78s/it, loss=2.82, epoch=0.433, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1829/4220 [1:56:22<2:30:32,  3.78s/it, loss=3, epoch=0.433, learning_rate=1.21e-5]   \u001b[A\n",
      " 43%|████▎     | 1830/4220 [1:56:25<2:30:29,  3.78s/it, loss=3, epoch=0.433, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1830/4220 [1:56:25<2:30:29,  3.78s/it, loss=2.53, epoch=0.433, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1831/4220 [1:56:29<2:30:29,  3.78s/it, loss=2.53, epoch=0.433, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1831/4220 [1:56:29<2:30:29,  3.78s/it, loss=3.08, epoch=0.434, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1832/4220 [1:56:33<2:30:26,  3.78s/it, loss=3.08, epoch=0.434, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1832/4220 [1:56:33<2:30:26,  3.78s/it, loss=2.82, epoch=0.434, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1833/4220 [1:56:37<2:30:22,  3.78s/it, loss=2.82, epoch=0.434, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1833/4220 [1:56:37<2:30:22,  3.78s/it, loss=2.61, epoch=0.434, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1834/4220 [1:56:41<2:30:17,  3.78s/it, loss=2.61, epoch=0.434, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1834/4220 [1:56:41<2:30:17,  3.78s/it, loss=2.62, epoch=0.434, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1835/4220 [1:56:44<2:30:12,  3.78s/it, loss=2.62, epoch=0.434, learning_rate=1.21e-5]\u001b[A\n",
      " 43%|████▎     | 1835/4220 [1:56:44<2:30:12,  3.78s/it, loss=2.86, epoch=0.435, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1836/4220 [1:56:48<2:30:08,  3.78s/it, loss=2.86, epoch=0.435, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1836/4220 [1:56:48<2:30:08,  3.78s/it, loss=2.58, epoch=0.435, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1837/4220 [1:56:52<2:30:05,  3.78s/it, loss=2.58, epoch=0.435, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1837/4220 [1:56:52<2:30:05,  3.78s/it, loss=2.54, epoch=0.435, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1838/4220 [1:56:56<2:30:01,  3.78s/it, loss=2.54, epoch=0.435, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1838/4220 [1:56:56<2:30:01,  3.78s/it, loss=2.86, epoch=0.435, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1839/4220 [1:56:59<2:29:53,  3.78s/it, loss=2.86, epoch=0.435, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1839/4220 [1:56:59<2:29:53,  3.78s/it, loss=2.45, epoch=0.436, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1840/4220 [1:57:03<2:29:53,  3.78s/it, loss=2.45, epoch=0.436, learning_rate=1.21e-5]\u001b[A\n",
      " 44%|████▎     | 1840/4220 [1:57:03<2:29:53,  3.78s/it, loss=3.27, epoch=0.436, learning_rate=1.2e-5] \u001b[A\n",
      " 44%|████▎     | 1841/4220 [1:57:07<2:29:46,  3.78s/it, loss=3.27, epoch=0.436, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1841/4220 [1:57:07<2:29:46,  3.78s/it, loss=2.46, epoch=0.436, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1842/4220 [1:57:11<2:29:42,  3.78s/it, loss=2.46, epoch=0.436, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1842/4220 [1:57:11<2:29:42,  3.78s/it, loss=2.81, epoch=0.436, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1843/4220 [1:57:15<2:29:42,  3.78s/it, loss=2.81, epoch=0.436, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1843/4220 [1:57:15<2:29:42,  3.78s/it, loss=2.82, epoch=0.436, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1844/4220 [1:57:18<2:29:35,  3.78s/it, loss=2.82, epoch=0.436, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1844/4220 [1:57:18<2:29:35,  3.78s/it, loss=3.1, epoch=0.437, learning_rate=1.2e-5] \u001b[A\n",
      " 44%|████▎     | 1845/4220 [1:57:22<2:29:31,  3.78s/it, loss=3.1, epoch=0.437, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1845/4220 [1:57:22<2:29:31,  3.78s/it, loss=2.66, epoch=0.437, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1846/4220 [1:57:26<2:29:30,  3.78s/it, loss=2.66, epoch=0.437, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▎     | 1846/4220 [1:57:26<2:29:30,  3.78s/it, loss=2.47, epoch=0.437, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1847/4220 [1:57:30<2:29:22,  3.78s/it, loss=2.47, epoch=0.437, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1847/4220 [1:57:30<2:29:22,  3.78s/it, loss=2.47, epoch=0.437, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1848/4220 [1:57:33<2:29:21,  3.78s/it, loss=2.47, epoch=0.437, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1848/4220 [1:57:33<2:29:21,  3.78s/it, loss=2.7, epoch=0.438, learning_rate=1.2e-5] \u001b[A\n",
      " 44%|████▍     | 1849/4220 [1:57:37<2:29:20,  3.78s/it, loss=2.7, epoch=0.438, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1849/4220 [1:57:37<2:29:20,  3.78s/it, loss=2.75, epoch=0.438, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1850/4220 [1:57:41<2:29:13,  3.78s/it, loss=2.75, epoch=0.438, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1850/4220 [1:57:41<2:29:13,  3.78s/it, loss=2.68, epoch=0.438, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1851/4220 [1:57:45<2:29:11,  3.78s/it, loss=2.68, epoch=0.438, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1851/4220 [1:57:45<2:29:11,  3.78s/it, loss=3.1, epoch=0.438, learning_rate=1.2e-5] \u001b[A\n",
      " 44%|████▍     | 1852/4220 [1:57:49<2:29:03,  3.78s/it, loss=3.1, epoch=0.438, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1852/4220 [1:57:49<2:29:03,  3.78s/it, loss=3.16, epoch=0.439, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1853/4220 [1:57:52<2:29:03,  3.78s/it, loss=3.16, epoch=0.439, learning_rate=1.2e-5]\u001b[A\n",
      " 44%|████▍     | 1853/4220 [1:57:52<2:29:03,  3.78s/it, loss=2.95, epoch=0.439, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1854/4220 [1:57:56<2:28:59,  3.78s/it, loss=2.95, epoch=0.439, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1854/4220 [1:57:56<2:28:59,  3.78s/it, loss=2.95, epoch=0.439, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1855/4220 [1:58:00<2:28:55,  3.78s/it, loss=2.95, epoch=0.439, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1855/4220 [1:58:00<2:28:55,  3.78s/it, loss=2.62, epoch=0.439, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1856/4220 [1:58:04<2:28:53,  3.78s/it, loss=2.62, epoch=0.439, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1856/4220 [1:58:04<2:28:53,  3.78s/it, loss=3.01, epoch=0.44, learning_rate=1.19e-5] \u001b[A\n",
      " 44%|████▍     | 1857/4220 [1:58:07<2:28:50,  3.78s/it, loss=3.01, epoch=0.44, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1857/4220 [1:58:07<2:28:50,  3.78s/it, loss=2.79, epoch=0.44, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1858/4220 [1:58:11<2:28:42,  3.78s/it, loss=2.79, epoch=0.44, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1858/4220 [1:58:11<2:28:42,  3.78s/it, loss=2.56, epoch=0.44, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1859/4220 [1:58:15<2:28:42,  3.78s/it, loss=2.56, epoch=0.44, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1859/4220 [1:58:15<2:28:42,  3.78s/it, loss=3.05, epoch=0.44, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1860/4220 [1:58:19<2:28:39,  3.78s/it, loss=3.05, epoch=0.44, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1860/4220 [1:58:19<2:28:39,  3.78s/it, loss=2.53, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1861/4220 [1:58:23<2:28:34,  3.78s/it, loss=2.53, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1861/4220 [1:58:23<2:28:34,  3.78s/it, loss=3.14, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1862/4220 [1:58:26<2:28:28,  3.78s/it, loss=3.14, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1862/4220 [1:58:26<2:28:28,  3.78s/it, loss=2.32, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1863/4220 [1:58:30<2:28:25,  3.78s/it, loss=2.32, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1863/4220 [1:58:30<2:28:25,  3.78s/it, loss=2.83, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1864/4220 [1:58:34<2:28:24,  3.78s/it, loss=2.83, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1864/4220 [1:58:34<2:28:24,  3.78s/it, loss=3.09, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1865/4220 [1:58:38<2:28:21,  3.78s/it, loss=3.09, epoch=0.441, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1865/4220 [1:58:38<2:28:21,  3.78s/it, loss=2.72, epoch=0.442, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1866/4220 [1:58:41<2:28:11,  3.78s/it, loss=2.72, epoch=0.442, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1866/4220 [1:58:41<2:28:11,  3.78s/it, loss=2.82, epoch=0.442, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1867/4220 [1:58:45<2:28:11,  3.78s/it, loss=2.82, epoch=0.442, learning_rate=1.19e-5]\u001b[A\n",
      " 44%|████▍     | 1867/4220 [1:58:45<2:28:11,  3.78s/it, loss=2.93, epoch=0.442, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1868/4220 [1:58:49<2:28:06,  3.78s/it, loss=2.93, epoch=0.442, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1868/4220 [1:58:49<2:28:06,  3.78s/it, loss=2.49, epoch=0.442, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1869/4220 [1:58:53<2:28:02,  3.78s/it, loss=2.49, epoch=0.442, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1869/4220 [1:58:53<2:28:02,  3.78s/it, loss=3.22, epoch=0.443, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1870/4220 [1:58:57<2:27:55,  3.78s/it, loss=3.22, epoch=0.443, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1870/4220 [1:58:57<2:27:55,  3.78s/it, loss=3.01, epoch=0.443, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1871/4220 [1:59:00<2:27:53,  3.78s/it, loss=3.01, epoch=0.443, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1871/4220 [1:59:00<2:27:53,  3.78s/it, loss=2.58, epoch=0.443, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1872/4220 [1:59:04<2:27:47,  3.78s/it, loss=2.58, epoch=0.443, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1872/4220 [1:59:04<2:27:47,  3.78s/it, loss=3.32, epoch=0.443, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1873/4220 [1:59:08<2:27:44,  3.78s/it, loss=3.32, epoch=0.443, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1873/4220 [1:59:08<2:27:44,  3.78s/it, loss=2.76, epoch=0.444, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1874/4220 [1:59:12<2:27:42,  3.78s/it, loss=2.76, epoch=0.444, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1874/4220 [1:59:12<2:27:42,  3.78s/it, loss=3.01, epoch=0.444, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1875/4220 [1:59:15<2:27:38,  3.78s/it, loss=3.01, epoch=0.444, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1875/4220 [1:59:15<2:27:38,  3.78s/it, loss=3.33, epoch=0.444, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1876/4220 [1:59:19<2:27:36,  3.78s/it, loss=3.33, epoch=0.444, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1876/4220 [1:59:19<2:27:36,  3.78s/it, loss=2.66, epoch=0.444, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1877/4220 [1:59:23<2:27:31,  3.78s/it, loss=2.66, epoch=0.444, learning_rate=1.18e-5]\u001b[A\n",
      " 44%|████▍     | 1877/4220 [1:59:23<2:27:31,  3.78s/it, loss=2.98, epoch=0.445, learning_rate=1.18e-5]\u001b[A\n",
      " 45%|████▍     | 1878/4220 [1:59:27<2:27:23,  3.78s/it, loss=2.98, epoch=0.445, learning_rate=1.18e-5]\u001b[A\n",
      " 45%|████▍     | 1878/4220 [1:59:27<2:27:23,  3.78s/it, loss=2.56, epoch=0.445, learning_rate=1.18e-5]\u001b[A\n",
      " 45%|████▍     | 1879/4220 [1:59:31<2:27:22,  3.78s/it, loss=2.56, epoch=0.445, learning_rate=1.18e-5]\u001b[A\n",
      " 45%|████▍     | 1879/4220 [1:59:31<2:27:22,  3.78s/it, loss=2.83, epoch=0.445, learning_rate=1.18e-5]\u001b[A\n",
      " 45%|████▍     | 1880/4220 [1:59:34<2:27:19,  3.78s/it, loss=2.83, epoch=0.445, learning_rate=1.18e-5]\u001b[A\n",
      " 45%|████▍     | 1880/4220 [1:59:34<2:27:19,  3.78s/it, loss=2.7, epoch=0.445, learning_rate=1.18e-5] \u001b[A\n",
      " 45%|████▍     | 1881/4220 [1:59:38<2:27:17,  3.78s/it, loss=2.7, epoch=0.445, learning_rate=1.18e-5]\u001b[A\n",
      " 45%|████▍     | 1881/4220 [1:59:38<2:27:17,  3.78s/it, loss=2.83, epoch=0.445, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1882/4220 [1:59:42<2:27:12,  3.78s/it, loss=2.83, epoch=0.445, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1882/4220 [1:59:42<2:27:12,  3.78s/it, loss=2.88, epoch=0.446, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1883/4220 [1:59:46<2:27:10,  3.78s/it, loss=2.88, epoch=0.446, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1883/4220 [1:59:46<2:27:10,  3.78s/it, loss=2.85, epoch=0.446, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1884/4220 [1:59:49<2:27:00,  3.78s/it, loss=2.85, epoch=0.446, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1884/4220 [1:59:49<2:27:00,  3.78s/it, loss=3.37, epoch=0.446, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1885/4220 [1:59:53<2:27:00,  3.78s/it, loss=3.37, epoch=0.446, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1885/4220 [1:59:53<2:27:00,  3.78s/it, loss=3.19, epoch=0.446, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1886/4220 [1:59:57<2:26:54,  3.78s/it, loss=3.19, epoch=0.446, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1886/4220 [1:59:57<2:26:54,  3.78s/it, loss=2.73, epoch=0.447, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1887/4220 [2:00:01<2:26:50,  3.78s/it, loss=2.73, epoch=0.447, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1887/4220 [2:00:01<2:26:50,  3.78s/it, loss=2.41, epoch=0.447, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1888/4220 [2:00:05<2:26:45,  3.78s/it, loss=2.41, epoch=0.447, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1888/4220 [2:00:05<2:26:45,  3.78s/it, loss=3.46, epoch=0.447, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1889/4220 [2:00:08<2:26:42,  3.78s/it, loss=3.46, epoch=0.447, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1889/4220 [2:00:08<2:26:42,  3.78s/it, loss=2.62, epoch=0.447, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1890/4220 [2:00:12<2:26:39,  3.78s/it, loss=2.62, epoch=0.447, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1890/4220 [2:00:12<2:26:39,  3.78s/it, loss=3.14, epoch=0.448, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1891/4220 [2:00:16<2:26:37,  3.78s/it, loss=3.14, epoch=0.448, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1891/4220 [2:00:16<2:26:37,  3.78s/it, loss=2.96, epoch=0.448, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1892/4220 [2:00:20<2:26:35,  3.78s/it, loss=2.96, epoch=0.448, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1892/4220 [2:00:20<2:26:35,  3.78s/it, loss=2.45, epoch=0.448, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1893/4220 [2:00:23<2:26:33,  3.78s/it, loss=2.45, epoch=0.448, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1893/4220 [2:00:23<2:26:33,  3.78s/it, loss=2.53, epoch=0.448, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1894/4220 [2:00:27<2:26:30,  3.78s/it, loss=2.53, epoch=0.448, learning_rate=1.17e-5]\u001b[A\n",
      " 45%|████▍     | 1894/4220 [2:00:27<2:26:30,  3.78s/it, loss=2.34, epoch=0.449, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▍     | 1895/4220 [2:00:31<2:26:20,  3.78s/it, loss=2.34, epoch=0.449, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▍     | 1895/4220 [2:00:31<2:26:20,  3.78s/it, loss=2.98, epoch=0.449, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▍     | 1896/4220 [2:00:35<2:26:17,  3.78s/it, loss=2.98, epoch=0.449, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▍     | 1896/4220 [2:00:35<2:26:17,  3.78s/it, loss=2.73, epoch=0.449, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▍     | 1897/4220 [2:00:39<2:26:12,  3.78s/it, loss=2.73, epoch=0.449, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▍     | 1897/4220 [2:00:39<2:26:12,  3.78s/it, loss=3.29, epoch=0.449, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▍     | 1898/4220 [2:00:42<2:26:08,  3.78s/it, loss=3.29, epoch=0.449, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▍     | 1898/4220 [2:00:42<2:26:08,  3.78s/it, loss=2.95, epoch=0.45, learning_rate=1.16e-5] \u001b[A\n",
      " 45%|████▌     | 1899/4220 [2:00:46<2:26:06,  3.78s/it, loss=2.95, epoch=0.45, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1899/4220 [2:00:46<2:26:06,  3.78s/it, loss=2.96, epoch=0.45, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1900/4220 [2:00:50<2:26:01,  3.78s/it, loss=2.96, epoch=0.45, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1900/4220 [2:00:50<2:26:01,  3.78s/it, loss=2.56, epoch=0.45, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1901/4220 [2:00:54<2:25:56,  3.78s/it, loss=2.56, epoch=0.45, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1901/4220 [2:00:54<2:25:56,  3.78s/it, loss=3.03, epoch=0.45, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1902/4220 [2:00:57<2:25:58,  3.78s/it, loss=3.03, epoch=0.45, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1902/4220 [2:00:57<2:25:58,  3.78s/it, loss=2.92, epoch=0.45, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1903/4220 [2:01:01<2:25:54,  3.78s/it, loss=2.92, epoch=0.45, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1903/4220 [2:01:01<2:25:54,  3.78s/it, loss=2.84, epoch=0.451, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1904/4220 [2:01:05<2:25:48,  3.78s/it, loss=2.84, epoch=0.451, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1904/4220 [2:01:05<2:25:48,  3.78s/it, loss=3.07, epoch=0.451, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1905/4220 [2:01:09<2:25:48,  3.78s/it, loss=3.07, epoch=0.451, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1905/4220 [2:01:09<2:25:48,  3.78s/it, loss=2.9, epoch=0.451, learning_rate=1.16e-5] \u001b[A\n",
      " 45%|████▌     | 1906/4220 [2:01:13<2:25:44,  3.78s/it, loss=2.9, epoch=0.451, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1906/4220 [2:01:13<2:25:44,  3.78s/it, loss=3.19, epoch=0.451, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1907/4220 [2:01:16<2:25:39,  3.78s/it, loss=3.19, epoch=0.451, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1907/4220 [2:01:16<2:25:39,  3.78s/it, loss=2.96, epoch=0.452, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1908/4220 [2:01:20<2:25:36,  3.78s/it, loss=2.96, epoch=0.452, learning_rate=1.16e-5]\u001b[A\n",
      " 45%|████▌     | 1908/4220 [2:01:20<2:25:36,  3.78s/it, loss=3.04, epoch=0.452, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1909/4220 [2:01:24<2:25:31,  3.78s/it, loss=3.04, epoch=0.452, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1909/4220 [2:01:24<2:25:31,  3.78s/it, loss=2.79, epoch=0.452, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1910/4220 [2:01:28<2:25:28,  3.78s/it, loss=2.79, epoch=0.452, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1910/4220 [2:01:28<2:25:28,  3.78s/it, loss=2.97, epoch=0.452, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1911/4220 [2:01:31<2:25:25,  3.78s/it, loss=2.97, epoch=0.452, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1911/4220 [2:01:31<2:25:25,  3.78s/it, loss=2.85, epoch=0.453, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1912/4220 [2:01:35<2:25:16,  3.78s/it, loss=2.85, epoch=0.453, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1912/4220 [2:01:35<2:25:16,  3.78s/it, loss=2.94, epoch=0.453, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1913/4220 [2:01:39<2:25:14,  3.78s/it, loss=2.94, epoch=0.453, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1913/4220 [2:01:39<2:25:14,  3.78s/it, loss=2.32, epoch=0.453, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1914/4220 [2:01:43<2:25:11,  3.78s/it, loss=2.32, epoch=0.453, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1914/4220 [2:01:43<2:25:11,  3.78s/it, loss=2.56, epoch=0.453, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1915/4220 [2:01:47<2:25:10,  3.78s/it, loss=2.56, epoch=0.453, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1915/4220 [2:01:47<2:25:10,  3.78s/it, loss=2.4, epoch=0.454, learning_rate=1.15e-5] \u001b[A\n",
      " 45%|████▌     | 1916/4220 [2:01:50<2:25:05,  3.78s/it, loss=2.4, epoch=0.454, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1916/4220 [2:01:50<2:25:05,  3.78s/it, loss=3.25, epoch=0.454, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1917/4220 [2:01:54<2:24:59,  3.78s/it, loss=3.25, epoch=0.454, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1917/4220 [2:01:54<2:24:59,  3.78s/it, loss=2.8, epoch=0.454, learning_rate=1.15e-5] \u001b[A\n",
      " 45%|████▌     | 1918/4220 [2:01:58<2:24:58,  3.78s/it, loss=2.8, epoch=0.454, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1918/4220 [2:01:58<2:24:58,  3.78s/it, loss=2.73, epoch=0.454, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1919/4220 [2:02:02<2:24:55,  3.78s/it, loss=2.73, epoch=0.454, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1919/4220 [2:02:02<2:24:55,  3.78s/it, loss=3.12, epoch=0.455, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1920/4220 [2:02:05<2:24:51,  3.78s/it, loss=3.12, epoch=0.455, learning_rate=1.15e-5]\u001b[A\n",
      " 45%|████▌     | 1920/4220 [2:02:05<2:24:51,  3.78s/it, loss=3.21, epoch=0.455, learning_rate=1.15e-5]\u001b[A\n",
      " 46%|████▌     | 1921/4220 [2:02:09<2:24:47,  3.78s/it, loss=3.21, epoch=0.455, learning_rate=1.15e-5]\u001b[A\n",
      " 46%|████▌     | 1921/4220 [2:02:09<2:24:47,  3.78s/it, loss=2.96, epoch=0.455, learning_rate=1.15e-5]\u001b[A\n",
      " 46%|████▌     | 1922/4220 [2:02:13<2:24:44,  3.78s/it, loss=2.96, epoch=0.455, learning_rate=1.15e-5]\u001b[A\n",
      " 46%|████▌     | 1922/4220 [2:02:13<2:24:44,  3.78s/it, loss=2.74, epoch=0.455, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1923/4220 [2:02:17<2:24:40,  3.78s/it, loss=2.74, epoch=0.455, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1923/4220 [2:02:17<2:24:40,  3.78s/it, loss=2.5, epoch=0.455, learning_rate=1.14e-5] \u001b[A\n",
      " 46%|████▌     | 1924/4220 [2:02:21<2:24:37,  3.78s/it, loss=2.5, epoch=0.455, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1924/4220 [2:02:21<2:24:37,  3.78s/it, loss=2.64, epoch=0.456, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1925/4220 [2:02:24<2:24:33,  3.78s/it, loss=2.64, epoch=0.456, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1925/4220 [2:02:24<2:24:33,  3.78s/it, loss=2.67, epoch=0.456, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1926/4220 [2:02:28<2:24:30,  3.78s/it, loss=2.67, epoch=0.456, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1926/4220 [2:02:28<2:24:30,  3.78s/it, loss=2.46, epoch=0.456, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1927/4220 [2:02:32<2:24:26,  3.78s/it, loss=2.46, epoch=0.456, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1927/4220 [2:02:32<2:24:26,  3.78s/it, loss=2.85, epoch=0.456, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1928/4220 [2:02:36<2:24:20,  3.78s/it, loss=2.85, epoch=0.456, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1928/4220 [2:02:36<2:24:20,  3.78s/it, loss=2.65, epoch=0.457, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1929/4220 [2:02:39<2:24:18,  3.78s/it, loss=2.65, epoch=0.457, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1929/4220 [2:02:39<2:24:18,  3.78s/it, loss=3.68, epoch=0.457, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1930/4220 [2:02:43<2:24:15,  3.78s/it, loss=3.68, epoch=0.457, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1930/4220 [2:02:43<2:24:15,  3.78s/it, loss=2.7, epoch=0.457, learning_rate=1.14e-5] \u001b[A\n",
      " 46%|████▌     | 1931/4220 [2:02:47<2:24:12,  3.78s/it, loss=2.7, epoch=0.457, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1931/4220 [2:02:47<2:24:12,  3.78s/it, loss=2.8, epoch=0.457, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1932/4220 [2:02:51<2:24:01,  3.78s/it, loss=2.8, epoch=0.457, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1932/4220 [2:02:51<2:24:01,  3.78s/it, loss=2.71, epoch=0.458, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1933/4220 [2:02:55<2:23:58,  3.78s/it, loss=2.71, epoch=0.458, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1933/4220 [2:02:55<2:23:58,  3.78s/it, loss=3.54, epoch=0.458, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1934/4220 [2:02:58<2:23:54,  3.78s/it, loss=3.54, epoch=0.458, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1934/4220 [2:02:58<2:23:54,  3.78s/it, loss=2.57, epoch=0.458, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1935/4220 [2:03:02<2:23:51,  3.78s/it, loss=2.57, epoch=0.458, learning_rate=1.14e-5]\u001b[A\n",
      " 46%|████▌     | 1935/4220 [2:03:02<2:23:51,  3.78s/it, loss=2.94, epoch=0.458, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1936/4220 [2:03:06<2:23:50,  3.78s/it, loss=2.94, epoch=0.458, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1936/4220 [2:03:06<2:23:50,  3.78s/it, loss=2.69, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1937/4220 [2:03:10<2:23:45,  3.78s/it, loss=2.69, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1937/4220 [2:03:10<2:23:45,  3.78s/it, loss=2.81, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1938/4220 [2:03:13<2:23:41,  3.78s/it, loss=2.81, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1938/4220 [2:03:13<2:23:41,  3.78s/it, loss=3.07, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1939/4220 [2:03:17<2:23:37,  3.78s/it, loss=3.07, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1939/4220 [2:03:17<2:23:37,  3.78s/it, loss=2.89, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1940/4220 [2:03:21<2:23:32,  3.78s/it, loss=2.89, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1940/4220 [2:03:21<2:23:32,  3.78s/it, loss=2.62, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1941/4220 [2:03:25<2:23:26,  3.78s/it, loss=2.62, epoch=0.459, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1941/4220 [2:03:25<2:23:26,  3.78s/it, loss=2.29, epoch=0.46, learning_rate=1.13e-5] \u001b[A\n",
      " 46%|████▌     | 1942/4220 [2:03:29<2:23:24,  3.78s/it, loss=2.29, epoch=0.46, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1942/4220 [2:03:29<2:23:24,  3.78s/it, loss=2.82, epoch=0.46, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1943/4220 [2:03:32<2:23:19,  3.78s/it, loss=2.82, epoch=0.46, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1943/4220 [2:03:32<2:23:19,  3.78s/it, loss=2.67, epoch=0.46, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1944/4220 [2:03:36<2:23:16,  3.78s/it, loss=2.67, epoch=0.46, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1944/4220 [2:03:36<2:23:16,  3.78s/it, loss=2.49, epoch=0.46, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1945/4220 [2:03:40<2:23:11,  3.78s/it, loss=2.49, epoch=0.46, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1945/4220 [2:03:40<2:23:11,  3.78s/it, loss=2.89, epoch=0.461, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1946/4220 [2:03:44<2:23:10,  3.78s/it, loss=2.89, epoch=0.461, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1946/4220 [2:03:44<2:23:10,  3.78s/it, loss=2.78, epoch=0.461, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1947/4220 [2:03:47<2:23:10,  3.78s/it, loss=2.78, epoch=0.461, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1947/4220 [2:03:47<2:23:10,  3.78s/it, loss=2.8, epoch=0.461, learning_rate=1.13e-5] \u001b[A\n",
      " 46%|████▌     | 1948/4220 [2:03:51<2:23:05,  3.78s/it, loss=2.8, epoch=0.461, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1948/4220 [2:03:51<2:23:05,  3.78s/it, loss=2.54, epoch=0.461, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1949/4220 [2:03:55<2:22:59,  3.78s/it, loss=2.54, epoch=0.461, learning_rate=1.13e-5]\u001b[A\n",
      " 46%|████▌     | 1949/4220 [2:03:55<2:22:59,  3.78s/it, loss=3.07, epoch=0.462, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▌     | 1950/4220 [2:03:59<2:22:56,  3.78s/it, loss=3.07, epoch=0.462, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▌     | 1950/4220 [2:03:59<2:22:56,  3.78s/it, loss=2.94, epoch=0.462, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▌     | 1951/4220 [2:04:03<2:22:50,  3.78s/it, loss=2.94, epoch=0.462, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▌     | 1951/4220 [2:04:03<2:22:50,  3.78s/it, loss=2.88, epoch=0.462, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1952/4220 [2:04:06<2:22:45,  3.78s/it, loss=2.88, epoch=0.462, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1952/4220 [2:04:06<2:22:45,  3.78s/it, loss=2.5, epoch=0.462, learning_rate=1.12e-5] \u001b[A\n",
      " 46%|████▋     | 1953/4220 [2:04:10<2:22:56,  3.78s/it, loss=2.5, epoch=0.462, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1953/4220 [2:04:10<2:22:56,  3.78s/it, loss=3.07, epoch=0.463, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1954/4220 [2:04:14<2:22:51,  3.78s/it, loss=3.07, epoch=0.463, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1954/4220 [2:04:14<2:22:51,  3.78s/it, loss=2.69, epoch=0.463, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1955/4220 [2:04:18<2:22:47,  3.78s/it, loss=2.69, epoch=0.463, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1955/4220 [2:04:18<2:22:47,  3.78s/it, loss=2.77, epoch=0.463, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1956/4220 [2:04:21<2:22:42,  3.78s/it, loss=2.77, epoch=0.463, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1956/4220 [2:04:21<2:22:42,  3.78s/it, loss=3.01, epoch=0.463, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1957/4220 [2:04:25<2:22:33,  3.78s/it, loss=3.01, epoch=0.463, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1957/4220 [2:04:25<2:22:33,  3.78s/it, loss=2.56, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1958/4220 [2:04:29<2:22:27,  3.78s/it, loss=2.56, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1958/4220 [2:04:29<2:22:27,  3.78s/it, loss=2.48, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1959/4220 [2:04:33<2:22:23,  3.78s/it, loss=2.48, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1959/4220 [2:04:33<2:22:23,  3.78s/it, loss=2.57, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1960/4220 [2:04:37<2:22:17,  3.78s/it, loss=2.57, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1960/4220 [2:04:37<2:22:17,  3.78s/it, loss=2.87, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1961/4220 [2:04:40<2:22:13,  3.78s/it, loss=2.87, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1961/4220 [2:04:40<2:22:13,  3.78s/it, loss=2.94, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1962/4220 [2:04:44<2:22:10,  3.78s/it, loss=2.94, epoch=0.464, learning_rate=1.12e-5]\u001b[A\n",
      " 46%|████▋     | 1962/4220 [2:04:44<2:22:10,  3.78s/it, loss=2.77, epoch=0.465, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1963/4220 [2:04:48<2:22:08,  3.78s/it, loss=2.77, epoch=0.465, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1963/4220 [2:04:48<2:22:08,  3.78s/it, loss=2.5, epoch=0.465, learning_rate=1.11e-5] \u001b[A\n",
      " 47%|████▋     | 1964/4220 [2:04:52<2:22:05,  3.78s/it, loss=2.5, epoch=0.465, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1964/4220 [2:04:52<2:22:05,  3.78s/it, loss=2.62, epoch=0.465, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1965/4220 [2:04:55<2:22:01,  3.78s/it, loss=2.62, epoch=0.465, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1965/4220 [2:04:55<2:22:01,  3.78s/it, loss=2.7, epoch=0.465, learning_rate=1.11e-5] \u001b[A\n",
      " 47%|████▋     | 1966/4220 [2:04:59<2:21:59,  3.78s/it, loss=2.7, epoch=0.465, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1966/4220 [2:04:59<2:21:59,  3.78s/it, loss=2.64, epoch=0.466, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1967/4220 [2:05:03<2:21:55,  3.78s/it, loss=2.64, epoch=0.466, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1967/4220 [2:05:03<2:21:55,  3.78s/it, loss=3.06, epoch=0.466, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1968/4220 [2:05:07<2:21:46,  3.78s/it, loss=3.06, epoch=0.466, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1968/4220 [2:05:07<2:21:46,  3.78s/it, loss=2.37, epoch=0.466, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1969/4220 [2:05:11<2:21:43,  3.78s/it, loss=2.37, epoch=0.466, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1969/4220 [2:05:11<2:21:43,  3.78s/it, loss=2.26, epoch=0.466, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1970/4220 [2:05:14<2:21:41,  3.78s/it, loss=2.26, epoch=0.466, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1970/4220 [2:05:14<2:21:41,  3.78s/it, loss=3.11, epoch=0.467, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1971/4220 [2:05:18<2:21:35,  3.78s/it, loss=3.11, epoch=0.467, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1971/4220 [2:05:18<2:21:35,  3.78s/it, loss=2.9, epoch=0.467, learning_rate=1.11e-5] \u001b[A\n",
      " 47%|████▋     | 1972/4220 [2:05:22<2:21:32,  3.78s/it, loss=2.9, epoch=0.467, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1972/4220 [2:05:22<2:21:32,  3.78s/it, loss=2.6, epoch=0.467, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1973/4220 [2:05:26<2:21:28,  3.78s/it, loss=2.6, epoch=0.467, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1973/4220 [2:05:26<2:21:28,  3.78s/it, loss=2.64, epoch=0.467, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1974/4220 [2:05:30<2:21:30,  3.78s/it, loss=2.64, epoch=0.467, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1974/4220 [2:05:30<2:21:30,  3.78s/it, loss=2.71, epoch=0.468, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1975/4220 [2:05:33<2:21:25,  3.78s/it, loss=2.71, epoch=0.468, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1975/4220 [2:05:33<2:21:25,  3.78s/it, loss=3.07, epoch=0.468, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1976/4220 [2:05:37<2:21:22,  3.78s/it, loss=3.07, epoch=0.468, learning_rate=1.11e-5]\u001b[A\n",
      " 47%|████▋     | 1976/4220 [2:05:37<2:21:22,  3.78s/it, loss=2.61, epoch=0.468, learning_rate=1.1e-5] \u001b[A\n",
      " 47%|████▋     | 1977/4220 [2:05:41<2:21:15,  3.78s/it, loss=2.61, epoch=0.468, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1977/4220 [2:05:41<2:21:15,  3.78s/it, loss=3.01, epoch=0.468, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1978/4220 [2:05:45<2:21:10,  3.78s/it, loss=3.01, epoch=0.468, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1978/4220 [2:05:45<2:21:10,  3.78s/it, loss=2.64, epoch=0.468, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1979/4220 [2:05:48<2:21:07,  3.78s/it, loss=2.64, epoch=0.468, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1979/4220 [2:05:48<2:21:07,  3.78s/it, loss=3.1, epoch=0.469, learning_rate=1.1e-5] \u001b[A\n",
      " 47%|████▋     | 1980/4220 [2:05:52<2:21:02,  3.78s/it, loss=3.1, epoch=0.469, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1980/4220 [2:05:52<2:21:02,  3.78s/it, loss=2.77, epoch=0.469, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1981/4220 [2:05:56<2:20:59,  3.78s/it, loss=2.77, epoch=0.469, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1981/4220 [2:05:56<2:20:59,  3.78s/it, loss=2.59, epoch=0.469, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1982/4220 [2:06:00<2:20:58,  3.78s/it, loss=2.59, epoch=0.469, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1982/4220 [2:06:00<2:20:58,  3.78s/it, loss=2.89, epoch=0.469, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1983/4220 [2:06:04<2:20:56,  3.78s/it, loss=2.89, epoch=0.469, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1983/4220 [2:06:04<2:20:56,  3.78s/it, loss=2.95, epoch=0.47, learning_rate=1.1e-5] \u001b[A\n",
      " 47%|████▋     | 1984/4220 [2:06:07<2:20:47,  3.78s/it, loss=2.95, epoch=0.47, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1984/4220 [2:06:07<2:20:47,  3.78s/it, loss=2.83, epoch=0.47, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1985/4220 [2:06:11<2:20:44,  3.78s/it, loss=2.83, epoch=0.47, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1985/4220 [2:06:11<2:20:44,  3.78s/it, loss=2.65, epoch=0.47, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1986/4220 [2:06:15<2:20:43,  3.78s/it, loss=2.65, epoch=0.47, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1986/4220 [2:06:15<2:20:43,  3.78s/it, loss=2.97, epoch=0.47, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1987/4220 [2:06:19<2:20:41,  3.78s/it, loss=2.97, epoch=0.47, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1987/4220 [2:06:19<2:20:41,  3.78s/it, loss=2.23, epoch=0.471, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1988/4220 [2:06:22<2:20:33,  3.78s/it, loss=2.23, epoch=0.471, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1988/4220 [2:06:22<2:20:33,  3.78s/it, loss=3.11, epoch=0.471, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1989/4220 [2:06:26<2:20:31,  3.78s/it, loss=3.11, epoch=0.471, learning_rate=1.1e-5]\u001b[A\n",
      " 47%|████▋     | 1989/4220 [2:06:26<2:20:31,  3.78s/it, loss=2.74, epoch=0.471, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1990/4220 [2:06:30<2:20:25,  3.78s/it, loss=2.74, epoch=0.471, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1990/4220 [2:06:30<2:20:25,  3.78s/it, loss=2.7, epoch=0.471, learning_rate=1.09e-5] \u001b[A\n",
      " 47%|████▋     | 1991/4220 [2:06:34<2:20:20,  3.78s/it, loss=2.7, epoch=0.471, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1991/4220 [2:06:34<2:20:20,  3.78s/it, loss=2.9, epoch=0.472, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1992/4220 [2:06:38<2:20:20,  3.78s/it, loss=2.9, epoch=0.472, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1992/4220 [2:06:38<2:20:20,  3.78s/it, loss=2.82, epoch=0.472, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1993/4220 [2:06:41<2:20:15,  3.78s/it, loss=2.82, epoch=0.472, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1993/4220 [2:06:41<2:20:15,  3.78s/it, loss=2.91, epoch=0.472, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1994/4220 [2:06:45<2:20:11,  3.78s/it, loss=2.91, epoch=0.472, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1994/4220 [2:06:45<2:20:11,  3.78s/it, loss=2.7, epoch=0.472, learning_rate=1.09e-5] \u001b[A\n",
      " 47%|████▋     | 1995/4220 [2:06:49<2:20:08,  3.78s/it, loss=2.7, epoch=0.472, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1995/4220 [2:06:49<2:20:08,  3.78s/it, loss=2.56, epoch=0.473, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1996/4220 [2:06:53<2:20:04,  3.78s/it, loss=2.56, epoch=0.473, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1996/4220 [2:06:53<2:20:04,  3.78s/it, loss=2.5, epoch=0.473, learning_rate=1.09e-5] \u001b[A\n",
      " 47%|████▋     | 1997/4220 [2:06:56<2:20:00,  3.78s/it, loss=2.5, epoch=0.473, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1997/4220 [2:06:56<2:20:00,  3.78s/it, loss=3.32, epoch=0.473, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1998/4220 [2:07:00<2:19:55,  3.78s/it, loss=3.32, epoch=0.473, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1998/4220 [2:07:00<2:19:55,  3.78s/it, loss=2.6, epoch=0.473, learning_rate=1.09e-5] \u001b[A\n",
      " 47%|████▋     | 1999/4220 [2:07:04<2:19:53,  3.78s/it, loss=2.6, epoch=0.473, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 1999/4220 [2:07:04<2:19:53,  3.78s/it, loss=2.35, epoch=0.473, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 2000/4220 [2:07:08<2:19:46,  3.78s/it, loss=2.35, epoch=0.473, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 2000/4220 [2:07:08<2:19:46,  3.78s/it, loss=2.56, epoch=0.474, learning_rate=1.09e-5]\u001b[ARemoved shared tensor {'model.unembed.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "\n",
      " 47%|████▋     | 2001/4220 [2:08:16<14:16:06, 23.15s/it, loss=2.56, epoch=0.474, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 2001/4220 [2:08:16<14:16:06, 23.15s/it, loss=2.54, epoch=0.474, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 2002/4220 [2:08:20<10:40:34, 17.33s/it, loss=2.54, epoch=0.474, learning_rate=1.09e-5]\u001b[A\n",
      " 47%|████▋     | 2002/4220 [2:08:20<10:40:34, 17.33s/it, loss=3.01, epoch=0.474, learning_rate=1.08e-5]\u001b[A\n",
      " 47%|████▋     | 2003/4220 [2:08:24<8:09:39, 13.25s/it, loss=3.01, epoch=0.474, learning_rate=1.08e-5] \u001b[A\n",
      " 47%|████▋     | 2003/4220 [2:08:24<8:09:39, 13.25s/it, loss=3.24, epoch=0.474, learning_rate=1.08e-5]\u001b[A\n",
      " 47%|████▋     | 2004/4220 [2:08:27<6:24:01, 10.40s/it, loss=3.24, epoch=0.474, learning_rate=1.08e-5]\u001b[A\n",
      " 47%|████▋     | 2004/4220 [2:08:27<6:24:01, 10.40s/it, loss=2.7, epoch=0.475, learning_rate=1.08e-5] \u001b[A\n",
      " 48%|████▊     | 2005/4220 [2:08:31<5:10:09,  8.40s/it, loss=2.7, epoch=0.475, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2005/4220 [2:08:31<5:10:09,  8.40s/it, loss=2.44, epoch=0.475, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2006/4220 [2:08:35<4:18:36,  7.01s/it, loss=2.44, epoch=0.475, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2006/4220 [2:08:35<4:18:36,  7.01s/it, loss=2.83, epoch=0.475, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2007/4220 [2:08:39<3:42:27,  6.03s/it, loss=2.83, epoch=0.475, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2007/4220 [2:08:39<3:42:27,  6.03s/it, loss=2.64, epoch=0.475, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2008/4220 [2:08:42<3:17:14,  5.35s/it, loss=2.64, epoch=0.475, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2008/4220 [2:08:42<3:17:14,  5.35s/it, loss=2.74, epoch=0.476, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2009/4220 [2:08:46<2:59:35,  4.87s/it, loss=2.74, epoch=0.476, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2009/4220 [2:08:46<2:59:35,  4.87s/it, loss=2.91, epoch=0.476, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2010/4220 [2:08:50<2:47:15,  4.54s/it, loss=2.91, epoch=0.476, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2010/4220 [2:08:50<2:47:15,  4.54s/it, loss=2.7, epoch=0.476, learning_rate=1.08e-5] \u001b[A\n",
      " 48%|████▊     | 2011/4220 [2:08:54<2:38:35,  4.31s/it, loss=2.7, epoch=0.476, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2011/4220 [2:08:54<2:38:35,  4.31s/it, loss=2.82, epoch=0.476, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2012/4220 [2:08:57<2:32:30,  4.14s/it, loss=2.82, epoch=0.476, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2012/4220 [2:08:57<2:32:30,  4.14s/it, loss=2.74, epoch=0.477, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2013/4220 [2:09:01<2:28:15,  4.03s/it, loss=2.74, epoch=0.477, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2013/4220 [2:09:01<2:28:15,  4.03s/it, loss=2.68, epoch=0.477, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2014/4220 [2:09:05<2:25:19,  3.95s/it, loss=2.68, epoch=0.477, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2014/4220 [2:09:05<2:25:19,  3.95s/it, loss=2.76, epoch=0.477, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2015/4220 [2:09:09<2:23:19,  3.90s/it, loss=2.76, epoch=0.477, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2015/4220 [2:09:09<2:23:19,  3.90s/it, loss=2.5, epoch=0.477, learning_rate=1.08e-5] \u001b[A\n",
      " 48%|████▊     | 2016/4220 [2:09:12<2:21:49,  3.86s/it, loss=2.5, epoch=0.477, learning_rate=1.08e-5]\u001b[A\n",
      " 48%|████▊     | 2016/4220 [2:09:12<2:21:49,  3.86s/it, loss=2.67, epoch=0.477, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2017/4220 [2:09:16<2:20:49,  3.84s/it, loss=2.67, epoch=0.477, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2017/4220 [2:09:16<2:20:49,  3.84s/it, loss=2.62, epoch=0.478, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2018/4220 [2:09:20<2:20:01,  3.82s/it, loss=2.62, epoch=0.478, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2018/4220 [2:09:20<2:20:01,  3.82s/it, loss=2.64, epoch=0.478, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2019/4220 [2:09:24<2:19:25,  3.80s/it, loss=2.64, epoch=0.478, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2019/4220 [2:09:24<2:19:25,  3.80s/it, loss=2.7, epoch=0.478, learning_rate=1.07e-5] \u001b[A\n",
      " 48%|████▊     | 2020/4220 [2:09:28<2:19:07,  3.79s/it, loss=2.7, epoch=0.478, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2020/4220 [2:09:28<2:19:07,  3.79s/it, loss=2.76, epoch=0.478, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2021/4220 [2:09:31<2:18:51,  3.79s/it, loss=2.76, epoch=0.478, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2021/4220 [2:09:31<2:18:51,  3.79s/it, loss=2.86, epoch=0.479, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2022/4220 [2:09:35<2:18:37,  3.78s/it, loss=2.86, epoch=0.479, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2022/4220 [2:09:35<2:18:37,  3.78s/it, loss=2.95, epoch=0.479, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2023/4220 [2:09:39<2:18:28,  3.78s/it, loss=2.95, epoch=0.479, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2023/4220 [2:09:39<2:18:28,  3.78s/it, loss=2.86, epoch=0.479, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2024/4220 [2:09:43<2:18:21,  3.78s/it, loss=2.86, epoch=0.479, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2024/4220 [2:09:43<2:18:21,  3.78s/it, loss=3.25, epoch=0.479, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2025/4220 [2:09:46<2:18:13,  3.78s/it, loss=3.25, epoch=0.479, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2025/4220 [2:09:46<2:18:13,  3.78s/it, loss=3.11, epoch=0.48, learning_rate=1.07e-5] \u001b[A\n",
      " 48%|████▊     | 2026/4220 [2:09:50<2:18:11,  3.78s/it, loss=3.11, epoch=0.48, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2026/4220 [2:09:50<2:18:11,  3.78s/it, loss=2.78, epoch=0.48, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2027/4220 [2:09:54<2:18:04,  3.78s/it, loss=2.78, epoch=0.48, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2027/4220 [2:09:54<2:18:04,  3.78s/it, loss=2.77, epoch=0.48, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2028/4220 [2:09:58<2:17:58,  3.78s/it, loss=2.77, epoch=0.48, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2028/4220 [2:09:58<2:17:58,  3.78s/it, loss=2.52, epoch=0.48, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2029/4220 [2:10:02<2:17:56,  3.78s/it, loss=2.52, epoch=0.48, learning_rate=1.07e-5]\u001b[A\n",
      " 48%|████▊     | 2029/4220 [2:10:02<2:17:56,  3.78s/it, loss=3.23, epoch=0.481, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2030/4220 [2:10:05<2:17:51,  3.78s/it, loss=3.23, epoch=0.481, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2030/4220 [2:10:05<2:17:51,  3.78s/it, loss=2.38, epoch=0.481, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2031/4220 [2:10:09<2:17:50,  3.78s/it, loss=2.38, epoch=0.481, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2031/4220 [2:10:09<2:17:50,  3.78s/it, loss=2.84, epoch=0.481, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2032/4220 [2:10:13<2:17:45,  3.78s/it, loss=2.84, epoch=0.481, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2032/4220 [2:10:13<2:17:45,  3.78s/it, loss=2.41, epoch=0.481, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2033/4220 [2:10:17<2:17:40,  3.78s/it, loss=2.41, epoch=0.481, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2033/4220 [2:10:17<2:17:40,  3.78s/it, loss=3.32, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2034/4220 [2:10:20<2:17:36,  3.78s/it, loss=3.32, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2034/4220 [2:10:20<2:17:36,  3.78s/it, loss=3.01, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2035/4220 [2:10:24<2:17:31,  3.78s/it, loss=3.01, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2035/4220 [2:10:24<2:17:31,  3.78s/it, loss=2.65, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2036/4220 [2:10:28<2:17:29,  3.78s/it, loss=2.65, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2036/4220 [2:10:28<2:17:29,  3.78s/it, loss=3.33, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2037/4220 [2:10:32<2:17:26,  3.78s/it, loss=3.33, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2037/4220 [2:10:32<2:17:26,  3.78s/it, loss=2.84, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2038/4220 [2:10:36<2:17:24,  3.78s/it, loss=2.84, epoch=0.482, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2038/4220 [2:10:36<2:17:24,  3.78s/it, loss=2.97, epoch=0.483, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2039/4220 [2:10:39<2:17:22,  3.78s/it, loss=2.97, epoch=0.483, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2039/4220 [2:10:39<2:17:22,  3.78s/it, loss=2.43, epoch=0.483, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2040/4220 [2:10:43<2:17:21,  3.78s/it, loss=2.43, epoch=0.483, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2040/4220 [2:10:43<2:17:21,  3.78s/it, loss=2.57, epoch=0.483, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2041/4220 [2:10:47<2:17:13,  3.78s/it, loss=2.57, epoch=0.483, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2041/4220 [2:10:47<2:17:13,  3.78s/it, loss=3.31, epoch=0.483, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2042/4220 [2:10:51<2:17:11,  3.78s/it, loss=3.31, epoch=0.483, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2042/4220 [2:10:51<2:17:11,  3.78s/it, loss=2.8, epoch=0.484, learning_rate=1.06e-5] \u001b[A\n",
      " 48%|████▊     | 2043/4220 [2:10:54<2:17:08,  3.78s/it, loss=2.8, epoch=0.484, learning_rate=1.06e-5]\u001b[A\n",
      " 48%|████▊     | 2043/4220 [2:10:54<2:17:08,  3.78s/it, loss=2.65, epoch=0.484, learning_rate=1.05e-5]\u001b[A\n",
      " 48%|████▊     | 2044/4220 [2:10:58<2:17:02,  3.78s/it, loss=2.65, epoch=0.484, learning_rate=1.05e-5]\u001b[A\n",
      " 48%|████▊     | 2044/4220 [2:10:58<2:17:02,  3.78s/it, loss=2.48, epoch=0.484, learning_rate=1.05e-5]\u001b[A\n",
      " 48%|████▊     | 2045/4220 [2:11:02<2:16:55,  3.78s/it, loss=2.48, epoch=0.484, learning_rate=1.05e-5]\u001b[A\n",
      " 48%|████▊     | 2045/4220 [2:11:02<2:16:55,  3.78s/it, loss=2.53, epoch=0.484, learning_rate=1.05e-5]\u001b[A\n",
      " 48%|████▊     | 2046/4220 [2:11:06<2:16:53,  3.78s/it, loss=2.53, epoch=0.484, learning_rate=1.05e-5]\u001b[A\n",
      " 48%|████▊     | 2046/4220 [2:11:06<2:16:53,  3.78s/it, loss=2.59, epoch=0.485, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2047/4220 [2:11:10<2:16:52,  3.78s/it, loss=2.59, epoch=0.485, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2047/4220 [2:11:10<2:16:52,  3.78s/it, loss=3.04, epoch=0.485, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2048/4220 [2:11:13<2:16:46,  3.78s/it, loss=3.04, epoch=0.485, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2048/4220 [2:11:13<2:16:46,  3.78s/it, loss=2.74, epoch=0.485, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2049/4220 [2:11:17<2:16:38,  3.78s/it, loss=2.74, epoch=0.485, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2049/4220 [2:11:17<2:16:38,  3.78s/it, loss=2.38, epoch=0.485, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2050/4220 [2:11:21<2:16:33,  3.78s/it, loss=2.38, epoch=0.485, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2050/4220 [2:11:21<2:16:33,  3.78s/it, loss=2.35, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2051/4220 [2:11:25<2:16:31,  3.78s/it, loss=2.35, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2051/4220 [2:11:25<2:16:31,  3.78s/it, loss=2.59, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2052/4220 [2:11:28<2:16:26,  3.78s/it, loss=2.59, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2052/4220 [2:11:28<2:16:26,  3.78s/it, loss=3.01, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2053/4220 [2:11:32<2:16:24,  3.78s/it, loss=3.01, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2053/4220 [2:11:32<2:16:24,  3.78s/it, loss=3.18, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2054/4220 [2:11:36<2:16:22,  3.78s/it, loss=3.18, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2054/4220 [2:11:36<2:16:22,  3.78s/it, loss=2.96, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2055/4220 [2:11:40<2:16:15,  3.78s/it, loss=2.96, epoch=0.486, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2055/4220 [2:11:40<2:16:15,  3.78s/it, loss=2.35, epoch=0.487, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2056/4220 [2:11:44<2:16:16,  3.78s/it, loss=2.35, epoch=0.487, learning_rate=1.05e-5]\u001b[A\n",
      " 49%|████▊     | 2056/4220 [2:11:44<2:16:16,  3.78s/it, loss=2.84, epoch=0.487, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▊     | 2057/4220 [2:11:47<2:16:12,  3.78s/it, loss=2.84, epoch=0.487, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▊     | 2057/4220 [2:11:47<2:16:12,  3.78s/it, loss=3.31, epoch=0.487, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2058/4220 [2:11:51<2:16:06,  3.78s/it, loss=3.31, epoch=0.487, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2058/4220 [2:11:51<2:16:06,  3.78s/it, loss=2.69, epoch=0.487, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2059/4220 [2:11:55<2:16:00,  3.78s/it, loss=2.69, epoch=0.487, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2059/4220 [2:11:55<2:16:00,  3.78s/it, loss=3, epoch=0.488, learning_rate=1.04e-5]   \u001b[A\n",
      " 49%|████▉     | 2060/4220 [2:11:59<2:16:01,  3.78s/it, loss=3, epoch=0.488, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2060/4220 [2:11:59<2:16:01,  3.78s/it, loss=3.39, epoch=0.488, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2061/4220 [2:12:02<2:15:56,  3.78s/it, loss=3.39, epoch=0.488, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2061/4220 [2:12:02<2:15:56,  3.78s/it, loss=2.5, epoch=0.488, learning_rate=1.04e-5] \u001b[A\n",
      " 49%|████▉     | 2062/4220 [2:12:06<2:15:52,  3.78s/it, loss=2.5, epoch=0.488, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2062/4220 [2:12:06<2:15:52,  3.78s/it, loss=3.35, epoch=0.488, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2063/4220 [2:12:10<2:15:50,  3.78s/it, loss=3.35, epoch=0.488, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2063/4220 [2:12:10<2:15:50,  3.78s/it, loss=3.21, epoch=0.489, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2064/4220 [2:12:14<2:15:46,  3.78s/it, loss=3.21, epoch=0.489, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2064/4220 [2:12:14<2:15:46,  3.78s/it, loss=2.51, epoch=0.489, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2065/4220 [2:12:18<2:15:40,  3.78s/it, loss=2.51, epoch=0.489, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2065/4220 [2:12:18<2:15:40,  3.78s/it, loss=2.74, epoch=0.489, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2066/4220 [2:12:21<2:15:39,  3.78s/it, loss=2.74, epoch=0.489, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2066/4220 [2:12:21<2:15:39,  3.78s/it, loss=2.63, epoch=0.489, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2067/4220 [2:12:25<2:15:33,  3.78s/it, loss=2.63, epoch=0.489, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2067/4220 [2:12:25<2:15:33,  3.78s/it, loss=2.6, epoch=0.49, learning_rate=1.04e-5]  \u001b[A\n",
      " 49%|████▉     | 2068/4220 [2:12:29<2:15:30,  3.78s/it, loss=2.6, epoch=0.49, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2068/4220 [2:12:29<2:15:30,  3.78s/it, loss=2.4, epoch=0.49, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2069/4220 [2:12:33<2:15:26,  3.78s/it, loss=2.4, epoch=0.49, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2069/4220 [2:12:33<2:15:26,  3.78s/it, loss=2.67, epoch=0.49, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2070/4220 [2:12:36<2:15:25,  3.78s/it, loss=2.67, epoch=0.49, learning_rate=1.04e-5]\u001b[A\n",
      " 49%|████▉     | 2070/4220 [2:12:36<2:15:25,  3.78s/it, loss=2.69, epoch=0.49, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2071/4220 [2:12:40<2:15:22,  3.78s/it, loss=2.69, epoch=0.49, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2071/4220 [2:12:40<2:15:22,  3.78s/it, loss=2.91, epoch=0.491, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2072/4220 [2:12:44<2:15:16,  3.78s/it, loss=2.91, epoch=0.491, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2072/4220 [2:12:44<2:15:16,  3.78s/it, loss=2.99, epoch=0.491, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2073/4220 [2:12:48<2:15:13,  3.78s/it, loss=2.99, epoch=0.491, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2073/4220 [2:12:48<2:15:13,  3.78s/it, loss=3.06, epoch=0.491, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2074/4220 [2:12:52<2:15:11,  3.78s/it, loss=3.06, epoch=0.491, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2074/4220 [2:12:52<2:15:11,  3.78s/it, loss=3, epoch=0.491, learning_rate=1.03e-5]   \u001b[A\n",
      " 49%|████▉     | 2075/4220 [2:12:55<2:15:06,  3.78s/it, loss=3, epoch=0.491, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2075/4220 [2:12:55<2:15:06,  3.78s/it, loss=2.66, epoch=0.491, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2076/4220 [2:12:59<2:15:03,  3.78s/it, loss=2.66, epoch=0.491, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2076/4220 [2:12:59<2:15:03,  3.78s/it, loss=2.73, epoch=0.492, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2077/4220 [2:13:03<2:15:00,  3.78s/it, loss=2.73, epoch=0.492, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2077/4220 [2:13:03<2:15:00,  3.78s/it, loss=2.67, epoch=0.492, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2078/4220 [2:13:07<2:14:55,  3.78s/it, loss=2.67, epoch=0.492, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2078/4220 [2:13:07<2:14:55,  3.78s/it, loss=3.12, epoch=0.492, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2079/4220 [2:13:10<2:14:51,  3.78s/it, loss=3.12, epoch=0.492, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2079/4220 [2:13:10<2:14:51,  3.78s/it, loss=2.68, epoch=0.492, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2080/4220 [2:13:14<2:14:46,  3.78s/it, loss=2.68, epoch=0.492, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2080/4220 [2:13:14<2:14:46,  3.78s/it, loss=2.56, epoch=0.493, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2081/4220 [2:13:18<2:14:45,  3.78s/it, loss=2.56, epoch=0.493, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2081/4220 [2:13:18<2:14:45,  3.78s/it, loss=2.47, epoch=0.493, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2082/4220 [2:13:22<2:14:41,  3.78s/it, loss=2.47, epoch=0.493, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2082/4220 [2:13:22<2:14:41,  3.78s/it, loss=2.7, epoch=0.493, learning_rate=1.03e-5] \u001b[A\n",
      " 49%|████▉     | 2083/4220 [2:13:26<2:14:33,  3.78s/it, loss=2.7, epoch=0.493, learning_rate=1.03e-5]\u001b[A\n",
      " 49%|████▉     | 2083/4220 [2:13:26<2:14:33,  3.78s/it, loss=2.83, epoch=0.493, learning_rate=1.02e-5]\u001b[A\n",
      " 49%|████▉     | 2084/4220 [2:13:29<2:14:31,  3.78s/it, loss=2.83, epoch=0.493, learning_rate=1.02e-5]\u001b[A\n",
      " 49%|████▉     | 2084/4220 [2:13:29<2:14:31,  3.78s/it, loss=2.62, epoch=0.494, learning_rate=1.02e-5]\u001b[A\n",
      " 49%|████▉     | 2085/4220 [2:13:33<2:14:27,  3.78s/it, loss=2.62, epoch=0.494, learning_rate=1.02e-5]\u001b[A\n",
      " 49%|████▉     | 2085/4220 [2:13:33<2:14:27,  3.78s/it, loss=3.54, epoch=0.494, learning_rate=1.02e-5]\u001b[A\n",
      " 49%|████▉     | 2086/4220 [2:13:37<2:14:28,  3.78s/it, loss=3.54, epoch=0.494, learning_rate=1.02e-5]\u001b[A\n",
      " 49%|████▉     | 2086/4220 [2:13:37<2:14:28,  3.78s/it, loss=2.7, epoch=0.494, learning_rate=1.02e-5] \u001b[A\n",
      " 49%|████▉     | 2087/4220 [2:13:41<2:14:22,  3.78s/it, loss=2.7, epoch=0.494, learning_rate=1.02e-5]\u001b[A\n",
      " 49%|████▉     | 2087/4220 [2:13:41<2:14:22,  3.78s/it, loss=3.38, epoch=0.494, learning_rate=1.02e-5]\u001b[A\n",
      " 49%|████▉     | 2088/4220 [2:13:44<2:14:17,  3.78s/it, loss=3.38, epoch=0.494, learning_rate=1.02e-5]\u001b[A\n",
      " 49%|████▉     | 2088/4220 [2:13:44<2:14:17,  3.78s/it, loss=2.65, epoch=0.495, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2089/4220 [2:13:48<2:14:14,  3.78s/it, loss=2.65, epoch=0.495, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2089/4220 [2:13:48<2:14:14,  3.78s/it, loss=2.8, epoch=0.495, learning_rate=1.02e-5] \u001b[A\n",
      " 50%|████▉     | 2090/4220 [2:13:52<2:14:13,  3.78s/it, loss=2.8, epoch=0.495, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2090/4220 [2:13:52<2:14:13,  3.78s/it, loss=3.02, epoch=0.495, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2091/4220 [2:13:56<2:14:10,  3.78s/it, loss=3.02, epoch=0.495, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2091/4220 [2:13:56<2:14:10,  3.78s/it, loss=3.21, epoch=0.495, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2092/4220 [2:14:00<2:14:08,  3.78s/it, loss=3.21, epoch=0.495, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2092/4220 [2:14:00<2:14:08,  3.78s/it, loss=2.79, epoch=0.495, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2093/4220 [2:14:03<2:14:04,  3.78s/it, loss=2.79, epoch=0.495, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2093/4220 [2:14:03<2:14:04,  3.78s/it, loss=2.99, epoch=0.496, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2094/4220 [2:14:07<2:13:55,  3.78s/it, loss=2.99, epoch=0.496, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2094/4220 [2:14:07<2:13:55,  3.78s/it, loss=2.87, epoch=0.496, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2095/4220 [2:14:11<2:13:49,  3.78s/it, loss=2.87, epoch=0.496, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2095/4220 [2:14:11<2:13:49,  3.78s/it, loss=3.36, epoch=0.496, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2096/4220 [2:14:15<2:13:43,  3.78s/it, loss=3.36, epoch=0.496, learning_rate=1.02e-5]\u001b[A\n",
      " 50%|████▉     | 2096/4220 [2:14:15<2:13:43,  3.78s/it, loss=2.81, epoch=0.496, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2097/4220 [2:14:18<2:13:46,  3.78s/it, loss=2.81, epoch=0.496, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2097/4220 [2:14:18<2:13:46,  3.78s/it, loss=3.24, epoch=0.497, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2098/4220 [2:14:22<2:13:40,  3.78s/it, loss=3.24, epoch=0.497, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2098/4220 [2:14:22<2:13:40,  3.78s/it, loss=2.14, epoch=0.497, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2099/4220 [2:14:26<2:13:37,  3.78s/it, loss=2.14, epoch=0.497, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2099/4220 [2:14:26<2:13:37,  3.78s/it, loss=2.91, epoch=0.497, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2100/4220 [2:14:30<2:13:34,  3.78s/it, loss=2.91, epoch=0.497, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2100/4220 [2:14:30<2:13:34,  3.78s/it, loss=2.58, epoch=0.497, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2101/4220 [2:14:34<2:13:30,  3.78s/it, loss=2.58, epoch=0.497, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2101/4220 [2:14:34<2:13:30,  3.78s/it, loss=2.44, epoch=0.498, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2102/4220 [2:14:37<2:13:21,  3.78s/it, loss=2.44, epoch=0.498, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2102/4220 [2:14:37<2:13:21,  3.78s/it, loss=2.75, epoch=0.498, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2103/4220 [2:14:41<2:13:22,  3.78s/it, loss=2.75, epoch=0.498, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2103/4220 [2:14:41<2:13:22,  3.78s/it, loss=2.63, epoch=0.498, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2104/4220 [2:14:45<2:13:19,  3.78s/it, loss=2.63, epoch=0.498, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2104/4220 [2:14:45<2:13:19,  3.78s/it, loss=2.76, epoch=0.498, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2105/4220 [2:14:49<2:13:16,  3.78s/it, loss=2.76, epoch=0.498, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2105/4220 [2:14:49<2:13:16,  3.78s/it, loss=3, epoch=0.499, learning_rate=1.01e-5]   \u001b[A\n",
      " 50%|████▉     | 2106/4220 [2:14:53<2:13:12,  3.78s/it, loss=3, epoch=0.499, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2106/4220 [2:14:53<2:13:12,  3.78s/it, loss=3.51, epoch=0.499, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2107/4220 [2:14:56<2:13:10,  3.78s/it, loss=3.51, epoch=0.499, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2107/4220 [2:14:56<2:13:10,  3.78s/it, loss=2.67, epoch=0.499, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2108/4220 [2:15:00<2:13:07,  3.78s/it, loss=2.67, epoch=0.499, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2108/4220 [2:15:00<2:13:07,  3.78s/it, loss=3.06, epoch=0.499, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2109/4220 [2:15:04<2:13:02,  3.78s/it, loss=3.06, epoch=0.499, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|████▉     | 2109/4220 [2:15:04<2:13:02,  3.78s/it, loss=3.22, epoch=0.5, learning_rate=1.01e-5]  \u001b[A\n",
      " 50%|█████     | 2110/4220 [2:15:08<2:12:52,  3.78s/it, loss=3.22, epoch=0.5, learning_rate=1.01e-5]\u001b[A\n",
      " 50%|█████     | 2110/4220 [2:15:08<2:12:52,  3.78s/it, loss=2.97, epoch=0.5, learning_rate=1e-5]   \u001b[A\n",
      " 50%|█████     | 2111/4220 [2:15:11<2:12:48,  3.78s/it, loss=2.97, epoch=0.5, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2111/4220 [2:15:11<2:12:48,  3.78s/it, loss=2.83, epoch=0.5, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2112/4220 [2:15:15<2:12:43,  3.78s/it, loss=2.83, epoch=0.5, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2112/4220 [2:15:15<2:12:43,  3.78s/it, loss=3.38, epoch=0.5, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2113/4220 [2:15:19<2:12:41,  3.78s/it, loss=3.38, epoch=0.5, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2113/4220 [2:15:19<2:12:41,  3.78s/it, loss=2.62, epoch=0.5, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2114/4220 [2:15:23<2:12:43,  3.78s/it, loss=2.62, epoch=0.5, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2114/4220 [2:15:23<2:12:43,  3.78s/it, loss=2.51, epoch=0.501, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2115/4220 [2:15:27<2:12:39,  3.78s/it, loss=2.51, epoch=0.501, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2115/4220 [2:15:27<2:12:39,  3.78s/it, loss=2.55, epoch=0.501, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2116/4220 [2:15:30<2:12:35,  3.78s/it, loss=2.55, epoch=0.501, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2116/4220 [2:15:30<2:12:35,  3.78s/it, loss=3.1, epoch=0.501, learning_rate=1e-5] \u001b[A\n",
      " 50%|█████     | 2117/4220 [2:15:34<2:12:33,  3.78s/it, loss=3.1, epoch=0.501, learning_rate=1e-5]\u001b[A\n",
      " 50%|█████     | 2117/4220 [2:15:34<2:12:33,  3.78s/it, loss=2.95, epoch=0.501, learning_rate=9.99e-6]\u001b[A\n",
      " 50%|█████     | 2118/4220 [2:15:38<2:12:31,  3.78s/it, loss=2.95, epoch=0.501, learning_rate=9.99e-6]\u001b[A\n",
      " 50%|█████     | 2118/4220 [2:15:38<2:12:31,  3.78s/it, loss=2.83, epoch=0.502, learning_rate=9.99e-6]\u001b[A\n",
      " 50%|█████     | 2119/4220 [2:15:42<2:12:27,  3.78s/it, loss=2.83, epoch=0.502, learning_rate=9.99e-6]\u001b[A\n",
      " 50%|█████     | 2119/4220 [2:15:42<2:12:27,  3.78s/it, loss=3.4, epoch=0.502, learning_rate=9.98e-6] \u001b[A\n",
      " 50%|█████     | 2120/4220 [2:15:45<2:12:23,  3.78s/it, loss=3.4, epoch=0.502, learning_rate=9.98e-6]\u001b[A\n",
      " 50%|█████     | 2120/4220 [2:15:45<2:12:23,  3.78s/it, loss=2.59, epoch=0.502, learning_rate=9.97e-6]\u001b[A\n",
      " 50%|█████     | 2121/4220 [2:15:49<2:12:19,  3.78s/it, loss=2.59, epoch=0.502, learning_rate=9.97e-6]\u001b[A\n",
      " 50%|█████     | 2121/4220 [2:15:49<2:12:19,  3.78s/it, loss=3.1, epoch=0.502, learning_rate=9.96e-6] \u001b[A\n",
      " 50%|█████     | 2122/4220 [2:15:53<2:12:15,  3.78s/it, loss=3.1, epoch=0.502, learning_rate=9.96e-6]\u001b[A\n",
      " 50%|█████     | 2122/4220 [2:15:53<2:12:15,  3.78s/it, loss=3.05, epoch=0.503, learning_rate=9.96e-6]\u001b[A\n",
      " 50%|█████     | 2123/4220 [2:15:57<2:12:08,  3.78s/it, loss=3.05, epoch=0.503, learning_rate=9.96e-6]\u001b[A\n",
      " 50%|█████     | 2123/4220 [2:15:57<2:12:08,  3.78s/it, loss=3.06, epoch=0.503, learning_rate=9.95e-6]\u001b[A\n",
      " 50%|█████     | 2124/4220 [2:16:01<2:12:05,  3.78s/it, loss=3.06, epoch=0.503, learning_rate=9.95e-6]\u001b[A\n",
      " 50%|█████     | 2124/4220 [2:16:01<2:12:05,  3.78s/it, loss=2.85, epoch=0.503, learning_rate=9.94e-6]\u001b[A\n",
      " 50%|█████     | 2125/4220 [2:16:04<2:11:58,  3.78s/it, loss=2.85, epoch=0.503, learning_rate=9.94e-6]\u001b[A\n",
      " 50%|█████     | 2125/4220 [2:16:04<2:11:58,  3.78s/it, loss=2.6, epoch=0.503, learning_rate=9.93e-6] \u001b[A\n",
      " 50%|█████     | 2126/4220 [2:16:08<2:11:54,  3.78s/it, loss=2.6, epoch=0.503, learning_rate=9.93e-6]\u001b[A\n",
      " 50%|█████     | 2126/4220 [2:16:08<2:11:54,  3.78s/it, loss=2.93, epoch=0.504, learning_rate=9.93e-6]\u001b[A\n",
      " 50%|█████     | 2127/4220 [2:16:12<2:11:49,  3.78s/it, loss=2.93, epoch=0.504, learning_rate=9.93e-6]\u001b[A\n",
      " 50%|█████     | 2127/4220 [2:16:12<2:11:49,  3.78s/it, loss=2.43, epoch=0.504, learning_rate=9.92e-6]\u001b[A\n",
      " 50%|█████     | 2128/4220 [2:16:16<2:11:47,  3.78s/it, loss=2.43, epoch=0.504, learning_rate=9.92e-6]\u001b[A\n",
      " 50%|█████     | 2128/4220 [2:16:16<2:11:47,  3.78s/it, loss=2.8, epoch=0.504, learning_rate=9.91e-6] \u001b[A\n",
      " 50%|█████     | 2129/4220 [2:16:19<2:11:47,  3.78s/it, loss=2.8, epoch=0.504, learning_rate=9.91e-6]\u001b[A\n",
      " 50%|█████     | 2129/4220 [2:16:19<2:11:47,  3.78s/it, loss=2.89, epoch=0.504, learning_rate=9.9e-6]\u001b[A\n",
      " 50%|█████     | 2130/4220 [2:16:23<2:11:45,  3.78s/it, loss=2.89, epoch=0.504, learning_rate=9.9e-6]\u001b[A\n",
      " 50%|█████     | 2130/4220 [2:16:23<2:11:45,  3.78s/it, loss=3.16, epoch=0.505, learning_rate=9.9e-6]\u001b[A\n",
      " 50%|█████     | 2131/4220 [2:16:27<2:11:40,  3.78s/it, loss=3.16, epoch=0.505, learning_rate=9.9e-6]\u001b[A\n",
      " 50%|█████     | 2131/4220 [2:16:27<2:11:40,  3.78s/it, loss=2.97, epoch=0.505, learning_rate=9.89e-6]\u001b[A\n",
      " 51%|█████     | 2132/4220 [2:16:31<2:11:33,  3.78s/it, loss=2.97, epoch=0.505, learning_rate=9.89e-6]\u001b[A\n",
      " 51%|█████     | 2132/4220 [2:16:31<2:11:33,  3.78s/it, loss=2.96, epoch=0.505, learning_rate=9.88e-6]\u001b[A\n",
      " 51%|█████     | 2133/4220 [2:16:35<2:11:29,  3.78s/it, loss=2.96, epoch=0.505, learning_rate=9.88e-6]\u001b[A\n",
      " 51%|█████     | 2133/4220 [2:16:35<2:11:29,  3.78s/it, loss=2.75, epoch=0.505, learning_rate=9.87e-6]\u001b[A\n",
      " 51%|█████     | 2134/4220 [2:16:38<2:11:25,  3.78s/it, loss=2.75, epoch=0.505, learning_rate=9.87e-6]\u001b[A\n",
      " 51%|█████     | 2134/4220 [2:16:38<2:11:25,  3.78s/it, loss=3.05, epoch=0.505, learning_rate=9.87e-6]\u001b[A\n",
      " 51%|█████     | 2135/4220 [2:16:42<2:11:21,  3.78s/it, loss=3.05, epoch=0.505, learning_rate=9.87e-6]\u001b[A\n",
      " 51%|█████     | 2135/4220 [2:16:42<2:11:21,  3.78s/it, loss=2.91, epoch=0.506, learning_rate=9.86e-6]\u001b[A\n",
      " 51%|█████     | 2136/4220 [2:16:46<2:11:18,  3.78s/it, loss=2.91, epoch=0.506, learning_rate=9.86e-6]\u001b[A\n",
      " 51%|█████     | 2136/4220 [2:16:46<2:11:18,  3.78s/it, loss=2.95, epoch=0.506, learning_rate=9.85e-6]\u001b[A\n",
      " 51%|█████     | 2137/4220 [2:16:50<2:11:14,  3.78s/it, loss=2.95, epoch=0.506, learning_rate=9.85e-6]\u001b[A\n",
      " 51%|█████     | 2137/4220 [2:16:50<2:11:14,  3.78s/it, loss=2.5, epoch=0.506, learning_rate=9.84e-6] \u001b[A\n",
      " 51%|█████     | 2138/4220 [2:16:54<2:11:12,  3.78s/it, loss=2.5, epoch=0.506, learning_rate=9.84e-6]\u001b[A\n",
      " 51%|█████     | 2138/4220 [2:16:54<2:11:12,  3.78s/it, loss=2.67, epoch=0.506, learning_rate=9.84e-6]\u001b[A\n",
      " 51%|█████     | 2139/4220 [2:16:57<2:11:09,  3.78s/it, loss=2.67, epoch=0.506, learning_rate=9.84e-6]\u001b[A\n",
      " 51%|█████     | 2139/4220 [2:16:57<2:11:09,  3.78s/it, loss=3.24, epoch=0.507, learning_rate=9.83e-6]\u001b[A\n",
      " 51%|█████     | 2140/4220 [2:17:01<2:11:00,  3.78s/it, loss=3.24, epoch=0.507, learning_rate=9.83e-6]\u001b[A\n",
      " 51%|█████     | 2140/4220 [2:17:01<2:11:00,  3.78s/it, loss=3.08, epoch=0.507, learning_rate=9.82e-6]\u001b[A\n",
      " 51%|█████     | 2141/4220 [2:17:05<2:10:57,  3.78s/it, loss=3.08, epoch=0.507, learning_rate=9.82e-6]\u001b[A\n",
      " 51%|█████     | 2141/4220 [2:17:05<2:10:57,  3.78s/it, loss=2.63, epoch=0.507, learning_rate=9.81e-6]\u001b[A\n",
      " 51%|█████     | 2142/4220 [2:17:09<2:10:57,  3.78s/it, loss=2.63, epoch=0.507, learning_rate=9.81e-6]\u001b[A\n",
      " 51%|█████     | 2142/4220 [2:17:09<2:10:57,  3.78s/it, loss=2.8, epoch=0.507, learning_rate=9.81e-6] \u001b[A\n",
      " 51%|█████     | 2143/4220 [2:17:12<2:10:53,  3.78s/it, loss=2.8, epoch=0.507, learning_rate=9.81e-6]\u001b[A\n",
      " 51%|█████     | 2143/4220 [2:17:12<2:10:53,  3.78s/it, loss=3.19, epoch=0.508, learning_rate=9.8e-6]\u001b[A\n",
      " 51%|█████     | 2144/4220 [2:17:16<2:10:48,  3.78s/it, loss=3.19, epoch=0.508, learning_rate=9.8e-6]\u001b[A\n",
      " 51%|█████     | 2144/4220 [2:17:16<2:10:48,  3.78s/it, loss=2.84, epoch=0.508, learning_rate=9.79e-6]\u001b[A\n",
      " 51%|█████     | 2145/4220 [2:17:20<2:10:46,  3.78s/it, loss=2.84, epoch=0.508, learning_rate=9.79e-6]\u001b[A\n",
      " 51%|█████     | 2145/4220 [2:17:20<2:10:46,  3.78s/it, loss=3, epoch=0.508, learning_rate=9.78e-6]   \u001b[A\n",
      " 51%|█████     | 2146/4220 [2:17:24<2:10:40,  3.78s/it, loss=3, epoch=0.508, learning_rate=9.78e-6]\u001b[A\n",
      " 51%|█████     | 2146/4220 [2:17:24<2:10:40,  3.78s/it, loss=2.69, epoch=0.508, learning_rate=9.78e-6]\u001b[A\n",
      " 51%|█████     | 2147/4220 [2:17:28<2:10:36,  3.78s/it, loss=2.69, epoch=0.508, learning_rate=9.78e-6]\u001b[A\n",
      " 51%|█████     | 2147/4220 [2:17:28<2:10:36,  3.78s/it, loss=3.3, epoch=0.509, learning_rate=9.77e-6] \u001b[A\n",
      " 51%|█████     | 2148/4220 [2:17:31<2:10:33,  3.78s/it, loss=3.3, epoch=0.509, learning_rate=9.77e-6]\u001b[A\n",
      " 51%|█████     | 2148/4220 [2:17:31<2:10:33,  3.78s/it, loss=2.63, epoch=0.509, learning_rate=9.76e-6]\u001b[A\n",
      " 51%|█████     | 2149/4220 [2:17:35<2:10:30,  3.78s/it, loss=2.63, epoch=0.509, learning_rate=9.76e-6]\u001b[A\n",
      " 51%|█████     | 2149/4220 [2:17:35<2:10:30,  3.78s/it, loss=2.8, epoch=0.509, learning_rate=9.75e-6] \u001b[A\n",
      " 51%|█████     | 2150/4220 [2:17:39<2:10:22,  3.78s/it, loss=2.8, epoch=0.509, learning_rate=9.75e-6]\u001b[A\n",
      " 51%|█████     | 2150/4220 [2:17:39<2:10:22,  3.78s/it, loss=2.68, epoch=0.509, learning_rate=9.75e-6]\u001b[A\n",
      " 51%|█████     | 2151/4220 [2:17:43<2:10:20,  3.78s/it, loss=2.68, epoch=0.509, learning_rate=9.75e-6]\u001b[A\n",
      " 51%|█████     | 2151/4220 [2:17:43<2:10:20,  3.78s/it, loss=2.53, epoch=0.509, learning_rate=9.74e-6]\u001b[A\n",
      " 51%|█████     | 2152/4220 [2:17:46<2:10:18,  3.78s/it, loss=2.53, epoch=0.509, learning_rate=9.74e-6]\u001b[A\n",
      " 51%|█████     | 2152/4220 [2:17:46<2:10:18,  3.78s/it, loss=2.76, epoch=0.51, learning_rate=9.73e-6] \u001b[A\n",
      " 51%|█████     | 2153/4220 [2:17:50<2:10:17,  3.78s/it, loss=2.76, epoch=0.51, learning_rate=9.73e-6]\u001b[A\n",
      " 51%|█████     | 2153/4220 [2:17:50<2:10:17,  3.78s/it, loss=2.82, epoch=0.51, learning_rate=9.72e-6]\u001b[A\n",
      " 51%|█████     | 2154/4220 [2:17:54<2:10:14,  3.78s/it, loss=2.82, epoch=0.51, learning_rate=9.72e-6]\u001b[A\n",
      " 51%|█████     | 2154/4220 [2:17:54<2:10:14,  3.78s/it, loss=2.99, epoch=0.51, learning_rate=9.72e-6]\u001b[A\n",
      " 51%|█████     | 2155/4220 [2:17:58<2:10:12,  3.78s/it, loss=2.99, epoch=0.51, learning_rate=9.72e-6]\u001b[A\n",
      " 51%|█████     | 2155/4220 [2:17:58<2:10:12,  3.78s/it, loss=2.48, epoch=0.51, learning_rate=9.71e-6]\u001b[A\n",
      " 51%|█████     | 2156/4220 [2:18:02<2:10:04,  3.78s/it, loss=2.48, epoch=0.51, learning_rate=9.71e-6]\u001b[A\n",
      " 51%|█████     | 2156/4220 [2:18:02<2:10:04,  3.78s/it, loss=2.76, epoch=0.511, learning_rate=9.7e-6]\u001b[A\n",
      " 51%|█████     | 2157/4220 [2:18:05<2:10:02,  3.78s/it, loss=2.76, epoch=0.511, learning_rate=9.7e-6]\u001b[A\n",
      " 51%|█████     | 2157/4220 [2:18:05<2:10:02,  3.78s/it, loss=3.04, epoch=0.511, learning_rate=9.69e-6]\u001b[A\n",
      " 51%|█████     | 2158/4220 [2:18:09<2:09:58,  3.78s/it, loss=3.04, epoch=0.511, learning_rate=9.69e-6]\u001b[A\n",
      " 51%|█████     | 2158/4220 [2:18:09<2:09:58,  3.78s/it, loss=3.19, epoch=0.511, learning_rate=9.69e-6]\u001b[A\n",
      " 51%|█████     | 2159/4220 [2:18:13<2:09:52,  3.78s/it, loss=3.19, epoch=0.511, learning_rate=9.69e-6]\u001b[A\n",
      " 51%|█████     | 2159/4220 [2:18:13<2:09:52,  3.78s/it, loss=2.72, epoch=0.511, learning_rate=9.68e-6]\u001b[A\n",
      " 51%|█████     | 2160/4220 [2:18:17<2:09:46,  3.78s/it, loss=2.72, epoch=0.511, learning_rate=9.68e-6]\u001b[A\n",
      " 51%|█████     | 2160/4220 [2:18:17<2:09:46,  3.78s/it, loss=2.83, epoch=0.512, learning_rate=9.67e-6]\u001b[A\n",
      " 51%|█████     | 2161/4220 [2:18:20<2:09:43,  3.78s/it, loss=2.83, epoch=0.512, learning_rate=9.67e-6]\u001b[A\n",
      " 51%|█████     | 2161/4220 [2:18:20<2:09:43,  3.78s/it, loss=3.03, epoch=0.512, learning_rate=9.66e-6]\u001b[A\n",
      " 51%|█████     | 2162/4220 [2:18:24<2:09:43,  3.78s/it, loss=3.03, epoch=0.512, learning_rate=9.66e-6]\u001b[A\n",
      " 51%|█████     | 2162/4220 [2:18:24<2:09:43,  3.78s/it, loss=3.39, epoch=0.512, learning_rate=9.66e-6]\u001b[A\n",
      " 51%|█████▏    | 2163/4220 [2:18:28<2:09:38,  3.78s/it, loss=3.39, epoch=0.512, learning_rate=9.66e-6]\u001b[A\n",
      " 51%|█████▏    | 2163/4220 [2:18:28<2:09:38,  3.78s/it, loss=2.18, epoch=0.512, learning_rate=9.65e-6]\u001b[A\n",
      " 51%|█████▏    | 2164/4220 [2:18:32<2:09:34,  3.78s/it, loss=2.18, epoch=0.512, learning_rate=9.65e-6]\u001b[A\n",
      " 51%|█████▏    | 2164/4220 [2:18:32<2:09:34,  3.78s/it, loss=2.41, epoch=0.513, learning_rate=9.64e-6]\u001b[A\n",
      " 51%|█████▏    | 2165/4220 [2:18:36<2:09:30,  3.78s/it, loss=2.41, epoch=0.513, learning_rate=9.64e-6]\u001b[A\n",
      " 51%|█████▏    | 2165/4220 [2:18:36<2:09:30,  3.78s/it, loss=2.58, epoch=0.513, learning_rate=9.63e-6]\u001b[A\n",
      " 51%|█████▏    | 2166/4220 [2:18:39<2:09:23,  3.78s/it, loss=2.58, epoch=0.513, learning_rate=9.63e-6]\u001b[A\n",
      " 51%|█████▏    | 2166/4220 [2:18:39<2:09:23,  3.78s/it, loss=2.61, epoch=0.513, learning_rate=9.63e-6]\u001b[A\n",
      " 51%|█████▏    | 2167/4220 [2:18:43<2:09:17,  3.78s/it, loss=2.61, epoch=0.513, learning_rate=9.63e-6]\u001b[A\n",
      " 51%|█████▏    | 2167/4220 [2:18:43<2:09:17,  3.78s/it, loss=2.63, epoch=0.513, learning_rate=9.62e-6]\u001b[A\n",
      " 51%|█████▏    | 2168/4220 [2:18:47<2:09:16,  3.78s/it, loss=2.63, epoch=0.513, learning_rate=9.62e-6]\u001b[A\n",
      " 51%|█████▏    | 2168/4220 [2:18:47<2:09:16,  3.78s/it, loss=2.92, epoch=0.514, learning_rate=9.61e-6]\u001b[A\n",
      " 51%|█████▏    | 2169/4220 [2:18:51<2:09:14,  3.78s/it, loss=2.92, epoch=0.514, learning_rate=9.61e-6]\u001b[A\n",
      " 51%|█████▏    | 2169/4220 [2:18:51<2:09:14,  3.78s/it, loss=2.42, epoch=0.514, learning_rate=9.6e-6] \u001b[A\n",
      " 51%|█████▏    | 2170/4220 [2:18:54<2:09:11,  3.78s/it, loss=2.42, epoch=0.514, learning_rate=9.6e-6]\u001b[A\n",
      " 51%|█████▏    | 2170/4220 [2:18:54<2:09:11,  3.78s/it, loss=2.97, epoch=0.514, learning_rate=9.6e-6]\u001b[A\n",
      " 51%|█████▏    | 2171/4220 [2:18:58<2:09:11,  3.78s/it, loss=2.97, epoch=0.514, learning_rate=9.6e-6]\u001b[A\n",
      " 51%|█████▏    | 2171/4220 [2:18:58<2:09:11,  3.78s/it, loss=3.16, epoch=0.514, learning_rate=9.59e-6]\u001b[A\n",
      " 51%|█████▏    | 2172/4220 [2:19:02<2:09:07,  3.78s/it, loss=3.16, epoch=0.514, learning_rate=9.59e-6]\u001b[A\n",
      " 51%|█████▏    | 2172/4220 [2:19:02<2:09:07,  3.78s/it, loss=2.93, epoch=0.514, learning_rate=9.58e-6]\u001b[A\n",
      " 51%|█████▏    | 2173/4220 [2:19:06<2:09:03,  3.78s/it, loss=2.93, epoch=0.514, learning_rate=9.58e-6]\u001b[A\n",
      " 51%|█████▏    | 2173/4220 [2:19:06<2:09:03,  3.78s/it, loss=3.02, epoch=0.515, learning_rate=9.57e-6]\u001b[A\n",
      " 52%|█████▏    | 2174/4220 [2:19:10<2:08:59,  3.78s/it, loss=3.02, epoch=0.515, learning_rate=9.57e-6]\u001b[A\n",
      " 52%|█████▏    | 2174/4220 [2:19:10<2:08:59,  3.78s/it, loss=3.42, epoch=0.515, learning_rate=9.57e-6]\u001b[A\n",
      " 52%|█████▏    | 2175/4220 [2:19:13<2:08:54,  3.78s/it, loss=3.42, epoch=0.515, learning_rate=9.57e-6]\u001b[A\n",
      " 52%|█████▏    | 2175/4220 [2:19:13<2:08:54,  3.78s/it, loss=3.28, epoch=0.515, learning_rate=9.56e-6]\u001b[A\n",
      " 52%|█████▏    | 2176/4220 [2:19:17<2:08:48,  3.78s/it, loss=3.28, epoch=0.515, learning_rate=9.56e-6]\u001b[A\n",
      " 52%|█████▏    | 2176/4220 [2:19:17<2:08:48,  3.78s/it, loss=3.05, epoch=0.515, learning_rate=9.55e-6]\u001b[A\n",
      " 52%|█████▏    | 2177/4220 [2:19:21<2:08:43,  3.78s/it, loss=3.05, epoch=0.515, learning_rate=9.55e-6]\u001b[A\n",
      " 52%|█████▏    | 2177/4220 [2:19:21<2:08:43,  3.78s/it, loss=2.39, epoch=0.516, learning_rate=9.54e-6]\u001b[A\n",
      " 52%|█████▏    | 2178/4220 [2:19:25<2:08:41,  3.78s/it, loss=2.39, epoch=0.516, learning_rate=9.54e-6]\u001b[A\n",
      " 52%|█████▏    | 2178/4220 [2:19:25<2:08:41,  3.78s/it, loss=2.92, epoch=0.516, learning_rate=9.54e-6]\u001b[A\n",
      " 52%|█████▏    | 2179/4220 [2:19:29<2:08:38,  3.78s/it, loss=2.92, epoch=0.516, learning_rate=9.54e-6]\u001b[A\n",
      " 52%|█████▏    | 2179/4220 [2:19:29<2:08:38,  3.78s/it, loss=2.97, epoch=0.516, learning_rate=9.53e-6]\u001b[A\n",
      " 52%|█████▏    | 2180/4220 [2:19:32<2:08:36,  3.78s/it, loss=2.97, epoch=0.516, learning_rate=9.53e-6]\u001b[A\n",
      " 52%|█████▏    | 2180/4220 [2:19:32<2:08:36,  3.78s/it, loss=3.07, epoch=0.516, learning_rate=9.52e-6]\u001b[A\n",
      " 52%|█████▏    | 2181/4220 [2:19:36<2:08:31,  3.78s/it, loss=3.07, epoch=0.516, learning_rate=9.52e-6]\u001b[A\n",
      " 52%|█████▏    | 2181/4220 [2:19:36<2:08:31,  3.78s/it, loss=2.9, epoch=0.517, learning_rate=9.52e-6] \u001b[A\n",
      " 52%|█████▏    | 2182/4220 [2:19:40<2:08:28,  3.78s/it, loss=2.9, epoch=0.517, learning_rate=9.52e-6]\u001b[A\n",
      " 52%|█████▏    | 2182/4220 [2:19:40<2:08:28,  3.78s/it, loss=2.9, epoch=0.517, learning_rate=9.51e-6]\u001b[A\n",
      " 52%|█████▏    | 2183/4220 [2:19:44<2:08:25,  3.78s/it, loss=2.9, epoch=0.517, learning_rate=9.51e-6]\u001b[A\n",
      " 52%|█████▏    | 2183/4220 [2:19:44<2:08:25,  3.78s/it, loss=2.77, epoch=0.517, learning_rate=9.5e-6]\u001b[A\n",
      " 52%|█████▏    | 2184/4220 [2:19:47<2:08:16,  3.78s/it, loss=2.77, epoch=0.517, learning_rate=9.5e-6]\u001b[A\n",
      " 52%|█████▏    | 2184/4220 [2:19:47<2:08:16,  3.78s/it, loss=2.9, epoch=0.517, learning_rate=9.49e-6]\u001b[A\n",
      " 52%|█████▏    | 2185/4220 [2:19:51<2:08:13,  3.78s/it, loss=2.9, epoch=0.517, learning_rate=9.49e-6]\u001b[A\n",
      " 52%|█████▏    | 2185/4220 [2:19:51<2:08:13,  3.78s/it, loss=2.97, epoch=0.518, learning_rate=9.49e-6]\u001b[A\n",
      " 52%|█████▏    | 2186/4220 [2:19:55<2:08:09,  3.78s/it, loss=2.97, epoch=0.518, learning_rate=9.49e-6]\u001b[A\n",
      " 52%|█████▏    | 2186/4220 [2:19:55<2:08:09,  3.78s/it, loss=2.92, epoch=0.518, learning_rate=9.48e-6]\u001b[A\n",
      " 52%|█████▏    | 2187/4220 [2:19:59<2:08:07,  3.78s/it, loss=2.92, epoch=0.518, learning_rate=9.48e-6]\u001b[A\n",
      " 52%|█████▏    | 2187/4220 [2:19:59<2:08:07,  3.78s/it, loss=2.65, epoch=0.518, learning_rate=9.47e-6]\u001b[A\n",
      " 52%|█████▏    | 2188/4220 [2:20:03<2:08:05,  3.78s/it, loss=2.65, epoch=0.518, learning_rate=9.47e-6]\u001b[A\n",
      " 52%|█████▏    | 2188/4220 [2:20:03<2:08:05,  3.78s/it, loss=3.15, epoch=0.518, learning_rate=9.46e-6]\u001b[A\n",
      " 52%|█████▏    | 2189/4220 [2:20:06<2:08:04,  3.78s/it, loss=3.15, epoch=0.518, learning_rate=9.46e-6]\u001b[A\n",
      " 52%|█████▏    | 2189/4220 [2:20:06<2:08:04,  3.78s/it, loss=2.85, epoch=0.518, learning_rate=9.46e-6]\u001b[A\n",
      " 52%|█████▏    | 2190/4220 [2:20:10<2:07:58,  3.78s/it, loss=2.85, epoch=0.518, learning_rate=9.46e-6]\u001b[A\n",
      " 52%|█████▏    | 2190/4220 [2:20:10<2:07:58,  3.78s/it, loss=2.67, epoch=0.519, learning_rate=9.45e-6]\u001b[A\n",
      " 52%|█████▏    | 2191/4220 [2:20:14<2:07:51,  3.78s/it, loss=2.67, epoch=0.519, learning_rate=9.45e-6]\u001b[A\n",
      " 52%|█████▏    | 2191/4220 [2:20:14<2:07:51,  3.78s/it, loss=2.66, epoch=0.519, learning_rate=9.44e-6]\u001b[A\n",
      " 52%|█████▏    | 2192/4220 [2:20:18<2:07:49,  3.78s/it, loss=2.66, epoch=0.519, learning_rate=9.44e-6]\u001b[A\n",
      " 52%|█████▏    | 2192/4220 [2:20:18<2:07:49,  3.78s/it, loss=2.63, epoch=0.519, learning_rate=9.43e-6]\u001b[A\n",
      " 52%|█████▏    | 2193/4220 [2:20:21<2:07:42,  3.78s/it, loss=2.63, epoch=0.519, learning_rate=9.43e-6]\u001b[A\n",
      " 52%|█████▏    | 2193/4220 [2:20:21<2:07:42,  3.78s/it, loss=2.81, epoch=0.519, learning_rate=9.43e-6]\u001b[A\n",
      " 52%|█████▏    | 2194/4220 [2:20:25<2:07:38,  3.78s/it, loss=2.81, epoch=0.519, learning_rate=9.43e-6]\u001b[A\n",
      " 52%|█████▏    | 2194/4220 [2:20:25<2:07:38,  3.78s/it, loss=3, epoch=0.52, learning_rate=9.42e-6]    \u001b[A\n",
      " 52%|█████▏    | 2195/4220 [2:20:29<2:07:38,  3.78s/it, loss=3, epoch=0.52, learning_rate=9.42e-6]\u001b[A\n",
      " 52%|█████▏    | 2195/4220 [2:20:29<2:07:38,  3.78s/it, loss=2.91, epoch=0.52, learning_rate=9.41e-6]\u001b[A\n",
      " 52%|█████▏    | 2196/4220 [2:20:33<2:07:30,  3.78s/it, loss=2.91, epoch=0.52, learning_rate=9.41e-6]\u001b[A\n",
      " 52%|█████▏    | 2196/4220 [2:20:33<2:07:30,  3.78s/it, loss=3.46, epoch=0.52, learning_rate=9.4e-6] \u001b[A\n",
      " 52%|█████▏    | 2197/4220 [2:20:37<2:07:28,  3.78s/it, loss=3.46, epoch=0.52, learning_rate=9.4e-6]\u001b[A\n",
      " 52%|█████▏    | 2197/4220 [2:20:37<2:07:28,  3.78s/it, loss=2.62, epoch=0.52, learning_rate=9.4e-6]\u001b[A\n",
      " 52%|█████▏    | 2198/4220 [2:20:40<2:07:24,  3.78s/it, loss=2.62, epoch=0.52, learning_rate=9.4e-6]\u001b[A\n",
      " 52%|█████▏    | 2198/4220 [2:20:40<2:07:24,  3.78s/it, loss=2.8, epoch=0.521, learning_rate=9.39e-6]\u001b[A\n",
      " 52%|█████▏    | 2199/4220 [2:20:44<2:07:22,  3.78s/it, loss=2.8, epoch=0.521, learning_rate=9.39e-6]\u001b[A\n",
      " 52%|█████▏    | 2199/4220 [2:20:44<2:07:22,  3.78s/it, loss=2.99, epoch=0.521, learning_rate=9.38e-6]\u001b[A\n",
      " 52%|█████▏    | 2200/4220 [2:20:48<2:07:21,  3.78s/it, loss=2.99, epoch=0.521, learning_rate=9.38e-6]\u001b[A\n",
      " 52%|█████▏    | 2200/4220 [2:20:48<2:07:21,  3.78s/it, loss=2.54, epoch=0.521, learning_rate=9.37e-6]\u001b[A\n",
      " 52%|█████▏    | 2201/4220 [2:20:52<2:07:17,  3.78s/it, loss=2.54, epoch=0.521, learning_rate=9.37e-6]\u001b[A\n",
      " 52%|█████▏    | 2201/4220 [2:20:52<2:07:17,  3.78s/it, loss=2.76, epoch=0.521, learning_rate=9.37e-6]\u001b[A\n",
      " 52%|█████▏    | 2202/4220 [2:20:56<2:07:10,  3.78s/it, loss=2.76, epoch=0.521, learning_rate=9.37e-6]\u001b[A\n",
      " 52%|█████▏    | 2202/4220 [2:20:56<2:07:10,  3.78s/it, loss=3.32, epoch=0.522, learning_rate=9.36e-6]\u001b[A\n",
      " 52%|█████▏    | 2203/4220 [2:20:59<2:07:06,  3.78s/it, loss=3.32, epoch=0.522, learning_rate=9.36e-6]\u001b[A\n",
      " 52%|█████▏    | 2203/4220 [2:20:59<2:07:06,  3.78s/it, loss=3.3, epoch=0.522, learning_rate=9.35e-6] \u001b[A\n",
      " 52%|█████▏    | 2204/4220 [2:21:03<2:07:02,  3.78s/it, loss=3.3, epoch=0.522, learning_rate=9.35e-6]\u001b[A\n",
      " 52%|█████▏    | 2204/4220 [2:21:03<2:07:02,  3.78s/it, loss=2.51, epoch=0.522, learning_rate=9.34e-6]\u001b[A\n",
      " 52%|█████▏    | 2205/4220 [2:21:07<2:07:00,  3.78s/it, loss=2.51, epoch=0.522, learning_rate=9.34e-6]\u001b[A\n",
      " 52%|█████▏    | 2205/4220 [2:21:07<2:07:00,  3.78s/it, loss=2.92, epoch=0.522, learning_rate=9.34e-6]\u001b[A\n",
      " 52%|█████▏    | 2206/4220 [2:21:11<2:06:56,  3.78s/it, loss=2.92, epoch=0.522, learning_rate=9.34e-6]\u001b[A\n",
      " 52%|█████▏    | 2206/4220 [2:21:11<2:06:56,  3.78s/it, loss=2.36, epoch=0.523, learning_rate=9.33e-6]\u001b[A\n",
      " 52%|█████▏    | 2207/4220 [2:21:14<2:06:54,  3.78s/it, loss=2.36, epoch=0.523, learning_rate=9.33e-6]\u001b[A\n",
      " 52%|█████▏    | 2207/4220 [2:21:14<2:06:54,  3.78s/it, loss=2.71, epoch=0.523, learning_rate=9.32e-6]\u001b[A\n",
      " 52%|█████▏    | 2208/4220 [2:21:18<2:06:50,  3.78s/it, loss=2.71, epoch=0.523, learning_rate=9.32e-6]\u001b[A\n",
      " 52%|█████▏    | 2208/4220 [2:21:18<2:06:50,  3.78s/it, loss=3.03, epoch=0.523, learning_rate=9.31e-6]\u001b[A\n",
      " 52%|█████▏    | 2209/4220 [2:21:22<2:06:48,  3.78s/it, loss=3.03, epoch=0.523, learning_rate=9.31e-6]\u001b[A\n",
      " 52%|█████▏    | 2209/4220 [2:21:22<2:06:48,  3.78s/it, loss=2.8, epoch=0.523, learning_rate=9.31e-6] \u001b[A\n",
      " 52%|█████▏    | 2210/4220 [2:21:26<2:06:43,  3.78s/it, loss=2.8, epoch=0.523, learning_rate=9.31e-6]\u001b[A\n",
      " 52%|█████▏    | 2210/4220 [2:21:26<2:06:43,  3.78s/it, loss=2.7, epoch=0.523, learning_rate=9.3e-6] \u001b[A\n",
      " 52%|█████▏    | 2211/4220 [2:21:30<2:06:38,  3.78s/it, loss=2.7, epoch=0.523, learning_rate=9.3e-6]\u001b[A\n",
      " 52%|█████▏    | 2211/4220 [2:21:30<2:06:38,  3.78s/it, loss=2.65, epoch=0.524, learning_rate=9.29e-6]\u001b[A\n",
      " 52%|█████▏    | 2212/4220 [2:21:33<2:06:38,  3.78s/it, loss=2.65, epoch=0.524, learning_rate=9.29e-6]\u001b[A\n",
      " 52%|█████▏    | 2212/4220 [2:21:33<2:06:38,  3.78s/it, loss=2.51, epoch=0.524, learning_rate=9.28e-6]\u001b[A\n",
      " 52%|█████▏    | 2213/4220 [2:21:37<2:06:31,  3.78s/it, loss=2.51, epoch=0.524, learning_rate=9.28e-6]\u001b[A\n",
      " 52%|█████▏    | 2213/4220 [2:21:37<2:06:31,  3.78s/it, loss=2.58, epoch=0.524, learning_rate=9.28e-6]\u001b[A\n",
      " 52%|█████▏    | 2214/4220 [2:21:41<2:06:27,  3.78s/it, loss=2.58, epoch=0.524, learning_rate=9.28e-6]\u001b[A\n",
      " 52%|█████▏    | 2214/4220 [2:21:41<2:06:27,  3.78s/it, loss=2.66, epoch=0.524, learning_rate=9.27e-6]\u001b[A\n",
      " 52%|█████▏    | 2215/4220 [2:21:45<2:06:26,  3.78s/it, loss=2.66, epoch=0.524, learning_rate=9.27e-6]\u001b[A\n",
      " 52%|█████▏    | 2215/4220 [2:21:45<2:06:26,  3.78s/it, loss=2.71, epoch=0.525, learning_rate=9.26e-6]\u001b[A\n",
      " 53%|█████▎    | 2216/4220 [2:21:48<2:06:20,  3.78s/it, loss=2.71, epoch=0.525, learning_rate=9.26e-6]\u001b[A\n",
      " 53%|█████▎    | 2216/4220 [2:21:48<2:06:20,  3.78s/it, loss=2.79, epoch=0.525, learning_rate=9.25e-6]\u001b[A\n",
      " 53%|█████▎    | 2217/4220 [2:21:52<2:06:16,  3.78s/it, loss=2.79, epoch=0.525, learning_rate=9.25e-6]\u001b[A\n",
      " 53%|█████▎    | 2217/4220 [2:21:52<2:06:16,  3.78s/it, loss=2.83, epoch=0.525, learning_rate=9.25e-6]\u001b[A\n",
      " 53%|█████▎    | 2218/4220 [2:21:56<2:06:11,  3.78s/it, loss=2.83, epoch=0.525, learning_rate=9.25e-6]\u001b[A\n",
      " 53%|█████▎    | 2218/4220 [2:21:56<2:06:11,  3.78s/it, loss=2.52, epoch=0.525, learning_rate=9.24e-6]\u001b[A\n",
      " 53%|█████▎    | 2219/4220 [2:22:00<2:06:05,  3.78s/it, loss=2.52, epoch=0.525, learning_rate=9.24e-6]\u001b[A\n",
      " 53%|█████▎    | 2219/4220 [2:22:00<2:06:05,  3.78s/it, loss=2.74, epoch=0.526, learning_rate=9.23e-6]\u001b[A\n",
      " 53%|█████▎    | 2220/4220 [2:22:04<2:06:04,  3.78s/it, loss=2.74, epoch=0.526, learning_rate=9.23e-6]\u001b[A\n",
      " 53%|█████▎    | 2220/4220 [2:22:04<2:06:04,  3.78s/it, loss=2.99, epoch=0.526, learning_rate=9.22e-6]\u001b[A\n",
      " 53%|█████▎    | 2221/4220 [2:22:07<2:05:58,  3.78s/it, loss=2.99, epoch=0.526, learning_rate=9.22e-6]\u001b[A\n",
      " 53%|█████▎    | 2221/4220 [2:22:07<2:05:58,  3.78s/it, loss=2.8, epoch=0.526, learning_rate=9.22e-6] \u001b[A\n",
      " 53%|█████▎    | 2222/4220 [2:22:11<2:05:56,  3.78s/it, loss=2.8, epoch=0.526, learning_rate=9.22e-6]\u001b[A\n",
      " 53%|█████▎    | 2222/4220 [2:22:11<2:05:56,  3.78s/it, loss=2.41, epoch=0.526, learning_rate=9.21e-6]\u001b[A\n",
      " 53%|█████▎    | 2223/4220 [2:22:15<2:05:54,  3.78s/it, loss=2.41, epoch=0.526, learning_rate=9.21e-6]\u001b[A\n",
      " 53%|█████▎    | 2223/4220 [2:22:15<2:05:54,  3.78s/it, loss=2.76, epoch=0.527, learning_rate=9.2e-6] \u001b[A\n",
      " 53%|█████▎    | 2224/4220 [2:22:19<2:05:49,  3.78s/it, loss=2.76, epoch=0.527, learning_rate=9.2e-6]\u001b[A\n",
      " 53%|█████▎    | 2224/4220 [2:22:19<2:05:49,  3.78s/it, loss=2.85, epoch=0.527, learning_rate=9.19e-6]\u001b[A\n",
      " 53%|█████▎    | 2225/4220 [2:22:22<2:05:44,  3.78s/it, loss=2.85, epoch=0.527, learning_rate=9.19e-6]\u001b[A\n",
      " 53%|█████▎    | 2225/4220 [2:22:23<2:05:44,  3.78s/it, loss=2.98, epoch=0.527, learning_rate=9.19e-6]\u001b[A\n",
      " 53%|█████▎    | 2226/4220 [2:22:26<2:05:42,  3.78s/it, loss=2.98, epoch=0.527, learning_rate=9.19e-6]\u001b[A\n",
      " 53%|█████▎    | 2226/4220 [2:22:26<2:05:42,  3.78s/it, loss=3.19, epoch=0.527, learning_rate=9.18e-6]\u001b[A\n",
      " 53%|█████▎    | 2227/4220 [2:22:30<2:05:36,  3.78s/it, loss=3.19, epoch=0.527, learning_rate=9.18e-6]\u001b[A\n",
      " 53%|█████▎    | 2227/4220 [2:22:30<2:05:36,  3.78s/it, loss=2.79, epoch=0.527, learning_rate=9.17e-6]\u001b[A\n",
      " 53%|█████▎    | 2228/4220 [2:22:34<2:05:33,  3.78s/it, loss=2.79, epoch=0.527, learning_rate=9.17e-6]\u001b[A\n",
      " 53%|█████▎    | 2228/4220 [2:22:34<2:05:33,  3.78s/it, loss=3.09, epoch=0.528, learning_rate=9.17e-6]\u001b[A\n",
      " 53%|█████▎    | 2229/4220 [2:22:38<2:05:29,  3.78s/it, loss=3.09, epoch=0.528, learning_rate=9.17e-6]\u001b[A\n",
      " 53%|█████▎    | 2229/4220 [2:22:38<2:05:29,  3.78s/it, loss=2.77, epoch=0.528, learning_rate=9.16e-6]\u001b[A\n",
      " 53%|█████▎    | 2230/4220 [2:22:41<2:05:21,  3.78s/it, loss=2.77, epoch=0.528, learning_rate=9.16e-6]\u001b[A\n",
      " 53%|█████▎    | 2230/4220 [2:22:41<2:05:21,  3.78s/it, loss=2.42, epoch=0.528, learning_rate=9.15e-6]\u001b[A\n",
      " 53%|█████▎    | 2231/4220 [2:22:45<2:05:18,  3.78s/it, loss=2.42, epoch=0.528, learning_rate=9.15e-6]\u001b[A\n",
      " 53%|█████▎    | 2231/4220 [2:22:45<2:05:18,  3.78s/it, loss=3.16, epoch=0.528, learning_rate=9.14e-6]\u001b[A\n",
      " 53%|█████▎    | 2232/4220 [2:22:49<2:05:14,  3.78s/it, loss=3.16, epoch=0.528, learning_rate=9.14e-6]\u001b[A\n",
      " 53%|█████▎    | 2232/4220 [2:22:49<2:05:14,  3.78s/it, loss=3.11, epoch=0.529, learning_rate=9.14e-6]\u001b[A\n",
      " 53%|█████▎    | 2233/4220 [2:22:53<2:05:12,  3.78s/it, loss=3.11, epoch=0.529, learning_rate=9.14e-6]\u001b[A\n",
      " 53%|█████▎    | 2233/4220 [2:22:53<2:05:12,  3.78s/it, loss=3, epoch=0.529, learning_rate=9.13e-6]   \u001b[A\n",
      " 53%|█████▎    | 2234/4220 [2:22:57<2:05:06,  3.78s/it, loss=3, epoch=0.529, learning_rate=9.13e-6]\u001b[A\n",
      " 53%|█████▎    | 2234/4220 [2:22:57<2:05:06,  3.78s/it, loss=2.69, epoch=0.529, learning_rate=9.12e-6]\u001b[A\n",
      " 53%|█████▎    | 2235/4220 [2:23:00<2:05:05,  3.78s/it, loss=2.69, epoch=0.529, learning_rate=9.12e-6]\u001b[A\n",
      " 53%|█████▎    | 2235/4220 [2:23:00<2:05:05,  3.78s/it, loss=2.6, epoch=0.529, learning_rate=9.11e-6] \u001b[A\n",
      " 53%|█████▎    | 2236/4220 [2:23:04<2:04:59,  3.78s/it, loss=2.6, epoch=0.529, learning_rate=9.11e-6]\u001b[A\n",
      " 53%|█████▎    | 2236/4220 [2:23:04<2:04:59,  3.78s/it, loss=2.62, epoch=0.53, learning_rate=9.11e-6]\u001b[A\n",
      " 53%|█████▎    | 2237/4220 [2:23:08<2:04:55,  3.78s/it, loss=2.62, epoch=0.53, learning_rate=9.11e-6]\u001b[A\n",
      " 53%|█████▎    | 2237/4220 [2:23:08<2:04:55,  3.78s/it, loss=2.36, epoch=0.53, learning_rate=9.1e-6] \u001b[A\n",
      " 53%|█████▎    | 2238/4220 [2:23:12<2:04:53,  3.78s/it, loss=2.36, epoch=0.53, learning_rate=9.1e-6]\u001b[A\n",
      " 53%|█████▎    | 2238/4220 [2:23:12<2:04:53,  3.78s/it, loss=2.73, epoch=0.53, learning_rate=9.09e-6]\u001b[A\n",
      " 53%|█████▎    | 2239/4220 [2:23:15<2:04:48,  3.78s/it, loss=2.73, epoch=0.53, learning_rate=9.09e-6]\u001b[A\n",
      " 53%|█████▎    | 2239/4220 [2:23:15<2:04:48,  3.78s/it, loss=2.82, epoch=0.53, learning_rate=9.08e-6]\u001b[A\n",
      " 53%|█████▎    | 2240/4220 [2:23:19<2:04:46,  3.78s/it, loss=2.82, epoch=0.53, learning_rate=9.08e-6]\u001b[A\n",
      " 53%|█████▎    | 2240/4220 [2:23:19<2:04:46,  3.78s/it, loss=2.61, epoch=0.531, learning_rate=9.08e-6]\u001b[A\n",
      " 53%|█████▎    | 2241/4220 [2:23:23<2:04:43,  3.78s/it, loss=2.61, epoch=0.531, learning_rate=9.08e-6]\u001b[A\n",
      " 53%|█████▎    | 2241/4220 [2:23:23<2:04:43,  3.78s/it, loss=2.44, epoch=0.531, learning_rate=9.07e-6]\u001b[A\n",
      " 53%|█████▎    | 2242/4220 [2:23:27<2:04:43,  3.78s/it, loss=2.44, epoch=0.531, learning_rate=9.07e-6]\u001b[A\n",
      " 53%|█████▎    | 2242/4220 [2:23:27<2:04:43,  3.78s/it, loss=3.04, epoch=0.531, learning_rate=9.06e-6]\u001b[A\n",
      " 53%|█████▎    | 2243/4220 [2:23:31<2:04:40,  3.78s/it, loss=3.04, epoch=0.531, learning_rate=9.06e-6]\u001b[A\n",
      " 53%|█████▎    | 2243/4220 [2:23:31<2:04:40,  3.78s/it, loss=2.82, epoch=0.531, learning_rate=9.05e-6]\u001b[A\n",
      " 53%|█████▎    | 2244/4220 [2:23:34<2:04:32,  3.78s/it, loss=2.82, epoch=0.531, learning_rate=9.05e-6]\u001b[A\n",
      " 53%|█████▎    | 2244/4220 [2:23:34<2:04:32,  3.78s/it, loss=2.52, epoch=0.532, learning_rate=9.05e-6]\u001b[A\n",
      " 53%|█████▎    | 2245/4220 [2:23:38<2:04:28,  3.78s/it, loss=2.52, epoch=0.532, learning_rate=9.05e-6]\u001b[A\n",
      " 53%|█████▎    | 2245/4220 [2:23:38<2:04:28,  3.78s/it, loss=2.47, epoch=0.532, learning_rate=9.04e-6]\u001b[A\n",
      " 53%|█████▎    | 2246/4220 [2:23:42<2:04:24,  3.78s/it, loss=2.47, epoch=0.532, learning_rate=9.04e-6]\u001b[A\n",
      " 53%|█████▎    | 2246/4220 [2:23:42<2:04:24,  3.78s/it, loss=2.52, epoch=0.532, learning_rate=9.03e-6]\u001b[A\n",
      " 53%|█████▎    | 2247/4220 [2:23:46<2:04:19,  3.78s/it, loss=2.52, epoch=0.532, learning_rate=9.03e-6]\u001b[A\n",
      " 53%|█████▎    | 2247/4220 [2:23:46<2:04:19,  3.78s/it, loss=2.73, epoch=0.532, learning_rate=9.02e-6]\u001b[A\n",
      " 53%|█████▎    | 2248/4220 [2:23:49<2:04:18,  3.78s/it, loss=2.73, epoch=0.532, learning_rate=9.02e-6]\u001b[A\n",
      " 53%|█████▎    | 2248/4220 [2:23:49<2:04:18,  3.78s/it, loss=2.83, epoch=0.532, learning_rate=9.02e-6]\u001b[A\n",
      " 53%|█████▎    | 2249/4220 [2:23:53<2:04:13,  3.78s/it, loss=2.83, epoch=0.532, learning_rate=9.02e-6]\u001b[A\n",
      " 53%|█████▎    | 2249/4220 [2:23:53<2:04:13,  3.78s/it, loss=2.98, epoch=0.533, learning_rate=9.01e-6]\u001b[A\n",
      " 53%|█████▎    | 2250/4220 [2:23:57<2:04:11,  3.78s/it, loss=2.98, epoch=0.533, learning_rate=9.01e-6]\u001b[A\n",
      " 53%|█████▎    | 2250/4220 [2:23:57<2:04:11,  3.78s/it, loss=2.86, epoch=0.533, learning_rate=9e-6]   \u001b[A\n",
      " 53%|█████▎    | 2251/4220 [2:24:01<2:04:03,  3.78s/it, loss=2.86, epoch=0.533, learning_rate=9e-6]\u001b[A\n",
      " 53%|█████▎    | 2251/4220 [2:24:01<2:04:03,  3.78s/it, loss=3.16, epoch=0.533, learning_rate=8.99e-6]\u001b[A\n",
      " 53%|█████▎    | 2252/4220 [2:24:05<2:03:58,  3.78s/it, loss=3.16, epoch=0.533, learning_rate=8.99e-6]\u001b[A\n",
      " 53%|█████▎    | 2252/4220 [2:24:05<2:03:58,  3.78s/it, loss=2.31, epoch=0.533, learning_rate=8.99e-6]\u001b[A\n",
      " 53%|█████▎    | 2253/4220 [2:24:08<2:03:55,  3.78s/it, loss=2.31, epoch=0.533, learning_rate=8.99e-6]\u001b[A\n",
      " 53%|█████▎    | 2253/4220 [2:24:08<2:03:55,  3.78s/it, loss=2.85, epoch=0.534, learning_rate=8.98e-6]\u001b[A\n",
      " 53%|█████▎    | 2254/4220 [2:24:12<2:03:47,  3.78s/it, loss=2.85, epoch=0.534, learning_rate=8.98e-6]\u001b[A\n",
      " 53%|█████▎    | 2254/4220 [2:24:12<2:03:47,  3.78s/it, loss=2.6, epoch=0.534, learning_rate=8.97e-6] \u001b[A\n",
      " 53%|█████▎    | 2255/4220 [2:24:16<2:03:46,  3.78s/it, loss=2.6, epoch=0.534, learning_rate=8.97e-6]\u001b[A\n",
      " 53%|█████▎    | 2255/4220 [2:24:16<2:03:46,  3.78s/it, loss=2.42, epoch=0.534, learning_rate=8.96e-6]\u001b[A\n",
      " 53%|█████▎    | 2256/4220 [2:24:20<2:03:42,  3.78s/it, loss=2.42, epoch=0.534, learning_rate=8.96e-6]\u001b[A\n",
      " 53%|█████▎    | 2256/4220 [2:24:20<2:03:42,  3.78s/it, loss=2.67, epoch=0.534, learning_rate=8.96e-6]\u001b[A\n",
      " 53%|█████▎    | 2257/4220 [2:24:23<2:03:37,  3.78s/it, loss=2.67, epoch=0.534, learning_rate=8.96e-6]\u001b[A\n",
      " 53%|█████▎    | 2257/4220 [2:24:23<2:03:37,  3.78s/it, loss=3.02, epoch=0.535, learning_rate=8.95e-6]\u001b[A\n",
      " 54%|█████▎    | 2258/4220 [2:24:27<2:03:36,  3.78s/it, loss=3.02, epoch=0.535, learning_rate=8.95e-6]\u001b[A\n",
      " 54%|█████▎    | 2258/4220 [2:24:27<2:03:36,  3.78s/it, loss=2.97, epoch=0.535, learning_rate=8.94e-6]\u001b[A\n",
      " 54%|█████▎    | 2259/4220 [2:24:31<2:03:33,  3.78s/it, loss=2.97, epoch=0.535, learning_rate=8.94e-6]\u001b[A\n",
      " 54%|█████▎    | 2259/4220 [2:24:31<2:03:33,  3.78s/it, loss=2.76, epoch=0.535, learning_rate=8.93e-6]\u001b[A\n",
      " 54%|█████▎    | 2260/4220 [2:24:35<2:03:24,  3.78s/it, loss=2.76, epoch=0.535, learning_rate=8.93e-6]\u001b[A\n",
      " 54%|█████▎    | 2260/4220 [2:24:35<2:03:24,  3.78s/it, loss=2.9, epoch=0.535, learning_rate=8.93e-6] \u001b[A\n",
      " 54%|█████▎    | 2261/4220 [2:24:39<2:03:23,  3.78s/it, loss=2.9, epoch=0.535, learning_rate=8.93e-6]\u001b[A\n",
      " 54%|█████▎    | 2261/4220 [2:24:39<2:03:23,  3.78s/it, loss=3.11, epoch=0.536, learning_rate=8.92e-6]\u001b[A\n",
      " 54%|█████▎    | 2262/4220 [2:24:42<2:03:16,  3.78s/it, loss=3.11, epoch=0.536, learning_rate=8.92e-6]\u001b[A\n",
      " 54%|█████▎    | 2262/4220 [2:24:42<2:03:16,  3.78s/it, loss=2.95, epoch=0.536, learning_rate=8.91e-6]\u001b[A\n",
      " 54%|█████▎    | 2263/4220 [2:24:46<2:03:16,  3.78s/it, loss=2.95, epoch=0.536, learning_rate=8.91e-6]\u001b[A\n",
      " 54%|█████▎    | 2263/4220 [2:24:46<2:03:16,  3.78s/it, loss=2.85, epoch=0.536, learning_rate=8.91e-6]\u001b[A\n",
      " 54%|█████▎    | 2264/4220 [2:24:50<2:03:13,  3.78s/it, loss=2.85, epoch=0.536, learning_rate=8.91e-6]\u001b[A\n",
      " 54%|█████▎    | 2264/4220 [2:24:50<2:03:13,  3.78s/it, loss=2.48, epoch=0.536, learning_rate=8.9e-6] \u001b[A\n",
      " 54%|█████▎    | 2265/4220 [2:24:54<2:03:10,  3.78s/it, loss=2.48, epoch=0.536, learning_rate=8.9e-6]\u001b[A\n",
      " 54%|█████▎    | 2265/4220 [2:24:54<2:03:10,  3.78s/it, loss=2.46, epoch=0.536, learning_rate=8.89e-6]\u001b[A\n",
      " 54%|█████▎    | 2266/4220 [2:24:58<2:03:08,  3.78s/it, loss=2.46, epoch=0.536, learning_rate=8.89e-6]\u001b[A\n",
      " 54%|█████▎    | 2266/4220 [2:24:58<2:03:08,  3.78s/it, loss=2.58, epoch=0.537, learning_rate=8.88e-6]\u001b[A\n",
      " 54%|█████▎    | 2267/4220 [2:25:01<2:03:03,  3.78s/it, loss=2.58, epoch=0.537, learning_rate=8.88e-6]\u001b[A\n",
      " 54%|█████▎    | 2267/4220 [2:25:01<2:03:03,  3.78s/it, loss=3.02, epoch=0.537, learning_rate=8.88e-6]\u001b[A\n",
      " 54%|█████▎    | 2268/4220 [2:25:05<2:03:00,  3.78s/it, loss=3.02, epoch=0.537, learning_rate=8.88e-6]\u001b[A\n",
      " 54%|█████▎    | 2268/4220 [2:25:05<2:03:00,  3.78s/it, loss=2.45, epoch=0.537, learning_rate=8.87e-6]\u001b[A\n",
      " 54%|█████▍    | 2269/4220 [2:25:09<2:02:56,  3.78s/it, loss=2.45, epoch=0.537, learning_rate=8.87e-6]\u001b[A\n",
      " 54%|█████▍    | 2269/4220 [2:25:09<2:02:56,  3.78s/it, loss=2.96, epoch=0.537, learning_rate=8.86e-6]\u001b[A\n",
      " 54%|█████▍    | 2270/4220 [2:25:13<2:02:50,  3.78s/it, loss=2.96, epoch=0.537, learning_rate=8.86e-6]\u001b[A\n",
      " 54%|█████▍    | 2270/4220 [2:25:13<2:02:50,  3.78s/it, loss=2.82, epoch=0.538, learning_rate=8.85e-6]\u001b[A\n",
      " 54%|█████▍    | 2271/4220 [2:25:16<2:02:46,  3.78s/it, loss=2.82, epoch=0.538, learning_rate=8.85e-6]\u001b[A\n",
      " 54%|█████▍    | 2271/4220 [2:25:16<2:02:46,  3.78s/it, loss=3.17, epoch=0.538, learning_rate=8.85e-6]\u001b[A\n",
      " 54%|█████▍    | 2272/4220 [2:25:20<2:02:46,  3.78s/it, loss=3.17, epoch=0.538, learning_rate=8.85e-6]\u001b[A\n",
      " 54%|█████▍    | 2272/4220 [2:25:20<2:02:46,  3.78s/it, loss=2.73, epoch=0.538, learning_rate=8.84e-6]\u001b[A\n",
      " 54%|█████▍    | 2273/4220 [2:25:24<2:02:41,  3.78s/it, loss=2.73, epoch=0.538, learning_rate=8.84e-6]\u001b[A\n",
      " 54%|█████▍    | 2273/4220 [2:25:24<2:02:41,  3.78s/it, loss=3.17, epoch=0.538, learning_rate=8.83e-6]\u001b[A\n",
      " 54%|█████▍    | 2274/4220 [2:25:28<2:02:36,  3.78s/it, loss=3.17, epoch=0.538, learning_rate=8.83e-6]\u001b[A\n",
      " 54%|█████▍    | 2274/4220 [2:25:28<2:02:36,  3.78s/it, loss=2.72, epoch=0.539, learning_rate=8.82e-6]\u001b[A\n",
      " 54%|█████▍    | 2275/4220 [2:25:32<2:02:29,  3.78s/it, loss=2.72, epoch=0.539, learning_rate=8.82e-6]\u001b[A\n",
      " 54%|█████▍    | 2275/4220 [2:25:32<2:02:29,  3.78s/it, loss=3.05, epoch=0.539, learning_rate=8.82e-6]\u001b[A\n",
      " 54%|█████▍    | 2276/4220 [2:25:35<2:02:26,  3.78s/it, loss=3.05, epoch=0.539, learning_rate=8.82e-6]\u001b[A\n",
      " 54%|█████▍    | 2276/4220 [2:25:35<2:02:26,  3.78s/it, loss=2.85, epoch=0.539, learning_rate=8.81e-6]\u001b[A\n",
      " 54%|█████▍    | 2277/4220 [2:25:39<2:02:24,  3.78s/it, loss=2.85, epoch=0.539, learning_rate=8.81e-6]\u001b[A\n",
      " 54%|█████▍    | 2277/4220 [2:25:39<2:02:24,  3.78s/it, loss=3.18, epoch=0.539, learning_rate=8.8e-6] \u001b[A\n",
      " 54%|█████▍    | 2278/4220 [2:25:43<2:02:23,  3.78s/it, loss=3.18, epoch=0.539, learning_rate=8.8e-6]\u001b[A\n",
      " 54%|█████▍    | 2278/4220 [2:25:43<2:02:23,  3.78s/it, loss=3.01, epoch=0.54, learning_rate=8.79e-6]\u001b[A\n",
      " 54%|█████▍    | 2279/4220 [2:25:47<2:02:21,  3.78s/it, loss=3.01, epoch=0.54, learning_rate=8.79e-6]\u001b[A\n",
      " 54%|█████▍    | 2279/4220 [2:25:47<2:02:21,  3.78s/it, loss=2.93, epoch=0.54, learning_rate=8.79e-6]\u001b[A\n",
      " 54%|█████▍    | 2280/4220 [2:25:50<2:02:18,  3.78s/it, loss=2.93, epoch=0.54, learning_rate=8.79e-6]\u001b[A\n",
      " 54%|█████▍    | 2280/4220 [2:25:50<2:02:18,  3.78s/it, loss=2.86, epoch=0.54, learning_rate=8.78e-6]\u001b[A\n",
      " 54%|█████▍    | 2281/4220 [2:25:54<2:02:13,  3.78s/it, loss=2.86, epoch=0.54, learning_rate=8.78e-6]\u001b[A\n",
      " 54%|█████▍    | 2281/4220 [2:25:54<2:02:13,  3.78s/it, loss=2.97, epoch=0.54, learning_rate=8.77e-6]\u001b[A\n",
      " 54%|█████▍    | 2282/4220 [2:25:58<2:02:07,  3.78s/it, loss=2.97, epoch=0.54, learning_rate=8.77e-6]\u001b[A\n",
      " 54%|█████▍    | 2282/4220 [2:25:58<2:02:07,  3.78s/it, loss=2.63, epoch=0.541, learning_rate=8.76e-6]\u001b[A\n",
      " 54%|█████▍    | 2283/4220 [2:26:02<2:02:04,  3.78s/it, loss=2.63, epoch=0.541, learning_rate=8.76e-6]\u001b[A\n",
      " 54%|█████▍    | 2283/4220 [2:26:02<2:02:04,  3.78s/it, loss=2.58, epoch=0.541, learning_rate=8.76e-6]\u001b[A\n",
      " 54%|█████▍    | 2284/4220 [2:26:06<2:02:02,  3.78s/it, loss=2.58, epoch=0.541, learning_rate=8.76e-6]\u001b[A\n",
      " 54%|█████▍    | 2284/4220 [2:26:06<2:02:02,  3.78s/it, loss=2.5, epoch=0.541, learning_rate=8.75e-6] \u001b[A\n",
      " 54%|█████▍    | 2285/4220 [2:26:09<2:01:58,  3.78s/it, loss=2.5, epoch=0.541, learning_rate=8.75e-6]\u001b[A\n",
      " 54%|█████▍    | 2285/4220 [2:26:09<2:01:58,  3.78s/it, loss=2.76, epoch=0.541, learning_rate=8.74e-6]\u001b[A\n",
      " 54%|█████▍    | 2286/4220 [2:26:13<2:01:52,  3.78s/it, loss=2.76, epoch=0.541, learning_rate=8.74e-6]\u001b[A\n",
      " 54%|█████▍    | 2286/4220 [2:26:13<2:01:52,  3.78s/it, loss=2.77, epoch=0.541, learning_rate=8.73e-6]\u001b[A\n",
      " 54%|█████▍    | 2287/4220 [2:26:17<2:01:47,  3.78s/it, loss=2.77, epoch=0.541, learning_rate=8.73e-6]\u001b[A\n",
      " 54%|█████▍    | 2287/4220 [2:26:17<2:01:47,  3.78s/it, loss=2.98, epoch=0.542, learning_rate=8.73e-6]\u001b[A\n",
      " 54%|█████▍    | 2288/4220 [2:26:21<2:01:45,  3.78s/it, loss=2.98, epoch=0.542, learning_rate=8.73e-6]\u001b[A\n",
      " 54%|█████▍    | 2288/4220 [2:26:21<2:01:45,  3.78s/it, loss=3.79, epoch=0.542, learning_rate=8.72e-6]\u001b[A\n",
      " 54%|█████▍    | 2289/4220 [2:26:24<2:01:41,  3.78s/it, loss=3.79, epoch=0.542, learning_rate=8.72e-6]\u001b[A\n",
      " 54%|█████▍    | 2289/4220 [2:26:24<2:01:41,  3.78s/it, loss=3.08, epoch=0.542, learning_rate=8.71e-6]\u001b[A\n",
      " 54%|█████▍    | 2290/4220 [2:26:28<2:01:38,  3.78s/it, loss=3.08, epoch=0.542, learning_rate=8.71e-6]\u001b[A\n",
      " 54%|█████▍    | 2290/4220 [2:26:28<2:01:38,  3.78s/it, loss=2.67, epoch=0.542, learning_rate=8.71e-6]\u001b[A\n",
      " 54%|█████▍    | 2291/4220 [2:26:32<2:01:31,  3.78s/it, loss=2.67, epoch=0.542, learning_rate=8.71e-6]\u001b[A\n",
      " 54%|█████▍    | 2291/4220 [2:26:32<2:01:31,  3.78s/it, loss=3.17, epoch=0.543, learning_rate=8.7e-6] \u001b[A\n",
      " 54%|█████▍    | 2292/4220 [2:26:36<2:01:28,  3.78s/it, loss=3.17, epoch=0.543, learning_rate=8.7e-6]\u001b[A\n",
      " 54%|█████▍    | 2292/4220 [2:26:36<2:01:28,  3.78s/it, loss=2.57, epoch=0.543, learning_rate=8.69e-6]\u001b[A\n",
      " 54%|█████▍    | 2293/4220 [2:26:40<2:01:26,  3.78s/it, loss=2.57, epoch=0.543, learning_rate=8.69e-6]\u001b[A\n",
      " 54%|█████▍    | 2293/4220 [2:26:40<2:01:26,  3.78s/it, loss=2.96, epoch=0.543, learning_rate=8.68e-6]\u001b[A\n",
      " 54%|█████▍    | 2294/4220 [2:26:43<2:01:21,  3.78s/it, loss=2.96, epoch=0.543, learning_rate=8.68e-6]\u001b[A\n",
      " 54%|█████▍    | 2294/4220 [2:26:43<2:01:21,  3.78s/it, loss=2.67, epoch=0.543, learning_rate=8.68e-6]\u001b[A\n",
      " 54%|█████▍    | 2295/4220 [2:26:47<2:01:19,  3.78s/it, loss=2.67, epoch=0.543, learning_rate=8.68e-6]\u001b[A\n",
      " 54%|█████▍    | 2295/4220 [2:26:47<2:01:19,  3.78s/it, loss=3.56, epoch=0.544, learning_rate=8.67e-6]\u001b[A\n",
      " 54%|█████▍    | 2296/4220 [2:26:51<2:01:16,  3.78s/it, loss=3.56, epoch=0.544, learning_rate=8.67e-6]\u001b[A\n",
      " 54%|█████▍    | 2296/4220 [2:26:51<2:01:16,  3.78s/it, loss=2.84, epoch=0.544, learning_rate=8.66e-6]\u001b[A\n",
      " 54%|█████▍    | 2297/4220 [2:26:55<2:01:12,  3.78s/it, loss=2.84, epoch=0.544, learning_rate=8.66e-6]\u001b[A\n",
      " 54%|█████▍    | 2297/4220 [2:26:55<2:01:12,  3.78s/it, loss=2.84, epoch=0.544, learning_rate=8.65e-6]\u001b[A\n",
      " 54%|█████▍    | 2298/4220 [2:26:58<2:01:10,  3.78s/it, loss=2.84, epoch=0.544, learning_rate=8.65e-6]\u001b[A\n",
      " 54%|█████▍    | 2298/4220 [2:26:58<2:01:10,  3.78s/it, loss=2.79, epoch=0.544, learning_rate=8.65e-6]\u001b[A\n",
      " 54%|█████▍    | 2299/4220 [2:27:02<2:01:04,  3.78s/it, loss=2.79, epoch=0.544, learning_rate=8.65e-6]\u001b[A\n",
      " 54%|█████▍    | 2299/4220 [2:27:02<2:01:04,  3.78s/it, loss=3.01, epoch=0.545, learning_rate=8.64e-6]\u001b[A\n",
      " 55%|█████▍    | 2300/4220 [2:27:06<2:00:59,  3.78s/it, loss=3.01, epoch=0.545, learning_rate=8.64e-6]\u001b[A\n",
      " 55%|█████▍    | 2300/4220 [2:27:06<2:00:59,  3.78s/it, loss=2.81, epoch=0.545, learning_rate=8.63e-6]\u001b[A\n",
      " 55%|█████▍    | 2301/4220 [2:27:10<2:00:54,  3.78s/it, loss=2.81, epoch=0.545, learning_rate=8.63e-6]\u001b[A\n",
      " 55%|█████▍    | 2301/4220 [2:27:10<2:00:54,  3.78s/it, loss=2.94, epoch=0.545, learning_rate=8.62e-6]\u001b[A\n",
      " 55%|█████▍    | 2302/4220 [2:27:14<2:00:50,  3.78s/it, loss=2.94, epoch=0.545, learning_rate=8.62e-6]\u001b[A\n",
      " 55%|█████▍    | 2302/4220 [2:27:14<2:00:50,  3.78s/it, loss=2.64, epoch=0.545, learning_rate=8.62e-6]\u001b[A\n",
      " 55%|█████▍    | 2303/4220 [2:27:17<2:00:46,  3.78s/it, loss=2.64, epoch=0.545, learning_rate=8.62e-6]\u001b[A\n",
      " 55%|█████▍    | 2303/4220 [2:27:17<2:00:46,  3.78s/it, loss=2.84, epoch=0.545, learning_rate=8.61e-6]\u001b[A\n",
      " 55%|█████▍    | 2304/4220 [2:27:21<2:00:43,  3.78s/it, loss=2.84, epoch=0.545, learning_rate=8.61e-6]\u001b[A\n",
      " 55%|█████▍    | 2304/4220 [2:27:21<2:00:43,  3.78s/it, loss=2.77, epoch=0.546, learning_rate=8.6e-6] \u001b[A\n",
      " 55%|█████▍    | 2305/4220 [2:27:25<2:00:39,  3.78s/it, loss=2.77, epoch=0.546, learning_rate=8.6e-6]\u001b[A\n",
      " 55%|█████▍    | 2305/4220 [2:27:25<2:00:39,  3.78s/it, loss=2.8, epoch=0.546, learning_rate=8.59e-6]\u001b[A\n",
      " 55%|█████▍    | 2306/4220 [2:27:29<2:00:37,  3.78s/it, loss=2.8, epoch=0.546, learning_rate=8.59e-6]\u001b[A\n",
      " 55%|█████▍    | 2306/4220 [2:27:29<2:00:37,  3.78s/it, loss=2.84, epoch=0.546, learning_rate=8.59e-6]\u001b[A\n",
      " 55%|█████▍    | 2307/4220 [2:27:33<2:00:33,  3.78s/it, loss=2.84, epoch=0.546, learning_rate=8.59e-6]\u001b[A\n",
      " 55%|█████▍    | 2307/4220 [2:27:33<2:00:33,  3.78s/it, loss=3.36, epoch=0.546, learning_rate=8.58e-6]\u001b[A\n",
      " 55%|█████▍    | 2308/4220 [2:27:36<2:00:32,  3.78s/it, loss=3.36, epoch=0.546, learning_rate=8.58e-6]\u001b[A\n",
      " 55%|█████▍    | 2308/4220 [2:27:36<2:00:32,  3.78s/it, loss=2.67, epoch=0.547, learning_rate=8.57e-6]\u001b[A\n",
      " 55%|█████▍    | 2309/4220 [2:27:40<2:00:24,  3.78s/it, loss=2.67, epoch=0.547, learning_rate=8.57e-6]\u001b[A\n",
      " 55%|█████▍    | 2309/4220 [2:27:40<2:00:24,  3.78s/it, loss=2.66, epoch=0.547, learning_rate=8.56e-6]\u001b[A\n",
      " 55%|█████▍    | 2310/4220 [2:27:44<2:00:20,  3.78s/it, loss=2.66, epoch=0.547, learning_rate=8.56e-6]\u001b[A\n",
      " 55%|█████▍    | 2310/4220 [2:27:44<2:00:20,  3.78s/it, loss=3.16, epoch=0.547, learning_rate=8.56e-6]\u001b[A\n",
      " 55%|█████▍    | 2311/4220 [2:27:48<2:00:16,  3.78s/it, loss=3.16, epoch=0.547, learning_rate=8.56e-6]\u001b[A\n",
      " 55%|█████▍    | 2311/4220 [2:27:48<2:00:16,  3.78s/it, loss=2.56, epoch=0.547, learning_rate=8.55e-6]\u001b[A\n",
      " 55%|█████▍    | 2312/4220 [2:27:51<2:00:14,  3.78s/it, loss=2.56, epoch=0.547, learning_rate=8.55e-6]\u001b[A\n",
      " 55%|█████▍    | 2312/4220 [2:27:51<2:00:14,  3.78s/it, loss=2.69, epoch=0.548, learning_rate=8.54e-6]\u001b[A\n",
      " 55%|█████▍    | 2313/4220 [2:27:55<2:00:09,  3.78s/it, loss=2.69, epoch=0.548, learning_rate=8.54e-6]\u001b[A\n",
      " 55%|█████▍    | 2313/4220 [2:27:55<2:00:09,  3.78s/it, loss=2.88, epoch=0.548, learning_rate=8.54e-6]\u001b[A\n",
      " 55%|█████▍    | 2314/4220 [2:27:59<2:00:04,  3.78s/it, loss=2.88, epoch=0.548, learning_rate=8.54e-6]\u001b[A\n",
      " 55%|█████▍    | 2314/4220 [2:27:59<2:00:04,  3.78s/it, loss=2.77, epoch=0.548, learning_rate=8.53e-6]\u001b[A\n",
      " 55%|█████▍    | 2315/4220 [2:28:03<2:00:01,  3.78s/it, loss=2.77, epoch=0.548, learning_rate=8.53e-6]\u001b[A\n",
      " 55%|█████▍    | 2315/4220 [2:28:03<2:00:01,  3.78s/it, loss=3.4, epoch=0.548, learning_rate=8.52e-6] \u001b[A\n",
      " 55%|█████▍    | 2316/4220 [2:28:07<1:59:59,  3.78s/it, loss=3.4, epoch=0.548, learning_rate=8.52e-6]\u001b[A\n",
      " 55%|█████▍    | 2316/4220 [2:28:07<1:59:59,  3.78s/it, loss=2.39, epoch=0.549, learning_rate=8.51e-6]\u001b[A\n",
      " 55%|█████▍    | 2317/4220 [2:28:10<1:59:53,  3.78s/it, loss=2.39, epoch=0.549, learning_rate=8.51e-6]\u001b[A\n",
      " 55%|█████▍    | 2317/4220 [2:28:10<1:59:53,  3.78s/it, loss=3.12, epoch=0.549, learning_rate=8.51e-6]\u001b[A\n",
      " 55%|█████▍    | 2318/4220 [2:28:14<1:59:49,  3.78s/it, loss=3.12, epoch=0.549, learning_rate=8.51e-6]\u001b[A\n",
      " 55%|█████▍    | 2318/4220 [2:28:14<1:59:49,  3.78s/it, loss=2.73, epoch=0.549, learning_rate=8.5e-6] \u001b[A\n",
      " 55%|█████▍    | 2319/4220 [2:28:18<1:59:46,  3.78s/it, loss=2.73, epoch=0.549, learning_rate=8.5e-6]\u001b[A\n",
      " 55%|█████▍    | 2319/4220 [2:28:18<1:59:46,  3.78s/it, loss=2.73, epoch=0.549, learning_rate=8.49e-6]\u001b[A\n",
      " 55%|█████▍    | 2320/4220 [2:28:22<1:59:38,  3.78s/it, loss=2.73, epoch=0.549, learning_rate=8.49e-6]\u001b[A\n",
      " 55%|█████▍    | 2320/4220 [2:28:22<1:59:38,  3.78s/it, loss=3.13, epoch=0.55, learning_rate=8.48e-6] \u001b[A\n",
      " 55%|█████▌    | 2321/4220 [2:28:25<1:59:37,  3.78s/it, loss=3.13, epoch=0.55, learning_rate=8.48e-6]\u001b[A\n",
      " 55%|█████▌    | 2321/4220 [2:28:25<1:59:37,  3.78s/it, loss=3.06, epoch=0.55, learning_rate=8.48e-6]\u001b[A\n",
      " 55%|█████▌    | 2322/4220 [2:28:29<1:59:36,  3.78s/it, loss=3.06, epoch=0.55, learning_rate=8.48e-6]\u001b[A\n",
      " 55%|█████▌    | 2322/4220 [2:28:29<1:59:36,  3.78s/it, loss=3.05, epoch=0.55, learning_rate=8.47e-6]\u001b[A\n",
      " 55%|█████▌    | 2323/4220 [2:28:33<1:59:34,  3.78s/it, loss=3.05, epoch=0.55, learning_rate=8.47e-6]\u001b[A\n",
      " 55%|█████▌    | 2323/4220 [2:28:33<1:59:34,  3.78s/it, loss=2.64, epoch=0.55, learning_rate=8.46e-6]\u001b[A\n",
      " 55%|█████▌    | 2324/4220 [2:28:37<1:59:29,  3.78s/it, loss=2.64, epoch=0.55, learning_rate=8.46e-6]\u001b[A\n",
      " 55%|█████▌    | 2324/4220 [2:28:37<1:59:29,  3.78s/it, loss=2.46, epoch=0.55, learning_rate=8.45e-6]\u001b[A\n",
      " 55%|█████▌    | 2325/4220 [2:28:41<1:59:27,  3.78s/it, loss=2.46, epoch=0.55, learning_rate=8.45e-6]\u001b[A\n",
      " 55%|█████▌    | 2325/4220 [2:28:41<1:59:27,  3.78s/it, loss=2.62, epoch=0.551, learning_rate=8.45e-6]\u001b[A\n",
      " 55%|█████▌    | 2326/4220 [2:28:44<1:59:23,  3.78s/it, loss=2.62, epoch=0.551, learning_rate=8.45e-6]\u001b[A\n",
      " 55%|█████▌    | 2326/4220 [2:28:44<1:59:23,  3.78s/it, loss=3.05, epoch=0.551, learning_rate=8.44e-6]\u001b[A\n",
      " 55%|█████▌    | 2327/4220 [2:28:48<1:59:18,  3.78s/it, loss=3.05, epoch=0.551, learning_rate=8.44e-6]\u001b[A\n",
      " 55%|█████▌    | 2327/4220 [2:28:48<1:59:18,  3.78s/it, loss=2.56, epoch=0.551, learning_rate=8.43e-6]\u001b[A\n",
      " 55%|█████▌    | 2328/4220 [2:28:52<1:59:13,  3.78s/it, loss=2.56, epoch=0.551, learning_rate=8.43e-6]\u001b[A\n",
      " 55%|█████▌    | 2328/4220 [2:28:52<1:59:13,  3.78s/it, loss=2.72, epoch=0.551, learning_rate=8.42e-6]\u001b[A\n",
      " 55%|█████▌    | 2329/4220 [2:28:56<1:59:08,  3.78s/it, loss=2.72, epoch=0.551, learning_rate=8.42e-6]\u001b[A\n",
      " 55%|█████▌    | 2329/4220 [2:28:56<1:59:08,  3.78s/it, loss=2.35, epoch=0.552, learning_rate=8.42e-6]\u001b[A\n",
      " 55%|█████▌    | 2330/4220 [2:28:59<1:59:04,  3.78s/it, loss=2.35, epoch=0.552, learning_rate=8.42e-6]\u001b[A\n",
      " 55%|█████▌    | 2330/4220 [2:28:59<1:59:04,  3.78s/it, loss=2.63, epoch=0.552, learning_rate=8.41e-6]\u001b[A\n",
      " 55%|█████▌    | 2331/4220 [2:29:03<1:59:00,  3.78s/it, loss=2.63, epoch=0.552, learning_rate=8.41e-6]\u001b[A\n",
      " 55%|█████▌    | 2331/4220 [2:29:03<1:59:00,  3.78s/it, loss=2.99, epoch=0.552, learning_rate=8.4e-6] \u001b[A\n",
      " 55%|█████▌    | 2332/4220 [2:29:07<1:58:56,  3.78s/it, loss=2.99, epoch=0.552, learning_rate=8.4e-6]\u001b[A\n",
      " 55%|█████▌    | 2332/4220 [2:29:07<1:58:56,  3.78s/it, loss=3.07, epoch=0.552, learning_rate=8.4e-6]\u001b[A\n",
      " 55%|█████▌    | 2333/4220 [2:29:11<1:58:55,  3.78s/it, loss=3.07, epoch=0.552, learning_rate=8.4e-6]\u001b[A\n",
      " 55%|█████▌    | 2333/4220 [2:29:11<1:58:55,  3.78s/it, loss=3.03, epoch=0.553, learning_rate=8.39e-6]\u001b[A\n",
      " 55%|█████▌    | 2334/4220 [2:29:15<1:58:50,  3.78s/it, loss=3.03, epoch=0.553, learning_rate=8.39e-6]\u001b[A\n",
      " 55%|█████▌    | 2334/4220 [2:29:15<1:58:50,  3.78s/it, loss=2.43, epoch=0.553, learning_rate=8.38e-6]\u001b[A\n",
      " 55%|█████▌    | 2335/4220 [2:29:18<1:58:45,  3.78s/it, loss=2.43, epoch=0.553, learning_rate=8.38e-6]\u001b[A\n",
      " 55%|█████▌    | 2335/4220 [2:29:18<1:58:45,  3.78s/it, loss=2.6, epoch=0.553, learning_rate=8.37e-6] \u001b[A\n",
      " 55%|█████▌    | 2336/4220 [2:29:22<1:58:38,  3.78s/it, loss=2.6, epoch=0.553, learning_rate=8.37e-6]\u001b[A\n",
      " 55%|█████▌    | 2336/4220 [2:29:22<1:58:38,  3.78s/it, loss=2.75, epoch=0.553, learning_rate=8.37e-6]\u001b[A\n",
      " 55%|█████▌    | 2337/4220 [2:29:26<1:58:36,  3.78s/it, loss=2.75, epoch=0.553, learning_rate=8.37e-6]\u001b[A\n",
      " 55%|█████▌    | 2337/4220 [2:29:26<1:58:36,  3.78s/it, loss=3.14, epoch=0.554, learning_rate=8.36e-6]\u001b[A\n",
      " 55%|█████▌    | 2338/4220 [2:29:30<1:58:35,  3.78s/it, loss=3.14, epoch=0.554, learning_rate=8.36e-6]\u001b[A\n",
      " 55%|█████▌    | 2338/4220 [2:29:30<1:58:35,  3.78s/it, loss=3.03, epoch=0.554, learning_rate=8.35e-6]\u001b[A\n",
      " 55%|█████▌    | 2339/4220 [2:29:34<1:58:31,  3.78s/it, loss=3.03, epoch=0.554, learning_rate=8.35e-6]\u001b[A\n",
      " 55%|█████▌    | 2339/4220 [2:29:34<1:58:31,  3.78s/it, loss=3.12, epoch=0.554, learning_rate=8.34e-6]\u001b[A\n",
      " 55%|█████▌    | 2340/4220 [2:29:37<1:58:29,  3.78s/it, loss=3.12, epoch=0.554, learning_rate=8.34e-6]\u001b[A\n",
      " 55%|█████▌    | 2340/4220 [2:29:37<1:58:29,  3.78s/it, loss=2.69, epoch=0.554, learning_rate=8.34e-6]\u001b[A\n",
      " 55%|█████▌    | 2341/4220 [2:29:41<1:58:25,  3.78s/it, loss=2.69, epoch=0.554, learning_rate=8.34e-6]\u001b[A\n",
      " 55%|█████▌    | 2341/4220 [2:29:41<1:58:25,  3.78s/it, loss=3.03, epoch=0.555, learning_rate=8.33e-6]\u001b[A\n",
      " 55%|█████▌    | 2342/4220 [2:29:45<1:58:21,  3.78s/it, loss=3.03, epoch=0.555, learning_rate=8.33e-6]\u001b[A\n",
      " 55%|█████▌    | 2342/4220 [2:29:45<1:58:21,  3.78s/it, loss=2.69, epoch=0.555, learning_rate=8.32e-6]\u001b[A\n",
      " 56%|█████▌    | 2343/4220 [2:29:49<1:58:19,  3.78s/it, loss=2.69, epoch=0.555, learning_rate=8.32e-6]\u001b[A\n",
      " 56%|█████▌    | 2343/4220 [2:29:49<1:58:19,  3.78s/it, loss=3.01, epoch=0.555, learning_rate=8.31e-6]\u001b[A\n",
      " 56%|█████▌    | 2344/4220 [2:29:52<1:58:13,  3.78s/it, loss=3.01, epoch=0.555, learning_rate=8.31e-6]\u001b[A\n",
      " 56%|█████▌    | 2344/4220 [2:29:52<1:58:13,  3.78s/it, loss=2.92, epoch=0.555, learning_rate=8.31e-6]\u001b[A\n",
      " 56%|█████▌    | 2345/4220 [2:29:56<1:58:08,  3.78s/it, loss=2.92, epoch=0.555, learning_rate=8.31e-6]\u001b[A\n",
      " 56%|█████▌    | 2345/4220 [2:29:56<1:58:08,  3.78s/it, loss=3.07, epoch=0.555, learning_rate=8.3e-6] \u001b[A\n",
      " 56%|█████▌    | 2346/4220 [2:30:00<1:58:02,  3.78s/it, loss=3.07, epoch=0.555, learning_rate=8.3e-6]\u001b[A\n",
      " 56%|█████▌    | 2346/4220 [2:30:00<1:58:02,  3.78s/it, loss=2.71, epoch=0.556, learning_rate=8.29e-6]\u001b[A\n",
      " 56%|█████▌    | 2347/4220 [2:30:04<1:58:01,  3.78s/it, loss=2.71, epoch=0.556, learning_rate=8.29e-6]\u001b[A\n",
      " 56%|█████▌    | 2347/4220 [2:30:04<1:58:01,  3.78s/it, loss=2.87, epoch=0.556, learning_rate=8.28e-6]\u001b[A\n",
      " 56%|█████▌    | 2348/4220 [2:30:08<1:57:54,  3.78s/it, loss=2.87, epoch=0.556, learning_rate=8.28e-6]\u001b[A\n",
      " 56%|█████▌    | 2348/4220 [2:30:08<1:57:54,  3.78s/it, loss=2.41, epoch=0.556, learning_rate=8.28e-6]\u001b[A\n",
      " 56%|█████▌    | 2349/4220 [2:30:11<1:57:49,  3.78s/it, loss=2.41, epoch=0.556, learning_rate=8.28e-6]\u001b[A\n",
      " 56%|█████▌    | 2349/4220 [2:30:11<1:57:49,  3.78s/it, loss=2.7, epoch=0.556, learning_rate=8.27e-6] \u001b[A\n",
      " 56%|█████▌    | 2350/4220 [2:30:15<1:57:46,  3.78s/it, loss=2.7, epoch=0.556, learning_rate=8.27e-6]\u001b[A\n",
      " 56%|█████▌    | 2350/4220 [2:30:15<1:57:46,  3.78s/it, loss=2.8, epoch=0.557, learning_rate=8.26e-6]\u001b[A\n",
      " 56%|█████▌    | 2351/4220 [2:30:19<1:57:43,  3.78s/it, loss=2.8, epoch=0.557, learning_rate=8.26e-6]\u001b[A\n",
      " 56%|█████▌    | 2351/4220 [2:30:19<1:57:43,  3.78s/it, loss=3.29, epoch=0.557, learning_rate=8.26e-6]\u001b[A\n",
      " 56%|█████▌    | 2352/4220 [2:30:23<1:57:38,  3.78s/it, loss=3.29, epoch=0.557, learning_rate=8.26e-6]\u001b[A\n",
      " 56%|█████▌    | 2352/4220 [2:30:23<1:57:38,  3.78s/it, loss=2.66, epoch=0.557, learning_rate=8.25e-6]\u001b[A\n",
      " 56%|█████▌    | 2353/4220 [2:30:26<1:57:33,  3.78s/it, loss=2.66, epoch=0.557, learning_rate=8.25e-6]\u001b[A\n",
      " 56%|█████▌    | 2353/4220 [2:30:26<1:57:33,  3.78s/it, loss=2.41, epoch=0.557, learning_rate=8.24e-6]\u001b[A\n",
      " 56%|█████▌    | 2354/4220 [2:30:30<1:57:33,  3.78s/it, loss=2.41, epoch=0.557, learning_rate=8.24e-6]\u001b[A\n",
      " 56%|█████▌    | 2354/4220 [2:30:30<1:57:33,  3.78s/it, loss=3.04, epoch=0.558, learning_rate=8.23e-6]\u001b[A\n",
      " 56%|█████▌    | 2355/4220 [2:30:34<1:57:30,  3.78s/it, loss=3.04, epoch=0.558, learning_rate=8.23e-6]\u001b[A\n",
      " 56%|█████▌    | 2355/4220 [2:30:34<1:57:30,  3.78s/it, loss=3.04, epoch=0.558, learning_rate=8.23e-6]\u001b[A\n",
      " 56%|█████▌    | 2356/4220 [2:30:38<1:57:28,  3.78s/it, loss=3.04, epoch=0.558, learning_rate=8.23e-6]\u001b[A\n",
      " 56%|█████▌    | 2356/4220 [2:30:38<1:57:28,  3.78s/it, loss=2.78, epoch=0.558, learning_rate=8.22e-6]\u001b[A\n",
      " 56%|█████▌    | 2357/4220 [2:30:42<1:57:25,  3.78s/it, loss=2.78, epoch=0.558, learning_rate=8.22e-6]\u001b[A\n",
      " 56%|█████▌    | 2357/4220 [2:30:42<1:57:25,  3.78s/it, loss=3.01, epoch=0.558, learning_rate=8.21e-6]\u001b[A\n",
      " 56%|█████▌    | 2358/4220 [2:30:45<1:57:18,  3.78s/it, loss=3.01, epoch=0.558, learning_rate=8.21e-6]\u001b[A\n",
      " 56%|█████▌    | 2358/4220 [2:30:45<1:57:18,  3.78s/it, loss=2.64, epoch=0.559, learning_rate=8.2e-6] \u001b[A\n",
      " 56%|█████▌    | 2359/4220 [2:30:49<1:57:16,  3.78s/it, loss=2.64, epoch=0.559, learning_rate=8.2e-6]\u001b[A\n",
      " 56%|█████▌    | 2359/4220 [2:30:49<1:57:16,  3.78s/it, loss=2.67, epoch=0.559, learning_rate=8.2e-6]\u001b[A\n",
      " 56%|█████▌    | 2360/4220 [2:30:53<1:57:14,  3.78s/it, loss=2.67, epoch=0.559, learning_rate=8.2e-6]\u001b[A\n",
      " 56%|█████▌    | 2360/4220 [2:30:53<1:57:14,  3.78s/it, loss=2.75, epoch=0.559, learning_rate=8.19e-6]\u001b[A\n",
      " 56%|█████▌    | 2361/4220 [2:30:57<1:57:11,  3.78s/it, loss=2.75, epoch=0.559, learning_rate=8.19e-6]\u001b[A\n",
      " 56%|█████▌    | 2361/4220 [2:30:57<1:57:11,  3.78s/it, loss=3.15, epoch=0.559, learning_rate=8.18e-6]\u001b[A\n",
      " 56%|█████▌    | 2362/4220 [2:31:00<1:57:09,  3.78s/it, loss=3.15, epoch=0.559, learning_rate=8.18e-6]\u001b[A\n",
      " 56%|█████▌    | 2362/4220 [2:31:00<1:57:09,  3.78s/it, loss=3.1, epoch=0.559, learning_rate=8.17e-6] \u001b[A\n",
      " 56%|█████▌    | 2363/4220 [2:31:04<1:57:01,  3.78s/it, loss=3.1, epoch=0.559, learning_rate=8.17e-6]\u001b[A\n",
      " 56%|█████▌    | 2363/4220 [2:31:04<1:57:01,  3.78s/it, loss=3.14, epoch=0.56, learning_rate=8.17e-6]\u001b[A\n",
      " 56%|█████▌    | 2364/4220 [2:31:08<1:56:59,  3.78s/it, loss=3.14, epoch=0.56, learning_rate=8.17e-6]\u001b[A\n",
      " 56%|█████▌    | 2364/4220 [2:31:08<1:56:59,  3.78s/it, loss=2.54, epoch=0.56, learning_rate=8.16e-6]\u001b[A\n",
      " 56%|█████▌    | 2365/4220 [2:31:12<1:56:55,  3.78s/it, loss=2.54, epoch=0.56, learning_rate=8.16e-6]\u001b[A\n",
      " 56%|█████▌    | 2365/4220 [2:31:12<1:56:55,  3.78s/it, loss=2.81, epoch=0.56, learning_rate=8.15e-6]\u001b[A\n",
      " 56%|█████▌    | 2366/4220 [2:31:16<1:56:50,  3.78s/it, loss=2.81, epoch=0.56, learning_rate=8.15e-6]\u001b[A\n",
      " 56%|█████▌    | 2366/4220 [2:31:16<1:56:50,  3.78s/it, loss=2.8, epoch=0.56, learning_rate=8.15e-6] \u001b[A\n",
      " 56%|█████▌    | 2367/4220 [2:31:19<1:56:45,  3.78s/it, loss=2.8, epoch=0.56, learning_rate=8.15e-6]\u001b[A\n",
      " 56%|█████▌    | 2367/4220 [2:31:19<1:56:45,  3.78s/it, loss=3.14, epoch=0.561, learning_rate=8.14e-6]\u001b[A\n",
      " 56%|█████▌    | 2368/4220 [2:31:23<1:56:45,  3.78s/it, loss=3.14, epoch=0.561, learning_rate=8.14e-6]\u001b[A\n",
      " 56%|█████▌    | 2368/4220 [2:31:23<1:56:45,  3.78s/it, loss=2.96, epoch=0.561, learning_rate=8.13e-6]\u001b[A\n",
      " 56%|█████▌    | 2369/4220 [2:31:27<1:56:39,  3.78s/it, loss=2.96, epoch=0.561, learning_rate=8.13e-6]\u001b[A\n",
      " 56%|█████▌    | 2369/4220 [2:31:27<1:56:39,  3.78s/it, loss=2.94, epoch=0.561, learning_rate=8.12e-6]\u001b[A\n",
      " 56%|█████▌    | 2370/4220 [2:31:31<1:56:34,  3.78s/it, loss=2.94, epoch=0.561, learning_rate=8.12e-6]\u001b[A\n",
      " 56%|█████▌    | 2370/4220 [2:31:31<1:56:34,  3.78s/it, loss=2.36, epoch=0.561, learning_rate=8.12e-6]\u001b[A\n",
      " 56%|█████▌    | 2371/4220 [2:31:34<1:56:31,  3.78s/it, loss=2.36, epoch=0.561, learning_rate=8.12e-6]\u001b[A\n",
      " 56%|█████▌    | 2371/4220 [2:31:34<1:56:31,  3.78s/it, loss=3.44, epoch=0.562, learning_rate=8.11e-6]\u001b[A\n",
      " 56%|█████▌    | 2372/4220 [2:31:38<1:56:28,  3.78s/it, loss=3.44, epoch=0.562, learning_rate=8.11e-6]\u001b[A\n",
      " 56%|█████▌    | 2372/4220 [2:31:38<1:56:28,  3.78s/it, loss=2.92, epoch=0.562, learning_rate=8.1e-6] \u001b[A\n",
      " 56%|█████▌    | 2373/4220 [2:31:42<1:56:23,  3.78s/it, loss=2.92, epoch=0.562, learning_rate=8.1e-6]\u001b[A\n",
      " 56%|█████▌    | 2373/4220 [2:31:42<1:56:23,  3.78s/it, loss=2.66, epoch=0.562, learning_rate=8.09e-6]\u001b[A\n",
      " 56%|█████▋    | 2374/4220 [2:31:46<1:56:18,  3.78s/it, loss=2.66, epoch=0.562, learning_rate=8.09e-6]\u001b[A\n",
      " 56%|█████▋    | 2374/4220 [2:31:46<1:56:18,  3.78s/it, loss=2.57, epoch=0.562, learning_rate=8.09e-6]\u001b[A\n",
      " 56%|█████▋    | 2375/4220 [2:31:50<1:56:15,  3.78s/it, loss=2.57, epoch=0.562, learning_rate=8.09e-6]\u001b[A\n",
      " 56%|█████▋    | 2375/4220 [2:31:50<1:56:15,  3.78s/it, loss=2.91, epoch=0.563, learning_rate=8.08e-6]\u001b[A\n",
      " 56%|█████▋    | 2376/4220 [2:31:53<1:56:12,  3.78s/it, loss=2.91, epoch=0.563, learning_rate=8.08e-6]\u001b[A\n",
      " 56%|█████▋    | 2376/4220 [2:31:53<1:56:12,  3.78s/it, loss=2.92, epoch=0.563, learning_rate=8.07e-6]\u001b[A\n",
      " 56%|█████▋    | 2377/4220 [2:31:57<1:56:09,  3.78s/it, loss=2.92, epoch=0.563, learning_rate=8.07e-6]\u001b[A\n",
      " 56%|█████▋    | 2377/4220 [2:31:57<1:56:09,  3.78s/it, loss=2.77, epoch=0.563, learning_rate=8.06e-6]\u001b[A\n",
      " 56%|█████▋    | 2378/4220 [2:32:01<1:56:03,  3.78s/it, loss=2.77, epoch=0.563, learning_rate=8.06e-6]\u001b[A\n",
      " 56%|█████▋    | 2378/4220 [2:32:01<1:56:03,  3.78s/it, loss=3.1, epoch=0.563, learning_rate=8.06e-6] \u001b[A\n",
      " 56%|█████▋    | 2379/4220 [2:32:05<1:56:00,  3.78s/it, loss=3.1, epoch=0.563, learning_rate=8.06e-6]\u001b[A\n",
      " 56%|█████▋    | 2379/4220 [2:32:05<1:56:00,  3.78s/it, loss=2.82, epoch=0.564, learning_rate=8.05e-6]\u001b[A\n",
      " 56%|█████▋    | 2380/4220 [2:32:09<1:55:55,  3.78s/it, loss=2.82, epoch=0.564, learning_rate=8.05e-6]\u001b[A\n",
      " 56%|█████▋    | 2380/4220 [2:32:09<1:55:55,  3.78s/it, loss=2.09, epoch=0.564, learning_rate=8.04e-6]\u001b[A\n",
      " 56%|█████▋    | 2381/4220 [2:32:12<1:55:48,  3.78s/it, loss=2.09, epoch=0.564, learning_rate=8.04e-6]\u001b[A\n",
      " 56%|█████▋    | 2381/4220 [2:32:12<1:55:48,  3.78s/it, loss=2.88, epoch=0.564, learning_rate=8.04e-6]\u001b[A\n",
      " 56%|█████▋    | 2382/4220 [2:32:16<1:55:46,  3.78s/it, loss=2.88, epoch=0.564, learning_rate=8.04e-6]\u001b[A\n",
      " 56%|█████▋    | 2382/4220 [2:32:16<1:55:46,  3.78s/it, loss=2.78, epoch=0.564, learning_rate=8.03e-6]\u001b[A\n",
      " 56%|█████▋    | 2383/4220 [2:32:20<1:55:43,  3.78s/it, loss=2.78, epoch=0.564, learning_rate=8.03e-6]\u001b[A\n",
      " 56%|█████▋    | 2383/4220 [2:32:20<1:55:43,  3.78s/it, loss=3.01, epoch=0.564, learning_rate=8.02e-6]\u001b[A\n",
      " 56%|█████▋    | 2384/4220 [2:32:24<1:55:38,  3.78s/it, loss=3.01, epoch=0.564, learning_rate=8.02e-6]\u001b[A\n",
      " 56%|█████▋    | 2384/4220 [2:32:24<1:55:38,  3.78s/it, loss=2.98, epoch=0.565, learning_rate=8.01e-6]\u001b[A\n",
      " 57%|█████▋    | 2385/4220 [2:32:27<1:55:35,  3.78s/it, loss=2.98, epoch=0.565, learning_rate=8.01e-6]\u001b[A\n",
      " 57%|█████▋    | 2385/4220 [2:32:27<1:55:35,  3.78s/it, loss=2.55, epoch=0.565, learning_rate=8.01e-6]\u001b[A\n",
      " 57%|█████▋    | 2386/4220 [2:32:31<1:55:34,  3.78s/it, loss=2.55, epoch=0.565, learning_rate=8.01e-6]\u001b[A\n",
      " 57%|█████▋    | 2386/4220 [2:32:31<1:55:34,  3.78s/it, loss=2.46, epoch=0.565, learning_rate=8e-6]   \u001b[A\n",
      " 57%|█████▋    | 2387/4220 [2:32:35<1:55:32,  3.78s/it, loss=2.46, epoch=0.565, learning_rate=8e-6]\u001b[A\n",
      " 57%|█████▋    | 2387/4220 [2:32:35<1:55:32,  3.78s/it, loss=2.86, epoch=0.565, learning_rate=7.99e-6]\u001b[A\n",
      " 57%|█████▋    | 2388/4220 [2:32:39<1:55:26,  3.78s/it, loss=2.86, epoch=0.565, learning_rate=7.99e-6]\u001b[A\n",
      " 57%|█████▋    | 2388/4220 [2:32:39<1:55:26,  3.78s/it, loss=2.67, epoch=0.566, learning_rate=7.98e-6]\u001b[A\n",
      " 57%|█████▋    | 2389/4220 [2:32:43<1:55:23,  3.78s/it, loss=2.67, epoch=0.566, learning_rate=7.98e-6]\u001b[A\n",
      " 57%|█████▋    | 2389/4220 [2:32:43<1:55:23,  3.78s/it, loss=3.2, epoch=0.566, learning_rate=7.98e-6] \u001b[A\n",
      " 57%|█████▋    | 2390/4220 [2:32:46<1:55:21,  3.78s/it, loss=3.2, epoch=0.566, learning_rate=7.98e-6]\u001b[A\n",
      " 57%|█████▋    | 2390/4220 [2:32:46<1:55:21,  3.78s/it, loss=3.26, epoch=0.566, learning_rate=7.97e-6]\u001b[A\n",
      " 57%|█████▋    | 2391/4220 [2:32:50<1:55:16,  3.78s/it, loss=3.26, epoch=0.566, learning_rate=7.97e-6]\u001b[A\n",
      " 57%|█████▋    | 2391/4220 [2:32:50<1:55:16,  3.78s/it, loss=2.75, epoch=0.566, learning_rate=7.96e-6]\u001b[A\n",
      " 57%|█████▋    | 2392/4220 [2:32:54<1:55:11,  3.78s/it, loss=2.75, epoch=0.566, learning_rate=7.96e-6]\u001b[A\n",
      " 57%|█████▋    | 2392/4220 [2:32:54<1:55:11,  3.78s/it, loss=2.95, epoch=0.567, learning_rate=7.95e-6]\u001b[A\n",
      " 57%|█████▋    | 2393/4220 [2:32:58<1:55:05,  3.78s/it, loss=2.95, epoch=0.567, learning_rate=7.95e-6]\u001b[A\n",
      " 57%|█████▋    | 2393/4220 [2:32:58<1:55:05,  3.78s/it, loss=3.03, epoch=0.567, learning_rate=7.95e-6]\u001b[A\n",
      " 57%|█████▋    | 2394/4220 [2:33:01<1:55:03,  3.78s/it, loss=3.03, epoch=0.567, learning_rate=7.95e-6]\u001b[A\n",
      " 57%|█████▋    | 2394/4220 [2:33:01<1:55:03,  3.78s/it, loss=2.83, epoch=0.567, learning_rate=7.94e-6]\u001b[A\n",
      " 57%|█████▋    | 2395/4220 [2:33:05<1:54:59,  3.78s/it, loss=2.83, epoch=0.567, learning_rate=7.94e-6]\u001b[A\n",
      " 57%|█████▋    | 2395/4220 [2:33:05<1:54:59,  3.78s/it, loss=3.05, epoch=0.567, learning_rate=7.93e-6]\u001b[A\n",
      " 57%|█████▋    | 2396/4220 [2:33:09<1:54:57,  3.78s/it, loss=3.05, epoch=0.567, learning_rate=7.93e-6]\u001b[A\n",
      " 57%|█████▋    | 2396/4220 [2:33:09<1:54:57,  3.78s/it, loss=2.48, epoch=0.568, learning_rate=7.93e-6]\u001b[A\n",
      " 57%|█████▋    | 2397/4220 [2:33:13<1:54:53,  3.78s/it, loss=2.48, epoch=0.568, learning_rate=7.93e-6]\u001b[A\n",
      " 57%|█████▋    | 2397/4220 [2:33:13<1:54:53,  3.78s/it, loss=2.96, epoch=0.568, learning_rate=7.92e-6]\u001b[A\n",
      " 57%|█████▋    | 2398/4220 [2:33:17<1:54:47,  3.78s/it, loss=2.96, epoch=0.568, learning_rate=7.92e-6]\u001b[A\n",
      " 57%|█████▋    | 2398/4220 [2:33:17<1:54:47,  3.78s/it, loss=3, epoch=0.568, learning_rate=7.91e-6]   \u001b[A\n",
      " 57%|█████▋    | 2399/4220 [2:33:20<1:54:44,  3.78s/it, loss=3, epoch=0.568, learning_rate=7.91e-6]\u001b[A\n",
      " 57%|█████▋    | 2399/4220 [2:33:20<1:54:44,  3.78s/it, loss=2.74, epoch=0.568, learning_rate=7.9e-6]\u001b[A\n",
      " 57%|█████▋    | 2400/4220 [2:33:24<1:54:40,  3.78s/it, loss=2.74, epoch=0.568, learning_rate=7.9e-6]\u001b[A\n",
      " 57%|█████▋    | 2400/4220 [2:33:24<1:54:40,  3.78s/it, loss=2.78, epoch=0.568, learning_rate=7.9e-6]\u001b[A\n",
      " 57%|█████▋    | 2401/4220 [2:33:28<1:54:35,  3.78s/it, loss=2.78, epoch=0.568, learning_rate=7.9e-6]\u001b[A\n",
      " 57%|█████▋    | 2401/4220 [2:33:28<1:54:35,  3.78s/it, loss=3.05, epoch=0.569, learning_rate=7.89e-6]\u001b[A\n",
      " 57%|█████▋    | 2402/4220 [2:33:32<1:54:31,  3.78s/it, loss=3.05, epoch=0.569, learning_rate=7.89e-6]\u001b[A\n",
      " 57%|█████▋    | 2402/4220 [2:33:32<1:54:31,  3.78s/it, loss=2.55, epoch=0.569, learning_rate=7.88e-6]\u001b[A\n",
      " 57%|█████▋    | 2403/4220 [2:33:35<1:54:29,  3.78s/it, loss=2.55, epoch=0.569, learning_rate=7.88e-6]\u001b[A\n",
      " 57%|█████▋    | 2403/4220 [2:33:35<1:54:29,  3.78s/it, loss=2.38, epoch=0.569, learning_rate=7.87e-6]\u001b[A\n",
      " 57%|█████▋    | 2404/4220 [2:33:39<1:54:28,  3.78s/it, loss=2.38, epoch=0.569, learning_rate=7.87e-6]\u001b[A\n",
      " 57%|█████▋    | 2404/4220 [2:33:39<1:54:28,  3.78s/it, loss=2.81, epoch=0.569, learning_rate=7.87e-6]\u001b[A\n",
      " 57%|█████▋    | 2405/4220 [2:33:43<1:55:12,  3.81s/it, loss=2.81, epoch=0.569, learning_rate=7.87e-6]\u001b[A\n",
      " 57%|█████▋    | 2405/4220 [2:33:43<1:55:12,  3.81s/it, loss=2.31, epoch=0.57, learning_rate=7.86e-6] \u001b[A\n",
      " 57%|█████▋    | 2406/4220 [2:33:47<1:54:54,  3.80s/it, loss=2.31, epoch=0.57, learning_rate=7.86e-6]\u001b[A\n",
      " 57%|█████▋    | 2406/4220 [2:33:47<1:54:54,  3.80s/it, loss=3.39, epoch=0.57, learning_rate=7.85e-6]\u001b[A\n",
      " 57%|█████▋    | 2407/4220 [2:33:51<1:54:40,  3.80s/it, loss=3.39, epoch=0.57, learning_rate=7.85e-6]\u001b[A\n",
      " 57%|█████▋    | 2407/4220 [2:33:51<1:54:40,  3.80s/it, loss=2.65, epoch=0.57, learning_rate=7.85e-6]\u001b[A\n",
      " 57%|█████▋    | 2408/4220 [2:33:54<1:54:27,  3.79s/it, loss=2.65, epoch=0.57, learning_rate=7.85e-6]\u001b[A\n",
      " 57%|█████▋    | 2408/4220 [2:33:54<1:54:27,  3.79s/it, loss=3.04, epoch=0.57, learning_rate=7.84e-6]\u001b[A\n",
      " 57%|█████▋    | 2409/4220 [2:33:58<1:54:18,  3.79s/it, loss=3.04, epoch=0.57, learning_rate=7.84e-6]\u001b[A\n",
      " 57%|█████▋    | 2409/4220 [2:33:58<1:54:18,  3.79s/it, loss=2.84, epoch=0.571, learning_rate=7.83e-6]\u001b[A\n",
      " 57%|█████▋    | 2410/4220 [2:34:02<1:54:13,  3.79s/it, loss=2.84, epoch=0.571, learning_rate=7.83e-6]\u001b[A\n",
      " 57%|█████▋    | 2410/4220 [2:34:02<1:54:13,  3.79s/it, loss=3.02, epoch=0.571, learning_rate=7.82e-6]\u001b[A\n",
      " 57%|█████▋    | 2411/4220 [2:34:06<1:54:06,  3.78s/it, loss=3.02, epoch=0.571, learning_rate=7.82e-6]\u001b[A\n",
      " 57%|█████▋    | 2411/4220 [2:34:06<1:54:06,  3.78s/it, loss=2.89, epoch=0.571, learning_rate=7.82e-6]\u001b[A\n",
      " 57%|█████▋    | 2412/4220 [2:34:10<1:54:00,  3.78s/it, loss=2.89, epoch=0.571, learning_rate=7.82e-6]\u001b[A\n",
      " 57%|█████▋    | 2412/4220 [2:34:10<1:54:00,  3.78s/it, loss=2.44, epoch=0.571, learning_rate=7.81e-6]\u001b[A\n",
      " 57%|█████▋    | 2413/4220 [2:34:13<1:53:56,  3.78s/it, loss=2.44, epoch=0.571, learning_rate=7.81e-6]\u001b[A\n",
      " 57%|█████▋    | 2413/4220 [2:34:13<1:53:56,  3.78s/it, loss=3.13, epoch=0.572, learning_rate=7.8e-6] \u001b[A\n",
      " 57%|█████▋    | 2414/4220 [2:34:17<1:53:52,  3.78s/it, loss=3.13, epoch=0.572, learning_rate=7.8e-6]\u001b[A\n",
      " 57%|█████▋    | 2414/4220 [2:34:17<1:53:52,  3.78s/it, loss=2.48, epoch=0.572, learning_rate=7.79e-6]\u001b[A\n",
      " 57%|█████▋    | 2415/4220 [2:34:21<1:53:45,  3.78s/it, loss=2.48, epoch=0.572, learning_rate=7.79e-6]\u001b[A\n",
      " 57%|█████▋    | 2415/4220 [2:34:21<1:53:45,  3.78s/it, loss=2.9, epoch=0.572, learning_rate=7.79e-6] \u001b[A\n",
      " 57%|█████▋    | 2416/4220 [2:34:25<1:53:41,  3.78s/it, loss=2.9, epoch=0.572, learning_rate=7.79e-6]\u001b[A\n",
      " 57%|█████▋    | 2416/4220 [2:34:25<1:53:41,  3.78s/it, loss=3.01, epoch=0.572, learning_rate=7.78e-6]\u001b[A\n",
      " 57%|█████▋    | 2417/4220 [2:34:28<1:53:35,  3.78s/it, loss=3.01, epoch=0.572, learning_rate=7.78e-6]\u001b[A\n",
      " 57%|█████▋    | 2417/4220 [2:34:28<1:53:35,  3.78s/it, loss=3.15, epoch=0.573, learning_rate=7.77e-6]\u001b[A\n",
      " 57%|█████▋    | 2418/4220 [2:34:32<1:53:32,  3.78s/it, loss=3.15, epoch=0.573, learning_rate=7.77e-6]\u001b[A\n",
      " 57%|█████▋    | 2418/4220 [2:34:32<1:53:32,  3.78s/it, loss=3.48, epoch=0.573, learning_rate=7.77e-6]\u001b[A\n",
      " 57%|█████▋    | 2419/4220 [2:34:36<1:53:29,  3.78s/it, loss=3.48, epoch=0.573, learning_rate=7.77e-6]\u001b[A\n",
      " 57%|█████▋    | 2419/4220 [2:34:36<1:53:29,  3.78s/it, loss=2.66, epoch=0.573, learning_rate=7.76e-6]\u001b[A\n",
      " 57%|█████▋    | 2420/4220 [2:34:40<1:53:27,  3.78s/it, loss=2.66, epoch=0.573, learning_rate=7.76e-6]\u001b[A\n",
      " 57%|█████▋    | 2420/4220 [2:34:40<1:53:27,  3.78s/it, loss=3.48, epoch=0.573, learning_rate=7.75e-6]\u001b[A\n",
      " 57%|█████▋    | 2421/4220 [2:34:44<1:53:23,  3.78s/it, loss=3.48, epoch=0.573, learning_rate=7.75e-6]\u001b[A\n",
      " 57%|█████▋    | 2421/4220 [2:34:44<1:53:23,  3.78s/it, loss=2.43, epoch=0.573, learning_rate=7.74e-6]\u001b[A\n",
      " 57%|█████▋    | 2422/4220 [2:34:47<1:53:18,  3.78s/it, loss=2.43, epoch=0.573, learning_rate=7.74e-6]\u001b[A\n",
      " 57%|█████▋    | 2422/4220 [2:34:47<1:53:18,  3.78s/it, loss=2.91, epoch=0.574, learning_rate=7.74e-6]\u001b[A\n",
      " 57%|█████▋    | 2423/4220 [2:34:51<1:53:15,  3.78s/it, loss=2.91, epoch=0.574, learning_rate=7.74e-6]\u001b[A\n",
      " 57%|█████▋    | 2423/4220 [2:34:51<1:53:15,  3.78s/it, loss=2.58, epoch=0.574, learning_rate=7.73e-6]\u001b[A\n",
      " 57%|█████▋    | 2424/4220 [2:34:55<1:53:07,  3.78s/it, loss=2.58, epoch=0.574, learning_rate=7.73e-6]\u001b[A\n",
      " 57%|█████▋    | 2424/4220 [2:34:55<1:53:07,  3.78s/it, loss=2.7, epoch=0.574, learning_rate=7.72e-6] \u001b[A\n",
      " 57%|█████▋    | 2425/4220 [2:34:59<1:53:05,  3.78s/it, loss=2.7, epoch=0.574, learning_rate=7.72e-6]\u001b[A\n",
      " 57%|█████▋    | 2425/4220 [2:34:59<1:53:05,  3.78s/it, loss=3.09, epoch=0.574, learning_rate=7.71e-6]\u001b[A\n",
      " 57%|█████▋    | 2426/4220 [2:35:03<1:53:00,  3.78s/it, loss=3.09, epoch=0.574, learning_rate=7.71e-6]\u001b[A\n",
      " 57%|█████▋    | 2426/4220 [2:35:03<1:53:00,  3.78s/it, loss=2.79, epoch=0.575, learning_rate=7.71e-6]\u001b[A\n",
      " 58%|█████▊    | 2427/4220 [2:35:06<1:52:58,  3.78s/it, loss=2.79, epoch=0.575, learning_rate=7.71e-6]\u001b[A\n",
      " 58%|█████▊    | 2427/4220 [2:35:06<1:52:58,  3.78s/it, loss=3.14, epoch=0.575, learning_rate=7.7e-6] \u001b[A\n",
      " 58%|█████▊    | 2428/4220 [2:35:10<1:52:56,  3.78s/it, loss=3.14, epoch=0.575, learning_rate=7.7e-6]\u001b[A\n",
      " 58%|█████▊    | 2428/4220 [2:35:10<1:52:56,  3.78s/it, loss=2.54, epoch=0.575, learning_rate=7.69e-6]\u001b[A\n",
      " 58%|█████▊    | 2429/4220 [2:35:14<1:52:51,  3.78s/it, loss=2.54, epoch=0.575, learning_rate=7.69e-6]\u001b[A\n",
      " 58%|█████▊    | 2429/4220 [2:35:14<1:52:51,  3.78s/it, loss=2.64, epoch=0.575, learning_rate=7.69e-6]\u001b[A\n",
      " 58%|█████▊    | 2430/4220 [2:35:18<1:52:43,  3.78s/it, loss=2.64, epoch=0.575, learning_rate=7.69e-6]\u001b[A\n",
      " 58%|█████▊    | 2430/4220 [2:35:18<1:52:43,  3.78s/it, loss=2.8, epoch=0.576, learning_rate=7.68e-6] \u001b[A\n",
      " 58%|█████▊    | 2431/4220 [2:35:21<1:52:40,  3.78s/it, loss=2.8, epoch=0.576, learning_rate=7.68e-6]\u001b[A\n",
      " 58%|█████▊    | 2431/4220 [2:35:21<1:52:40,  3.78s/it, loss=2.86, epoch=0.576, learning_rate=7.67e-6]\u001b[A\n",
      " 58%|█████▊    | 2432/4220 [2:35:25<1:52:36,  3.78s/it, loss=2.86, epoch=0.576, learning_rate=7.67e-6]\u001b[A\n",
      " 58%|█████▊    | 2432/4220 [2:35:25<1:52:36,  3.78s/it, loss=2.97, epoch=0.576, learning_rate=7.66e-6]\u001b[A\n",
      " 58%|█████▊    | 2433/4220 [2:35:29<1:52:32,  3.78s/it, loss=2.97, epoch=0.576, learning_rate=7.66e-6]\u001b[A\n",
      " 58%|█████▊    | 2433/4220 [2:35:29<1:52:32,  3.78s/it, loss=2.91, epoch=0.576, learning_rate=7.66e-6]\u001b[A\n",
      " 58%|█████▊    | 2434/4220 [2:35:33<1:52:32,  3.78s/it, loss=2.91, epoch=0.576, learning_rate=7.66e-6]\u001b[A\n",
      " 58%|█████▊    | 2434/4220 [2:35:33<1:52:32,  3.78s/it, loss=3.04, epoch=0.577, learning_rate=7.65e-6]\u001b[A\n",
      " 58%|█████▊    | 2435/4220 [2:35:37<1:52:28,  3.78s/it, loss=3.04, epoch=0.577, learning_rate=7.65e-6]\u001b[A\n",
      " 58%|█████▊    | 2435/4220 [2:35:37<1:52:28,  3.78s/it, loss=2.62, epoch=0.577, learning_rate=7.64e-6]\u001b[A\n",
      " 58%|█████▊    | 2436/4220 [2:35:40<1:52:24,  3.78s/it, loss=2.62, epoch=0.577, learning_rate=7.64e-6]\u001b[A\n",
      " 58%|█████▊    | 2436/4220 [2:35:40<1:52:24,  3.78s/it, loss=3.25, epoch=0.577, learning_rate=7.63e-6]\u001b[A\n",
      " 58%|█████▊    | 2437/4220 [2:35:44<1:52:21,  3.78s/it, loss=3.25, epoch=0.577, learning_rate=7.63e-6]\u001b[A\n",
      " 58%|█████▊    | 2437/4220 [2:35:44<1:52:21,  3.78s/it, loss=3.04, epoch=0.577, learning_rate=7.63e-6]\u001b[A\n",
      " 58%|█████▊    | 2438/4220 [2:35:48<1:52:19,  3.78s/it, loss=3.04, epoch=0.577, learning_rate=7.63e-6]\u001b[A\n",
      " 58%|█████▊    | 2438/4220 [2:35:48<1:52:19,  3.78s/it, loss=2.91, epoch=0.577, learning_rate=7.62e-6]\u001b[A\n",
      " 58%|█████▊    | 2439/4220 [2:35:52<1:52:15,  3.78s/it, loss=2.91, epoch=0.577, learning_rate=7.62e-6]\u001b[A\n",
      " 58%|█████▊    | 2439/4220 [2:35:52<1:52:15,  3.78s/it, loss=2.51, epoch=0.578, learning_rate=7.61e-6]\u001b[A\n",
      " 58%|█████▊    | 2440/4220 [2:35:55<1:52:11,  3.78s/it, loss=2.51, epoch=0.578, learning_rate=7.61e-6]\u001b[A\n",
      " 58%|█████▊    | 2440/4220 [2:35:55<1:52:11,  3.78s/it, loss=2.65, epoch=0.578, learning_rate=7.61e-6]\u001b[A\n",
      " 58%|█████▊    | 2441/4220 [2:35:59<1:52:10,  3.78s/it, loss=2.65, epoch=0.578, learning_rate=7.61e-6]\u001b[A\n",
      " 58%|█████▊    | 2441/4220 [2:35:59<1:52:10,  3.78s/it, loss=2.71, epoch=0.578, learning_rate=7.6e-6] \u001b[A\n",
      " 58%|█████▊    | 2442/4220 [2:36:03<1:52:04,  3.78s/it, loss=2.71, epoch=0.578, learning_rate=7.6e-6]\u001b[A\n",
      " 58%|█████▊    | 2442/4220 [2:36:03<1:52:04,  3.78s/it, loss=2.63, epoch=0.578, learning_rate=7.59e-6]\u001b[A\n",
      " 58%|█████▊    | 2443/4220 [2:36:07<1:51:59,  3.78s/it, loss=2.63, epoch=0.578, learning_rate=7.59e-6]\u001b[A\n",
      " 58%|█████▊    | 2443/4220 [2:36:07<1:51:59,  3.78s/it, loss=3.01, epoch=0.579, learning_rate=7.58e-6]\u001b[A\n",
      " 58%|█████▊    | 2444/4220 [2:36:11<1:51:56,  3.78s/it, loss=3.01, epoch=0.579, learning_rate=7.58e-6]\u001b[A\n",
      " 58%|█████▊    | 2444/4220 [2:36:11<1:51:56,  3.78s/it, loss=3.37, epoch=0.579, learning_rate=7.58e-6]\u001b[A\n",
      " 58%|█████▊    | 2445/4220 [2:36:14<1:51:50,  3.78s/it, loss=3.37, epoch=0.579, learning_rate=7.58e-6]\u001b[A\n",
      " 58%|█████▊    | 2445/4220 [2:36:14<1:51:50,  3.78s/it, loss=2.93, epoch=0.579, learning_rate=7.57e-6]\u001b[A\n",
      " 58%|█████▊    | 2446/4220 [2:36:18<1:51:47,  3.78s/it, loss=2.93, epoch=0.579, learning_rate=7.57e-6]\u001b[A\n",
      " 58%|█████▊    | 2446/4220 [2:36:18<1:51:47,  3.78s/it, loss=3.16, epoch=0.579, learning_rate=7.56e-6]\u001b[A\n",
      " 58%|█████▊    | 2447/4220 [2:36:22<1:51:42,  3.78s/it, loss=3.16, epoch=0.579, learning_rate=7.56e-6]\u001b[A\n",
      " 58%|█████▊    | 2447/4220 [2:36:22<1:51:42,  3.78s/it, loss=3.12, epoch=0.58, learning_rate=7.56e-6] \u001b[A\n",
      " 58%|█████▊    | 2448/4220 [2:36:26<1:51:40,  3.78s/it, loss=3.12, epoch=0.58, learning_rate=7.56e-6]\u001b[A\n",
      " 58%|█████▊    | 2448/4220 [2:36:26<1:51:40,  3.78s/it, loss=2.99, epoch=0.58, learning_rate=7.55e-6]\u001b[A\n",
      " 58%|█████▊    | 2449/4220 [2:36:29<1:51:35,  3.78s/it, loss=2.99, epoch=0.58, learning_rate=7.55e-6]\u001b[A\n",
      " 58%|█████▊    | 2449/4220 [2:36:29<1:51:35,  3.78s/it, loss=2.67, epoch=0.58, learning_rate=7.54e-6]\u001b[A\n",
      " 58%|█████▊    | 2450/4220 [2:36:33<1:51:31,  3.78s/it, loss=2.67, epoch=0.58, learning_rate=7.54e-6]\u001b[A\n",
      " 58%|█████▊    | 2450/4220 [2:36:33<1:51:31,  3.78s/it, loss=2.75, epoch=0.58, learning_rate=7.53e-6]\u001b[A\n",
      " 58%|█████▊    | 2451/4220 [2:36:37<1:51:26,  3.78s/it, loss=2.75, epoch=0.58, learning_rate=7.53e-6]\u001b[A\n",
      " 58%|█████▊    | 2451/4220 [2:36:37<1:51:26,  3.78s/it, loss=2.92, epoch=0.581, learning_rate=7.53e-6]\u001b[A\n",
      " 58%|█████▊    | 2452/4220 [2:36:41<1:51:19,  3.78s/it, loss=2.92, epoch=0.581, learning_rate=7.53e-6]\u001b[A\n",
      " 58%|█████▊    | 2452/4220 [2:36:41<1:51:19,  3.78s/it, loss=3.13, epoch=0.581, learning_rate=7.52e-6]\u001b[A\n",
      " 58%|█████▊    | 2453/4220 [2:36:45<1:51:18,  3.78s/it, loss=3.13, epoch=0.581, learning_rate=7.52e-6]\u001b[A\n",
      " 58%|█████▊    | 2453/4220 [2:36:45<1:51:18,  3.78s/it, loss=2.52, epoch=0.581, learning_rate=7.51e-6]\u001b[A\n",
      " 58%|█████▊    | 2454/4220 [2:36:48<1:51:14,  3.78s/it, loss=2.52, epoch=0.581, learning_rate=7.51e-6]\u001b[A\n",
      " 58%|█████▊    | 2454/4220 [2:36:48<1:51:14,  3.78s/it, loss=3.19, epoch=0.581, learning_rate=7.5e-6] \u001b[A\n",
      " 58%|█████▊    | 2455/4220 [2:36:52<1:51:13,  3.78s/it, loss=3.19, epoch=0.581, learning_rate=7.5e-6]\u001b[A\n",
      " 58%|█████▊    | 2455/4220 [2:36:52<1:51:13,  3.78s/it, loss=2.86, epoch=0.582, learning_rate=7.5e-6]\u001b[A\n",
      " 58%|█████▊    | 2456/4220 [2:36:56<1:51:08,  3.78s/it, loss=2.86, epoch=0.582, learning_rate=7.5e-6]\u001b[A\n",
      " 58%|█████▊    | 2456/4220 [2:36:56<1:51:08,  3.78s/it, loss=3.09, epoch=0.582, learning_rate=7.49e-6]\u001b[A\n",
      " 58%|█████▊    | 2457/4220 [2:37:00<1:51:09,  3.78s/it, loss=3.09, epoch=0.582, learning_rate=7.49e-6]\u001b[A\n",
      " 58%|█████▊    | 2457/4220 [2:37:00<1:51:09,  3.78s/it, loss=3.77, epoch=0.582, learning_rate=7.48e-6]\u001b[A\n",
      " 58%|█████▊    | 2458/4220 [2:37:04<1:51:05,  3.78s/it, loss=3.77, epoch=0.582, learning_rate=7.48e-6]\u001b[A\n",
      " 58%|█████▊    | 2458/4220 [2:37:04<1:51:05,  3.78s/it, loss=3, epoch=0.582, learning_rate=7.48e-6]   \u001b[A\n",
      " 58%|█████▊    | 2459/4220 [2:37:07<1:50:57,  3.78s/it, loss=3, epoch=0.582, learning_rate=7.48e-6]\u001b[A\n",
      " 58%|█████▊    | 2459/4220 [2:37:07<1:50:57,  3.78s/it, loss=3, epoch=0.582, learning_rate=7.47e-6]\u001b[A\n",
      " 58%|█████▊    | 2460/4220 [2:37:11<1:50:55,  3.78s/it, loss=3, epoch=0.582, learning_rate=7.47e-6]\u001b[A\n",
      " 58%|█████▊    | 2460/4220 [2:37:11<1:50:55,  3.78s/it, loss=3.1, epoch=0.583, learning_rate=7.46e-6]\u001b[A\n",
      " 58%|█████▊    | 2461/4220 [2:37:15<1:50:52,  3.78s/it, loss=3.1, epoch=0.583, learning_rate=7.46e-6]\u001b[A\n",
      " 58%|█████▊    | 2461/4220 [2:37:15<1:50:52,  3.78s/it, loss=2.65, epoch=0.583, learning_rate=7.45e-6]\u001b[A\n",
      " 58%|█████▊    | 2462/4220 [2:37:19<1:50:45,  3.78s/it, loss=2.65, epoch=0.583, learning_rate=7.45e-6]\u001b[A\n",
      " 58%|█████▊    | 2462/4220 [2:37:19<1:50:45,  3.78s/it, loss=2.9, epoch=0.583, learning_rate=7.45e-6] \u001b[A\n",
      " 58%|█████▊    | 2463/4220 [2:37:22<1:50:42,  3.78s/it, loss=2.9, epoch=0.583, learning_rate=7.45e-6]\u001b[A\n",
      " 58%|█████▊    | 2463/4220 [2:37:22<1:50:42,  3.78s/it, loss=3.28, epoch=0.583, learning_rate=7.44e-6]\u001b[A\n",
      " 58%|█████▊    | 2464/4220 [2:37:26<1:50:41,  3.78s/it, loss=3.28, epoch=0.583, learning_rate=7.44e-6]\u001b[A\n",
      " 58%|█████▊    | 2464/4220 [2:37:26<1:50:41,  3.78s/it, loss=3.2, epoch=0.584, learning_rate=7.43e-6] \u001b[A\n",
      " 58%|█████▊    | 2465/4220 [2:37:30<1:50:35,  3.78s/it, loss=3.2, epoch=0.584, learning_rate=7.43e-6]\u001b[A\n",
      " 58%|█████▊    | 2465/4220 [2:37:30<1:50:35,  3.78s/it, loss=2.15, epoch=0.584, learning_rate=7.43e-6]\u001b[A\n",
      " 58%|█████▊    | 2466/4220 [2:37:34<1:50:34,  3.78s/it, loss=2.15, epoch=0.584, learning_rate=7.43e-6]\u001b[A\n",
      " 58%|█████▊    | 2466/4220 [2:37:34<1:50:34,  3.78s/it, loss=2.79, epoch=0.584, learning_rate=7.42e-6]\u001b[A\n",
      " 58%|█████▊    | 2467/4220 [2:37:38<1:50:31,  3.78s/it, loss=2.79, epoch=0.584, learning_rate=7.42e-6]\u001b[A\n",
      " 58%|█████▊    | 2467/4220 [2:37:38<1:50:31,  3.78s/it, loss=3.18, epoch=0.584, learning_rate=7.41e-6]\u001b[A\n",
      " 58%|█████▊    | 2468/4220 [2:37:41<1:50:27,  3.78s/it, loss=3.18, epoch=0.584, learning_rate=7.41e-6]\u001b[A\n",
      " 58%|█████▊    | 2468/4220 [2:37:41<1:50:27,  3.78s/it, loss=3.44, epoch=0.585, learning_rate=7.4e-6] \u001b[A\n",
      " 59%|█████▊    | 2469/4220 [2:37:45<1:50:24,  3.78s/it, loss=3.44, epoch=0.585, learning_rate=7.4e-6]\u001b[A\n",
      " 59%|█████▊    | 2469/4220 [2:37:45<1:50:24,  3.78s/it, loss=2.8, epoch=0.585, learning_rate=7.4e-6] \u001b[A\n",
      " 59%|█████▊    | 2470/4220 [2:37:49<1:50:17,  3.78s/it, loss=2.8, epoch=0.585, learning_rate=7.4e-6]\u001b[A\n",
      " 59%|█████▊    | 2470/4220 [2:37:49<1:50:17,  3.78s/it, loss=2.86, epoch=0.585, learning_rate=7.39e-6]\u001b[A\n",
      " 59%|█████▊    | 2471/4220 [2:37:53<1:50:14,  3.78s/it, loss=2.86, epoch=0.585, learning_rate=7.39e-6]\u001b[A\n",
      " 59%|█████▊    | 2471/4220 [2:37:53<1:50:14,  3.78s/it, loss=2.7, epoch=0.585, learning_rate=7.38e-6] \u001b[A\n",
      " 59%|█████▊    | 2472/4220 [2:37:56<1:50:09,  3.78s/it, loss=2.7, epoch=0.585, learning_rate=7.38e-6]\u001b[A\n",
      " 59%|█████▊    | 2472/4220 [2:37:56<1:50:09,  3.78s/it, loss=2.49, epoch=0.586, learning_rate=7.37e-6]\u001b[A\n",
      " 59%|█████▊    | 2473/4220 [2:38:00<1:50:06,  3.78s/it, loss=2.49, epoch=0.586, learning_rate=7.37e-6]\u001b[A\n",
      " 59%|█████▊    | 2473/4220 [2:38:00<1:50:06,  3.78s/it, loss=3.22, epoch=0.586, learning_rate=7.37e-6]\u001b[A\n",
      " 59%|█████▊    | 2474/4220 [2:38:04<1:50:03,  3.78s/it, loss=3.22, epoch=0.586, learning_rate=7.37e-6]\u001b[A\n",
      " 59%|█████▊    | 2474/4220 [2:38:04<1:50:03,  3.78s/it, loss=2.83, epoch=0.586, learning_rate=7.36e-6]\u001b[A\n",
      " 59%|█████▊    | 2475/4220 [2:38:08<1:49:58,  3.78s/it, loss=2.83, epoch=0.586, learning_rate=7.36e-6]\u001b[A\n",
      " 59%|█████▊    | 2475/4220 [2:38:08<1:49:58,  3.78s/it, loss=2.53, epoch=0.586, learning_rate=7.35e-6]\u001b[A\n",
      " 59%|█████▊    | 2476/4220 [2:38:12<1:49:53,  3.78s/it, loss=2.53, epoch=0.586, learning_rate=7.35e-6]\u001b[A\n",
      " 59%|█████▊    | 2476/4220 [2:38:12<1:49:53,  3.78s/it, loss=3.03, epoch=0.586, learning_rate=7.35e-6]\u001b[A\n",
      " 59%|█████▊    | 2477/4220 [2:38:15<1:49:49,  3.78s/it, loss=3.03, epoch=0.586, learning_rate=7.35e-6]\u001b[A\n",
      " 59%|█████▊    | 2477/4220 [2:38:15<1:49:49,  3.78s/it, loss=2.58, epoch=0.587, learning_rate=7.34e-6]\u001b[A\n",
      " 59%|█████▊    | 2478/4220 [2:38:19<1:49:47,  3.78s/it, loss=2.58, epoch=0.587, learning_rate=7.34e-6]\u001b[A\n",
      " 59%|█████▊    | 2478/4220 [2:38:19<1:49:47,  3.78s/it, loss=2.72, epoch=0.587, learning_rate=7.33e-6]\u001b[A\n",
      " 59%|█████▊    | 2479/4220 [2:38:23<1:49:41,  3.78s/it, loss=2.72, epoch=0.587, learning_rate=7.33e-6]\u001b[A\n",
      " 59%|█████▊    | 2479/4220 [2:38:23<1:49:41,  3.78s/it, loss=2.89, epoch=0.587, learning_rate=7.32e-6]\u001b[A\n",
      " 59%|█████▉    | 2480/4220 [2:38:27<1:49:37,  3.78s/it, loss=2.89, epoch=0.587, learning_rate=7.32e-6]\u001b[A\n",
      " 59%|█████▉    | 2480/4220 [2:38:27<1:49:37,  3.78s/it, loss=2.66, epoch=0.587, learning_rate=7.32e-6]\u001b[A\n",
      " 59%|█████▉    | 2481/4220 [2:38:30<1:49:35,  3.78s/it, loss=2.66, epoch=0.587, learning_rate=7.32e-6]\u001b[A\n",
      " 59%|█████▉    | 2481/4220 [2:38:30<1:49:35,  3.78s/it, loss=2.77, epoch=0.588, learning_rate=7.31e-6]\u001b[A\n",
      " 59%|█████▉    | 2482/4220 [2:38:34<1:49:31,  3.78s/it, loss=2.77, epoch=0.588, learning_rate=7.31e-6]\u001b[A\n",
      " 59%|█████▉    | 2482/4220 [2:38:34<1:49:31,  3.78s/it, loss=3.16, epoch=0.588, learning_rate=7.3e-6] \u001b[A\n",
      " 59%|█████▉    | 2483/4220 [2:38:38<1:49:28,  3.78s/it, loss=3.16, epoch=0.588, learning_rate=7.3e-6]\u001b[A\n",
      " 59%|█████▉    | 2483/4220 [2:38:38<1:49:28,  3.78s/it, loss=2.9, epoch=0.588, learning_rate=7.3e-6] \u001b[A\n",
      " 59%|█████▉    | 2484/4220 [2:38:42<1:49:24,  3.78s/it, loss=2.9, epoch=0.588, learning_rate=7.3e-6]\u001b[A\n",
      " 59%|█████▉    | 2484/4220 [2:38:42<1:49:24,  3.78s/it, loss=3.03, epoch=0.588, learning_rate=7.29e-6]\u001b[A\n",
      " 59%|█████▉    | 2485/4220 [2:38:46<1:49:19,  3.78s/it, loss=3.03, epoch=0.588, learning_rate=7.29e-6]\u001b[A\n",
      " 59%|█████▉    | 2485/4220 [2:38:46<1:49:19,  3.78s/it, loss=2.83, epoch=0.589, learning_rate=7.28e-6]\u001b[A\n",
      " 59%|█████▉    | 2486/4220 [2:38:49<1:49:14,  3.78s/it, loss=2.83, epoch=0.589, learning_rate=7.28e-6]\u001b[A\n",
      " 59%|█████▉    | 2486/4220 [2:38:49<1:49:14,  3.78s/it, loss=2.54, epoch=0.589, learning_rate=7.27e-6]\u001b[A\n",
      " 59%|█████▉    | 2487/4220 [2:38:53<1:49:13,  3.78s/it, loss=2.54, epoch=0.589, learning_rate=7.27e-6]\u001b[A\n",
      " 59%|█████▉    | 2487/4220 [2:38:53<1:49:13,  3.78s/it, loss=3.12, epoch=0.589, learning_rate=7.27e-6]\u001b[A\n",
      " 59%|█████▉    | 2488/4220 [2:38:57<1:49:07,  3.78s/it, loss=3.12, epoch=0.589, learning_rate=7.27e-6]\u001b[A\n",
      " 59%|█████▉    | 2488/4220 [2:38:57<1:49:07,  3.78s/it, loss=2.56, epoch=0.589, learning_rate=7.26e-6]\u001b[A\n",
      " 59%|█████▉    | 2489/4220 [2:39:01<1:49:05,  3.78s/it, loss=2.56, epoch=0.589, learning_rate=7.26e-6]\u001b[A\n",
      " 59%|█████▉    | 2489/4220 [2:39:01<1:49:05,  3.78s/it, loss=3.19, epoch=0.59, learning_rate=7.25e-6] \u001b[A\n",
      " 59%|█████▉    | 2490/4220 [2:39:05<1:48:59,  3.78s/it, loss=3.19, epoch=0.59, learning_rate=7.25e-6]\u001b[A\n",
      " 59%|█████▉    | 2490/4220 [2:39:05<1:48:59,  3.78s/it, loss=2.47, epoch=0.59, learning_rate=7.25e-6]\u001b[A\n",
      " 59%|█████▉    | 2491/4220 [2:39:08<1:48:55,  3.78s/it, loss=2.47, epoch=0.59, learning_rate=7.25e-6]\u001b[A\n",
      " 59%|█████▉    | 2491/4220 [2:39:08<1:48:55,  3.78s/it, loss=2.66, epoch=0.59, learning_rate=7.24e-6]\u001b[A\n",
      " 59%|█████▉    | 2492/4220 [2:39:12<1:48:52,  3.78s/it, loss=2.66, epoch=0.59, learning_rate=7.24e-6]\u001b[A\n",
      " 59%|█████▉    | 2492/4220 [2:39:12<1:48:52,  3.78s/it, loss=2.85, epoch=0.59, learning_rate=7.23e-6]\u001b[A\n",
      " 59%|█████▉    | 2493/4220 [2:39:16<1:48:45,  3.78s/it, loss=2.85, epoch=0.59, learning_rate=7.23e-6]\u001b[A\n",
      " 59%|█████▉    | 2493/4220 [2:39:16<1:48:45,  3.78s/it, loss=3.51, epoch=0.591, learning_rate=7.22e-6]\u001b[A\n",
      " 59%|█████▉    | 2494/4220 [2:39:20<1:48:45,  3.78s/it, loss=3.51, epoch=0.591, learning_rate=7.22e-6]\u001b[A\n",
      " 59%|█████▉    | 2494/4220 [2:39:20<1:48:45,  3.78s/it, loss=2.44, epoch=0.591, learning_rate=7.22e-6]\u001b[A\n",
      " 59%|█████▉    | 2495/4220 [2:39:23<1:48:43,  3.78s/it, loss=2.44, epoch=0.591, learning_rate=7.22e-6]\u001b[A\n",
      " 59%|█████▉    | 2495/4220 [2:39:23<1:48:43,  3.78s/it, loss=2.84, epoch=0.591, learning_rate=7.21e-6]\u001b[A\n",
      " 59%|█████▉    | 2496/4220 [2:39:27<1:48:37,  3.78s/it, loss=2.84, epoch=0.591, learning_rate=7.21e-6]\u001b[A\n",
      " 59%|█████▉    | 2496/4220 [2:39:27<1:48:37,  3.78s/it, loss=2.75, epoch=0.591, learning_rate=7.2e-6] \u001b[A\n",
      " 59%|█████▉    | 2497/4220 [2:39:31<1:48:34,  3.78s/it, loss=2.75, epoch=0.591, learning_rate=7.2e-6]\u001b[A\n",
      " 59%|█████▉    | 2497/4220 [2:39:31<1:48:34,  3.78s/it, loss=2.42, epoch=0.591, learning_rate=7.2e-6]\u001b[A\n",
      " 59%|█████▉    | 2498/4220 [2:39:35<1:48:31,  3.78s/it, loss=2.42, epoch=0.591, learning_rate=7.2e-6]\u001b[A\n",
      " 59%|█████▉    | 2498/4220 [2:39:35<1:48:31,  3.78s/it, loss=2.37, epoch=0.592, learning_rate=7.19e-6]\u001b[A\n",
      " 59%|█████▉    | 2499/4220 [2:39:39<1:48:27,  3.78s/it, loss=2.37, epoch=0.592, learning_rate=7.19e-6]\u001b[A\n",
      " 59%|█████▉    | 2499/4220 [2:39:39<1:48:27,  3.78s/it, loss=2.74, epoch=0.592, learning_rate=7.18e-6]\u001b[A\n",
      " 59%|█████▉    | 2500/4220 [2:39:42<1:48:25,  3.78s/it, loss=2.74, epoch=0.592, learning_rate=7.18e-6]\u001b[A\n",
      " 59%|█████▉    | 2500/4220 [2:39:42<1:48:25,  3.78s/it, loss=3.04, epoch=0.592, learning_rate=7.17e-6]\u001b[A\n",
      " 59%|█████▉    | 2501/4220 [2:39:46<1:48:19,  3.78s/it, loss=3.04, epoch=0.592, learning_rate=7.17e-6]\u001b[A\n",
      " 59%|█████▉    | 2501/4220 [2:39:46<1:48:19,  3.78s/it, loss=2.56, epoch=0.592, learning_rate=7.17e-6]\u001b[A\n",
      " 59%|█████▉    | 2502/4220 [2:39:50<1:48:15,  3.78s/it, loss=2.56, epoch=0.592, learning_rate=7.17e-6]\u001b[A\n",
      " 59%|█████▉    | 2502/4220 [2:39:50<1:48:15,  3.78s/it, loss=2.35, epoch=0.593, learning_rate=7.16e-6]\u001b[A\n",
      " 59%|█████▉    | 2503/4220 [2:39:54<1:48:09,  3.78s/it, loss=2.35, epoch=0.593, learning_rate=7.16e-6]\u001b[A\n",
      " 59%|█████▉    | 2503/4220 [2:39:54<1:48:09,  3.78s/it, loss=2.73, epoch=0.593, learning_rate=7.15e-6]\u001b[A\n",
      " 59%|█████▉    | 2504/4220 [2:39:57<1:48:07,  3.78s/it, loss=2.73, epoch=0.593, learning_rate=7.15e-6]\u001b[A\n",
      " 59%|█████▉    | 2504/4220 [2:39:57<1:48:07,  3.78s/it, loss=2.76, epoch=0.593, learning_rate=7.14e-6]\u001b[A\n",
      " 59%|█████▉    | 2505/4220 [2:40:01<1:48:04,  3.78s/it, loss=2.76, epoch=0.593, learning_rate=7.14e-6]\u001b[A\n",
      " 59%|█████▉    | 2505/4220 [2:40:01<1:48:04,  3.78s/it, loss=3.22, epoch=0.593, learning_rate=7.14e-6]\u001b[A\n",
      " 59%|█████▉    | 2506/4220 [2:40:05<1:48:01,  3.78s/it, loss=3.22, epoch=0.593, learning_rate=7.14e-6]\u001b[A\n",
      " 59%|█████▉    | 2506/4220 [2:40:05<1:48:01,  3.78s/it, loss=2.65, epoch=0.594, learning_rate=7.13e-6]\u001b[A\n",
      " 59%|█████▉    | 2507/4220 [2:40:09<1:47:58,  3.78s/it, loss=2.65, epoch=0.594, learning_rate=7.13e-6]\u001b[A\n",
      " 59%|█████▉    | 2507/4220 [2:40:09<1:47:58,  3.78s/it, loss=3.22, epoch=0.594, learning_rate=7.12e-6]\u001b[A\n",
      " 59%|█████▉    | 2508/4220 [2:40:13<1:47:54,  3.78s/it, loss=3.22, epoch=0.594, learning_rate=7.12e-6]\u001b[A\n",
      " 59%|█████▉    | 2508/4220 [2:40:13<1:47:54,  3.78s/it, loss=3.04, epoch=0.594, learning_rate=7.12e-6]\u001b[A\n",
      " 59%|█████▉    | 2509/4220 [2:40:16<1:47:50,  3.78s/it, loss=3.04, epoch=0.594, learning_rate=7.12e-6]\u001b[A\n",
      " 59%|█████▉    | 2509/4220 [2:40:16<1:47:50,  3.78s/it, loss=2.55, epoch=0.594, learning_rate=7.11e-6]\u001b[A\n",
      " 59%|█████▉    | 2510/4220 [2:40:20<1:47:47,  3.78s/it, loss=2.55, epoch=0.594, learning_rate=7.11e-6]\u001b[A\n",
      " 59%|█████▉    | 2510/4220 [2:40:20<1:47:47,  3.78s/it, loss=2.88, epoch=0.595, learning_rate=7.1e-6] \u001b[A\n",
      " 60%|█████▉    | 2511/4220 [2:40:24<1:47:44,  3.78s/it, loss=2.88, epoch=0.595, learning_rate=7.1e-6]\u001b[A\n",
      " 60%|█████▉    | 2511/4220 [2:40:24<1:47:44,  3.78s/it, loss=2.96, epoch=0.595, learning_rate=7.09e-6]\u001b[A\n",
      " 60%|█████▉    | 2512/4220 [2:40:28<1:47:42,  3.78s/it, loss=2.96, epoch=0.595, learning_rate=7.09e-6]\u001b[A\n",
      " 60%|█████▉    | 2512/4220 [2:40:28<1:47:42,  3.78s/it, loss=2.56, epoch=0.595, learning_rate=7.09e-6]\u001b[A\n",
      " 60%|█████▉    | 2513/4220 [2:40:31<1:47:39,  3.78s/it, loss=2.56, epoch=0.595, learning_rate=7.09e-6]\u001b[A\n",
      " 60%|█████▉    | 2513/4220 [2:40:31<1:47:39,  3.78s/it, loss=2.93, epoch=0.595, learning_rate=7.08e-6]\u001b[A\n",
      " 60%|█████▉    | 2514/4220 [2:40:35<1:47:34,  3.78s/it, loss=2.93, epoch=0.595, learning_rate=7.08e-6]\u001b[A\n",
      " 60%|█████▉    | 2514/4220 [2:40:35<1:47:34,  3.78s/it, loss=2.76, epoch=0.595, learning_rate=7.07e-6]\u001b[A\n",
      " 60%|█████▉    | 2515/4220 [2:40:39<1:47:29,  3.78s/it, loss=2.76, epoch=0.595, learning_rate=7.07e-6]\u001b[A\n",
      " 60%|█████▉    | 2515/4220 [2:40:39<1:47:29,  3.78s/it, loss=2.68, epoch=0.596, learning_rate=7.07e-6]\u001b[A\n",
      " 60%|█████▉    | 2516/4220 [2:40:43<1:47:26,  3.78s/it, loss=2.68, epoch=0.596, learning_rate=7.07e-6]\u001b[A\n",
      " 60%|█████▉    | 2516/4220 [2:40:43<1:47:26,  3.78s/it, loss=2.93, epoch=0.596, learning_rate=7.06e-6]\u001b[A\n",
      " 60%|█████▉    | 2517/4220 [2:40:47<1:47:21,  3.78s/it, loss=2.93, epoch=0.596, learning_rate=7.06e-6]\u001b[A\n",
      " 60%|█████▉    | 2517/4220 [2:40:47<1:47:21,  3.78s/it, loss=2.66, epoch=0.596, learning_rate=7.05e-6]\u001b[A\n",
      " 60%|█████▉    | 2518/4220 [2:40:50<1:47:18,  3.78s/it, loss=2.66, epoch=0.596, learning_rate=7.05e-6]\u001b[A\n",
      " 60%|█████▉    | 2518/4220 [2:40:50<1:47:18,  3.78s/it, loss=2.78, epoch=0.596, learning_rate=7.04e-6]\u001b[A\n",
      " 60%|█████▉    | 2519/4220 [2:40:54<1:47:13,  3.78s/it, loss=2.78, epoch=0.596, learning_rate=7.04e-6]\u001b[A\n",
      " 60%|█████▉    | 2519/4220 [2:40:54<1:47:13,  3.78s/it, loss=3.05, epoch=0.597, learning_rate=7.04e-6]\u001b[A\n",
      " 60%|█████▉    | 2520/4220 [2:40:58<1:47:09,  3.78s/it, loss=3.05, epoch=0.597, learning_rate=7.04e-6]\u001b[A\n",
      " 60%|█████▉    | 2520/4220 [2:40:58<1:47:09,  3.78s/it, loss=3.35, epoch=0.597, learning_rate=7.03e-6]\u001b[A\n",
      " 60%|█████▉    | 2521/4220 [2:41:02<1:47:05,  3.78s/it, loss=3.35, epoch=0.597, learning_rate=7.03e-6]\u001b[A\n",
      " 60%|█████▉    | 2521/4220 [2:41:02<1:47:05,  3.78s/it, loss=2.87, epoch=0.597, learning_rate=7.02e-6]\u001b[A\n",
      " 60%|█████▉    | 2522/4220 [2:41:06<1:47:01,  3.78s/it, loss=2.87, epoch=0.597, learning_rate=7.02e-6]\u001b[A\n",
      " 60%|█████▉    | 2522/4220 [2:41:06<1:47:01,  3.78s/it, loss=2.7, epoch=0.597, learning_rate=7.02e-6] \u001b[A\n",
      " 60%|█████▉    | 2523/4220 [2:41:09<1:46:54,  3.78s/it, loss=2.7, epoch=0.597, learning_rate=7.02e-6]\u001b[A\n",
      " 60%|█████▉    | 2523/4220 [2:41:09<1:46:54,  3.78s/it, loss=3.53, epoch=0.598, learning_rate=7.01e-6]\u001b[A\n",
      " 60%|█████▉    | 2524/4220 [2:41:13<1:46:50,  3.78s/it, loss=3.53, epoch=0.598, learning_rate=7.01e-6]\u001b[A\n",
      " 60%|█████▉    | 2524/4220 [2:41:13<1:46:50,  3.78s/it, loss=2.58, epoch=0.598, learning_rate=7e-6]   \u001b[A\n",
      " 60%|█████▉    | 2525/4220 [2:41:17<1:46:49,  3.78s/it, loss=2.58, epoch=0.598, learning_rate=7e-6]\u001b[A\n",
      " 60%|█████▉    | 2525/4220 [2:41:17<1:46:49,  3.78s/it, loss=2.05, epoch=0.598, learning_rate=7e-6]\u001b[A\n",
      " 60%|█████▉    | 2526/4220 [2:41:21<1:46:44,  3.78s/it, loss=2.05, epoch=0.598, learning_rate=7e-6]\u001b[A\n",
      " 60%|█████▉    | 2526/4220 [2:41:21<1:46:44,  3.78s/it, loss=2.77, epoch=0.598, learning_rate=6.99e-6]\u001b[A\n",
      " 60%|█████▉    | 2527/4220 [2:41:24<1:46:40,  3.78s/it, loss=2.77, epoch=0.598, learning_rate=6.99e-6]\u001b[A\n",
      " 60%|█████▉    | 2527/4220 [2:41:24<1:46:40,  3.78s/it, loss=2.02, epoch=0.599, learning_rate=6.98e-6]\u001b[A\n",
      " 60%|█████▉    | 2528/4220 [2:41:28<1:46:38,  3.78s/it, loss=2.02, epoch=0.599, learning_rate=6.98e-6]\u001b[A\n",
      " 60%|█████▉    | 2528/4220 [2:41:28<1:46:38,  3.78s/it, loss=2.91, epoch=0.599, learning_rate=6.97e-6]\u001b[A\n",
      " 60%|█████▉    | 2529/4220 [2:41:32<1:46:34,  3.78s/it, loss=2.91, epoch=0.599, learning_rate=6.97e-6]\u001b[A\n",
      " 60%|█████▉    | 2529/4220 [2:41:32<1:46:34,  3.78s/it, loss=2.61, epoch=0.599, learning_rate=6.97e-6]\u001b[A\n",
      " 60%|█████▉    | 2530/4220 [2:41:36<1:46:28,  3.78s/it, loss=2.61, epoch=0.599, learning_rate=6.97e-6]\u001b[A\n",
      " 60%|█████▉    | 2530/4220 [2:41:36<1:46:28,  3.78s/it, loss=2.95, epoch=0.599, learning_rate=6.96e-6]\u001b[A\n",
      " 60%|█████▉    | 2531/4220 [2:41:40<1:46:25,  3.78s/it, loss=2.95, epoch=0.599, learning_rate=6.96e-6]\u001b[A\n",
      " 60%|█████▉    | 2531/4220 [2:41:40<1:46:25,  3.78s/it, loss=2.48, epoch=0.6, learning_rate=6.95e-6]  \u001b[A\n",
      " 60%|██████    | 2532/4220 [2:41:43<1:46:18,  3.78s/it, loss=2.48, epoch=0.6, learning_rate=6.95e-6]\u001b[A\n",
      " 60%|██████    | 2532/4220 [2:41:43<1:46:18,  3.78s/it, loss=2.7, epoch=0.6, learning_rate=6.95e-6] \u001b[A\n",
      " 60%|██████    | 2533/4220 [2:41:47<1:46:18,  3.78s/it, loss=2.7, epoch=0.6, learning_rate=6.95e-6]\u001b[A\n",
      " 60%|██████    | 2533/4220 [2:41:47<1:46:18,  3.78s/it, loss=3.2, epoch=0.6, learning_rate=6.94e-6]\u001b[A\n",
      " 60%|██████    | 2534/4220 [2:41:51<1:46:15,  3.78s/it, loss=3.2, epoch=0.6, learning_rate=6.94e-6]\u001b[A\n",
      " 60%|██████    | 2534/4220 [2:41:51<1:46:15,  3.78s/it, loss=3.07, epoch=0.6, learning_rate=6.93e-6]\u001b[A\n",
      " 60%|██████    | 2535/4220 [2:41:55<1:46:13,  3.78s/it, loss=3.07, epoch=0.6, learning_rate=6.93e-6]\u001b[A\n",
      " 60%|██████    | 2535/4220 [2:41:55<1:46:13,  3.78s/it, loss=2.98, epoch=0.6, learning_rate=6.92e-6]\u001b[A\n",
      " 60%|██████    | 2536/4220 [2:41:58<1:46:09,  3.78s/it, loss=2.98, epoch=0.6, learning_rate=6.92e-6]\u001b[A\n",
      " 60%|██████    | 2536/4220 [2:41:58<1:46:09,  3.78s/it, loss=2.8, epoch=0.601, learning_rate=6.92e-6]\u001b[A\n",
      " 60%|██████    | 2537/4220 [2:42:02<1:46:07,  3.78s/it, loss=2.8, epoch=0.601, learning_rate=6.92e-6]\u001b[A\n",
      " 60%|██████    | 2537/4220 [2:42:02<1:46:07,  3.78s/it, loss=2.9, epoch=0.601, learning_rate=6.91e-6]\u001b[A\n",
      " 60%|██████    | 2538/4220 [2:42:06<1:46:01,  3.78s/it, loss=2.9, epoch=0.601, learning_rate=6.91e-6]\u001b[A\n",
      " 60%|██████    | 2538/4220 [2:42:06<1:46:01,  3.78s/it, loss=2.54, epoch=0.601, learning_rate=6.9e-6]\u001b[A\n",
      " 60%|██████    | 2539/4220 [2:42:10<1:45:59,  3.78s/it, loss=2.54, epoch=0.601, learning_rate=6.9e-6]\u001b[A\n",
      " 60%|██████    | 2539/4220 [2:42:10<1:45:59,  3.78s/it, loss=2.77, epoch=0.601, learning_rate=6.9e-6]\u001b[A\n",
      " 60%|██████    | 2540/4220 [2:42:14<1:45:55,  3.78s/it, loss=2.77, epoch=0.601, learning_rate=6.9e-6]\u001b[A\n",
      " 60%|██████    | 2540/4220 [2:42:14<1:45:55,  3.78s/it, loss=2.58, epoch=0.602, learning_rate=6.89e-6]\u001b[A\n",
      " 60%|██████    | 2541/4220 [2:42:17<1:45:48,  3.78s/it, loss=2.58, epoch=0.602, learning_rate=6.89e-6]\u001b[A\n",
      " 60%|██████    | 2541/4220 [2:42:17<1:45:48,  3.78s/it, loss=2.46, epoch=0.602, learning_rate=6.88e-6]\u001b[A\n",
      " 60%|██████    | 2542/4220 [2:42:21<1:45:47,  3.78s/it, loss=2.46, epoch=0.602, learning_rate=6.88e-6]\u001b[A\n",
      " 60%|██████    | 2542/4220 [2:42:21<1:45:47,  3.78s/it, loss=2.49, epoch=0.602, learning_rate=6.87e-6]\u001b[A\n",
      " 60%|██████    | 2543/4220 [2:42:25<1:45:42,  3.78s/it, loss=2.49, epoch=0.602, learning_rate=6.87e-6]\u001b[A\n",
      " 60%|██████    | 2543/4220 [2:42:25<1:45:42,  3.78s/it, loss=2.66, epoch=0.602, learning_rate=6.87e-6]\u001b[A\n",
      " 60%|██████    | 2544/4220 [2:42:29<1:45:37,  3.78s/it, loss=2.66, epoch=0.602, learning_rate=6.87e-6]\u001b[A\n",
      " 60%|██████    | 2544/4220 [2:42:29<1:45:37,  3.78s/it, loss=2.6, epoch=0.603, learning_rate=6.86e-6] \u001b[A\n",
      " 60%|██████    | 2545/4220 [2:42:32<1:45:35,  3.78s/it, loss=2.6, epoch=0.603, learning_rate=6.86e-6]\u001b[A\n",
      " 60%|██████    | 2545/4220 [2:42:32<1:45:35,  3.78s/it, loss=2.87, epoch=0.603, learning_rate=6.85e-6]\u001b[A\n",
      " 60%|██████    | 2546/4220 [2:42:36<1:45:34,  3.78s/it, loss=2.87, epoch=0.603, learning_rate=6.85e-6]\u001b[A\n",
      " 60%|██████    | 2546/4220 [2:42:36<1:45:34,  3.78s/it, loss=2.65, epoch=0.603, learning_rate=6.85e-6]\u001b[A\n",
      " 60%|██████    | 2547/4220 [2:42:40<1:45:29,  3.78s/it, loss=2.65, epoch=0.603, learning_rate=6.85e-6]\u001b[A\n",
      " 60%|██████    | 2547/4220 [2:42:40<1:45:29,  3.78s/it, loss=2.86, epoch=0.603, learning_rate=6.84e-6]\u001b[A\n",
      " 60%|██████    | 2548/4220 [2:42:44<1:45:25,  3.78s/it, loss=2.86, epoch=0.603, learning_rate=6.84e-6]\u001b[A\n",
      " 60%|██████    | 2548/4220 [2:42:44<1:45:25,  3.78s/it, loss=2.72, epoch=0.604, learning_rate=6.83e-6]\u001b[A\n",
      " 60%|██████    | 2549/4220 [2:42:48<1:45:17,  3.78s/it, loss=2.72, epoch=0.604, learning_rate=6.83e-6]\u001b[A\n",
      " 60%|██████    | 2549/4220 [2:42:48<1:45:17,  3.78s/it, loss=2.93, epoch=0.604, learning_rate=6.82e-6]\u001b[A\n",
      " 60%|██████    | 2550/4220 [2:42:51<1:45:14,  3.78s/it, loss=2.93, epoch=0.604, learning_rate=6.82e-6]\u001b[A\n",
      " 60%|██████    | 2550/4220 [2:42:51<1:45:14,  3.78s/it, loss=2.38, epoch=0.604, learning_rate=6.82e-6]\u001b[A\n",
      " 60%|██████    | 2551/4220 [2:42:55<1:45:12,  3.78s/it, loss=2.38, epoch=0.604, learning_rate=6.82e-6]\u001b[A\n",
      " 60%|██████    | 2551/4220 [2:42:55<1:45:12,  3.78s/it, loss=3.3, epoch=0.604, learning_rate=6.81e-6] \u001b[A\n",
      " 60%|██████    | 2552/4220 [2:42:59<1:45:08,  3.78s/it, loss=3.3, epoch=0.604, learning_rate=6.81e-6]\u001b[A\n",
      " 60%|██████    | 2552/4220 [2:42:59<1:45:08,  3.78s/it, loss=3.04, epoch=0.605, learning_rate=6.8e-6]\u001b[A\n",
      " 60%|██████    | 2553/4220 [2:43:03<1:45:02,  3.78s/it, loss=3.04, epoch=0.605, learning_rate=6.8e-6]\u001b[A\n",
      " 60%|██████    | 2553/4220 [2:43:03<1:45:02,  3.78s/it, loss=3.25, epoch=0.605, learning_rate=6.8e-6]\u001b[A\n",
      " 61%|██████    | 2554/4220 [2:43:07<1:44:59,  3.78s/it, loss=3.25, epoch=0.605, learning_rate=6.8e-6]\u001b[A\n",
      " 61%|██████    | 2554/4220 [2:43:07<1:44:59,  3.78s/it, loss=3.25, epoch=0.605, learning_rate=6.79e-6]\u001b[A\n",
      " 61%|██████    | 2555/4220 [2:43:10<1:44:56,  3.78s/it, loss=3.25, epoch=0.605, learning_rate=6.79e-6]\u001b[A\n",
      " 61%|██████    | 2555/4220 [2:43:10<1:44:56,  3.78s/it, loss=2.5, epoch=0.605, learning_rate=6.78e-6] \u001b[A\n",
      " 61%|██████    | 2556/4220 [2:43:14<1:44:53,  3.78s/it, loss=2.5, epoch=0.605, learning_rate=6.78e-6]\u001b[A\n",
      " 61%|██████    | 2556/4220 [2:43:14<1:44:53,  3.78s/it, loss=2.93, epoch=0.605, learning_rate=6.78e-6]\u001b[A\n",
      " 61%|██████    | 2557/4220 [2:43:18<1:44:49,  3.78s/it, loss=2.93, epoch=0.605, learning_rate=6.78e-6]\u001b[A\n",
      " 61%|██████    | 2557/4220 [2:43:18<1:44:49,  3.78s/it, loss=2.86, epoch=0.606, learning_rate=6.77e-6]\u001b[A\n",
      " 61%|██████    | 2558/4220 [2:43:22<1:44:44,  3.78s/it, loss=2.86, epoch=0.606, learning_rate=6.77e-6]\u001b[A\n",
      " 61%|██████    | 2558/4220 [2:43:22<1:44:44,  3.78s/it, loss=2.35, epoch=0.606, learning_rate=6.76e-6]\u001b[A\n",
      " 61%|██████    | 2559/4220 [2:43:25<1:44:40,  3.78s/it, loss=2.35, epoch=0.606, learning_rate=6.76e-6]\u001b[A\n",
      " 61%|██████    | 2559/4220 [2:43:25<1:44:40,  3.78s/it, loss=3.25, epoch=0.606, learning_rate=6.75e-6]\u001b[A\n",
      " 61%|██████    | 2560/4220 [2:43:29<1:44:36,  3.78s/it, loss=3.25, epoch=0.606, learning_rate=6.75e-6]\u001b[A\n",
      " 61%|██████    | 2560/4220 [2:43:29<1:44:36,  3.78s/it, loss=2.75, epoch=0.606, learning_rate=6.75e-6]\u001b[A\n",
      " 61%|██████    | 2561/4220 [2:43:33<1:44:32,  3.78s/it, loss=2.75, epoch=0.606, learning_rate=6.75e-6]\u001b[A\n",
      " 61%|██████    | 2561/4220 [2:43:33<1:44:32,  3.78s/it, loss=2.69, epoch=0.607, learning_rate=6.74e-6]\u001b[A\n",
      " 61%|██████    | 2562/4220 [2:43:37<1:44:28,  3.78s/it, loss=2.69, epoch=0.607, learning_rate=6.74e-6]\u001b[A\n",
      " 61%|██████    | 2562/4220 [2:43:37<1:44:28,  3.78s/it, loss=2.56, epoch=0.607, learning_rate=6.73e-6]\u001b[A\n",
      " 61%|██████    | 2563/4220 [2:43:41<1:44:24,  3.78s/it, loss=2.56, epoch=0.607, learning_rate=6.73e-6]\u001b[A\n",
      " 61%|██████    | 2563/4220 [2:43:41<1:44:24,  3.78s/it, loss=2.48, epoch=0.607, learning_rate=6.73e-6]\u001b[A\n",
      " 61%|██████    | 2564/4220 [2:43:44<1:44:20,  3.78s/it, loss=2.48, epoch=0.607, learning_rate=6.73e-6]\u001b[A\n",
      " 61%|██████    | 2564/4220 [2:43:44<1:44:20,  3.78s/it, loss=3.04, epoch=0.607, learning_rate=6.72e-6]\u001b[A\n",
      " 61%|██████    | 2565/4220 [2:43:48<1:44:18,  3.78s/it, loss=3.04, epoch=0.607, learning_rate=6.72e-6]\u001b[A\n",
      " 61%|██████    | 2565/4220 [2:43:48<1:44:18,  3.78s/it, loss=3.05, epoch=0.608, learning_rate=6.71e-6]\u001b[A\n",
      " 61%|██████    | 2566/4220 [2:43:52<1:44:15,  3.78s/it, loss=3.05, epoch=0.608, learning_rate=6.71e-6]\u001b[A\n",
      " 61%|██████    | 2566/4220 [2:43:52<1:44:15,  3.78s/it, loss=2.67, epoch=0.608, learning_rate=6.7e-6] \u001b[A\n",
      " 61%|██████    | 2567/4220 [2:43:56<1:44:07,  3.78s/it, loss=2.67, epoch=0.608, learning_rate=6.7e-6]\u001b[A\n",
      " 61%|██████    | 2567/4220 [2:43:56<1:44:07,  3.78s/it, loss=2.99, epoch=0.608, learning_rate=6.7e-6]\u001b[A\n",
      " 61%|██████    | 2568/4220 [2:43:59<1:44:06,  3.78s/it, loss=2.99, epoch=0.608, learning_rate=6.7e-6]\u001b[A\n",
      " 61%|██████    | 2568/4220 [2:43:59<1:44:06,  3.78s/it, loss=3.03, epoch=0.608, learning_rate=6.69e-6]\u001b[A\n",
      " 61%|██████    | 2569/4220 [2:44:03<1:44:01,  3.78s/it, loss=3.03, epoch=0.608, learning_rate=6.69e-6]\u001b[A\n",
      " 61%|██████    | 2569/4220 [2:44:03<1:44:01,  3.78s/it, loss=2.27, epoch=0.609, learning_rate=6.68e-6]\u001b[A\n",
      " 61%|██████    | 2570/4220 [2:44:07<1:43:56,  3.78s/it, loss=2.27, epoch=0.609, learning_rate=6.68e-6]\u001b[A\n",
      " 61%|██████    | 2570/4220 [2:44:07<1:43:56,  3.78s/it, loss=2.78, epoch=0.609, learning_rate=6.68e-6]\u001b[A\n",
      " 61%|██████    | 2571/4220 [2:44:11<1:43:55,  3.78s/it, loss=2.78, epoch=0.609, learning_rate=6.68e-6]\u001b[A\n",
      " 61%|██████    | 2571/4220 [2:44:11<1:43:55,  3.78s/it, loss=3.01, epoch=0.609, learning_rate=6.67e-6]\u001b[A\n",
      " 61%|██████    | 2572/4220 [2:44:15<1:43:50,  3.78s/it, loss=3.01, epoch=0.609, learning_rate=6.67e-6]\u001b[A\n",
      " 61%|██████    | 2572/4220 [2:44:15<1:43:50,  3.78s/it, loss=3.14, epoch=0.609, learning_rate=6.66e-6]\u001b[A\n",
      " 61%|██████    | 2573/4220 [2:44:18<1:43:47,  3.78s/it, loss=3.14, epoch=0.609, learning_rate=6.66e-6]\u001b[A\n",
      " 61%|██████    | 2573/4220 [2:44:18<1:43:47,  3.78s/it, loss=3.1, epoch=0.609, learning_rate=6.66e-6] \u001b[A\n",
      " 61%|██████    | 2574/4220 [2:44:22<1:43:44,  3.78s/it, loss=3.1, epoch=0.609, learning_rate=6.66e-6]\u001b[A\n",
      " 61%|██████    | 2574/4220 [2:44:22<1:43:44,  3.78s/it, loss=3.01, epoch=0.61, learning_rate=6.65e-6]\u001b[A\n",
      " 61%|██████    | 2575/4220 [2:44:26<1:43:43,  3.78s/it, loss=3.01, epoch=0.61, learning_rate=6.65e-6]\u001b[A\n",
      " 61%|██████    | 2575/4220 [2:44:26<1:43:43,  3.78s/it, loss=2.74, epoch=0.61, learning_rate=6.64e-6]\u001b[A\n",
      " 61%|██████    | 2576/4220 [2:44:30<1:43:39,  3.78s/it, loss=2.74, epoch=0.61, learning_rate=6.64e-6]\u001b[A\n",
      " 61%|██████    | 2576/4220 [2:44:30<1:43:39,  3.78s/it, loss=2.81, epoch=0.61, learning_rate=6.63e-6]\u001b[A\n",
      " 61%|██████    | 2577/4220 [2:44:34<1:43:32,  3.78s/it, loss=2.81, epoch=0.61, learning_rate=6.63e-6]\u001b[A\n",
      " 61%|██████    | 2577/4220 [2:44:34<1:43:32,  3.78s/it, loss=2.93, epoch=0.61, learning_rate=6.63e-6]\u001b[A\n",
      " 61%|██████    | 2578/4220 [2:44:37<1:43:27,  3.78s/it, loss=2.93, epoch=0.61, learning_rate=6.63e-6]\u001b[A\n",
      " 61%|██████    | 2578/4220 [2:44:37<1:43:27,  3.78s/it, loss=3.07, epoch=0.611, learning_rate=6.62e-6]\u001b[A\n",
      " 61%|██████    | 2579/4220 [2:44:41<1:43:24,  3.78s/it, loss=3.07, epoch=0.611, learning_rate=6.62e-6]\u001b[A\n",
      " 61%|██████    | 2579/4220 [2:44:41<1:43:24,  3.78s/it, loss=3.44, epoch=0.611, learning_rate=6.61e-6]\u001b[A\n",
      " 61%|██████    | 2580/4220 [2:44:45<1:43:22,  3.78s/it, loss=3.44, epoch=0.611, learning_rate=6.61e-6]\u001b[A\n",
      " 61%|██████    | 2580/4220 [2:44:45<1:43:22,  3.78s/it, loss=3.32, epoch=0.611, learning_rate=6.61e-6]\u001b[A\n",
      " 61%|██████    | 2581/4220 [2:44:49<1:43:19,  3.78s/it, loss=3.32, epoch=0.611, learning_rate=6.61e-6]\u001b[A\n",
      " 61%|██████    | 2581/4220 [2:44:49<1:43:19,  3.78s/it, loss=2.59, epoch=0.611, learning_rate=6.6e-6] \u001b[A\n",
      " 61%|██████    | 2582/4220 [2:44:52<1:43:16,  3.78s/it, loss=2.59, epoch=0.611, learning_rate=6.6e-6]\u001b[A\n",
      " 61%|██████    | 2582/4220 [2:44:52<1:43:16,  3.78s/it, loss=3.36, epoch=0.612, learning_rate=6.59e-6]\u001b[A\n",
      " 61%|██████    | 2583/4220 [2:44:56<1:43:11,  3.78s/it, loss=3.36, epoch=0.612, learning_rate=6.59e-6]\u001b[A\n",
      " 61%|██████    | 2583/4220 [2:44:56<1:43:11,  3.78s/it, loss=3.08, epoch=0.612, learning_rate=6.59e-6]\u001b[A\n",
      " 61%|██████    | 2584/4220 [2:45:00<1:43:06,  3.78s/it, loss=3.08, epoch=0.612, learning_rate=6.59e-6]\u001b[A\n",
      " 61%|██████    | 2584/4220 [2:45:00<1:43:06,  3.78s/it, loss=2.5, epoch=0.612, learning_rate=6.58e-6] \u001b[A\n",
      " 61%|██████▏   | 2585/4220 [2:45:04<1:43:04,  3.78s/it, loss=2.5, epoch=0.612, learning_rate=6.58e-6]\u001b[A\n",
      " 61%|██████▏   | 2585/4220 [2:45:04<1:43:04,  3.78s/it, loss=2.57, epoch=0.612, learning_rate=6.57e-6]\u001b[A\n",
      " 61%|██████▏   | 2586/4220 [2:45:08<1:43:01,  3.78s/it, loss=2.57, epoch=0.612, learning_rate=6.57e-6]\u001b[A\n",
      " 61%|██████▏   | 2586/4220 [2:45:08<1:43:01,  3.78s/it, loss=3.32, epoch=0.613, learning_rate=6.56e-6]\u001b[A\n",
      " 61%|██████▏   | 2587/4220 [2:45:11<1:42:56,  3.78s/it, loss=3.32, epoch=0.613, learning_rate=6.56e-6]\u001b[A\n",
      " 61%|██████▏   | 2587/4220 [2:45:11<1:42:56,  3.78s/it, loss=3.01, epoch=0.613, learning_rate=6.56e-6]\u001b[A\n",
      " 61%|██████▏   | 2588/4220 [2:45:15<1:42:52,  3.78s/it, loss=3.01, epoch=0.613, learning_rate=6.56e-6]\u001b[A\n",
      " 61%|██████▏   | 2588/4220 [2:45:15<1:42:52,  3.78s/it, loss=3.53, epoch=0.613, learning_rate=6.55e-6]\u001b[A\n",
      " 61%|██████▏   | 2589/4220 [2:45:19<1:42:48,  3.78s/it, loss=3.53, epoch=0.613, learning_rate=6.55e-6]\u001b[A\n",
      " 61%|██████▏   | 2589/4220 [2:45:19<1:42:48,  3.78s/it, loss=2.91, epoch=0.613, learning_rate=6.54e-6]\u001b[A\n",
      " 61%|██████▏   | 2590/4220 [2:45:23<1:42:45,  3.78s/it, loss=2.91, epoch=0.613, learning_rate=6.54e-6]\u001b[A\n",
      " 61%|██████▏   | 2590/4220 [2:45:23<1:42:45,  3.78s/it, loss=2.61, epoch=0.614, learning_rate=6.54e-6]\u001b[A\n",
      " 61%|██████▏   | 2591/4220 [2:45:26<1:42:41,  3.78s/it, loss=2.61, epoch=0.614, learning_rate=6.54e-6]\u001b[A\n",
      " 61%|██████▏   | 2591/4220 [2:45:26<1:42:41,  3.78s/it, loss=2.47, epoch=0.614, learning_rate=6.53e-6]\u001b[A\n",
      " 61%|██████▏   | 2592/4220 [2:45:30<1:42:37,  3.78s/it, loss=2.47, epoch=0.614, learning_rate=6.53e-6]\u001b[A\n",
      " 61%|██████▏   | 2592/4220 [2:45:30<1:42:37,  3.78s/it, loss=2.71, epoch=0.614, learning_rate=6.52e-6]\u001b[A\n",
      " 61%|██████▏   | 2593/4220 [2:45:34<1:42:33,  3.78s/it, loss=2.71, epoch=0.614, learning_rate=6.52e-6]\u001b[A\n",
      " 61%|██████▏   | 2593/4220 [2:45:34<1:42:33,  3.78s/it, loss=2.56, epoch=0.614, learning_rate=6.52e-6]\u001b[A\n",
      " 61%|██████▏   | 2594/4220 [2:45:38<1:42:25,  3.78s/it, loss=2.56, epoch=0.614, learning_rate=6.52e-6]\u001b[A\n",
      " 61%|██████▏   | 2594/4220 [2:45:38<1:42:25,  3.78s/it, loss=2.77, epoch=0.614, learning_rate=6.51e-6]\u001b[A\n",
      " 61%|██████▏   | 2595/4220 [2:45:42<1:42:23,  3.78s/it, loss=2.77, epoch=0.614, learning_rate=6.51e-6]\u001b[A\n",
      " 61%|██████▏   | 2595/4220 [2:45:42<1:42:23,  3.78s/it, loss=2.73, epoch=0.615, learning_rate=6.5e-6] \u001b[A\n",
      " 62%|██████▏   | 2596/4220 [2:45:45<1:42:19,  3.78s/it, loss=2.73, epoch=0.615, learning_rate=6.5e-6]\u001b[A\n",
      " 62%|██████▏   | 2596/4220 [2:45:45<1:42:19,  3.78s/it, loss=2.77, epoch=0.615, learning_rate=6.49e-6]\u001b[A\n",
      " 62%|██████▏   | 2597/4220 [2:45:49<1:42:17,  3.78s/it, loss=2.77, epoch=0.615, learning_rate=6.49e-6]\u001b[A\n",
      " 62%|██████▏   | 2597/4220 [2:45:49<1:42:17,  3.78s/it, loss=3.31, epoch=0.615, learning_rate=6.49e-6]\u001b[A\n",
      " 62%|██████▏   | 2598/4220 [2:45:53<1:42:13,  3.78s/it, loss=3.31, epoch=0.615, learning_rate=6.49e-6]\u001b[A\n",
      " 62%|██████▏   | 2598/4220 [2:45:53<1:42:13,  3.78s/it, loss=3.02, epoch=0.615, learning_rate=6.48e-6]\u001b[A\n",
      " 62%|██████▏   | 2599/4220 [2:45:57<1:42:07,  3.78s/it, loss=3.02, epoch=0.615, learning_rate=6.48e-6]\u001b[A\n",
      " 62%|██████▏   | 2599/4220 [2:45:57<1:42:07,  3.78s/it, loss=2.8, epoch=0.616, learning_rate=6.47e-6] \u001b[A\n",
      " 62%|██████▏   | 2600/4220 [2:46:00<1:42:05,  3.78s/it, loss=2.8, epoch=0.616, learning_rate=6.47e-6]\u001b[A\n",
      " 62%|██████▏   | 2600/4220 [2:46:00<1:42:05,  3.78s/it, loss=2.81, epoch=0.616, learning_rate=6.47e-6]\u001b[A\n",
      " 62%|██████▏   | 2601/4220 [2:46:04<1:42:01,  3.78s/it, loss=2.81, epoch=0.616, learning_rate=6.47e-6]\u001b[A\n",
      " 62%|██████▏   | 2601/4220 [2:46:04<1:42:01,  3.78s/it, loss=2.41, epoch=0.616, learning_rate=6.46e-6]\u001b[A\n",
      " 62%|██████▏   | 2602/4220 [2:46:08<1:41:57,  3.78s/it, loss=2.41, epoch=0.616, learning_rate=6.46e-6]\u001b[A\n",
      " 62%|██████▏   | 2602/4220 [2:46:08<1:41:57,  3.78s/it, loss=3.03, epoch=0.616, learning_rate=6.45e-6]\u001b[A\n",
      " 62%|██████▏   | 2603/4220 [2:46:12<1:41:51,  3.78s/it, loss=3.03, epoch=0.616, learning_rate=6.45e-6]\u001b[A\n",
      " 62%|██████▏   | 2603/4220 [2:46:12<1:41:51,  3.78s/it, loss=2.62, epoch=0.617, learning_rate=6.45e-6]\u001b[A\n",
      " 62%|██████▏   | 2604/4220 [2:46:16<1:41:49,  3.78s/it, loss=2.62, epoch=0.617, learning_rate=6.45e-6]\u001b[A\n",
      " 62%|██████▏   | 2604/4220 [2:46:16<1:41:49,  3.78s/it, loss=2.9, epoch=0.617, learning_rate=6.44e-6] \u001b[A\n",
      " 62%|██████▏   | 2605/4220 [2:46:19<1:41:41,  3.78s/it, loss=2.9, epoch=0.617, learning_rate=6.44e-6]\u001b[A\n",
      " 62%|██████▏   | 2605/4220 [2:46:19<1:41:41,  3.78s/it, loss=2.46, epoch=0.617, learning_rate=6.43e-6]\u001b[A\n",
      " 62%|██████▏   | 2606/4220 [2:46:23<1:41:39,  3.78s/it, loss=2.46, epoch=0.617, learning_rate=6.43e-6]\u001b[A\n",
      " 62%|██████▏   | 2606/4220 [2:46:23<1:41:39,  3.78s/it, loss=2.73, epoch=0.617, learning_rate=6.42e-6]\u001b[A\n",
      " 62%|██████▏   | 2607/4220 [2:46:27<1:41:37,  3.78s/it, loss=2.73, epoch=0.617, learning_rate=6.42e-6]\u001b[A\n",
      " 62%|██████▏   | 2607/4220 [2:46:27<1:41:37,  3.78s/it, loss=2.72, epoch=0.618, learning_rate=6.42e-6]\u001b[A\n",
      " 62%|██████▏   | 2608/4220 [2:46:31<1:41:34,  3.78s/it, loss=2.72, epoch=0.618, learning_rate=6.42e-6]\u001b[A\n",
      " 62%|██████▏   | 2608/4220 [2:46:31<1:41:34,  3.78s/it, loss=2.86, epoch=0.618, learning_rate=6.41e-6]\u001b[A\n",
      " 62%|██████▏   | 2609/4220 [2:46:35<1:41:30,  3.78s/it, loss=2.86, epoch=0.618, learning_rate=6.41e-6]\u001b[A\n",
      " 62%|██████▏   | 2609/4220 [2:46:35<1:41:30,  3.78s/it, loss=2.5, epoch=0.618, learning_rate=6.4e-6]  \u001b[A\n",
      " 62%|██████▏   | 2610/4220 [2:46:38<1:41:27,  3.78s/it, loss=2.5, epoch=0.618, learning_rate=6.4e-6]\u001b[A\n",
      " 62%|██████▏   | 2610/4220 [2:46:38<1:41:27,  3.78s/it, loss=2.78, epoch=0.618, learning_rate=6.4e-6]\u001b[A\n",
      " 62%|██████▏   | 2611/4220 [2:46:42<1:41:26,  3.78s/it, loss=2.78, epoch=0.618, learning_rate=6.4e-6]\u001b[A\n",
      " 62%|██████▏   | 2611/4220 [2:46:42<1:41:26,  3.78s/it, loss=2.8, epoch=0.618, learning_rate=6.39e-6]\u001b[A\n",
      " 62%|██████▏   | 2612/4220 [2:46:46<1:41:22,  3.78s/it, loss=2.8, epoch=0.618, learning_rate=6.39e-6]\u001b[A\n",
      " 62%|██████▏   | 2612/4220 [2:46:46<1:41:22,  3.78s/it, loss=2.53, epoch=0.619, learning_rate=6.38e-6]\u001b[A\n",
      " 62%|██████▏   | 2613/4220 [2:46:50<1:41:16,  3.78s/it, loss=2.53, epoch=0.619, learning_rate=6.38e-6]\u001b[A\n",
      " 62%|██████▏   | 2613/4220 [2:46:50<1:41:16,  3.78s/it, loss=3.23, epoch=0.619, learning_rate=6.38e-6]\u001b[A\n",
      " 62%|██████▏   | 2614/4220 [2:46:53<1:41:11,  3.78s/it, loss=3.23, epoch=0.619, learning_rate=6.38e-6]\u001b[A\n",
      " 62%|██████▏   | 2614/4220 [2:46:53<1:41:11,  3.78s/it, loss=2.74, epoch=0.619, learning_rate=6.37e-6]\u001b[A\n",
      " 62%|██████▏   | 2615/4220 [2:46:57<1:41:09,  3.78s/it, loss=2.74, epoch=0.619, learning_rate=6.37e-6]\u001b[A\n",
      " 62%|██████▏   | 2615/4220 [2:46:57<1:41:09,  3.78s/it, loss=3.16, epoch=0.619, learning_rate=6.36e-6]\u001b[A\n",
      " 62%|██████▏   | 2616/4220 [2:47:01<1:41:07,  3.78s/it, loss=3.16, epoch=0.619, learning_rate=6.36e-6]\u001b[A\n",
      " 62%|██████▏   | 2616/4220 [2:47:01<1:41:07,  3.78s/it, loss=2.87, epoch=0.62, learning_rate=6.35e-6] \u001b[A\n",
      " 62%|██████▏   | 2617/4220 [2:47:05<1:41:04,  3.78s/it, loss=2.87, epoch=0.62, learning_rate=6.35e-6]\u001b[A\n",
      " 62%|██████▏   | 2617/4220 [2:47:05<1:41:04,  3.78s/it, loss=2.87, epoch=0.62, learning_rate=6.35e-6]\u001b[A\n",
      " 62%|██████▏   | 2618/4220 [2:47:09<1:40:59,  3.78s/it, loss=2.87, epoch=0.62, learning_rate=6.35e-6]\u001b[A\n",
      " 62%|██████▏   | 2618/4220 [2:47:09<1:40:59,  3.78s/it, loss=2.83, epoch=0.62, learning_rate=6.34e-6]\u001b[A\n",
      " 62%|██████▏   | 2619/4220 [2:47:12<1:40:53,  3.78s/it, loss=2.83, epoch=0.62, learning_rate=6.34e-6]\u001b[A\n",
      " 62%|██████▏   | 2619/4220 [2:47:12<1:40:53,  3.78s/it, loss=3.08, epoch=0.62, learning_rate=6.33e-6]\u001b[A\n",
      " 62%|██████▏   | 2620/4220 [2:47:16<1:40:50,  3.78s/it, loss=3.08, epoch=0.62, learning_rate=6.33e-6]\u001b[A\n",
      " 62%|██████▏   | 2620/4220 [2:47:16<1:40:50,  3.78s/it, loss=3.02, epoch=0.621, learning_rate=6.33e-6]\u001b[A\n",
      " 62%|██████▏   | 2621/4220 [2:47:20<1:40:45,  3.78s/it, loss=3.02, epoch=0.621, learning_rate=6.33e-6]\u001b[A\n",
      " 62%|██████▏   | 2621/4220 [2:47:20<1:40:45,  3.78s/it, loss=3.4, epoch=0.621, learning_rate=6.32e-6] \u001b[A\n",
      " 62%|██████▏   | 2622/4220 [2:47:24<1:40:43,  3.78s/it, loss=3.4, epoch=0.621, learning_rate=6.32e-6]\u001b[A\n",
      " 62%|██████▏   | 2622/4220 [2:47:24<1:40:43,  3.78s/it, loss=2.96, epoch=0.621, learning_rate=6.31e-6]\u001b[A\n",
      " 62%|██████▏   | 2623/4220 [2:47:27<1:40:41,  3.78s/it, loss=2.96, epoch=0.621, learning_rate=6.31e-6]\u001b[A\n",
      " 62%|██████▏   | 2623/4220 [2:47:27<1:40:41,  3.78s/it, loss=2.83, epoch=0.621, learning_rate=6.31e-6]\u001b[A\n",
      " 62%|██████▏   | 2624/4220 [2:47:31<1:40:38,  3.78s/it, loss=2.83, epoch=0.621, learning_rate=6.31e-6]\u001b[A\n",
      " 62%|██████▏   | 2624/4220 [2:47:31<1:40:38,  3.78s/it, loss=3.22, epoch=0.622, learning_rate=6.3e-6] \u001b[A\n",
      " 62%|██████▏   | 2625/4220 [2:47:35<1:40:35,  3.78s/it, loss=3.22, epoch=0.622, learning_rate=6.3e-6]\u001b[A\n",
      " 62%|██████▏   | 2625/4220 [2:47:35<1:40:35,  3.78s/it, loss=2.62, epoch=0.622, learning_rate=6.29e-6]\u001b[A\n",
      " 62%|██████▏   | 2626/4220 [2:47:39<1:40:32,  3.78s/it, loss=2.62, epoch=0.622, learning_rate=6.29e-6]\u001b[A\n",
      " 62%|██████▏   | 2626/4220 [2:47:39<1:40:32,  3.78s/it, loss=3.28, epoch=0.622, learning_rate=6.29e-6]\u001b[A\n",
      " 62%|██████▏   | 2627/4220 [2:47:43<1:40:27,  3.78s/it, loss=3.28, epoch=0.622, learning_rate=6.29e-6]\u001b[A\n",
      " 62%|██████▏   | 2627/4220 [2:47:43<1:40:27,  3.78s/it, loss=2.51, epoch=0.622, learning_rate=6.28e-6]\u001b[A\n",
      " 62%|██████▏   | 2628/4220 [2:47:46<1:40:23,  3.78s/it, loss=2.51, epoch=0.622, learning_rate=6.28e-6]\u001b[A\n",
      " 62%|██████▏   | 2628/4220 [2:47:46<1:40:23,  3.78s/it, loss=2.94, epoch=0.623, learning_rate=6.27e-6]\u001b[A\n",
      " 62%|██████▏   | 2629/4220 [2:47:50<1:40:20,  3.78s/it, loss=2.94, epoch=0.623, learning_rate=6.27e-6]\u001b[A\n",
      " 62%|██████▏   | 2629/4220 [2:47:50<1:40:20,  3.78s/it, loss=3.02, epoch=0.623, learning_rate=6.26e-6]\u001b[A\n",
      " 62%|██████▏   | 2630/4220 [2:47:54<1:40:15,  3.78s/it, loss=3.02, epoch=0.623, learning_rate=6.26e-6]\u001b[A\n",
      " 62%|██████▏   | 2630/4220 [2:47:54<1:40:15,  3.78s/it, loss=2.89, epoch=0.623, learning_rate=6.26e-6]\u001b[A\n",
      " 62%|██████▏   | 2631/4220 [2:47:58<1:40:10,  3.78s/it, loss=2.89, epoch=0.623, learning_rate=6.26e-6]\u001b[A\n",
      " 62%|██████▏   | 2631/4220 [2:47:58<1:40:10,  3.78s/it, loss=2.63, epoch=0.623, learning_rate=6.25e-6]\u001b[A\n",
      " 62%|██████▏   | 2632/4220 [2:48:02<1:40:04,  3.78s/it, loss=2.63, epoch=0.623, learning_rate=6.25e-6]\u001b[A\n",
      " 62%|██████▏   | 2632/4220 [2:48:02<1:40:04,  3.78s/it, loss=3.07, epoch=0.623, learning_rate=6.24e-6]\u001b[A\n",
      " 62%|██████▏   | 2633/4220 [2:48:05<1:40:01,  3.78s/it, loss=3.07, epoch=0.623, learning_rate=6.24e-6]\u001b[A\n",
      " 62%|██████▏   | 2633/4220 [2:48:05<1:40:01,  3.78s/it, loss=3, epoch=0.624, learning_rate=6.24e-6]   \u001b[A\n",
      " 62%|██████▏   | 2634/4220 [2:48:09<1:39:57,  3.78s/it, loss=3, epoch=0.624, learning_rate=6.24e-6]\u001b[A\n",
      " 62%|██████▏   | 2634/4220 [2:48:09<1:39:57,  3.78s/it, loss=2.15, epoch=0.624, learning_rate=6.23e-6]\u001b[A\n",
      " 62%|██████▏   | 2635/4220 [2:48:13<1:39:55,  3.78s/it, loss=2.15, epoch=0.624, learning_rate=6.23e-6]\u001b[A\n",
      " 62%|██████▏   | 2635/4220 [2:48:13<1:39:55,  3.78s/it, loss=2.73, epoch=0.624, learning_rate=6.22e-6]\u001b[A\n",
      " 62%|██████▏   | 2636/4220 [2:48:17<1:39:49,  3.78s/it, loss=2.73, epoch=0.624, learning_rate=6.22e-6]\u001b[A\n",
      " 62%|██████▏   | 2636/4220 [2:48:17<1:39:49,  3.78s/it, loss=3, epoch=0.624, learning_rate=6.22e-6]   \u001b[A\n",
      " 62%|██████▏   | 2637/4220 [2:48:20<1:39:46,  3.78s/it, loss=3, epoch=0.624, learning_rate=6.22e-6]\u001b[A\n",
      " 62%|██████▏   | 2637/4220 [2:48:20<1:39:46,  3.78s/it, loss=3.22, epoch=0.625, learning_rate=6.21e-6]\u001b[A\n",
      " 63%|██████▎   | 2638/4220 [2:48:24<1:39:41,  3.78s/it, loss=3.22, epoch=0.625, learning_rate=6.21e-6]\u001b[A\n",
      " 63%|██████▎   | 2638/4220 [2:48:24<1:39:41,  3.78s/it, loss=3.3, epoch=0.625, learning_rate=6.2e-6]  \u001b[A\n",
      " 63%|██████▎   | 2639/4220 [2:48:28<1:39:38,  3.78s/it, loss=3.3, epoch=0.625, learning_rate=6.2e-6]\u001b[A\n",
      " 63%|██████▎   | 2639/4220 [2:48:28<1:39:38,  3.78s/it, loss=2.76, epoch=0.625, learning_rate=6.2e-6]\u001b[A\n",
      " 63%|██████▎   | 2640/4220 [2:48:32<1:39:34,  3.78s/it, loss=2.76, epoch=0.625, learning_rate=6.2e-6]\u001b[A\n",
      " 63%|██████▎   | 2640/4220 [2:48:32<1:39:34,  3.78s/it, loss=2.73, epoch=0.625, learning_rate=6.19e-6]\u001b[A\n",
      " 63%|██████▎   | 2641/4220 [2:48:36<1:39:29,  3.78s/it, loss=2.73, epoch=0.625, learning_rate=6.19e-6]\u001b[A\n",
      " 63%|██████▎   | 2641/4220 [2:48:36<1:39:29,  3.78s/it, loss=2.68, epoch=0.626, learning_rate=6.18e-6]\u001b[A\n",
      " 63%|██████▎   | 2642/4220 [2:48:39<1:39:24,  3.78s/it, loss=2.68, epoch=0.626, learning_rate=6.18e-6]\u001b[A\n",
      " 63%|██████▎   | 2642/4220 [2:48:39<1:39:24,  3.78s/it, loss=2.44, epoch=0.626, learning_rate=6.17e-6]\u001b[A\n",
      " 63%|██████▎   | 2643/4220 [2:48:43<1:39:21,  3.78s/it, loss=2.44, epoch=0.626, learning_rate=6.17e-6]\u001b[A\n",
      " 63%|██████▎   | 2643/4220 [2:48:43<1:39:21,  3.78s/it, loss=2.94, epoch=0.626, learning_rate=6.17e-6]\u001b[A\n",
      " 63%|██████▎   | 2644/4220 [2:48:47<1:39:18,  3.78s/it, loss=2.94, epoch=0.626, learning_rate=6.17e-6]\u001b[A\n",
      " 63%|██████▎   | 2644/4220 [2:48:47<1:39:18,  3.78s/it, loss=3.01, epoch=0.626, learning_rate=6.16e-6]\u001b[A\n",
      " 63%|██████▎   | 2645/4220 [2:48:51<1:39:16,  3.78s/it, loss=3.01, epoch=0.626, learning_rate=6.16e-6]\u001b[A\n",
      " 63%|██████▎   | 2645/4220 [2:48:51<1:39:16,  3.78s/it, loss=3.02, epoch=0.627, learning_rate=6.15e-6]\u001b[A\n",
      " 63%|██████▎   | 2646/4220 [2:48:54<1:39:12,  3.78s/it, loss=3.02, epoch=0.627, learning_rate=6.15e-6]\u001b[A\n",
      " 63%|██████▎   | 2646/4220 [2:48:54<1:39:12,  3.78s/it, loss=3.05, epoch=0.627, learning_rate=6.15e-6]\u001b[A\n",
      " 63%|██████▎   | 2647/4220 [2:48:58<1:39:07,  3.78s/it, loss=3.05, epoch=0.627, learning_rate=6.15e-6]\u001b[A\n",
      " 63%|██████▎   | 2647/4220 [2:48:58<1:39:07,  3.78s/it, loss=2.79, epoch=0.627, learning_rate=6.14e-6]\u001b[A\n",
      " 63%|██████▎   | 2648/4220 [2:49:02<1:39:04,  3.78s/it, loss=2.79, epoch=0.627, learning_rate=6.14e-6]\u001b[A\n",
      " 63%|██████▎   | 2648/4220 [2:49:02<1:39:04,  3.78s/it, loss=2, epoch=0.627, learning_rate=6.13e-6]   \u001b[A\n",
      " 63%|██████▎   | 2649/4220 [2:49:06<1:38:59,  3.78s/it, loss=2, epoch=0.627, learning_rate=6.13e-6]\u001b[A\n",
      " 63%|██████▎   | 2649/4220 [2:49:06<1:38:59,  3.78s/it, loss=2.66, epoch=0.627, learning_rate=6.13e-6]\u001b[A\n",
      " 63%|██████▎   | 2650/4220 [2:49:10<1:38:57,  3.78s/it, loss=2.66, epoch=0.627, learning_rate=6.13e-6]\u001b[A\n",
      " 63%|██████▎   | 2650/4220 [2:49:10<1:38:57,  3.78s/it, loss=3.11, epoch=0.628, learning_rate=6.12e-6]\u001b[A\n",
      " 63%|██████▎   | 2651/4220 [2:49:13<1:38:50,  3.78s/it, loss=3.11, epoch=0.628, learning_rate=6.12e-6]\u001b[A\n",
      " 63%|██████▎   | 2651/4220 [2:49:13<1:38:50,  3.78s/it, loss=2.76, epoch=0.628, learning_rate=6.11e-6]\u001b[A\n",
      " 63%|██████▎   | 2652/4220 [2:49:17<1:38:47,  3.78s/it, loss=2.76, epoch=0.628, learning_rate=6.11e-6]\u001b[A\n",
      " 63%|██████▎   | 2652/4220 [2:49:17<1:38:47,  3.78s/it, loss=2.41, epoch=0.628, learning_rate=6.11e-6]\u001b[A\n",
      " 63%|██████▎   | 2653/4220 [2:49:21<1:38:44,  3.78s/it, loss=2.41, epoch=0.628, learning_rate=6.11e-6]\u001b[A\n",
      " 63%|██████▎   | 2653/4220 [2:49:21<1:38:44,  3.78s/it, loss=2.64, epoch=0.628, learning_rate=6.1e-6] \u001b[A\n",
      " 63%|██████▎   | 2654/4220 [2:49:25<1:38:41,  3.78s/it, loss=2.64, epoch=0.628, learning_rate=6.1e-6]\u001b[A\n",
      " 63%|██████▎   | 2654/4220 [2:49:25<1:38:41,  3.78s/it, loss=2.53, epoch=0.629, learning_rate=6.09e-6]\u001b[A\n",
      " 63%|██████▎   | 2655/4220 [2:49:28<1:38:36,  3.78s/it, loss=2.53, epoch=0.629, learning_rate=6.09e-6]\u001b[A\n",
      " 63%|██████▎   | 2655/4220 [2:49:28<1:38:36,  3.78s/it, loss=2.17, epoch=0.629, learning_rate=6.09e-6]\u001b[A\n",
      " 63%|██████▎   | 2656/4220 [2:49:32<1:38:32,  3.78s/it, loss=2.17, epoch=0.629, learning_rate=6.09e-6]\u001b[A\n",
      " 63%|██████▎   | 2656/4220 [2:49:32<1:38:32,  3.78s/it, loss=2.89, epoch=0.629, learning_rate=6.08e-6]\u001b[A\n",
      " 63%|██████▎   | 2657/4220 [2:49:36<1:38:27,  3.78s/it, loss=2.89, epoch=0.629, learning_rate=6.08e-6]\u001b[A\n",
      " 63%|██████▎   | 2657/4220 [2:49:36<1:38:27,  3.78s/it, loss=2.84, epoch=0.629, learning_rate=6.07e-6]\u001b[A\n",
      " 63%|██████▎   | 2658/4220 [2:49:40<1:38:27,  3.78s/it, loss=2.84, epoch=0.629, learning_rate=6.07e-6]\u001b[A\n",
      " 63%|██████▎   | 2658/4220 [2:49:40<1:38:27,  3.78s/it, loss=3.1, epoch=0.63, learning_rate=6.06e-6]  \u001b[A\n",
      " 63%|██████▎   | 2659/4220 [2:49:44<1:38:23,  3.78s/it, loss=3.1, epoch=0.63, learning_rate=6.06e-6]\u001b[A\n",
      " 63%|██████▎   | 2659/4220 [2:49:44<1:38:23,  3.78s/it, loss=3.05, epoch=0.63, learning_rate=6.06e-6]\u001b[A\n",
      " 63%|██████▎   | 2660/4220 [2:49:47<1:38:20,  3.78s/it, loss=3.05, epoch=0.63, learning_rate=6.06e-6]\u001b[A\n",
      " 63%|██████▎   | 2660/4220 [2:49:47<1:38:20,  3.78s/it, loss=3.01, epoch=0.63, learning_rate=6.05e-6]\u001b[A\n",
      " 63%|██████▎   | 2661/4220 [2:49:51<1:38:18,  3.78s/it, loss=3.01, epoch=0.63, learning_rate=6.05e-6]\u001b[A\n",
      " 63%|██████▎   | 2661/4220 [2:49:51<1:38:18,  3.78s/it, loss=2.72, epoch=0.63, learning_rate=6.04e-6]\u001b[A\n",
      " 63%|██████▎   | 2662/4220 [2:49:55<1:38:13,  3.78s/it, loss=2.72, epoch=0.63, learning_rate=6.04e-6]\u001b[A\n",
      " 63%|██████▎   | 2662/4220 [2:49:55<1:38:13,  3.78s/it, loss=3.15, epoch=0.631, learning_rate=6.04e-6]\u001b[A\n",
      " 63%|██████▎   | 2663/4220 [2:49:59<1:38:09,  3.78s/it, loss=3.15, epoch=0.631, learning_rate=6.04e-6]\u001b[A\n",
      " 63%|██████▎   | 2663/4220 [2:49:59<1:38:09,  3.78s/it, loss=2.73, epoch=0.631, learning_rate=6.03e-6]\u001b[A\n",
      " 63%|██████▎   | 2664/4220 [2:50:03<1:38:06,  3.78s/it, loss=2.73, epoch=0.631, learning_rate=6.03e-6]\u001b[A\n",
      " 63%|██████▎   | 2664/4220 [2:50:03<1:38:06,  3.78s/it, loss=2.68, epoch=0.631, learning_rate=6.02e-6]\u001b[A\n",
      " 63%|██████▎   | 2665/4220 [2:50:06<1:38:04,  3.78s/it, loss=2.68, epoch=0.631, learning_rate=6.02e-6]\u001b[A\n",
      " 63%|██████▎   | 2665/4220 [2:50:06<1:38:04,  3.78s/it, loss=3.06, epoch=0.631, learning_rate=6.02e-6]\u001b[A\n",
      " 63%|██████▎   | 2666/4220 [2:50:10<1:37:56,  3.78s/it, loss=3.06, epoch=0.631, learning_rate=6.02e-6]\u001b[A\n",
      " 63%|██████▎   | 2666/4220 [2:50:10<1:37:56,  3.78s/it, loss=3.1, epoch=0.632, learning_rate=6.01e-6] \u001b[A\n",
      " 63%|██████▎   | 2667/4220 [2:50:14<1:37:52,  3.78s/it, loss=3.1, epoch=0.632, learning_rate=6.01e-6]\u001b[A\n",
      " 63%|██████▎   | 2667/4220 [2:50:14<1:37:52,  3.78s/it, loss=2.9, epoch=0.632, learning_rate=6e-6]   \u001b[A\n",
      " 63%|██████▎   | 2668/4220 [2:50:18<1:37:50,  3.78s/it, loss=2.9, epoch=0.632, learning_rate=6e-6]\u001b[A\n",
      " 63%|██████▎   | 2668/4220 [2:50:18<1:37:50,  3.78s/it, loss=2.99, epoch=0.632, learning_rate=6e-6]\u001b[A\n",
      " 63%|██████▎   | 2669/4220 [2:50:21<1:37:47,  3.78s/it, loss=2.99, epoch=0.632, learning_rate=6e-6]\u001b[A\n",
      " 63%|██████▎   | 2669/4220 [2:50:21<1:37:47,  3.78s/it, loss=2.79, epoch=0.632, learning_rate=5.99e-6]\u001b[A\n",
      " 63%|██████▎   | 2670/4220 [2:50:25<1:37:42,  3.78s/it, loss=2.79, epoch=0.632, learning_rate=5.99e-6]\u001b[A\n",
      " 63%|██████▎   | 2670/4220 [2:50:25<1:37:42,  3.78s/it, loss=2.56, epoch=0.632, learning_rate=5.98e-6]\u001b[A\n",
      " 63%|██████▎   | 2671/4220 [2:50:29<1:37:38,  3.78s/it, loss=2.56, epoch=0.632, learning_rate=5.98e-6]\u001b[A\n",
      " 63%|██████▎   | 2671/4220 [2:50:29<1:37:38,  3.78s/it, loss=2.66, epoch=0.633, learning_rate=5.98e-6]\u001b[A\n",
      " 63%|██████▎   | 2672/4220 [2:50:33<1:37:34,  3.78s/it, loss=2.66, epoch=0.633, learning_rate=5.98e-6]\u001b[A\n",
      " 63%|██████▎   | 2672/4220 [2:50:33<1:37:34,  3.78s/it, loss=2.97, epoch=0.633, learning_rate=5.97e-6]\u001b[A\n",
      " 63%|██████▎   | 2673/4220 [2:50:37<1:37:32,  3.78s/it, loss=2.97, epoch=0.633, learning_rate=5.97e-6]\u001b[A\n",
      " 63%|██████▎   | 2673/4220 [2:50:37<1:37:32,  3.78s/it, loss=2.69, epoch=0.633, learning_rate=5.96e-6]\u001b[A\n",
      " 63%|██████▎   | 2674/4220 [2:50:40<1:37:29,  3.78s/it, loss=2.69, epoch=0.633, learning_rate=5.96e-6]\u001b[A\n",
      " 63%|██████▎   | 2674/4220 [2:50:40<1:37:29,  3.78s/it, loss=3.2, epoch=0.633, learning_rate=5.96e-6] \u001b[A\n",
      " 63%|██████▎   | 2675/4220 [2:50:44<1:37:22,  3.78s/it, loss=3.2, epoch=0.633, learning_rate=5.96e-6]\u001b[A\n",
      " 63%|██████▎   | 2675/4220 [2:50:44<1:37:22,  3.78s/it, loss=3.03, epoch=0.634, learning_rate=5.95e-6]\u001b[A\n",
      " 63%|██████▎   | 2676/4220 [2:50:48<1:37:22,  3.78s/it, loss=3.03, epoch=0.634, learning_rate=5.95e-6]\u001b[A\n",
      " 63%|██████▎   | 2676/4220 [2:50:48<1:37:22,  3.78s/it, loss=3.4, epoch=0.634, learning_rate=5.94e-6] \u001b[A\n",
      " 63%|██████▎   | 2677/4220 [2:50:52<1:37:17,  3.78s/it, loss=3.4, epoch=0.634, learning_rate=5.94e-6]\u001b[A\n",
      " 63%|██████▎   | 2677/4220 [2:50:52<1:37:17,  3.78s/it, loss=3.27, epoch=0.634, learning_rate=5.93e-6]\u001b[A\n",
      " 63%|██████▎   | 2678/4220 [2:50:55<1:37:12,  3.78s/it, loss=3.27, epoch=0.634, learning_rate=5.93e-6]\u001b[A\n",
      " 63%|██████▎   | 2678/4220 [2:50:55<1:37:12,  3.78s/it, loss=2.95, epoch=0.634, learning_rate=5.93e-6]\u001b[A\n",
      " 63%|██████▎   | 2679/4220 [2:50:59<1:37:09,  3.78s/it, loss=2.95, epoch=0.634, learning_rate=5.93e-6]\u001b[A\n",
      " 63%|██████▎   | 2679/4220 [2:50:59<1:37:09,  3.78s/it, loss=3.59, epoch=0.635, learning_rate=5.92e-6]\u001b[A\n",
      " 64%|██████▎   | 2680/4220 [2:51:03<1:37:04,  3.78s/it, loss=3.59, epoch=0.635, learning_rate=5.92e-6]\u001b[A\n",
      " 64%|██████▎   | 2680/4220 [2:51:03<1:37:04,  3.78s/it, loss=2.29, epoch=0.635, learning_rate=5.91e-6]\u001b[A\n",
      " 64%|██████▎   | 2681/4220 [2:51:07<1:37:00,  3.78s/it, loss=2.29, epoch=0.635, learning_rate=5.91e-6]\u001b[A\n",
      " 64%|██████▎   | 2681/4220 [2:51:07<1:37:00,  3.78s/it, loss=2.36, epoch=0.635, learning_rate=5.91e-6]\u001b[A\n",
      " 64%|██████▎   | 2682/4220 [2:51:11<1:36:58,  3.78s/it, loss=2.36, epoch=0.635, learning_rate=5.91e-6]\u001b[A\n",
      " 64%|██████▎   | 2682/4220 [2:51:11<1:36:58,  3.78s/it, loss=3.74, epoch=0.635, learning_rate=5.9e-6] \u001b[A\n",
      " 64%|██████▎   | 2683/4220 [2:51:14<1:36:53,  3.78s/it, loss=3.74, epoch=0.635, learning_rate=5.9e-6]\u001b[A\n",
      " 64%|██████▎   | 2683/4220 [2:51:14<1:36:53,  3.78s/it, loss=2.87, epoch=0.636, learning_rate=5.89e-6]\u001b[A\n",
      " 64%|██████▎   | 2684/4220 [2:51:18<1:36:48,  3.78s/it, loss=2.87, epoch=0.636, learning_rate=5.89e-6]\u001b[A\n",
      " 64%|██████▎   | 2684/4220 [2:51:18<1:36:48,  3.78s/it, loss=2.86, epoch=0.636, learning_rate=5.89e-6]\u001b[A\n",
      " 64%|██████▎   | 2685/4220 [2:51:22<1:36:44,  3.78s/it, loss=2.86, epoch=0.636, learning_rate=5.89e-6]\u001b[A\n",
      " 64%|██████▎   | 2685/4220 [2:51:22<1:36:44,  3.78s/it, loss=3.3, epoch=0.636, learning_rate=5.88e-6] \u001b[A\n",
      " 64%|██████▎   | 2686/4220 [2:51:26<1:36:42,  3.78s/it, loss=3.3, epoch=0.636, learning_rate=5.88e-6]\u001b[A\n",
      " 64%|██████▎   | 2686/4220 [2:51:26<1:36:42,  3.78s/it, loss=3.26, epoch=0.636, learning_rate=5.87e-6]\u001b[A\n",
      " 64%|██████▎   | 2687/4220 [2:51:30<1:36:39,  3.78s/it, loss=3.26, epoch=0.636, learning_rate=5.87e-6]\u001b[A\n",
      " 64%|██████▎   | 2687/4220 [2:51:30<1:36:39,  3.78s/it, loss=2.9, epoch=0.636, learning_rate=5.87e-6] \u001b[A\n",
      " 64%|██████▎   | 2688/4220 [2:51:33<1:36:37,  3.78s/it, loss=2.9, epoch=0.636, learning_rate=5.87e-6]\u001b[A\n",
      " 64%|██████▎   | 2688/4220 [2:51:33<1:36:37,  3.78s/it, loss=3.4, epoch=0.637, learning_rate=5.86e-6]\u001b[A\n",
      " 64%|██████▎   | 2689/4220 [2:51:37<1:36:33,  3.78s/it, loss=3.4, epoch=0.637, learning_rate=5.86e-6]\u001b[A\n",
      " 64%|██████▎   | 2689/4220 [2:51:37<1:36:33,  3.78s/it, loss=3.23, epoch=0.637, learning_rate=5.85e-6]\u001b[A\n",
      " 64%|██████▎   | 2690/4220 [2:51:41<1:36:29,  3.78s/it, loss=3.23, epoch=0.637, learning_rate=5.85e-6]\u001b[A\n",
      " 64%|██████▎   | 2690/4220 [2:51:41<1:36:29,  3.78s/it, loss=2.33, epoch=0.637, learning_rate=5.85e-6]\u001b[A\n",
      " 64%|██████▍   | 2691/4220 [2:51:45<1:36:23,  3.78s/it, loss=2.33, epoch=0.637, learning_rate=5.85e-6]\u001b[A\n",
      " 64%|██████▍   | 2691/4220 [2:51:45<1:36:23,  3.78s/it, loss=2.43, epoch=0.637, learning_rate=5.84e-6]\u001b[A\n",
      " 64%|██████▍   | 2692/4220 [2:51:48<1:36:20,  3.78s/it, loss=2.43, epoch=0.637, learning_rate=5.84e-6]\u001b[A\n",
      " 64%|██████▍   | 2692/4220 [2:51:48<1:36:20,  3.78s/it, loss=3.08, epoch=0.638, learning_rate=5.83e-6]\u001b[A\n",
      " 64%|██████▍   | 2693/4220 [2:51:52<1:36:18,  3.78s/it, loss=3.08, epoch=0.638, learning_rate=5.83e-6]\u001b[A\n",
      " 64%|██████▍   | 2693/4220 [2:51:52<1:36:18,  3.78s/it, loss=2.68, epoch=0.638, learning_rate=5.83e-6]\u001b[A\n",
      " 64%|██████▍   | 2694/4220 [2:51:56<1:36:13,  3.78s/it, loss=2.68, epoch=0.638, learning_rate=5.83e-6]\u001b[A\n",
      " 64%|██████▍   | 2694/4220 [2:51:56<1:36:13,  3.78s/it, loss=2.48, epoch=0.638, learning_rate=5.82e-6]\u001b[A\n",
      " 64%|██████▍   | 2695/4220 [2:52:00<1:36:09,  3.78s/it, loss=2.48, epoch=0.638, learning_rate=5.82e-6]\u001b[A\n",
      " 64%|██████▍   | 2695/4220 [2:52:00<1:36:09,  3.78s/it, loss=3.61, epoch=0.638, learning_rate=5.81e-6]\u001b[A\n",
      " 64%|██████▍   | 2696/4220 [2:52:04<1:36:05,  3.78s/it, loss=3.61, epoch=0.638, learning_rate=5.81e-6]\u001b[A\n",
      " 64%|██████▍   | 2696/4220 [2:52:04<1:36:05,  3.78s/it, loss=2.75, epoch=0.639, learning_rate=5.81e-6]\u001b[A\n",
      " 64%|██████▍   | 2697/4220 [2:52:07<1:36:02,  3.78s/it, loss=2.75, epoch=0.639, learning_rate=5.81e-6]\u001b[A\n",
      " 64%|██████▍   | 2697/4220 [2:52:07<1:36:02,  3.78s/it, loss=3.08, epoch=0.639, learning_rate=5.8e-6] \u001b[A\n",
      " 64%|██████▍   | 2698/4220 [2:52:11<1:35:56,  3.78s/it, loss=3.08, epoch=0.639, learning_rate=5.8e-6]\u001b[A\n",
      " 64%|██████▍   | 2698/4220 [2:52:11<1:35:56,  3.78s/it, loss=2.95, epoch=0.639, learning_rate=5.79e-6]\u001b[A\n",
      " 64%|██████▍   | 2699/4220 [2:52:15<1:35:49,  3.78s/it, loss=2.95, epoch=0.639, learning_rate=5.79e-6]\u001b[A\n",
      " 64%|██████▍   | 2699/4220 [2:52:15<1:35:49,  3.78s/it, loss=2.86, epoch=0.639, learning_rate=5.79e-6]\u001b[A\n",
      " 64%|██████▍   | 2700/4220 [2:52:19<1:35:46,  3.78s/it, loss=2.86, epoch=0.639, learning_rate=5.79e-6]\u001b[A\n",
      " 64%|██████▍   | 2700/4220 [2:52:19<1:35:46,  3.78s/it, loss=2.8, epoch=0.64, learning_rate=5.78e-6]  \u001b[A\n",
      " 64%|██████▍   | 2701/4220 [2:52:22<1:35:41,  3.78s/it, loss=2.8, epoch=0.64, learning_rate=5.78e-6]\u001b[A\n",
      " 64%|██████▍   | 2701/4220 [2:52:22<1:35:41,  3.78s/it, loss=2.67, epoch=0.64, learning_rate=5.77e-6]\u001b[A\n",
      " 64%|██████▍   | 2702/4220 [2:52:26<1:35:40,  3.78s/it, loss=2.67, epoch=0.64, learning_rate=5.77e-6]\u001b[A\n",
      " 64%|██████▍   | 2702/4220 [2:52:26<1:35:40,  3.78s/it, loss=3.11, epoch=0.64, learning_rate=5.77e-6]\u001b[A\n",
      " 64%|██████▍   | 2703/4220 [2:52:30<1:35:34,  3.78s/it, loss=3.11, epoch=0.64, learning_rate=5.77e-6]\u001b[A\n",
      " 64%|██████▍   | 2703/4220 [2:52:30<1:35:34,  3.78s/it, loss=3.12, epoch=0.64, learning_rate=5.76e-6]\u001b[A\n",
      " 64%|██████▍   | 2704/4220 [2:52:34<1:35:31,  3.78s/it, loss=3.12, epoch=0.64, learning_rate=5.76e-6]\u001b[A\n",
      " 64%|██████▍   | 2704/4220 [2:52:34<1:35:31,  3.78s/it, loss=2.3, epoch=0.641, learning_rate=5.75e-6]\u001b[A\n",
      " 64%|██████▍   | 2705/4220 [2:52:38<1:35:30,  3.78s/it, loss=2.3, epoch=0.641, learning_rate=5.75e-6]\u001b[A\n",
      " 64%|██████▍   | 2705/4220 [2:52:38<1:35:30,  3.78s/it, loss=2.74, epoch=0.641, learning_rate=5.74e-6]\u001b[A\n",
      " 64%|██████▍   | 2706/4220 [2:52:41<1:35:26,  3.78s/it, loss=2.74, epoch=0.641, learning_rate=5.74e-6]\u001b[A\n",
      " 64%|██████▍   | 2706/4220 [2:52:41<1:35:26,  3.78s/it, loss=2.25, epoch=0.641, learning_rate=5.74e-6]\u001b[A\n",
      " 64%|██████▍   | 2707/4220 [2:52:45<1:35:22,  3.78s/it, loss=2.25, epoch=0.641, learning_rate=5.74e-6]\u001b[A\n",
      " 64%|██████▍   | 2707/4220 [2:52:45<1:35:22,  3.78s/it, loss=3.09, epoch=0.641, learning_rate=5.73e-6]\u001b[A\n",
      " 64%|██████▍   | 2708/4220 [2:52:49<1:35:17,  3.78s/it, loss=3.09, epoch=0.641, learning_rate=5.73e-6]\u001b[A\n",
      " 64%|██████▍   | 2708/4220 [2:52:49<1:35:17,  3.78s/it, loss=2.5, epoch=0.641, learning_rate=5.72e-6] \u001b[A\n",
      " 64%|██████▍   | 2709/4220 [2:52:53<1:35:12,  3.78s/it, loss=2.5, epoch=0.641, learning_rate=5.72e-6]\u001b[A\n",
      " 64%|██████▍   | 2709/4220 [2:52:53<1:35:12,  3.78s/it, loss=2.53, epoch=0.642, learning_rate=5.72e-6]\u001b[A\n",
      " 64%|██████▍   | 2710/4220 [2:52:56<1:35:07,  3.78s/it, loss=2.53, epoch=0.642, learning_rate=5.72e-6]\u001b[A\n",
      " 64%|██████▍   | 2710/4220 [2:52:56<1:35:07,  3.78s/it, loss=2.97, epoch=0.642, learning_rate=5.71e-6]\u001b[A\n",
      " 64%|██████▍   | 2711/4220 [2:53:00<1:35:07,  3.78s/it, loss=2.97, epoch=0.642, learning_rate=5.71e-6]\u001b[A\n",
      " 64%|██████▍   | 2711/4220 [2:53:00<1:35:07,  3.78s/it, loss=2.67, epoch=0.642, learning_rate=5.7e-6] \u001b[A\n",
      " 64%|██████▍   | 2712/4220 [2:53:04<1:35:02,  3.78s/it, loss=2.67, epoch=0.642, learning_rate=5.7e-6]\u001b[A\n",
      " 64%|██████▍   | 2712/4220 [2:53:04<1:35:02,  3.78s/it, loss=2.55, epoch=0.642, learning_rate=5.7e-6]\u001b[A\n",
      " 64%|██████▍   | 2713/4220 [2:53:08<1:34:59,  3.78s/it, loss=2.55, epoch=0.642, learning_rate=5.7e-6]\u001b[A\n",
      " 64%|██████▍   | 2713/4220 [2:53:08<1:34:59,  3.78s/it, loss=2.59, epoch=0.643, learning_rate=5.69e-6]\u001b[A\n",
      " 64%|██████▍   | 2714/4220 [2:53:12<1:34:54,  3.78s/it, loss=2.59, epoch=0.643, learning_rate=5.69e-6]\u001b[A\n",
      " 64%|██████▍   | 2714/4220 [2:53:12<1:34:54,  3.78s/it, loss=3.05, epoch=0.643, learning_rate=5.68e-6]\u001b[A\n",
      " 64%|██████▍   | 2715/4220 [2:53:15<1:34:51,  3.78s/it, loss=3.05, epoch=0.643, learning_rate=5.68e-6]\u001b[A\n",
      " 64%|██████▍   | 2715/4220 [2:53:15<1:34:51,  3.78s/it, loss=2.59, epoch=0.643, learning_rate=5.68e-6]\u001b[A\n",
      " 64%|██████▍   | 2716/4220 [2:53:19<1:34:46,  3.78s/it, loss=2.59, epoch=0.643, learning_rate=5.68e-6]\u001b[A\n",
      " 64%|██████▍   | 2716/4220 [2:53:19<1:34:46,  3.78s/it, loss=2.77, epoch=0.643, learning_rate=5.67e-6]\u001b[A\n",
      " 64%|██████▍   | 2717/4220 [2:53:23<1:34:44,  3.78s/it, loss=2.77, epoch=0.643, learning_rate=5.67e-6]\u001b[A\n",
      " 64%|██████▍   | 2717/4220 [2:53:23<1:34:44,  3.78s/it, loss=2.66, epoch=0.644, learning_rate=5.66e-6]\u001b[A\n",
      " 64%|██████▍   | 2718/4220 [2:53:27<1:34:38,  3.78s/it, loss=2.66, epoch=0.644, learning_rate=5.66e-6]\u001b[A\n",
      " 64%|██████▍   | 2718/4220 [2:53:27<1:34:38,  3.78s/it, loss=2.99, epoch=0.644, learning_rate=5.66e-6]\u001b[A\n",
      " 64%|██████▍   | 2719/4220 [2:53:31<1:34:34,  3.78s/it, loss=2.99, epoch=0.644, learning_rate=5.66e-6]\u001b[A\n",
      " 64%|██████▍   | 2719/4220 [2:53:31<1:34:34,  3.78s/it, loss=3.04, epoch=0.644, learning_rate=5.65e-6]\u001b[A\n",
      " 64%|██████▍   | 2720/4220 [2:53:34<1:34:30,  3.78s/it, loss=3.04, epoch=0.644, learning_rate=5.65e-6]\u001b[A\n",
      " 64%|██████▍   | 2720/4220 [2:53:34<1:34:30,  3.78s/it, loss=2.54, epoch=0.644, learning_rate=5.64e-6]\u001b[A\n",
      " 64%|██████▍   | 2721/4220 [2:53:38<1:34:27,  3.78s/it, loss=2.54, epoch=0.644, learning_rate=5.64e-6]\u001b[A\n",
      " 64%|██████▍   | 2721/4220 [2:53:38<1:34:27,  3.78s/it, loss=2.51, epoch=0.645, learning_rate=5.64e-6]\u001b[A\n",
      " 65%|██████▍   | 2722/4220 [2:53:42<1:34:23,  3.78s/it, loss=2.51, epoch=0.645, learning_rate=5.64e-6]\u001b[A\n",
      " 65%|██████▍   | 2722/4220 [2:53:42<1:34:23,  3.78s/it, loss=2.51, epoch=0.645, learning_rate=5.63e-6]\u001b[A\n",
      " 65%|██████▍   | 2723/4220 [2:53:46<1:34:24,  3.78s/it, loss=2.51, epoch=0.645, learning_rate=5.63e-6]\u001b[A\n",
      " 65%|██████▍   | 2723/4220 [2:53:46<1:34:24,  3.78s/it, loss=2.71, epoch=0.645, learning_rate=5.62e-6]\u001b[A\n",
      " 65%|██████▍   | 2724/4220 [2:53:49<1:34:17,  3.78s/it, loss=2.71, epoch=0.645, learning_rate=5.62e-6]\u001b[A\n",
      " 65%|██████▍   | 2724/4220 [2:53:49<1:34:17,  3.78s/it, loss=2.41, epoch=0.645, learning_rate=5.62e-6]\u001b[A\n",
      " 65%|██████▍   | 2725/4220 [2:53:53<1:34:13,  3.78s/it, loss=2.41, epoch=0.645, learning_rate=5.62e-6]\u001b[A\n",
      " 65%|██████▍   | 2725/4220 [2:53:53<1:34:13,  3.78s/it, loss=2.58, epoch=0.645, learning_rate=5.61e-6]\u001b[A\n",
      " 65%|██████▍   | 2726/4220 [2:53:57<1:34:11,  3.78s/it, loss=2.58, epoch=0.645, learning_rate=5.61e-6]\u001b[A\n",
      " 65%|██████▍   | 2726/4220 [2:53:57<1:34:11,  3.78s/it, loss=2.96, epoch=0.646, learning_rate=5.6e-6] \u001b[A\n",
      " 65%|██████▍   | 2727/4220 [2:54:01<1:34:06,  3.78s/it, loss=2.96, epoch=0.646, learning_rate=5.6e-6]\u001b[A\n",
      " 65%|██████▍   | 2727/4220 [2:54:01<1:34:06,  3.78s/it, loss=2.79, epoch=0.646, learning_rate=5.6e-6]\u001b[A\n",
      " 65%|██████▍   | 2728/4220 [2:54:05<1:34:04,  3.78s/it, loss=2.79, epoch=0.646, learning_rate=5.6e-6]\u001b[A\n",
      " 65%|██████▍   | 2728/4220 [2:54:05<1:34:04,  3.78s/it, loss=3.58, epoch=0.646, learning_rate=5.59e-6]\u001b[A\n",
      " 65%|██████▍   | 2729/4220 [2:54:08<1:34:00,  3.78s/it, loss=3.58, epoch=0.646, learning_rate=5.59e-6]\u001b[A\n",
      " 65%|██████▍   | 2729/4220 [2:54:08<1:34:00,  3.78s/it, loss=2.95, epoch=0.646, learning_rate=5.58e-6]\u001b[A\n",
      " 65%|██████▍   | 2730/4220 [2:54:12<1:33:55,  3.78s/it, loss=2.95, epoch=0.646, learning_rate=5.58e-6]\u001b[A\n",
      " 65%|██████▍   | 2730/4220 [2:54:12<1:33:55,  3.78s/it, loss=2.77, epoch=0.647, learning_rate=5.58e-6]\u001b[A\n",
      " 65%|██████▍   | 2731/4220 [2:54:16<1:33:52,  3.78s/it, loss=2.77, epoch=0.647, learning_rate=5.58e-6]\u001b[A\n",
      " 65%|██████▍   | 2731/4220 [2:54:16<1:33:52,  3.78s/it, loss=2.62, epoch=0.647, learning_rate=5.57e-6]\u001b[A\n",
      " 65%|██████▍   | 2732/4220 [2:54:20<1:33:46,  3.78s/it, loss=2.62, epoch=0.647, learning_rate=5.57e-6]\u001b[A\n",
      " 65%|██████▍   | 2732/4220 [2:54:20<1:33:46,  3.78s/it, loss=2.88, epoch=0.647, learning_rate=5.56e-6]\u001b[A\n",
      " 65%|██████▍   | 2733/4220 [2:54:23<1:33:44,  3.78s/it, loss=2.88, epoch=0.647, learning_rate=5.56e-6]\u001b[A\n",
      " 65%|██████▍   | 2733/4220 [2:54:23<1:33:44,  3.78s/it, loss=2.71, epoch=0.647, learning_rate=5.56e-6]\u001b[A\n",
      " 65%|██████▍   | 2734/4220 [2:54:27<1:33:40,  3.78s/it, loss=2.71, epoch=0.647, learning_rate=5.56e-6]\u001b[A\n",
      " 65%|██████▍   | 2734/4220 [2:54:27<1:33:40,  3.78s/it, loss=3.11, epoch=0.648, learning_rate=5.55e-6]\u001b[A\n",
      " 65%|██████▍   | 2735/4220 [2:54:31<1:33:36,  3.78s/it, loss=3.11, epoch=0.648, learning_rate=5.55e-6]\u001b[A\n",
      " 65%|██████▍   | 2735/4220 [2:54:31<1:33:36,  3.78s/it, loss=2.46, epoch=0.648, learning_rate=5.54e-6]\u001b[A\n",
      " 65%|██████▍   | 2736/4220 [2:54:35<1:33:33,  3.78s/it, loss=2.46, epoch=0.648, learning_rate=5.54e-6]\u001b[A\n",
      " 65%|██████▍   | 2736/4220 [2:54:35<1:33:33,  3.78s/it, loss=2.91, epoch=0.648, learning_rate=5.54e-6]\u001b[A\n",
      " 65%|██████▍   | 2737/4220 [2:54:39<1:33:29,  3.78s/it, loss=2.91, epoch=0.648, learning_rate=5.54e-6]\u001b[A\n",
      " 65%|██████▍   | 2737/4220 [2:54:39<1:33:29,  3.78s/it, loss=3, epoch=0.648, learning_rate=5.53e-6]   \u001b[A\n",
      " 65%|██████▍   | 2738/4220 [2:54:42<1:33:26,  3.78s/it, loss=3, epoch=0.648, learning_rate=5.53e-6]\u001b[A\n",
      " 65%|██████▍   | 2738/4220 [2:54:42<1:33:26,  3.78s/it, loss=2.29, epoch=0.649, learning_rate=5.52e-6]\u001b[A\n",
      " 65%|██████▍   | 2739/4220 [2:54:46<1:33:20,  3.78s/it, loss=2.29, epoch=0.649, learning_rate=5.52e-6]\u001b[A\n",
      " 65%|██████▍   | 2739/4220 [2:54:46<1:33:20,  3.78s/it, loss=3.09, epoch=0.649, learning_rate=5.52e-6]\u001b[A\n",
      " 65%|██████▍   | 2740/4220 [2:54:50<1:33:18,  3.78s/it, loss=3.09, epoch=0.649, learning_rate=5.52e-6]\u001b[A\n",
      " 65%|██████▍   | 2740/4220 [2:54:50<1:33:18,  3.78s/it, loss=2.64, epoch=0.649, learning_rate=5.51e-6]\u001b[A\n",
      " 65%|██████▍   | 2741/4220 [2:54:54<1:33:15,  3.78s/it, loss=2.64, epoch=0.649, learning_rate=5.51e-6]\u001b[A\n",
      " 65%|██████▍   | 2741/4220 [2:54:54<1:33:15,  3.78s/it, loss=3.33, epoch=0.649, learning_rate=5.5e-6] \u001b[A\n",
      " 65%|██████▍   | 2742/4220 [2:54:58<1:33:10,  3.78s/it, loss=3.33, epoch=0.649, learning_rate=5.5e-6]\u001b[A\n",
      " 65%|██████▍   | 2742/4220 [2:54:58<1:33:10,  3.78s/it, loss=2.44, epoch=0.65, learning_rate=5.5e-6] \u001b[A\n",
      " 65%|██████▌   | 2743/4220 [2:55:01<1:33:08,  3.78s/it, loss=2.44, epoch=0.65, learning_rate=5.5e-6]\u001b[A\n",
      " 65%|██████▌   | 2743/4220 [2:55:01<1:33:08,  3.78s/it, loss=3.05, epoch=0.65, learning_rate=5.49e-6]\u001b[A\n",
      " 65%|██████▌   | 2744/4220 [2:55:05<1:33:03,  3.78s/it, loss=3.05, epoch=0.65, learning_rate=5.49e-6]\u001b[A\n",
      " 65%|██████▌   | 2744/4220 [2:55:05<1:33:03,  3.78s/it, loss=2.69, epoch=0.65, learning_rate=5.48e-6]\u001b[A\n",
      " 65%|██████▌   | 2745/4220 [2:55:09<1:32:57,  3.78s/it, loss=2.69, epoch=0.65, learning_rate=5.48e-6]\u001b[A\n",
      " 65%|██████▌   | 2745/4220 [2:55:09<1:32:57,  3.78s/it, loss=2.76, epoch=0.65, learning_rate=5.48e-6]\u001b[A\n",
      " 65%|██████▌   | 2746/4220 [2:55:13<1:32:55,  3.78s/it, loss=2.76, epoch=0.65, learning_rate=5.48e-6]\u001b[A\n",
      " 65%|██████▌   | 2746/4220 [2:55:13<1:32:55,  3.78s/it, loss=3.11, epoch=0.65, learning_rate=5.47e-6]\u001b[A\n",
      " 65%|██████▌   | 2747/4220 [2:55:16<1:32:47,  3.78s/it, loss=3.11, epoch=0.65, learning_rate=5.47e-6]\u001b[A\n",
      " 65%|██████▌   | 2747/4220 [2:55:16<1:32:47,  3.78s/it, loss=2.8, epoch=0.651, learning_rate=5.46e-6]\u001b[A\n",
      " 65%|██████▌   | 2748/4220 [2:55:20<1:32:46,  3.78s/it, loss=2.8, epoch=0.651, learning_rate=5.46e-6]\u001b[A\n",
      " 65%|██████▌   | 2748/4220 [2:55:20<1:32:46,  3.78s/it, loss=3.06, epoch=0.651, learning_rate=5.46e-6]\u001b[A\n",
      " 65%|██████▌   | 2749/4220 [2:55:24<1:32:42,  3.78s/it, loss=3.06, epoch=0.651, learning_rate=5.46e-6]\u001b[A\n",
      " 65%|██████▌   | 2749/4220 [2:55:24<1:32:42,  3.78s/it, loss=3.16, epoch=0.651, learning_rate=5.45e-6]\u001b[A\n",
      " 65%|██████▌   | 2750/4220 [2:55:28<1:32:40,  3.78s/it, loss=3.16, epoch=0.651, learning_rate=5.45e-6]\u001b[A\n",
      " 65%|██████▌   | 2750/4220 [2:55:28<1:32:40,  3.78s/it, loss=2.71, epoch=0.651, learning_rate=5.44e-6]\u001b[A\n",
      " 65%|██████▌   | 2751/4220 [2:55:32<1:32:37,  3.78s/it, loss=2.71, epoch=0.651, learning_rate=5.44e-6]\u001b[A\n",
      " 65%|██████▌   | 2751/4220 [2:55:32<1:32:37,  3.78s/it, loss=2.89, epoch=0.652, learning_rate=5.44e-6]\u001b[A\n",
      " 65%|██████▌   | 2752/4220 [2:55:35<1:32:33,  3.78s/it, loss=2.89, epoch=0.652, learning_rate=5.44e-6]\u001b[A\n",
      " 65%|██████▌   | 2752/4220 [2:55:35<1:32:33,  3.78s/it, loss=3.04, epoch=0.652, learning_rate=5.43e-6]\u001b[A\n",
      " 65%|██████▌   | 2753/4220 [2:55:39<1:32:27,  3.78s/it, loss=3.04, epoch=0.652, learning_rate=5.43e-6]\u001b[A\n",
      " 65%|██████▌   | 2753/4220 [2:55:39<1:32:27,  3.78s/it, loss=2.67, epoch=0.652, learning_rate=5.42e-6]\u001b[A\n",
      " 65%|██████▌   | 2754/4220 [2:55:43<1:32:23,  3.78s/it, loss=2.67, epoch=0.652, learning_rate=5.42e-6]\u001b[A\n",
      " 65%|██████▌   | 2754/4220 [2:55:43<1:32:23,  3.78s/it, loss=3.17, epoch=0.652, learning_rate=5.42e-6]\u001b[A\n",
      " 65%|██████▌   | 2755/4220 [2:55:47<1:32:19,  3.78s/it, loss=3.17, epoch=0.652, learning_rate=5.42e-6]\u001b[A\n",
      " 65%|██████▌   | 2755/4220 [2:55:47<1:32:19,  3.78s/it, loss=3.38, epoch=0.653, learning_rate=5.41e-6]\u001b[A\n",
      " 65%|██████▌   | 2756/4220 [2:55:50<1:32:14,  3.78s/it, loss=3.38, epoch=0.653, learning_rate=5.41e-6]\u001b[A\n",
      " 65%|██████▌   | 2756/4220 [2:55:50<1:32:14,  3.78s/it, loss=3.1, epoch=0.653, learning_rate=5.4e-6]  \u001b[A\n",
      " 65%|██████▌   | 2757/4220 [2:55:54<1:32:11,  3.78s/it, loss=3.1, epoch=0.653, learning_rate=5.4e-6]\u001b[A\n",
      " 65%|██████▌   | 2757/4220 [2:55:54<1:32:11,  3.78s/it, loss=3.15, epoch=0.653, learning_rate=5.4e-6]\u001b[A\n",
      " 65%|██████▌   | 2758/4220 [2:55:58<1:32:06,  3.78s/it, loss=3.15, epoch=0.653, learning_rate=5.4e-6]\u001b[A\n",
      " 65%|██████▌   | 2758/4220 [2:55:58<1:32:06,  3.78s/it, loss=2.44, epoch=0.653, learning_rate=5.39e-6]\u001b[A\n",
      " 65%|██████▌   | 2759/4220 [2:56:02<1:32:03,  3.78s/it, loss=2.44, epoch=0.653, learning_rate=5.39e-6]\u001b[A\n",
      " 65%|██████▌   | 2759/4220 [2:56:02<1:32:03,  3.78s/it, loss=2.94, epoch=0.654, learning_rate=5.38e-6]\u001b[A\n",
      " 65%|██████▌   | 2760/4220 [2:56:06<1:32:01,  3.78s/it, loss=2.94, epoch=0.654, learning_rate=5.38e-6]\u001b[A\n",
      " 65%|██████▌   | 2760/4220 [2:56:06<1:32:01,  3.78s/it, loss=2.74, epoch=0.654, learning_rate=5.38e-6]\u001b[A\n",
      " 65%|██████▌   | 2761/4220 [2:56:09<1:31:58,  3.78s/it, loss=2.74, epoch=0.654, learning_rate=5.38e-6]\u001b[A\n",
      " 65%|██████▌   | 2761/4220 [2:56:09<1:31:58,  3.78s/it, loss=3.01, epoch=0.654, learning_rate=5.37e-6]\u001b[A\n",
      " 65%|██████▌   | 2762/4220 [2:56:13<1:31:54,  3.78s/it, loss=3.01, epoch=0.654, learning_rate=5.37e-6]\u001b[A\n",
      " 65%|██████▌   | 2762/4220 [2:56:13<1:31:54,  3.78s/it, loss=3.13, epoch=0.654, learning_rate=5.36e-6]\u001b[A\n",
      " 65%|██████▌   | 2763/4220 [2:56:17<1:31:49,  3.78s/it, loss=3.13, epoch=0.654, learning_rate=5.36e-6]\u001b[A\n",
      " 65%|██████▌   | 2763/4220 [2:56:17<1:31:49,  3.78s/it, loss=3.09, epoch=0.655, learning_rate=5.36e-6]\u001b[A\n",
      " 65%|██████▌   | 2764/4220 [2:56:21<1:31:47,  3.78s/it, loss=3.09, epoch=0.655, learning_rate=5.36e-6]\u001b[A\n",
      " 65%|██████▌   | 2764/4220 [2:56:21<1:31:47,  3.78s/it, loss=2.84, epoch=0.655, learning_rate=5.35e-6]\u001b[A\n",
      " 66%|██████▌   | 2765/4220 [2:56:25<1:31:42,  3.78s/it, loss=2.84, epoch=0.655, learning_rate=5.35e-6]\u001b[A\n",
      " 66%|██████▌   | 2765/4220 [2:56:25<1:31:42,  3.78s/it, loss=2.74, epoch=0.655, learning_rate=5.34e-6]\u001b[A\n",
      " 66%|██████▌   | 2766/4220 [2:56:28<1:31:37,  3.78s/it, loss=2.74, epoch=0.655, learning_rate=5.34e-6]\u001b[A\n",
      " 66%|██████▌   | 2766/4220 [2:56:28<1:31:37,  3.78s/it, loss=2.71, epoch=0.655, learning_rate=5.34e-6]\u001b[A\n",
      " 66%|██████▌   | 2767/4220 [2:56:32<1:31:34,  3.78s/it, loss=2.71, epoch=0.655, learning_rate=5.34e-6]\u001b[A\n",
      " 66%|██████▌   | 2767/4220 [2:56:32<1:31:34,  3.78s/it, loss=2.29, epoch=0.655, learning_rate=5.33e-6]\u001b[A\n",
      " 66%|██████▌   | 2768/4220 [2:56:36<1:31:30,  3.78s/it, loss=2.29, epoch=0.655, learning_rate=5.33e-6]\u001b[A\n",
      " 66%|██████▌   | 2768/4220 [2:56:36<1:31:30,  3.78s/it, loss=3.02, epoch=0.656, learning_rate=5.32e-6]\u001b[A\n",
      " 66%|██████▌   | 2769/4220 [2:56:40<1:31:27,  3.78s/it, loss=3.02, epoch=0.656, learning_rate=5.32e-6]\u001b[A\n",
      " 66%|██████▌   | 2769/4220 [2:56:40<1:31:27,  3.78s/it, loss=3.2, epoch=0.656, learning_rate=5.32e-6] \u001b[A\n",
      " 66%|██████▌   | 2770/4220 [2:56:43<1:31:26,  3.78s/it, loss=3.2, epoch=0.656, learning_rate=5.32e-6]\u001b[A\n",
      " 66%|██████▌   | 2770/4220 [2:56:43<1:31:26,  3.78s/it, loss=2.74, epoch=0.656, learning_rate=5.31e-6]\u001b[A\n",
      " 66%|██████▌   | 2771/4220 [2:56:47<1:31:21,  3.78s/it, loss=2.74, epoch=0.656, learning_rate=5.31e-6]\u001b[A\n",
      " 66%|██████▌   | 2771/4220 [2:56:47<1:31:21,  3.78s/it, loss=2.98, epoch=0.656, learning_rate=5.3e-6] \u001b[A\n",
      " 66%|██████▌   | 2772/4220 [2:56:51<1:31:18,  3.78s/it, loss=2.98, epoch=0.656, learning_rate=5.3e-6]\u001b[A\n",
      " 66%|██████▌   | 2772/4220 [2:56:51<1:31:18,  3.78s/it, loss=2.65, epoch=0.657, learning_rate=5.3e-6]\u001b[A\n",
      " 66%|██████▌   | 2773/4220 [2:56:55<1:31:12,  3.78s/it, loss=2.65, epoch=0.657, learning_rate=5.3e-6]\u001b[A\n",
      " 66%|██████▌   | 2773/4220 [2:56:55<1:31:12,  3.78s/it, loss=2.87, epoch=0.657, learning_rate=5.29e-6]\u001b[A\n",
      " 66%|██████▌   | 2774/4220 [2:56:59<1:31:08,  3.78s/it, loss=2.87, epoch=0.657, learning_rate=5.29e-6]\u001b[A\n",
      " 66%|██████▌   | 2774/4220 [2:56:59<1:31:08,  3.78s/it, loss=2.72, epoch=0.657, learning_rate=5.28e-6]\u001b[A\n",
      " 66%|██████▌   | 2775/4220 [2:57:02<1:31:05,  3.78s/it, loss=2.72, epoch=0.657, learning_rate=5.28e-6]\u001b[A\n",
      " 66%|██████▌   | 2775/4220 [2:57:02<1:31:05,  3.78s/it, loss=2.94, epoch=0.657, learning_rate=5.28e-6]\u001b[A\n",
      " 66%|██████▌   | 2776/4220 [2:57:06<1:31:01,  3.78s/it, loss=2.94, epoch=0.657, learning_rate=5.28e-6]\u001b[A\n",
      " 66%|██████▌   | 2776/4220 [2:57:06<1:31:01,  3.78s/it, loss=2.7, epoch=0.658, learning_rate=5.27e-6] \u001b[A\n",
      " 66%|██████▌   | 2777/4220 [2:57:10<1:31:00,  3.78s/it, loss=2.7, epoch=0.658, learning_rate=5.27e-6]\u001b[A\n",
      " 66%|██████▌   | 2777/4220 [2:57:10<1:31:00,  3.78s/it, loss=3.08, epoch=0.658, learning_rate=5.27e-6]\u001b[A\n",
      " 66%|██████▌   | 2778/4220 [2:57:14<1:30:53,  3.78s/it, loss=3.08, epoch=0.658, learning_rate=5.27e-6]\u001b[A\n",
      " 66%|██████▌   | 2778/4220 [2:57:14<1:30:53,  3.78s/it, loss=2.44, epoch=0.658, learning_rate=5.26e-6]\u001b[A\n",
      " 66%|██████▌   | 2779/4220 [2:57:17<1:30:50,  3.78s/it, loss=2.44, epoch=0.658, learning_rate=5.26e-6]\u001b[A\n",
      " 66%|██████▌   | 2779/4220 [2:57:17<1:30:50,  3.78s/it, loss=2.88, epoch=0.658, learning_rate=5.25e-6]\u001b[A\n",
      " 66%|██████▌   | 2780/4220 [2:57:21<1:30:46,  3.78s/it, loss=2.88, epoch=0.658, learning_rate=5.25e-6]\u001b[A\n",
      " 66%|██████▌   | 2780/4220 [2:57:21<1:30:46,  3.78s/it, loss=3.27, epoch=0.659, learning_rate=5.25e-6]\u001b[A\n",
      " 66%|██████▌   | 2781/4220 [2:57:25<1:30:55,  3.79s/it, loss=3.27, epoch=0.659, learning_rate=5.25e-6]\u001b[A\n",
      " 66%|██████▌   | 2781/4220 [2:57:25<1:30:55,  3.79s/it, loss=3.12, epoch=0.659, learning_rate=5.24e-6]\u001b[A\n",
      " 66%|██████▌   | 2782/4220 [2:57:29<1:30:46,  3.79s/it, loss=3.12, epoch=0.659, learning_rate=5.24e-6]\u001b[A\n",
      " 66%|██████▌   | 2782/4220 [2:57:29<1:30:46,  3.79s/it, loss=2.76, epoch=0.659, learning_rate=5.23e-6]\u001b[A\n",
      " 66%|██████▌   | 2783/4220 [2:57:33<1:30:40,  3.79s/it, loss=2.76, epoch=0.659, learning_rate=5.23e-6]\u001b[A\n",
      " 66%|██████▌   | 2783/4220 [2:57:33<1:30:40,  3.79s/it, loss=2.44, epoch=0.659, learning_rate=5.23e-6]\u001b[A\n",
      " 66%|██████▌   | 2784/4220 [2:57:36<1:30:36,  3.79s/it, loss=2.44, epoch=0.659, learning_rate=5.23e-6]\u001b[A\n",
      " 66%|██████▌   | 2784/4220 [2:57:36<1:30:36,  3.79s/it, loss=3.09, epoch=0.659, learning_rate=5.22e-6]\u001b[A\n",
      " 66%|██████▌   | 2785/4220 [2:57:40<1:30:32,  3.79s/it, loss=3.09, epoch=0.659, learning_rate=5.22e-6]\u001b[A\n",
      " 66%|██████▌   | 2785/4220 [2:57:40<1:30:32,  3.79s/it, loss=3.11, epoch=0.66, learning_rate=5.21e-6] \u001b[A\n",
      " 66%|██████▌   | 2786/4220 [2:57:44<1:30:27,  3.79s/it, loss=3.11, epoch=0.66, learning_rate=5.21e-6]\u001b[A\n",
      " 66%|██████▌   | 2786/4220 [2:57:44<1:30:27,  3.79s/it, loss=3.36, epoch=0.66, learning_rate=5.21e-6]\u001b[A\n",
      " 66%|██████▌   | 2787/4220 [2:57:48<1:30:23,  3.79s/it, loss=3.36, epoch=0.66, learning_rate=5.21e-6]\u001b[A\n",
      " 66%|██████▌   | 2787/4220 [2:57:48<1:30:23,  3.79s/it, loss=2.73, epoch=0.66, learning_rate=5.2e-6] \u001b[A\n",
      " 66%|██████▌   | 2788/4220 [2:57:52<1:30:19,  3.78s/it, loss=2.73, epoch=0.66, learning_rate=5.2e-6]\u001b[A\n",
      " 66%|██████▌   | 2788/4220 [2:57:52<1:30:19,  3.78s/it, loss=3.39, epoch=0.66, learning_rate=5.19e-6]\u001b[A\n",
      " 66%|██████▌   | 2789/4220 [2:57:55<1:30:12,  3.78s/it, loss=3.39, epoch=0.66, learning_rate=5.19e-6]\u001b[A\n",
      " 66%|██████▌   | 2789/4220 [2:57:55<1:30:12,  3.78s/it, loss=2.86, epoch=0.661, learning_rate=5.19e-6]\u001b[A\n",
      " 66%|██████▌   | 2790/4220 [2:57:59<1:30:08,  3.78s/it, loss=2.86, epoch=0.661, learning_rate=5.19e-6]\u001b[A\n",
      " 66%|██████▌   | 2790/4220 [2:57:59<1:30:08,  3.78s/it, loss=2.58, epoch=0.661, learning_rate=5.18e-6]\u001b[A\n",
      " 66%|██████▌   | 2791/4220 [2:58:03<1:30:01,  3.78s/it, loss=2.58, epoch=0.661, learning_rate=5.18e-6]\u001b[A\n",
      " 66%|██████▌   | 2791/4220 [2:58:03<1:30:01,  3.78s/it, loss=2.49, epoch=0.661, learning_rate=5.17e-6]\u001b[A\n",
      " 66%|██████▌   | 2792/4220 [2:58:07<1:29:57,  3.78s/it, loss=2.49, epoch=0.661, learning_rate=5.17e-6]\u001b[A\n",
      " 66%|██████▌   | 2792/4220 [2:58:07<1:29:57,  3.78s/it, loss=2.35, epoch=0.661, learning_rate=5.17e-6]\u001b[A\n",
      " 66%|██████▌   | 2793/4220 [2:58:10<1:29:55,  3.78s/it, loss=2.35, epoch=0.661, learning_rate=5.17e-6]\u001b[A\n",
      " 66%|██████▌   | 2793/4220 [2:58:10<1:29:55,  3.78s/it, loss=2.96, epoch=0.662, learning_rate=5.16e-6]\u001b[A\n",
      " 66%|██████▌   | 2794/4220 [2:58:14<1:29:52,  3.78s/it, loss=2.96, epoch=0.662, learning_rate=5.16e-6]\u001b[A\n",
      " 66%|██████▌   | 2794/4220 [2:58:14<1:29:52,  3.78s/it, loss=2.43, epoch=0.662, learning_rate=5.15e-6]\u001b[A\n",
      " 66%|██████▌   | 2795/4220 [2:58:18<1:29:50,  3.78s/it, loss=2.43, epoch=0.662, learning_rate=5.15e-6]\u001b[A\n",
      " 66%|██████▌   | 2795/4220 [2:58:18<1:29:50,  3.78s/it, loss=2.48, epoch=0.662, learning_rate=5.15e-6]\u001b[A\n",
      " 66%|██████▋   | 2796/4220 [2:58:22<1:29:45,  3.78s/it, loss=2.48, epoch=0.662, learning_rate=5.15e-6]\u001b[A\n",
      " 66%|██████▋   | 2796/4220 [2:58:22<1:29:45,  3.78s/it, loss=2.65, epoch=0.662, learning_rate=5.14e-6]\u001b[A\n",
      " 66%|██████▋   | 2797/4220 [2:58:26<1:29:42,  3.78s/it, loss=2.65, epoch=0.662, learning_rate=5.14e-6]\u001b[A\n",
      " 66%|██████▋   | 2797/4220 [2:58:26<1:29:42,  3.78s/it, loss=2.69, epoch=0.663, learning_rate=5.13e-6]\u001b[A\n",
      " 66%|██████▋   | 2798/4220 [2:58:29<1:29:37,  3.78s/it, loss=2.69, epoch=0.663, learning_rate=5.13e-6]\u001b[A\n",
      " 66%|██████▋   | 2798/4220 [2:58:29<1:29:37,  3.78s/it, loss=2.59, epoch=0.663, learning_rate=5.13e-6]\u001b[A\n",
      " 66%|██████▋   | 2799/4220 [2:58:33<1:29:34,  3.78s/it, loss=2.59, epoch=0.663, learning_rate=5.13e-6]\u001b[A\n",
      " 66%|██████▋   | 2799/4220 [2:58:33<1:29:34,  3.78s/it, loss=2.67, epoch=0.663, learning_rate=5.12e-6]\u001b[A\n",
      " 66%|██████▋   | 2800/4220 [2:58:37<1:29:28,  3.78s/it, loss=2.67, epoch=0.663, learning_rate=5.12e-6]\u001b[A\n",
      " 66%|██████▋   | 2800/4220 [2:58:37<1:29:28,  3.78s/it, loss=2.49, epoch=0.663, learning_rate=5.11e-6]\u001b[A\n",
      " 66%|██████▋   | 2801/4220 [2:58:41<1:29:25,  3.78s/it, loss=2.49, epoch=0.663, learning_rate=5.11e-6]\u001b[A\n",
      " 66%|██████▋   | 2801/4220 [2:58:41<1:29:25,  3.78s/it, loss=2.79, epoch=0.664, learning_rate=5.11e-6]\u001b[A\n",
      " 66%|██████▋   | 2802/4220 [2:58:44<1:29:23,  3.78s/it, loss=2.79, epoch=0.664, learning_rate=5.11e-6]\u001b[A\n",
      " 66%|██████▋   | 2802/4220 [2:58:44<1:29:23,  3.78s/it, loss=2.66, epoch=0.664, learning_rate=5.1e-6] \u001b[A\n",
      " 66%|██████▋   | 2803/4220 [2:58:48<1:29:21,  3.78s/it, loss=2.66, epoch=0.664, learning_rate=5.1e-6]\u001b[A\n",
      " 66%|██████▋   | 2803/4220 [2:58:48<1:29:21,  3.78s/it, loss=2.94, epoch=0.664, learning_rate=5.1e-6]\u001b[A\n",
      " 66%|██████▋   | 2804/4220 [2:58:52<1:29:17,  3.78s/it, loss=2.94, epoch=0.664, learning_rate=5.1e-6]\u001b[A\n",
      " 66%|██████▋   | 2804/4220 [2:58:52<1:29:17,  3.78s/it, loss=3.21, epoch=0.664, learning_rate=5.09e-6]\u001b[A\n",
      " 66%|██████▋   | 2805/4220 [2:58:56<1:29:12,  3.78s/it, loss=3.21, epoch=0.664, learning_rate=5.09e-6]\u001b[A\n",
      " 66%|██████▋   | 2805/4220 [2:58:56<1:29:12,  3.78s/it, loss=3.06, epoch=0.664, learning_rate=5.08e-6]\u001b[A\n",
      " 66%|██████▋   | 2806/4220 [2:59:00<1:29:08,  3.78s/it, loss=3.06, epoch=0.664, learning_rate=5.08e-6]\u001b[A\n",
      " 66%|██████▋   | 2806/4220 [2:59:00<1:29:08,  3.78s/it, loss=3, epoch=0.665, learning_rate=5.08e-6]   \u001b[A\n",
      " 67%|██████▋   | 2807/4220 [2:59:03<1:29:05,  3.78s/it, loss=3, epoch=0.665, learning_rate=5.08e-6]\u001b[A\n",
      " 67%|██████▋   | 2807/4220 [2:59:03<1:29:05,  3.78s/it, loss=3.18, epoch=0.665, learning_rate=5.07e-6]\u001b[A\n",
      " 67%|██████▋   | 2808/4220 [2:59:07<1:29:01,  3.78s/it, loss=3.18, epoch=0.665, learning_rate=5.07e-6]\u001b[A\n",
      " 67%|██████▋   | 2808/4220 [2:59:07<1:29:01,  3.78s/it, loss=2.72, epoch=0.665, learning_rate=5.06e-6]\u001b[A\n",
      " 67%|██████▋   | 2809/4220 [2:59:11<1:28:56,  3.78s/it, loss=2.72, epoch=0.665, learning_rate=5.06e-6]\u001b[A\n",
      " 67%|██████▋   | 2809/4220 [2:59:11<1:28:56,  3.78s/it, loss=2.88, epoch=0.665, learning_rate=5.06e-6]\u001b[A\n",
      " 67%|██████▋   | 2810/4220 [2:59:15<1:28:50,  3.78s/it, loss=2.88, epoch=0.665, learning_rate=5.06e-6]\u001b[A\n",
      " 67%|██████▋   | 2810/4220 [2:59:15<1:28:50,  3.78s/it, loss=2.57, epoch=0.666, learning_rate=5.05e-6]\u001b[A\n",
      " 67%|██████▋   | 2811/4220 [2:59:19<1:28:47,  3.78s/it, loss=2.57, epoch=0.666, learning_rate=5.05e-6]\u001b[A\n",
      " 67%|██████▋   | 2811/4220 [2:59:19<1:28:47,  3.78s/it, loss=2.61, epoch=0.666, learning_rate=5.04e-6]\u001b[A\n",
      " 67%|██████▋   | 2812/4220 [2:59:22<1:28:43,  3.78s/it, loss=2.61, epoch=0.666, learning_rate=5.04e-6]\u001b[A\n",
      " 67%|██████▋   | 2812/4220 [2:59:22<1:28:43,  3.78s/it, loss=3.29, epoch=0.666, learning_rate=5.04e-6]\u001b[A\n",
      " 67%|██████▋   | 2813/4220 [2:59:26<1:28:40,  3.78s/it, loss=3.29, epoch=0.666, learning_rate=5.04e-6]\u001b[A\n",
      " 67%|██████▋   | 2813/4220 [2:59:26<1:28:40,  3.78s/it, loss=2.84, epoch=0.666, learning_rate=5.03e-6]\u001b[A\n",
      " 67%|██████▋   | 2814/4220 [2:59:30<1:28:36,  3.78s/it, loss=2.84, epoch=0.666, learning_rate=5.03e-6]\u001b[A\n",
      " 67%|██████▋   | 2814/4220 [2:59:30<1:28:36,  3.78s/it, loss=2.49, epoch=0.667, learning_rate=5.02e-6]\u001b[A\n",
      " 67%|██████▋   | 2815/4220 [2:59:34<1:28:32,  3.78s/it, loss=2.49, epoch=0.667, learning_rate=5.02e-6]\u001b[A\n",
      " 67%|██████▋   | 2815/4220 [2:59:34<1:28:32,  3.78s/it, loss=2.61, epoch=0.667, learning_rate=5.02e-6]\u001b[A\n",
      " 67%|██████▋   | 2816/4220 [2:59:37<1:28:28,  3.78s/it, loss=2.61, epoch=0.667, learning_rate=5.02e-6]\u001b[A\n",
      " 67%|██████▋   | 2816/4220 [2:59:37<1:28:28,  3.78s/it, loss=2.77, epoch=0.667, learning_rate=5.01e-6]\u001b[A\n",
      " 67%|██████▋   | 2817/4220 [2:59:41<1:28:25,  3.78s/it, loss=2.77, epoch=0.667, learning_rate=5.01e-6]\u001b[A\n",
      " 67%|██████▋   | 2817/4220 [2:59:41<1:28:25,  3.78s/it, loss=2.77, epoch=0.667, learning_rate=5e-6]   \u001b[A\n",
      " 67%|██████▋   | 2818/4220 [2:59:45<1:28:18,  3.78s/it, loss=2.77, epoch=0.667, learning_rate=5e-6]\u001b[A\n",
      " 67%|██████▋   | 2818/4220 [2:59:45<1:28:18,  3.78s/it, loss=2.98, epoch=0.668, learning_rate=5e-6]\u001b[A\n",
      " 67%|██████▋   | 2819/4220 [2:59:49<1:28:17,  3.78s/it, loss=2.98, epoch=0.668, learning_rate=5e-6]\u001b[A\n",
      " 67%|██████▋   | 2819/4220 [2:59:49<1:28:17,  3.78s/it, loss=2.65, epoch=0.668, learning_rate=4.99e-6]\u001b[A\n",
      " 67%|██████▋   | 2820/4220 [2:59:53<1:28:15,  3.78s/it, loss=2.65, epoch=0.668, learning_rate=4.99e-6]\u001b[A\n",
      " 67%|██████▋   | 2820/4220 [2:59:53<1:28:15,  3.78s/it, loss=2.87, epoch=0.668, learning_rate=4.98e-6]\u001b[A\n",
      " 67%|██████▋   | 2821/4220 [2:59:56<1:28:12,  3.78s/it, loss=2.87, epoch=0.668, learning_rate=4.98e-6]\u001b[A\n",
      " 67%|██████▋   | 2821/4220 [2:59:56<1:28:12,  3.78s/it, loss=2.94, epoch=0.668, learning_rate=4.98e-6]\u001b[A\n",
      " 67%|██████▋   | 2822/4220 [3:00:00<1:28:09,  3.78s/it, loss=2.94, epoch=0.668, learning_rate=4.98e-6]\u001b[A\n",
      " 67%|██████▋   | 2822/4220 [3:00:00<1:28:09,  3.78s/it, loss=3.11, epoch=0.668, learning_rate=4.97e-6]\u001b[A\n",
      " 67%|██████▋   | 2823/4220 [3:00:04<1:28:06,  3.78s/it, loss=3.11, epoch=0.668, learning_rate=4.97e-6]\u001b[A\n",
      " 67%|██████▋   | 2823/4220 [3:00:04<1:28:06,  3.78s/it, loss=3.15, epoch=0.669, learning_rate=4.97e-6]\u001b[A\n",
      " 67%|██████▋   | 2824/4220 [3:00:08<1:28:00,  3.78s/it, loss=3.15, epoch=0.669, learning_rate=4.97e-6]\u001b[A\n",
      " 67%|██████▋   | 2824/4220 [3:00:08<1:28:00,  3.78s/it, loss=2.68, epoch=0.669, learning_rate=4.96e-6]\u001b[A\n",
      " 67%|██████▋   | 2825/4220 [3:00:11<1:27:57,  3.78s/it, loss=2.68, epoch=0.669, learning_rate=4.96e-6]\u001b[A\n",
      " 67%|██████▋   | 2825/4220 [3:00:11<1:27:57,  3.78s/it, loss=2.98, epoch=0.669, learning_rate=4.95e-6]\u001b[A\n",
      " 67%|██████▋   | 2826/4220 [3:00:15<1:27:53,  3.78s/it, loss=2.98, epoch=0.669, learning_rate=4.95e-6]\u001b[A\n",
      " 67%|██████▋   | 2826/4220 [3:00:15<1:27:53,  3.78s/it, loss=2.51, epoch=0.669, learning_rate=4.95e-6]\u001b[A\n",
      " 67%|██████▋   | 2827/4220 [3:00:19<1:27:46,  3.78s/it, loss=2.51, epoch=0.669, learning_rate=4.95e-6]\u001b[A\n",
      " 67%|██████▋   | 2827/4220 [3:00:19<1:27:46,  3.78s/it, loss=2.65, epoch=0.67, learning_rate=4.94e-6] \u001b[A\n",
      " 67%|██████▋   | 2828/4220 [3:00:23<1:27:45,  3.78s/it, loss=2.65, epoch=0.67, learning_rate=4.94e-6]\u001b[A\n",
      " 67%|██████▋   | 2828/4220 [3:00:23<1:27:45,  3.78s/it, loss=3.22, epoch=0.67, learning_rate=4.93e-6]\u001b[A\n",
      " 67%|██████▋   | 2829/4220 [3:00:27<1:27:40,  3.78s/it, loss=3.22, epoch=0.67, learning_rate=4.93e-6]\u001b[A\n",
      " 67%|██████▋   | 2829/4220 [3:00:27<1:27:40,  3.78s/it, loss=2.84, epoch=0.67, learning_rate=4.93e-6]\u001b[A\n",
      " 67%|██████▋   | 2830/4220 [3:00:30<1:27:37,  3.78s/it, loss=2.84, epoch=0.67, learning_rate=4.93e-6]\u001b[A\n",
      " 67%|██████▋   | 2830/4220 [3:00:30<1:27:37,  3.78s/it, loss=3, epoch=0.67, learning_rate=4.92e-6]   \u001b[A\n",
      " 67%|██████▋   | 2831/4220 [3:00:34<1:27:33,  3.78s/it, loss=3, epoch=0.67, learning_rate=4.92e-6]\u001b[A\n",
      " 67%|██████▋   | 2831/4220 [3:00:34<1:27:33,  3.78s/it, loss=2.94, epoch=0.671, learning_rate=4.91e-6]\u001b[A\n",
      " 67%|██████▋   | 2832/4220 [3:00:38<1:27:30,  3.78s/it, loss=2.94, epoch=0.671, learning_rate=4.91e-6]\u001b[A\n",
      " 67%|██████▋   | 2832/4220 [3:00:38<1:27:30,  3.78s/it, loss=3.15, epoch=0.671, learning_rate=4.91e-6]\u001b[A\n",
      " 67%|██████▋   | 2833/4220 [3:00:42<1:27:27,  3.78s/it, loss=3.15, epoch=0.671, learning_rate=4.91e-6]\u001b[A\n",
      " 67%|██████▋   | 2833/4220 [3:00:42<1:27:27,  3.78s/it, loss=2.34, epoch=0.671, learning_rate=4.9e-6] \u001b[A\n",
      " 67%|██████▋   | 2834/4220 [3:00:46<1:27:23,  3.78s/it, loss=2.34, epoch=0.671, learning_rate=4.9e-6]\u001b[A\n",
      " 67%|██████▋   | 2834/4220 [3:00:46<1:27:23,  3.78s/it, loss=2.82, epoch=0.671, learning_rate=4.89e-6]\u001b[A\n",
      " 67%|██████▋   | 2835/4220 [3:00:49<1:27:19,  3.78s/it, loss=2.82, epoch=0.671, learning_rate=4.89e-6]\u001b[A\n",
      " 67%|██████▋   | 2835/4220 [3:00:49<1:27:19,  3.78s/it, loss=3.06, epoch=0.672, learning_rate=4.89e-6]\u001b[A\n",
      " 67%|██████▋   | 2836/4220 [3:00:53<1:27:13,  3.78s/it, loss=3.06, epoch=0.672, learning_rate=4.89e-6]\u001b[A\n",
      " 67%|██████▋   | 2836/4220 [3:00:53<1:27:13,  3.78s/it, loss=2.85, epoch=0.672, learning_rate=4.88e-6]\u001b[A\n",
      " 67%|██████▋   | 2837/4220 [3:00:57<1:27:09,  3.78s/it, loss=2.85, epoch=0.672, learning_rate=4.88e-6]\u001b[A\n",
      " 67%|██████▋   | 2837/4220 [3:00:57<1:27:09,  3.78s/it, loss=2.74, epoch=0.672, learning_rate=4.88e-6]\u001b[A\n",
      " 67%|██████▋   | 2838/4220 [3:01:01<1:27:06,  3.78s/it, loss=2.74, epoch=0.672, learning_rate=4.88e-6]\u001b[A\n",
      " 67%|██████▋   | 2838/4220 [3:01:01<1:27:06,  3.78s/it, loss=2.82, epoch=0.672, learning_rate=4.87e-6]\u001b[A\n",
      " 67%|██████▋   | 2839/4220 [3:01:04<1:27:03,  3.78s/it, loss=2.82, epoch=0.672, learning_rate=4.87e-6]\u001b[A\n",
      " 67%|██████▋   | 2839/4220 [3:01:04<1:27:03,  3.78s/it, loss=2.86, epoch=0.673, learning_rate=4.86e-6]\u001b[A\n",
      " 67%|██████▋   | 2840/4220 [3:01:08<1:27:00,  3.78s/it, loss=2.86, epoch=0.673, learning_rate=4.86e-6]\u001b[A\n",
      " 67%|██████▋   | 2840/4220 [3:01:08<1:27:00,  3.78s/it, loss=3.19, epoch=0.673, learning_rate=4.86e-6]\u001b[A\n",
      " 67%|██████▋   | 2841/4220 [3:01:12<1:26:57,  3.78s/it, loss=3.19, epoch=0.673, learning_rate=4.86e-6]\u001b[A\n",
      " 67%|██████▋   | 2841/4220 [3:01:12<1:26:57,  3.78s/it, loss=3.04, epoch=0.673, learning_rate=4.85e-6]\u001b[A\n",
      " 67%|██████▋   | 2842/4220 [3:01:16<1:26:53,  3.78s/it, loss=3.04, epoch=0.673, learning_rate=4.85e-6]\u001b[A\n",
      " 67%|██████▋   | 2842/4220 [3:01:16<1:26:53,  3.78s/it, loss=2.6, epoch=0.673, learning_rate=4.84e-6] \u001b[A\n",
      " 67%|██████▋   | 2843/4220 [3:01:20<1:26:49,  3.78s/it, loss=2.6, epoch=0.673, learning_rate=4.84e-6]\u001b[A\n",
      " 67%|██████▋   | 2843/4220 [3:01:20<1:26:49,  3.78s/it, loss=3.32, epoch=0.673, learning_rate=4.84e-6]\u001b[A\n",
      " 67%|██████▋   | 2844/4220 [3:01:23<1:26:46,  3.78s/it, loss=3.32, epoch=0.673, learning_rate=4.84e-6]\u001b[A\n",
      " 67%|██████▋   | 2844/4220 [3:01:23<1:26:46,  3.78s/it, loss=2.6, epoch=0.674, learning_rate=4.83e-6] \u001b[A\n",
      " 67%|██████▋   | 2845/4220 [3:01:27<1:26:41,  3.78s/it, loss=2.6, epoch=0.674, learning_rate=4.83e-6]\u001b[A\n",
      " 67%|██████▋   | 2845/4220 [3:01:27<1:26:41,  3.78s/it, loss=2.99, epoch=0.674, learning_rate=4.82e-6]\u001b[A\n",
      " 67%|██████▋   | 2846/4220 [3:01:31<1:26:38,  3.78s/it, loss=2.99, epoch=0.674, learning_rate=4.82e-6]\u001b[A\n",
      " 67%|██████▋   | 2846/4220 [3:01:31<1:26:38,  3.78s/it, loss=2.49, epoch=0.674, learning_rate=4.82e-6]\u001b[A\n",
      " 67%|██████▋   | 2847/4220 [3:01:35<1:26:32,  3.78s/it, loss=2.49, epoch=0.674, learning_rate=4.82e-6]\u001b[A\n",
      " 67%|██████▋   | 2847/4220 [3:01:35<1:26:32,  3.78s/it, loss=3.02, epoch=0.674, learning_rate=4.81e-6]\u001b[A\n",
      " 67%|██████▋   | 2848/4220 [3:01:38<1:26:27,  3.78s/it, loss=3.02, epoch=0.674, learning_rate=4.81e-6]\u001b[A\n",
      " 67%|██████▋   | 2848/4220 [3:01:38<1:26:27,  3.78s/it, loss=2.71, epoch=0.675, learning_rate=4.81e-6]\u001b[A\n",
      " 68%|██████▊   | 2849/4220 [3:01:42<1:26:24,  3.78s/it, loss=2.71, epoch=0.675, learning_rate=4.81e-6]\u001b[A\n",
      " 68%|██████▊   | 2849/4220 [3:01:42<1:26:24,  3.78s/it, loss=2.93, epoch=0.675, learning_rate=4.8e-6] \u001b[A\n",
      " 68%|██████▊   | 2850/4220 [3:01:46<1:26:20,  3.78s/it, loss=2.93, epoch=0.675, learning_rate=4.8e-6]\u001b[A\n",
      " 68%|██████▊   | 2850/4220 [3:01:46<1:26:20,  3.78s/it, loss=3.2, epoch=0.675, learning_rate=4.79e-6]\u001b[A\n",
      " 68%|██████▊   | 2851/4220 [3:01:50<1:26:18,  3.78s/it, loss=3.2, epoch=0.675, learning_rate=4.79e-6]\u001b[A\n",
      " 68%|██████▊   | 2851/4220 [3:01:50<1:26:18,  3.78s/it, loss=2.44, epoch=0.675, learning_rate=4.79e-6]\u001b[A\n",
      " 68%|██████▊   | 2852/4220 [3:01:54<1:26:14,  3.78s/it, loss=2.44, epoch=0.675, learning_rate=4.79e-6]\u001b[A\n",
      " 68%|██████▊   | 2852/4220 [3:01:54<1:26:14,  3.78s/it, loss=3.01, epoch=0.676, learning_rate=4.78e-6]\u001b[A\n",
      " 68%|██████▊   | 2853/4220 [3:01:57<1:26:08,  3.78s/it, loss=3.01, epoch=0.676, learning_rate=4.78e-6]\u001b[A\n",
      " 68%|██████▊   | 2853/4220 [3:01:57<1:26:08,  3.78s/it, loss=2.69, epoch=0.676, learning_rate=4.77e-6]\u001b[A\n",
      " 68%|██████▊   | 2854/4220 [3:02:01<1:26:06,  3.78s/it, loss=2.69, epoch=0.676, learning_rate=4.77e-6]\u001b[A\n",
      " 68%|██████▊   | 2854/4220 [3:02:01<1:26:06,  3.78s/it, loss=3, epoch=0.676, learning_rate=4.77e-6]   \u001b[A\n",
      " 68%|██████▊   | 2855/4220 [3:02:05<1:26:03,  3.78s/it, loss=3, epoch=0.676, learning_rate=4.77e-6]\u001b[A\n",
      " 68%|██████▊   | 2855/4220 [3:02:05<1:26:03,  3.78s/it, loss=2.61, epoch=0.676, learning_rate=4.76e-6]\u001b[A\n",
      " 68%|██████▊   | 2856/4220 [3:02:09<1:25:59,  3.78s/it, loss=2.61, epoch=0.676, learning_rate=4.76e-6]\u001b[A\n",
      " 68%|██████▊   | 2856/4220 [3:02:09<1:25:59,  3.78s/it, loss=2.76, epoch=0.677, learning_rate=4.75e-6]\u001b[A\n",
      " 68%|██████▊   | 2857/4220 [3:02:13<1:25:55,  3.78s/it, loss=2.76, epoch=0.677, learning_rate=4.75e-6]\u001b[A\n",
      " 68%|██████▊   | 2857/4220 [3:02:13<1:25:55,  3.78s/it, loss=2.89, epoch=0.677, learning_rate=4.75e-6]\u001b[A\n",
      " 68%|██████▊   | 2858/4220 [3:02:16<1:25:50,  3.78s/it, loss=2.89, epoch=0.677, learning_rate=4.75e-6]\u001b[A\n",
      " 68%|██████▊   | 2858/4220 [3:02:16<1:25:50,  3.78s/it, loss=2.5, epoch=0.677, learning_rate=4.74e-6] \u001b[A\n",
      " 68%|██████▊   | 2859/4220 [3:02:20<1:25:48,  3.78s/it, loss=2.5, epoch=0.677, learning_rate=4.74e-6]\u001b[A\n",
      " 68%|██████▊   | 2859/4220 [3:02:20<1:25:48,  3.78s/it, loss=3.02, epoch=0.677, learning_rate=4.74e-6]\u001b[A\n",
      " 68%|██████▊   | 2860/4220 [3:02:24<1:25:42,  3.78s/it, loss=3.02, epoch=0.677, learning_rate=4.74e-6]\u001b[A\n",
      " 68%|██████▊   | 2860/4220 [3:02:24<1:25:42,  3.78s/it, loss=3.59, epoch=0.677, learning_rate=4.73e-6]\u001b[A\n",
      " 68%|██████▊   | 2861/4220 [3:02:28<1:25:37,  3.78s/it, loss=3.59, epoch=0.677, learning_rate=4.73e-6]\u001b[A\n",
      " 68%|██████▊   | 2861/4220 [3:02:28<1:25:37,  3.78s/it, loss=2.9, epoch=0.678, learning_rate=4.72e-6] \u001b[A\n",
      " 68%|██████▊   | 2862/4220 [3:02:31<1:25:36,  3.78s/it, loss=2.9, epoch=0.678, learning_rate=4.72e-6]\u001b[A\n",
      " 68%|██████▊   | 2862/4220 [3:02:31<1:25:36,  3.78s/it, loss=2.89, epoch=0.678, learning_rate=4.72e-6]\u001b[A\n",
      " 68%|██████▊   | 2863/4220 [3:02:35<1:25:31,  3.78s/it, loss=2.89, epoch=0.678, learning_rate=4.72e-6]\u001b[A\n",
      " 68%|██████▊   | 2863/4220 [3:02:35<1:25:31,  3.78s/it, loss=3.41, epoch=0.678, learning_rate=4.71e-6]\u001b[A\n",
      " 68%|██████▊   | 2864/4220 [3:02:39<1:25:28,  3.78s/it, loss=3.41, epoch=0.678, learning_rate=4.71e-6]\u001b[A\n",
      " 68%|██████▊   | 2864/4220 [3:02:39<1:25:28,  3.78s/it, loss=2.51, epoch=0.678, learning_rate=4.7e-6] \u001b[A\n",
      " 68%|██████▊   | 2865/4220 [3:02:43<1:25:23,  3.78s/it, loss=2.51, epoch=0.678, learning_rate=4.7e-6]\u001b[A\n",
      " 68%|██████▊   | 2865/4220 [3:02:43<1:25:23,  3.78s/it, loss=2.95, epoch=0.679, learning_rate=4.7e-6]\u001b[A\n",
      " 68%|██████▊   | 2866/4220 [3:02:47<1:25:20,  3.78s/it, loss=2.95, epoch=0.679, learning_rate=4.7e-6]\u001b[A\n",
      " 68%|██████▊   | 2866/4220 [3:02:47<1:25:20,  3.78s/it, loss=2.98, epoch=0.679, learning_rate=4.69e-6]\u001b[A\n",
      " 68%|██████▊   | 2867/4220 [3:02:50<1:25:16,  3.78s/it, loss=2.98, epoch=0.679, learning_rate=4.69e-6]\u001b[A\n",
      " 68%|██████▊   | 2867/4220 [3:02:50<1:25:16,  3.78s/it, loss=2.68, epoch=0.679, learning_rate=4.68e-6]\u001b[A\n",
      " 68%|██████▊   | 2868/4220 [3:02:54<1:25:14,  3.78s/it, loss=2.68, epoch=0.679, learning_rate=4.68e-6]\u001b[A\n",
      " 68%|██████▊   | 2868/4220 [3:02:54<1:25:14,  3.78s/it, loss=2.75, epoch=0.679, learning_rate=4.68e-6]\u001b[A\n",
      " 68%|██████▊   | 2869/4220 [3:02:58<1:25:10,  3.78s/it, loss=2.75, epoch=0.679, learning_rate=4.68e-6]\u001b[A\n",
      " 68%|██████▊   | 2869/4220 [3:02:58<1:25:10,  3.78s/it, loss=2.91, epoch=0.68, learning_rate=4.67e-6] \u001b[A\n",
      " 68%|██████▊   | 2870/4220 [3:03:02<1:25:05,  3.78s/it, loss=2.91, epoch=0.68, learning_rate=4.67e-6]\u001b[A\n",
      " 68%|██████▊   | 2870/4220 [3:03:02<1:25:05,  3.78s/it, loss=2.69, epoch=0.68, learning_rate=4.67e-6]\u001b[A\n",
      " 68%|██████▊   | 2871/4220 [3:03:05<1:25:02,  3.78s/it, loss=2.69, epoch=0.68, learning_rate=4.67e-6]\u001b[A\n",
      " 68%|██████▊   | 2871/4220 [3:03:05<1:25:02,  3.78s/it, loss=2.93, epoch=0.68, learning_rate=4.66e-6]\u001b[A\n",
      " 68%|██████▊   | 2872/4220 [3:03:09<1:24:55,  3.78s/it, loss=2.93, epoch=0.68, learning_rate=4.66e-6]\u001b[A\n",
      " 68%|██████▊   | 2872/4220 [3:03:09<1:24:55,  3.78s/it, loss=2.8, epoch=0.68, learning_rate=4.65e-6] \u001b[A\n",
      " 68%|██████▊   | 2873/4220 [3:03:13<1:24:53,  3.78s/it, loss=2.8, epoch=0.68, learning_rate=4.65e-6]\u001b[A\n",
      " 68%|██████▊   | 2873/4220 [3:03:13<1:24:53,  3.78s/it, loss=2.82, epoch=0.681, learning_rate=4.65e-6]\u001b[A\n",
      " 68%|██████▊   | 2874/4220 [3:03:17<1:24:50,  3.78s/it, loss=2.82, epoch=0.681, learning_rate=4.65e-6]\u001b[A\n",
      " 68%|██████▊   | 2874/4220 [3:03:17<1:24:50,  3.78s/it, loss=2.92, epoch=0.681, learning_rate=4.64e-6]\u001b[A\n",
      " 68%|██████▊   | 2875/4220 [3:03:21<1:24:46,  3.78s/it, loss=2.92, epoch=0.681, learning_rate=4.64e-6]\u001b[A\n",
      " 68%|██████▊   | 2875/4220 [3:03:21<1:24:46,  3.78s/it, loss=2.84, epoch=0.681, learning_rate=4.63e-6]\u001b[A\n",
      " 68%|██████▊   | 2876/4220 [3:03:24<1:24:43,  3.78s/it, loss=2.84, epoch=0.681, learning_rate=4.63e-6]\u001b[A\n",
      " 68%|██████▊   | 2876/4220 [3:03:24<1:24:43,  3.78s/it, loss=2.64, epoch=0.681, learning_rate=4.63e-6]\u001b[A\n",
      " 68%|██████▊   | 2877/4220 [3:03:28<1:24:38,  3.78s/it, loss=2.64, epoch=0.681, learning_rate=4.63e-6]\u001b[A\n",
      " 68%|██████▊   | 2877/4220 [3:03:28<1:24:38,  3.78s/it, loss=2.77, epoch=0.682, learning_rate=4.62e-6]\u001b[A\n",
      " 68%|██████▊   | 2878/4220 [3:03:32<1:24:36,  3.78s/it, loss=2.77, epoch=0.682, learning_rate=4.62e-6]\u001b[A\n",
      " 68%|██████▊   | 2878/4220 [3:03:32<1:24:36,  3.78s/it, loss=3.48, epoch=0.682, learning_rate=4.62e-6]\u001b[A\n",
      " 68%|██████▊   | 2879/4220 [3:03:36<1:24:31,  3.78s/it, loss=3.48, epoch=0.682, learning_rate=4.62e-6]\u001b[A\n",
      " 68%|██████▊   | 2879/4220 [3:03:36<1:24:31,  3.78s/it, loss=2.59, epoch=0.682, learning_rate=4.61e-6]\u001b[A\n",
      " 68%|██████▊   | 2880/4220 [3:03:39<1:24:27,  3.78s/it, loss=2.59, epoch=0.682, learning_rate=4.61e-6]\u001b[A\n",
      " 68%|██████▊   | 2880/4220 [3:03:39<1:24:27,  3.78s/it, loss=3.48, epoch=0.682, learning_rate=4.6e-6] \u001b[A\n",
      " 68%|██████▊   | 2881/4220 [3:03:43<1:24:23,  3.78s/it, loss=3.48, epoch=0.682, learning_rate=4.6e-6]\u001b[A\n",
      " 68%|██████▊   | 2881/4220 [3:03:43<1:24:23,  3.78s/it, loss=2.66, epoch=0.682, learning_rate=4.6e-6]\u001b[A\n",
      " 68%|██████▊   | 2882/4220 [3:03:47<1:24:21,  3.78s/it, loss=2.66, epoch=0.682, learning_rate=4.6e-6]\u001b[A\n",
      " 68%|██████▊   | 2882/4220 [3:03:47<1:24:21,  3.78s/it, loss=2.65, epoch=0.683, learning_rate=4.59e-6]\u001b[A\n",
      " 68%|██████▊   | 2883/4220 [3:03:51<1:24:17,  3.78s/it, loss=2.65, epoch=0.683, learning_rate=4.59e-6]\u001b[A\n",
      " 68%|██████▊   | 2883/4220 [3:03:51<1:24:17,  3.78s/it, loss=3.44, epoch=0.683, learning_rate=4.58e-6]\u001b[A\n",
      " 68%|██████▊   | 2884/4220 [3:03:55<1:24:13,  3.78s/it, loss=3.44, epoch=0.683, learning_rate=4.58e-6]\u001b[A\n",
      " 68%|██████▊   | 2884/4220 [3:03:55<1:24:13,  3.78s/it, loss=2.52, epoch=0.683, learning_rate=4.58e-6]\u001b[A\n",
      " 68%|██████▊   | 2885/4220 [3:03:58<1:24:10,  3.78s/it, loss=2.52, epoch=0.683, learning_rate=4.58e-6]\u001b[A\n",
      " 68%|██████▊   | 2885/4220 [3:03:58<1:24:10,  3.78s/it, loss=2.67, epoch=0.683, learning_rate=4.57e-6]\u001b[A\n",
      " 68%|██████▊   | 2886/4220 [3:04:02<1:24:05,  3.78s/it, loss=2.67, epoch=0.683, learning_rate=4.57e-6]\u001b[A\n",
      " 68%|██████▊   | 2886/4220 [3:04:02<1:24:05,  3.78s/it, loss=3.05, epoch=0.684, learning_rate=4.57e-6]\u001b[A\n",
      " 68%|██████▊   | 2887/4220 [3:04:06<1:24:00,  3.78s/it, loss=3.05, epoch=0.684, learning_rate=4.57e-6]\u001b[A\n",
      " 68%|██████▊   | 2887/4220 [3:04:06<1:24:00,  3.78s/it, loss=2.74, epoch=0.684, learning_rate=4.56e-6]\u001b[A\n",
      " 68%|██████▊   | 2888/4220 [3:04:10<1:23:56,  3.78s/it, loss=2.74, epoch=0.684, learning_rate=4.56e-6]\u001b[A\n",
      " 68%|██████▊   | 2888/4220 [3:04:10<1:23:56,  3.78s/it, loss=3.03, epoch=0.684, learning_rate=4.55e-6]\u001b[A\n",
      " 68%|██████▊   | 2889/4220 [3:04:14<1:23:51,  3.78s/it, loss=3.03, epoch=0.684, learning_rate=4.55e-6]\u001b[A\n",
      " 68%|██████▊   | 2889/4220 [3:04:14<1:23:51,  3.78s/it, loss=3.25, epoch=0.684, learning_rate=4.55e-6]\u001b[A\n",
      " 68%|██████▊   | 2890/4220 [3:04:17<1:23:47,  3.78s/it, loss=3.25, epoch=0.684, learning_rate=4.55e-6]\u001b[A\n",
      " 68%|██████▊   | 2890/4220 [3:04:17<1:23:47,  3.78s/it, loss=3.44, epoch=0.685, learning_rate=4.54e-6]\u001b[A\n",
      " 69%|██████▊   | 2891/4220 [3:04:21<1:23:44,  3.78s/it, loss=3.44, epoch=0.685, learning_rate=4.54e-6]\u001b[A\n",
      " 69%|██████▊   | 2891/4220 [3:04:21<1:23:44,  3.78s/it, loss=2.73, epoch=0.685, learning_rate=4.53e-6]\u001b[A\n",
      " 69%|██████▊   | 2892/4220 [3:04:25<1:23:41,  3.78s/it, loss=2.73, epoch=0.685, learning_rate=4.53e-6]\u001b[A\n",
      " 69%|██████▊   | 2892/4220 [3:04:25<1:23:41,  3.78s/it, loss=2.89, epoch=0.685, learning_rate=4.53e-6]\u001b[A\n",
      " 69%|██████▊   | 2893/4220 [3:04:29<1:23:38,  3.78s/it, loss=2.89, epoch=0.685, learning_rate=4.53e-6]\u001b[A\n",
      " 69%|██████▊   | 2893/4220 [3:04:29<1:23:38,  3.78s/it, loss=2.77, epoch=0.685, learning_rate=4.52e-6]\u001b[A\n",
      " 69%|██████▊   | 2894/4220 [3:04:32<1:23:31,  3.78s/it, loss=2.77, epoch=0.685, learning_rate=4.52e-6]\u001b[A\n",
      " 69%|██████▊   | 2894/4220 [3:04:32<1:23:31,  3.78s/it, loss=2.66, epoch=0.686, learning_rate=4.52e-6]\u001b[A\n",
      " 69%|██████▊   | 2895/4220 [3:04:36<1:23:29,  3.78s/it, loss=2.66, epoch=0.686, learning_rate=4.52e-6]\u001b[A\n",
      " 69%|██████▊   | 2895/4220 [3:04:36<1:23:29,  3.78s/it, loss=3.49, epoch=0.686, learning_rate=4.51e-6]\u001b[A\n",
      " 69%|██████▊   | 2896/4220 [3:04:40<1:23:25,  3.78s/it, loss=3.49, epoch=0.686, learning_rate=4.51e-6]\u001b[A\n",
      " 69%|██████▊   | 2896/4220 [3:04:40<1:23:25,  3.78s/it, loss=2.6, epoch=0.686, learning_rate=4.5e-6]  \u001b[A\n",
      " 69%|██████▊   | 2897/4220 [3:04:44<1:23:23,  3.78s/it, loss=2.6, epoch=0.686, learning_rate=4.5e-6]\u001b[A\n",
      " 69%|██████▊   | 2897/4220 [3:04:44<1:23:23,  3.78s/it, loss=2.97, epoch=0.686, learning_rate=4.5e-6]\u001b[A\n",
      " 69%|██████▊   | 2898/4220 [3:04:48<1:23:18,  3.78s/it, loss=2.97, epoch=0.686, learning_rate=4.5e-6]\u001b[A\n",
      " 69%|██████▊   | 2898/4220 [3:04:48<1:23:18,  3.78s/it, loss=2.88, epoch=0.686, learning_rate=4.49e-6]\u001b[A\n",
      " 69%|██████▊   | 2899/4220 [3:04:51<1:23:15,  3.78s/it, loss=2.88, epoch=0.686, learning_rate=4.49e-6]\u001b[A\n",
      " 69%|██████▊   | 2899/4220 [3:04:51<1:23:15,  3.78s/it, loss=2.84, epoch=0.687, learning_rate=4.48e-6]\u001b[A\n",
      " 69%|██████▊   | 2900/4220 [3:04:55<1:23:10,  3.78s/it, loss=2.84, epoch=0.687, learning_rate=4.48e-6]\u001b[A\n",
      " 69%|██████▊   | 2900/4220 [3:04:55<1:23:10,  3.78s/it, loss=2.74, epoch=0.687, learning_rate=4.48e-6]\u001b[A\n",
      " 69%|██████▊   | 2901/4220 [3:04:59<1:23:06,  3.78s/it, loss=2.74, epoch=0.687, learning_rate=4.48e-6]\u001b[A\n",
      " 69%|██████▊   | 2901/4220 [3:04:59<1:23:06,  3.78s/it, loss=3.39, epoch=0.687, learning_rate=4.47e-6]\u001b[A\n",
      " 69%|██████▉   | 2902/4220 [3:05:03<1:23:03,  3.78s/it, loss=3.39, epoch=0.687, learning_rate=4.47e-6]\u001b[A\n",
      " 69%|██████▉   | 2902/4220 [3:05:03<1:23:03,  3.78s/it, loss=2.82, epoch=0.687, learning_rate=4.47e-6]\u001b[A\n",
      " 69%|██████▉   | 2903/4220 [3:05:06<1:23:00,  3.78s/it, loss=2.82, epoch=0.687, learning_rate=4.47e-6]\u001b[A\n",
      " 69%|██████▉   | 2903/4220 [3:05:06<1:23:00,  3.78s/it, loss=2.34, epoch=0.688, learning_rate=4.46e-6]\u001b[A\n",
      " 69%|██████▉   | 2904/4220 [3:05:10<1:22:57,  3.78s/it, loss=2.34, epoch=0.688, learning_rate=4.46e-6]\u001b[A\n",
      " 69%|██████▉   | 2904/4220 [3:05:10<1:22:57,  3.78s/it, loss=2.43, epoch=0.688, learning_rate=4.45e-6]\u001b[A\n",
      " 69%|██████▉   | 2905/4220 [3:05:14<1:22:52,  3.78s/it, loss=2.43, epoch=0.688, learning_rate=4.45e-6]\u001b[A\n",
      " 69%|██████▉   | 2905/4220 [3:05:14<1:22:52,  3.78s/it, loss=2.94, epoch=0.688, learning_rate=4.45e-6]\u001b[A\n",
      " 69%|██████▉   | 2906/4220 [3:05:18<1:22:48,  3.78s/it, loss=2.94, epoch=0.688, learning_rate=4.45e-6]\u001b[A\n",
      " 69%|██████▉   | 2906/4220 [3:05:18<1:22:48,  3.78s/it, loss=3.23, epoch=0.688, learning_rate=4.44e-6]\u001b[A\n",
      " 69%|██████▉   | 2907/4220 [3:05:22<1:22:45,  3.78s/it, loss=3.23, epoch=0.688, learning_rate=4.44e-6]\u001b[A\n",
      " 69%|██████▉   | 2907/4220 [3:05:22<1:22:45,  3.78s/it, loss=3.02, epoch=0.689, learning_rate=4.43e-6]\u001b[A\n",
      " 69%|██████▉   | 2908/4220 [3:05:25<1:22:44,  3.78s/it, loss=3.02, epoch=0.689, learning_rate=4.43e-6]\u001b[A\n",
      " 69%|██████▉   | 2908/4220 [3:05:25<1:22:44,  3.78s/it, loss=2.89, epoch=0.689, learning_rate=4.43e-6]\u001b[A\n",
      " 69%|██████▉   | 2909/4220 [3:05:29<1:22:40,  3.78s/it, loss=2.89, epoch=0.689, learning_rate=4.43e-6]\u001b[A\n",
      " 69%|██████▉   | 2909/4220 [3:05:29<1:22:40,  3.78s/it, loss=2.99, epoch=0.689, learning_rate=4.42e-6]\u001b[A\n",
      " 69%|██████▉   | 2910/4220 [3:05:33<1:22:36,  3.78s/it, loss=2.99, epoch=0.689, learning_rate=4.42e-6]\u001b[A\n",
      " 69%|██████▉   | 2910/4220 [3:05:33<1:22:36,  3.78s/it, loss=2.96, epoch=0.689, learning_rate=4.42e-6]\u001b[A\n",
      " 69%|██████▉   | 2911/4220 [3:05:37<1:22:32,  3.78s/it, loss=2.96, epoch=0.689, learning_rate=4.42e-6]\u001b[A\n",
      " 69%|██████▉   | 2911/4220 [3:05:37<1:22:32,  3.78s/it, loss=3.1, epoch=0.69, learning_rate=4.41e-6]  \u001b[A\n",
      " 69%|██████▉   | 2912/4220 [3:05:41<1:22:29,  3.78s/it, loss=3.1, epoch=0.69, learning_rate=4.41e-6]\u001b[A\n",
      " 69%|██████▉   | 2912/4220 [3:05:41<1:22:29,  3.78s/it, loss=3.15, epoch=0.69, learning_rate=4.4e-6]\u001b[A\n",
      " 69%|██████▉   | 2913/4220 [3:05:44<1:22:24,  3.78s/it, loss=3.15, epoch=0.69, learning_rate=4.4e-6]\u001b[A\n",
      " 69%|██████▉   | 2913/4220 [3:05:44<1:22:24,  3.78s/it, loss=2.64, epoch=0.69, learning_rate=4.4e-6]\u001b[A\n",
      " 69%|██████▉   | 2914/4220 [3:05:48<1:22:20,  3.78s/it, loss=2.64, epoch=0.69, learning_rate=4.4e-6]\u001b[A\n",
      " 69%|██████▉   | 2914/4220 [3:05:48<1:22:20,  3.78s/it, loss=2.58, epoch=0.69, learning_rate=4.39e-6]\u001b[A\n",
      " 69%|██████▉   | 2915/4220 [3:05:52<1:22:13,  3.78s/it, loss=2.58, epoch=0.69, learning_rate=4.39e-6]\u001b[A\n",
      " 69%|██████▉   | 2915/4220 [3:05:52<1:22:13,  3.78s/it, loss=2.32, epoch=0.691, learning_rate=4.38e-6]\u001b[A\n",
      " 69%|██████▉   | 2916/4220 [3:05:56<1:22:10,  3.78s/it, loss=2.32, epoch=0.691, learning_rate=4.38e-6]\u001b[A\n",
      " 69%|██████▉   | 2916/4220 [3:05:56<1:22:10,  3.78s/it, loss=3.1, epoch=0.691, learning_rate=4.38e-6] \u001b[A\n",
      " 69%|██████▉   | 2917/4220 [3:05:59<1:22:05,  3.78s/it, loss=3.1, epoch=0.691, learning_rate=4.38e-6]\u001b[A\n",
      " 69%|██████▉   | 2917/4220 [3:05:59<1:22:05,  3.78s/it, loss=3, epoch=0.691, learning_rate=4.37e-6]  \u001b[A\n",
      " 69%|██████▉   | 2918/4220 [3:06:03<1:22:02,  3.78s/it, loss=3, epoch=0.691, learning_rate=4.37e-6]\u001b[A\n",
      " 69%|██████▉   | 2918/4220 [3:06:03<1:22:02,  3.78s/it, loss=2.9, epoch=0.691, learning_rate=4.37e-6]\u001b[A\n",
      " 69%|██████▉   | 2919/4220 [3:06:07<1:21:58,  3.78s/it, loss=2.9, epoch=0.691, learning_rate=4.37e-6]\u001b[A\n",
      " 69%|██████▉   | 2919/4220 [3:06:07<1:21:58,  3.78s/it, loss=3.05, epoch=0.691, learning_rate=4.36e-6]\u001b[A\n",
      " 69%|██████▉   | 2920/4220 [3:06:11<1:21:55,  3.78s/it, loss=3.05, epoch=0.691, learning_rate=4.36e-6]\u001b[A\n",
      " 69%|██████▉   | 2920/4220 [3:06:11<1:21:55,  3.78s/it, loss=2.85, epoch=0.692, learning_rate=4.35e-6]\u001b[A\n",
      " 69%|██████▉   | 2921/4220 [3:06:15<1:21:52,  3.78s/it, loss=2.85, epoch=0.692, learning_rate=4.35e-6]\u001b[A\n",
      " 69%|██████▉   | 2921/4220 [3:06:15<1:21:52,  3.78s/it, loss=2.04, epoch=0.692, learning_rate=4.35e-6]\u001b[A\n",
      " 69%|██████▉   | 2922/4220 [3:06:18<1:21:46,  3.78s/it, loss=2.04, epoch=0.692, learning_rate=4.35e-6]\u001b[A\n",
      " 69%|██████▉   | 2922/4220 [3:06:18<1:21:46,  3.78s/it, loss=2.32, epoch=0.692, learning_rate=4.34e-6]\u001b[A\n",
      " 69%|██████▉   | 2923/4220 [3:06:22<1:21:42,  3.78s/it, loss=2.32, epoch=0.692, learning_rate=4.34e-6]\u001b[A\n",
      " 69%|██████▉   | 2923/4220 [3:06:22<1:21:42,  3.78s/it, loss=2.24, epoch=0.692, learning_rate=4.34e-6]\u001b[A\n",
      " 69%|██████▉   | 2924/4220 [3:06:26<1:21:40,  3.78s/it, loss=2.24, epoch=0.692, learning_rate=4.34e-6]\u001b[A\n",
      " 69%|██████▉   | 2924/4220 [3:06:26<1:21:40,  3.78s/it, loss=2.71, epoch=0.693, learning_rate=4.33e-6]\u001b[A\n",
      " 69%|██████▉   | 2925/4220 [3:06:30<1:21:36,  3.78s/it, loss=2.71, epoch=0.693, learning_rate=4.33e-6]\u001b[A\n",
      " 69%|██████▉   | 2925/4220 [3:06:30<1:21:36,  3.78s/it, loss=2.73, epoch=0.693, learning_rate=4.32e-6]\u001b[A\n",
      " 69%|██████▉   | 2926/4220 [3:06:33<1:21:33,  3.78s/it, loss=2.73, epoch=0.693, learning_rate=4.32e-6]\u001b[A\n",
      " 69%|██████▉   | 2926/4220 [3:06:33<1:21:33,  3.78s/it, loss=2.95, epoch=0.693, learning_rate=4.32e-6]\u001b[A\n",
      " 69%|██████▉   | 2927/4220 [3:06:37<1:21:29,  3.78s/it, loss=2.95, epoch=0.693, learning_rate=4.32e-6]\u001b[A\n",
      " 69%|██████▉   | 2927/4220 [3:06:37<1:21:29,  3.78s/it, loss=3.06, epoch=0.693, learning_rate=4.31e-6]\u001b[A\n",
      " 69%|██████▉   | 2928/4220 [3:06:41<1:21:26,  3.78s/it, loss=3.06, epoch=0.693, learning_rate=4.31e-6]\u001b[A\n",
      " 69%|██████▉   | 2928/4220 [3:06:41<1:21:26,  3.78s/it, loss=3.27, epoch=0.694, learning_rate=4.3e-6] \u001b[A\n",
      " 69%|██████▉   | 2929/4220 [3:06:45<1:21:23,  3.78s/it, loss=3.27, epoch=0.694, learning_rate=4.3e-6]\u001b[A\n",
      " 69%|██████▉   | 2929/4220 [3:06:45<1:21:23,  3.78s/it, loss=3.35, epoch=0.694, learning_rate=4.3e-6]\u001b[A\n",
      " 69%|██████▉   | 2930/4220 [3:06:49<1:21:20,  3.78s/it, loss=3.35, epoch=0.694, learning_rate=4.3e-6]\u001b[A\n",
      " 69%|██████▉   | 2930/4220 [3:06:49<1:21:20,  3.78s/it, loss=2.54, epoch=0.694, learning_rate=4.29e-6]\u001b[A\n",
      " 69%|██████▉   | 2931/4220 [3:06:52<1:21:16,  3.78s/it, loss=2.54, epoch=0.694, learning_rate=4.29e-6]\u001b[A\n",
      " 69%|██████▉   | 2931/4220 [3:06:52<1:21:16,  3.78s/it, loss=2.72, epoch=0.694, learning_rate=4.29e-6]\u001b[A\n",
      " 69%|██████▉   | 2932/4220 [3:06:56<1:21:13,  3.78s/it, loss=2.72, epoch=0.694, learning_rate=4.29e-6]\u001b[A\n",
      " 69%|██████▉   | 2932/4220 [3:06:56<1:21:13,  3.78s/it, loss=2.53, epoch=0.695, learning_rate=4.28e-6]\u001b[A\n",
      " 70%|██████▉   | 2933/4220 [3:07:00<1:21:09,  3.78s/it, loss=2.53, epoch=0.695, learning_rate=4.28e-6]\u001b[A\n",
      " 70%|██████▉   | 2933/4220 [3:07:00<1:21:09,  3.78s/it, loss=2.84, epoch=0.695, learning_rate=4.27e-6]\u001b[A\n",
      " 70%|██████▉   | 2934/4220 [3:07:04<1:21:03,  3.78s/it, loss=2.84, epoch=0.695, learning_rate=4.27e-6]\u001b[A\n",
      " 70%|██████▉   | 2934/4220 [3:07:04<1:21:03,  3.78s/it, loss=2.55, epoch=0.695, learning_rate=4.27e-6]\u001b[A\n",
      " 70%|██████▉   | 2935/4220 [3:07:07<1:20:58,  3.78s/it, loss=2.55, epoch=0.695, learning_rate=4.27e-6]\u001b[A\n",
      " 70%|██████▉   | 2935/4220 [3:07:07<1:20:58,  3.78s/it, loss=2.47, epoch=0.695, learning_rate=4.26e-6]\u001b[A\n",
      " 70%|██████▉   | 2936/4220 [3:07:11<1:20:55,  3.78s/it, loss=2.47, epoch=0.695, learning_rate=4.26e-6]\u001b[A\n",
      " 70%|██████▉   | 2936/4220 [3:07:11<1:20:55,  3.78s/it, loss=2.7, epoch=0.695, learning_rate=4.26e-6] \u001b[A\n",
      " 70%|██████▉   | 2937/4220 [3:07:15<1:20:53,  3.78s/it, loss=2.7, epoch=0.695, learning_rate=4.26e-6]\u001b[A\n",
      " 70%|██████▉   | 2937/4220 [3:07:15<1:20:53,  3.78s/it, loss=2.84, epoch=0.696, learning_rate=4.25e-6]\u001b[A\n",
      " 70%|██████▉   | 2938/4220 [3:07:19<1:20:50,  3.78s/it, loss=2.84, epoch=0.696, learning_rate=4.25e-6]\u001b[A\n",
      " 70%|██████▉   | 2938/4220 [3:07:19<1:20:50,  3.78s/it, loss=2.54, epoch=0.696, learning_rate=4.24e-6]\u001b[A\n",
      " 70%|██████▉   | 2939/4220 [3:07:23<1:20:47,  3.78s/it, loss=2.54, epoch=0.696, learning_rate=4.24e-6]\u001b[A\n",
      " 70%|██████▉   | 2939/4220 [3:07:23<1:20:47,  3.78s/it, loss=3.09, epoch=0.696, learning_rate=4.24e-6]\u001b[A\n",
      " 70%|██████▉   | 2940/4220 [3:07:26<1:20:43,  3.78s/it, loss=3.09, epoch=0.696, learning_rate=4.24e-6]\u001b[A\n",
      " 70%|██████▉   | 2940/4220 [3:07:26<1:20:43,  3.78s/it, loss=2.69, epoch=0.696, learning_rate=4.23e-6]\u001b[A\n",
      " 70%|██████▉   | 2941/4220 [3:07:30<1:20:40,  3.78s/it, loss=2.69, epoch=0.696, learning_rate=4.23e-6]\u001b[A\n",
      " 70%|██████▉   | 2941/4220 [3:07:30<1:20:40,  3.78s/it, loss=2.9, epoch=0.697, learning_rate=4.23e-6] \u001b[A\n",
      " 70%|██████▉   | 2942/4220 [3:07:34<1:20:36,  3.78s/it, loss=2.9, epoch=0.697, learning_rate=4.23e-6]\u001b[A\n",
      " 70%|██████▉   | 2942/4220 [3:07:34<1:20:36,  3.78s/it, loss=2.32, epoch=0.697, learning_rate=4.22e-6]\u001b[A\n",
      " 70%|██████▉   | 2943/4220 [3:07:38<1:20:31,  3.78s/it, loss=2.32, epoch=0.697, learning_rate=4.22e-6]\u001b[A\n",
      " 70%|██████▉   | 2943/4220 [3:07:38<1:20:31,  3.78s/it, loss=2.76, epoch=0.697, learning_rate=4.21e-6]\u001b[A\n",
      " 70%|██████▉   | 2944/4220 [3:07:42<1:20:26,  3.78s/it, loss=2.76, epoch=0.697, learning_rate=4.21e-6]\u001b[A\n",
      " 70%|██████▉   | 2944/4220 [3:07:42<1:20:26,  3.78s/it, loss=3.26, epoch=0.697, learning_rate=4.21e-6]\u001b[A\n",
      " 70%|██████▉   | 2945/4220 [3:07:45<1:20:21,  3.78s/it, loss=3.26, epoch=0.697, learning_rate=4.21e-6]\u001b[A\n",
      " 70%|██████▉   | 2945/4220 [3:07:45<1:20:21,  3.78s/it, loss=2.41, epoch=0.698, learning_rate=4.2e-6] \u001b[A\n",
      " 70%|██████▉   | 2946/4220 [3:07:49<1:20:16,  3.78s/it, loss=2.41, epoch=0.698, learning_rate=4.2e-6]\u001b[A\n",
      " 70%|██████▉   | 2946/4220 [3:07:49<1:20:16,  3.78s/it, loss=2.7, epoch=0.698, learning_rate=4.19e-6]\u001b[A\n",
      " 70%|██████▉   | 2947/4220 [3:07:53<1:20:13,  3.78s/it, loss=2.7, epoch=0.698, learning_rate=4.19e-6]\u001b[A\n",
      " 70%|██████▉   | 2947/4220 [3:07:53<1:20:13,  3.78s/it, loss=2.09, epoch=0.698, learning_rate=4.19e-6]\u001b[A\n",
      " 70%|██████▉   | 2948/4220 [3:07:57<1:20:10,  3.78s/it, loss=2.09, epoch=0.698, learning_rate=4.19e-6]\u001b[A\n",
      " 70%|██████▉   | 2948/4220 [3:07:57<1:20:10,  3.78s/it, loss=3.2, epoch=0.698, learning_rate=4.18e-6] \u001b[A\n",
      " 70%|██████▉   | 2949/4220 [3:08:00<1:20:07,  3.78s/it, loss=3.2, epoch=0.698, learning_rate=4.18e-6]\u001b[A\n",
      " 70%|██████▉   | 2949/4220 [3:08:00<1:20:07,  3.78s/it, loss=2.57, epoch=0.699, learning_rate=4.18e-6]\u001b[A\n",
      " 70%|██████▉   | 2950/4220 [3:08:04<1:20:04,  3.78s/it, loss=2.57, epoch=0.699, learning_rate=4.18e-6]\u001b[A\n",
      " 70%|██████▉   | 2950/4220 [3:08:04<1:20:04,  3.78s/it, loss=3, epoch=0.699, learning_rate=4.17e-6]   \u001b[A\n",
      " 70%|██████▉   | 2951/4220 [3:08:08<1:19:58,  3.78s/it, loss=3, epoch=0.699, learning_rate=4.17e-6]\u001b[A\n",
      " 70%|██████▉   | 2951/4220 [3:08:08<1:19:58,  3.78s/it, loss=2.63, epoch=0.699, learning_rate=4.16e-6]\u001b[A\n",
      " 70%|██████▉   | 2952/4220 [3:08:12<1:19:55,  3.78s/it, loss=2.63, epoch=0.699, learning_rate=4.16e-6]\u001b[A\n",
      " 70%|██████▉   | 2952/4220 [3:08:12<1:19:55,  3.78s/it, loss=3.08, epoch=0.699, learning_rate=4.16e-6]\u001b[A\n",
      " 70%|██████▉   | 2953/4220 [3:08:16<1:19:49,  3.78s/it, loss=3.08, epoch=0.699, learning_rate=4.16e-6]\u001b[A\n",
      " 70%|██████▉   | 2953/4220 [3:08:16<1:19:49,  3.78s/it, loss=2.89, epoch=0.7, learning_rate=4.15e-6]  \u001b[A\n",
      " 70%|███████   | 2954/4220 [3:08:19<1:19:48,  3.78s/it, loss=2.89, epoch=0.7, learning_rate=4.15e-6]\u001b[A\n",
      " 70%|███████   | 2954/4220 [3:08:19<1:19:48,  3.78s/it, loss=2.8, epoch=0.7, learning_rate=4.15e-6] \u001b[A\n",
      " 70%|███████   | 2955/4220 [3:08:23<1:19:44,  3.78s/it, loss=2.8, epoch=0.7, learning_rate=4.15e-6]\u001b[A\n",
      " 70%|███████   | 2955/4220 [3:08:23<1:19:44,  3.78s/it, loss=2.64, epoch=0.7, learning_rate=4.14e-6]\u001b[A\n",
      " 70%|███████   | 2956/4220 [3:08:27<1:19:39,  3.78s/it, loss=2.64, epoch=0.7, learning_rate=4.14e-6]\u001b[A\n",
      " 70%|███████   | 2956/4220 [3:08:27<1:19:39,  3.78s/it, loss=2.51, epoch=0.7, learning_rate=4.13e-6]\u001b[A\n",
      " 70%|███████   | 2957/4220 [3:08:31<1:19:34,  3.78s/it, loss=2.51, epoch=0.7, learning_rate=4.13e-6]\u001b[A\n",
      " 70%|███████   | 2957/4220 [3:08:31<1:19:34,  3.78s/it, loss=3.19, epoch=0.7, learning_rate=4.13e-6]\u001b[A\n",
      " 70%|███████   | 2958/4220 [3:08:34<1:19:31,  3.78s/it, loss=3.19, epoch=0.7, learning_rate=4.13e-6]\u001b[A\n",
      " 70%|███████   | 2958/4220 [3:08:34<1:19:31,  3.78s/it, loss=2.65, epoch=0.701, learning_rate=4.12e-6]\u001b[A\n",
      " 70%|███████   | 2959/4220 [3:08:38<1:19:26,  3.78s/it, loss=2.65, epoch=0.701, learning_rate=4.12e-6]\u001b[A\n",
      " 70%|███████   | 2959/4220 [3:08:38<1:19:26,  3.78s/it, loss=2.93, epoch=0.701, learning_rate=4.12e-6]\u001b[A\n",
      " 70%|███████   | 2960/4220 [3:08:42<1:19:24,  3.78s/it, loss=2.93, epoch=0.701, learning_rate=4.12e-6]\u001b[A\n",
      " 70%|███████   | 2960/4220 [3:08:42<1:19:24,  3.78s/it, loss=2.43, epoch=0.701, learning_rate=4.11e-6]\u001b[A\n",
      " 70%|███████   | 2961/4220 [3:08:46<1:19:20,  3.78s/it, loss=2.43, epoch=0.701, learning_rate=4.11e-6]\u001b[A\n",
      " 70%|███████   | 2961/4220 [3:08:46<1:19:20,  3.78s/it, loss=2.74, epoch=0.701, learning_rate=4.1e-6] \u001b[A\n",
      " 70%|███████   | 2962/4220 [3:08:50<1:19:16,  3.78s/it, loss=2.74, epoch=0.701, learning_rate=4.1e-6]\u001b[A\n",
      " 70%|███████   | 2962/4220 [3:08:50<1:19:16,  3.78s/it, loss=2.93, epoch=0.702, learning_rate=4.1e-6]\u001b[A\n",
      " 70%|███████   | 2963/4220 [3:08:53<1:19:12,  3.78s/it, loss=2.93, epoch=0.702, learning_rate=4.1e-6]\u001b[A\n",
      " 70%|███████   | 2963/4220 [3:08:53<1:19:12,  3.78s/it, loss=2.82, epoch=0.702, learning_rate=4.09e-6]\u001b[A\n",
      " 70%|███████   | 2964/4220 [3:08:57<1:20:34,  3.85s/it, loss=2.82, epoch=0.702, learning_rate=4.09e-6]\u001b[A\n",
      " 70%|███████   | 2964/4220 [3:08:57<1:20:34,  3.85s/it, loss=3.2, epoch=0.702, learning_rate=4.09e-6] \u001b[A\n",
      " 70%|███████   | 2965/4220 [3:09:01<1:20:06,  3.83s/it, loss=3.2, epoch=0.702, learning_rate=4.09e-6]\u001b[A\n",
      " 70%|███████   | 2965/4220 [3:09:01<1:20:06,  3.83s/it, loss=3.16, epoch=0.702, learning_rate=4.08e-6]\u001b[A\n",
      " 70%|███████   | 2966/4220 [3:09:05<1:19:46,  3.82s/it, loss=3.16, epoch=0.702, learning_rate=4.08e-6]\u001b[A\n",
      " 70%|███████   | 2966/4220 [3:09:05<1:19:46,  3.82s/it, loss=3.04, epoch=0.703, learning_rate=4.07e-6]\u001b[A\n",
      " 70%|███████   | 2967/4220 [3:09:09<1:19:29,  3.81s/it, loss=3.04, epoch=0.703, learning_rate=4.07e-6]\u001b[A\n",
      " 70%|███████   | 2967/4220 [3:09:09<1:19:29,  3.81s/it, loss=2.76, epoch=0.703, learning_rate=4.07e-6]\u001b[A\n",
      " 70%|███████   | 2968/4220 [3:09:13<1:19:16,  3.80s/it, loss=2.76, epoch=0.703, learning_rate=4.07e-6]\u001b[A\n",
      " 70%|███████   | 2968/4220 [3:09:13<1:19:16,  3.80s/it, loss=2.72, epoch=0.703, learning_rate=4.06e-6]\u001b[A\n",
      " 70%|███████   | 2969/4220 [3:09:16<1:19:05,  3.79s/it, loss=2.72, epoch=0.703, learning_rate=4.06e-6]\u001b[A\n",
      " 70%|███████   | 2969/4220 [3:09:16<1:19:05,  3.79s/it, loss=3, epoch=0.703, learning_rate=4.06e-6]   \u001b[A\n",
      " 70%|███████   | 2970/4220 [3:09:20<1:18:57,  3.79s/it, loss=3, epoch=0.703, learning_rate=4.06e-6]\u001b[A\n",
      " 70%|███████   | 2970/4220 [3:09:20<1:18:57,  3.79s/it, loss=3.02, epoch=0.704, learning_rate=4.05e-6]\u001b[A\n",
      " 70%|███████   | 2971/4220 [3:09:24<1:18:50,  3.79s/it, loss=3.02, epoch=0.704, learning_rate=4.05e-6]\u001b[A\n",
      " 70%|███████   | 2971/4220 [3:09:24<1:18:50,  3.79s/it, loss=2.63, epoch=0.704, learning_rate=4.04e-6]\u001b[A\n",
      " 70%|███████   | 2972/4220 [3:09:28<1:18:46,  3.79s/it, loss=2.63, epoch=0.704, learning_rate=4.04e-6]\u001b[A\n",
      " 70%|███████   | 2972/4220 [3:09:28<1:18:46,  3.79s/it, loss=2.88, epoch=0.704, learning_rate=4.04e-6]\u001b[A\n",
      " 70%|███████   | 2973/4220 [3:09:31<1:18:40,  3.79s/it, loss=2.88, epoch=0.704, learning_rate=4.04e-6]\u001b[A\n",
      " 70%|███████   | 2973/4220 [3:09:31<1:18:40,  3.79s/it, loss=2.85, epoch=0.704, learning_rate=4.03e-6]\u001b[A\n",
      " 70%|███████   | 2974/4220 [3:09:35<1:18:35,  3.78s/it, loss=2.85, epoch=0.704, learning_rate=4.03e-6]\u001b[A\n",
      " 70%|███████   | 2974/4220 [3:09:35<1:18:35,  3.78s/it, loss=2.45, epoch=0.705, learning_rate=4.03e-6]\u001b[A\n",
      " 70%|███████   | 2975/4220 [3:09:39<1:18:32,  3.79s/it, loss=2.45, epoch=0.705, learning_rate=4.03e-6]\u001b[A\n",
      " 70%|███████   | 2975/4220 [3:09:39<1:18:32,  3.79s/it, loss=3.07, epoch=0.705, learning_rate=4.02e-6]\u001b[A\n",
      " 71%|███████   | 2976/4220 [3:09:43<1:18:28,  3.78s/it, loss=3.07, epoch=0.705, learning_rate=4.02e-6]\u001b[A\n",
      " 71%|███████   | 2976/4220 [3:09:43<1:18:28,  3.78s/it, loss=2.73, epoch=0.705, learning_rate=4.01e-6]\u001b[A\n",
      " 71%|███████   | 2977/4220 [3:09:47<1:18:25,  3.79s/it, loss=2.73, epoch=0.705, learning_rate=4.01e-6]\u001b[A\n",
      " 71%|███████   | 2977/4220 [3:09:47<1:18:25,  3.79s/it, loss=3.23, epoch=0.705, learning_rate=4.01e-6]\u001b[A\n",
      " 71%|███████   | 2978/4220 [3:09:50<1:18:21,  3.79s/it, loss=3.23, epoch=0.705, learning_rate=4.01e-6]\u001b[A\n",
      " 71%|███████   | 2978/4220 [3:09:50<1:18:21,  3.79s/it, loss=3.23, epoch=0.705, learning_rate=4e-6]   \u001b[A\n",
      " 71%|███████   | 2979/4220 [3:09:54<1:18:16,  3.78s/it, loss=3.23, epoch=0.705, learning_rate=4e-6]\u001b[A\n",
      " 71%|███████   | 2979/4220 [3:09:54<1:18:16,  3.78s/it, loss=2.71, epoch=0.706, learning_rate=4e-6]\u001b[A\n",
      " 71%|███████   | 2980/4220 [3:09:58<1:18:12,  3.78s/it, loss=2.71, epoch=0.706, learning_rate=4e-6]\u001b[A\n",
      " 71%|███████   | 2980/4220 [3:09:58<1:18:12,  3.78s/it, loss=3.18, epoch=0.706, learning_rate=3.99e-6]\u001b[A\n",
      " 71%|███████   | 2981/4220 [3:10:02<1:18:09,  3.78s/it, loss=3.18, epoch=0.706, learning_rate=3.99e-6]\u001b[A\n",
      " 71%|███████   | 2981/4220 [3:10:02<1:18:09,  3.78s/it, loss=2.82, epoch=0.706, learning_rate=3.98e-6]\u001b[A\n",
      " 71%|███████   | 2982/4220 [3:10:05<1:18:02,  3.78s/it, loss=2.82, epoch=0.706, learning_rate=3.98e-6]\u001b[A\n",
      " 71%|███████   | 2982/4220 [3:10:05<1:18:02,  3.78s/it, loss=2.73, epoch=0.706, learning_rate=3.98e-6]\u001b[A\n",
      " 71%|███████   | 2983/4220 [3:10:09<1:17:59,  3.78s/it, loss=2.73, epoch=0.706, learning_rate=3.98e-6]\u001b[A\n",
      " 71%|███████   | 2983/4220 [3:10:09<1:17:59,  3.78s/it, loss=2.66, epoch=0.707, learning_rate=3.97e-6]\u001b[A\n",
      " 71%|███████   | 2984/4220 [3:10:13<1:17:54,  3.78s/it, loss=2.66, epoch=0.707, learning_rate=3.97e-6]\u001b[A\n",
      " 71%|███████   | 2984/4220 [3:10:13<1:17:54,  3.78s/it, loss=2.73, epoch=0.707, learning_rate=3.97e-6]\u001b[A\n",
      " 71%|███████   | 2985/4220 [3:10:17<1:17:51,  3.78s/it, loss=2.73, epoch=0.707, learning_rate=3.97e-6]\u001b[A\n",
      " 71%|███████   | 2985/4220 [3:10:17<1:17:51,  3.78s/it, loss=2.84, epoch=0.707, learning_rate=3.96e-6]\u001b[A\n",
      " 71%|███████   | 2986/4220 [3:10:21<1:17:48,  3.78s/it, loss=2.84, epoch=0.707, learning_rate=3.96e-6]\u001b[A\n",
      " 71%|███████   | 2986/4220 [3:10:21<1:17:48,  3.78s/it, loss=2.63, epoch=0.707, learning_rate=3.95e-6]\u001b[A\n",
      " 71%|███████   | 2987/4220 [3:10:24<1:17:45,  3.78s/it, loss=2.63, epoch=0.707, learning_rate=3.95e-6]\u001b[A\n",
      " 71%|███████   | 2987/4220 [3:10:24<1:17:45,  3.78s/it, loss=2.78, epoch=0.708, learning_rate=3.95e-6]\u001b[A\n",
      " 71%|███████   | 2988/4220 [3:10:28<1:17:38,  3.78s/it, loss=2.78, epoch=0.708, learning_rate=3.95e-6]\u001b[A\n",
      " 71%|███████   | 2988/4220 [3:10:28<1:17:38,  3.78s/it, loss=3.08, epoch=0.708, learning_rate=3.94e-6]\u001b[A\n",
      " 71%|███████   | 2989/4220 [3:10:32<1:17:36,  3.78s/it, loss=3.08, epoch=0.708, learning_rate=3.94e-6]\u001b[A\n",
      " 71%|███████   | 2989/4220 [3:10:32<1:17:36,  3.78s/it, loss=3.07, epoch=0.708, learning_rate=3.94e-6]\u001b[A\n",
      " 71%|███████   | 2990/4220 [3:10:36<1:17:33,  3.78s/it, loss=3.07, epoch=0.708, learning_rate=3.94e-6]\u001b[A\n",
      " 71%|███████   | 2990/4220 [3:10:36<1:17:33,  3.78s/it, loss=3.04, epoch=0.708, learning_rate=3.93e-6]\u001b[A\n",
      " 71%|███████   | 2991/4220 [3:10:40<1:17:29,  3.78s/it, loss=3.04, epoch=0.708, learning_rate=3.93e-6]\u001b[A\n",
      " 71%|███████   | 2991/4220 [3:10:40<1:17:29,  3.78s/it, loss=3.03, epoch=0.709, learning_rate=3.92e-6]\u001b[A\n",
      " 71%|███████   | 2992/4220 [3:10:43<1:17:24,  3.78s/it, loss=3.03, epoch=0.709, learning_rate=3.92e-6]\u001b[A\n",
      " 71%|███████   | 2992/4220 [3:10:43<1:17:24,  3.78s/it, loss=2.77, epoch=0.709, learning_rate=3.92e-6]\u001b[A\n",
      " 71%|███████   | 2993/4220 [3:10:47<1:17:20,  3.78s/it, loss=2.77, epoch=0.709, learning_rate=3.92e-6]\u001b[A\n",
      " 71%|███████   | 2993/4220 [3:10:47<1:17:20,  3.78s/it, loss=2.56, epoch=0.709, learning_rate=3.91e-6]\u001b[A\n",
      " 71%|███████   | 2994/4220 [3:10:51<1:17:18,  3.78s/it, loss=2.56, epoch=0.709, learning_rate=3.91e-6]\u001b[A\n",
      " 71%|███████   | 2994/4220 [3:10:51<1:17:18,  3.78s/it, loss=2.47, epoch=0.709, learning_rate=3.91e-6]\u001b[A\n",
      " 71%|███████   | 2995/4220 [3:10:55<1:17:16,  3.78s/it, loss=2.47, epoch=0.709, learning_rate=3.91e-6]\u001b[A\n",
      " 71%|███████   | 2995/4220 [3:10:55<1:17:16,  3.78s/it, loss=3.2, epoch=0.709, learning_rate=3.9e-6]  \u001b[A\n",
      " 71%|███████   | 2996/4220 [3:10:58<1:17:12,  3.78s/it, loss=3.2, epoch=0.709, learning_rate=3.9e-6]\u001b[A\n",
      " 71%|███████   | 2996/4220 [3:10:58<1:17:12,  3.78s/it, loss=2.72, epoch=0.71, learning_rate=3.9e-6]\u001b[A\n",
      " 71%|███████   | 2997/4220 [3:11:02<1:17:07,  3.78s/it, loss=2.72, epoch=0.71, learning_rate=3.9e-6]\u001b[A\n",
      " 71%|███████   | 2997/4220 [3:11:02<1:17:07,  3.78s/it, loss=3.12, epoch=0.71, learning_rate=3.89e-6]\u001b[A\n",
      " 71%|███████   | 2998/4220 [3:11:06<1:17:03,  3.78s/it, loss=3.12, epoch=0.71, learning_rate=3.89e-6]\u001b[A\n",
      " 71%|███████   | 2998/4220 [3:11:06<1:17:03,  3.78s/it, loss=2.57, epoch=0.71, learning_rate=3.88e-6]\u001b[A\n",
      " 71%|███████   | 2999/4220 [3:11:10<1:16:59,  3.78s/it, loss=2.57, epoch=0.71, learning_rate=3.88e-6]\u001b[A\n",
      " 71%|███████   | 2999/4220 [3:11:10<1:16:59,  3.78s/it, loss=2.64, epoch=0.71, learning_rate=3.88e-6]\u001b[A\n",
      " 71%|███████   | 3000/4220 [3:11:14<1:16:55,  3.78s/it, loss=2.64, epoch=0.71, learning_rate=3.88e-6]\u001b[A\n",
      " 71%|███████   | 3000/4220 [3:11:14<1:16:55,  3.78s/it, loss=2.86, epoch=0.711, learning_rate=3.87e-6]\u001b[ARemoved shared tensor {'model.unembed.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "\n",
      " 71%|███████   | 3001/4220 [3:12:22<7:51:35, 23.21s/it, loss=2.86, epoch=0.711, learning_rate=3.87e-6]\u001b[A\n",
      " 71%|███████   | 3001/4220 [3:12:22<7:51:35, 23.21s/it, loss=2.64, epoch=0.711, learning_rate=3.87e-6]\u001b[A\n",
      " 71%|███████   | 3002/4220 [3:12:26<5:52:37, 17.37s/it, loss=2.64, epoch=0.711, learning_rate=3.87e-6]\u001b[A\n",
      " 71%|███████   | 3002/4220 [3:12:26<5:52:37, 17.37s/it, loss=2.5, epoch=0.711, learning_rate=3.86e-6] \u001b[A\n",
      " 71%|███████   | 3003/4220 [3:12:30<4:29:24, 13.28s/it, loss=2.5, epoch=0.711, learning_rate=3.86e-6]\u001b[A\n",
      " 71%|███████   | 3003/4220 [3:12:30<4:29:24, 13.28s/it, loss=2.82, epoch=0.711, learning_rate=3.85e-6]\u001b[A\n",
      " 71%|███████   | 3004/4220 [3:12:33<3:31:11, 10.42s/it, loss=2.82, epoch=0.711, learning_rate=3.85e-6]\u001b[A\n",
      " 71%|███████   | 3004/4220 [3:12:33<3:31:11, 10.42s/it, loss=2.59, epoch=0.712, learning_rate=3.85e-6]\u001b[A\n",
      " 71%|███████   | 3005/4220 [3:12:37<2:50:30,  8.42s/it, loss=2.59, epoch=0.712, learning_rate=3.85e-6]\u001b[A\n",
      " 71%|███████   | 3005/4220 [3:12:37<2:50:30,  8.42s/it, loss=3.12, epoch=0.712, learning_rate=3.84e-6]\u001b[A\n",
      " 71%|███████   | 3006/4220 [3:12:41<2:22:04,  7.02s/it, loss=3.12, epoch=0.712, learning_rate=3.84e-6]\u001b[A\n",
      " 71%|███████   | 3006/4220 [3:12:41<2:22:04,  7.02s/it, loss=2.97, epoch=0.712, learning_rate=3.84e-6]\u001b[A\n",
      " 71%|███████▏  | 3007/4220 [3:12:45<2:02:08,  6.04s/it, loss=2.97, epoch=0.712, learning_rate=3.84e-6]\u001b[A\n",
      " 71%|███████▏  | 3007/4220 [3:12:45<2:02:08,  6.04s/it, loss=2.82, epoch=0.712, learning_rate=3.83e-6]\u001b[A\n",
      " 71%|███████▏  | 3008/4220 [3:12:48<1:48:11,  5.36s/it, loss=2.82, epoch=0.712, learning_rate=3.83e-6]\u001b[A\n",
      " 71%|███████▏  | 3008/4220 [3:12:48<1:48:11,  5.36s/it, loss=2.89, epoch=0.713, learning_rate=3.82e-6]\u001b[A\n",
      " 71%|███████▏  | 3009/4220 [3:12:52<1:38:28,  4.88s/it, loss=2.89, epoch=0.713, learning_rate=3.82e-6]\u001b[A\n",
      " 71%|███████▏  | 3009/4220 [3:12:52<1:38:28,  4.88s/it, loss=2.64, epoch=0.713, learning_rate=3.82e-6]\u001b[A\n",
      " 71%|███████▏  | 3010/4220 [3:12:56<1:31:39,  4.54s/it, loss=2.64, epoch=0.713, learning_rate=3.82e-6]\u001b[A\n",
      " 71%|███████▏  | 3010/4220 [3:12:56<1:31:39,  4.54s/it, loss=2.99, epoch=0.713, learning_rate=3.81e-6]\u001b[A\n",
      " 71%|███████▏  | 3011/4220 [3:13:00<1:26:51,  4.31s/it, loss=2.99, epoch=0.713, learning_rate=3.81e-6]\u001b[A\n",
      " 71%|███████▏  | 3011/4220 [3:13:00<1:26:51,  4.31s/it, loss=2.77, epoch=0.713, learning_rate=3.81e-6]\u001b[A\n",
      " 71%|███████▏  | 3012/4220 [3:13:03<1:23:29,  4.15s/it, loss=2.77, epoch=0.713, learning_rate=3.81e-6]\u001b[A\n",
      " 71%|███████▏  | 3012/4220 [3:13:03<1:23:29,  4.15s/it, loss=3, epoch=0.714, learning_rate=3.8e-6]    \u001b[A\n",
      " 71%|███████▏  | 3013/4220 [3:13:07<1:21:07,  4.03s/it, loss=3, epoch=0.714, learning_rate=3.8e-6]\u001b[A\n",
      " 71%|███████▏  | 3013/4220 [3:13:07<1:21:07,  4.03s/it, loss=2.54, epoch=0.714, learning_rate=3.8e-6]\u001b[A\n",
      " 71%|███████▏  | 3014/4220 [3:13:11<1:19:28,  3.95s/it, loss=2.54, epoch=0.714, learning_rate=3.8e-6]\u001b[A\n",
      " 71%|███████▏  | 3014/4220 [3:13:11<1:19:28,  3.95s/it, loss=2.77, epoch=0.714, learning_rate=3.79e-6]\u001b[A\n",
      " 71%|███████▏  | 3015/4220 [3:13:15<1:18:18,  3.90s/it, loss=2.77, epoch=0.714, learning_rate=3.79e-6]\u001b[A\n",
      " 71%|███████▏  | 3015/4220 [3:13:15<1:18:18,  3.90s/it, loss=2.79, epoch=0.714, learning_rate=3.78e-6]\u001b[A\n",
      " 71%|███████▏  | 3016/4220 [3:13:19<1:17:26,  3.86s/it, loss=2.79, epoch=0.714, learning_rate=3.78e-6]\u001b[A\n",
      " 71%|███████▏  | 3016/4220 [3:13:19<1:17:26,  3.86s/it, loss=2.76, epoch=0.714, learning_rate=3.78e-6]\u001b[A\n",
      " 71%|███████▏  | 3017/4220 [3:13:22<1:16:54,  3.84s/it, loss=2.76, epoch=0.714, learning_rate=3.78e-6]\u001b[A\n",
      " 71%|███████▏  | 3017/4220 [3:13:22<1:16:54,  3.84s/it, loss=2.89, epoch=0.715, learning_rate=3.77e-6]\u001b[A\n",
      " 72%|███████▏  | 3018/4220 [3:13:26<1:16:25,  3.82s/it, loss=2.89, epoch=0.715, learning_rate=3.77e-6]\u001b[A\n",
      " 72%|███████▏  | 3018/4220 [3:13:26<1:16:25,  3.82s/it, loss=2.59, epoch=0.715, learning_rate=3.77e-6]\u001b[A\n",
      " 72%|███████▏  | 3019/4220 [3:13:30<1:16:05,  3.80s/it, loss=2.59, epoch=0.715, learning_rate=3.77e-6]\u001b[A\n",
      " 72%|███████▏  | 3019/4220 [3:13:30<1:16:05,  3.80s/it, loss=2.45, epoch=0.715, learning_rate=3.76e-6]\u001b[A\n",
      " 72%|███████▏  | 3020/4220 [3:13:34<1:15:52,  3.79s/it, loss=2.45, epoch=0.715, learning_rate=3.76e-6]\u001b[A\n",
      " 72%|███████▏  | 3020/4220 [3:13:34<1:15:52,  3.79s/it, loss=2.83, epoch=0.715, learning_rate=3.75e-6]\u001b[A\n",
      " 72%|███████▏  | 3021/4220 [3:13:37<1:15:41,  3.79s/it, loss=2.83, epoch=0.715, learning_rate=3.75e-6]\u001b[A\n",
      " 72%|███████▏  | 3021/4220 [3:13:37<1:15:41,  3.79s/it, loss=2.78, epoch=0.716, learning_rate=3.75e-6]\u001b[A\n",
      " 72%|███████▏  | 3022/4220 [3:13:41<1:15:34,  3.79s/it, loss=2.78, epoch=0.716, learning_rate=3.75e-6]\u001b[A\n",
      " 72%|███████▏  | 3022/4220 [3:13:41<1:15:34,  3.79s/it, loss=3.11, epoch=0.716, learning_rate=3.74e-6]\u001b[A\n",
      " 72%|███████▏  | 3023/4220 [3:13:45<1:15:28,  3.78s/it, loss=3.11, epoch=0.716, learning_rate=3.74e-6]\u001b[A\n",
      " 72%|███████▏  | 3023/4220 [3:13:45<1:15:28,  3.78s/it, loss=2.56, epoch=0.716, learning_rate=3.74e-6]\u001b[A\n",
      " 72%|███████▏  | 3024/4220 [3:13:49<1:15:22,  3.78s/it, loss=2.56, epoch=0.716, learning_rate=3.74e-6]\u001b[A\n",
      " 72%|███████▏  | 3024/4220 [3:13:49<1:15:22,  3.78s/it, loss=3.29, epoch=0.716, learning_rate=3.73e-6]\u001b[A\n",
      " 72%|███████▏  | 3025/4220 [3:13:52<1:15:16,  3.78s/it, loss=3.29, epoch=0.716, learning_rate=3.73e-6]\u001b[A\n",
      " 72%|███████▏  | 3025/4220 [3:13:52<1:15:16,  3.78s/it, loss=3.35, epoch=0.717, learning_rate=3.73e-6]\u001b[A\n",
      " 72%|███████▏  | 3026/4220 [3:13:56<1:15:10,  3.78s/it, loss=3.35, epoch=0.717, learning_rate=3.73e-6]\u001b[A\n",
      " 72%|███████▏  | 3026/4220 [3:13:56<1:15:10,  3.78s/it, loss=2.87, epoch=0.717, learning_rate=3.72e-6]\u001b[A\n",
      " 72%|███████▏  | 3027/4220 [3:14:00<1:15:07,  3.78s/it, loss=2.87, epoch=0.717, learning_rate=3.72e-6]\u001b[A\n",
      " 72%|███████▏  | 3027/4220 [3:14:00<1:15:07,  3.78s/it, loss=2.78, epoch=0.717, learning_rate=3.71e-6]\u001b[A\n",
      " 72%|███████▏  | 3028/4220 [3:14:04<1:15:03,  3.78s/it, loss=2.78, epoch=0.717, learning_rate=3.71e-6]\u001b[A\n",
      " 72%|███████▏  | 3028/4220 [3:14:04<1:15:03,  3.78s/it, loss=2.43, epoch=0.717, learning_rate=3.71e-6]\u001b[A\n",
      " 72%|███████▏  | 3029/4220 [3:14:08<1:14:59,  3.78s/it, loss=2.43, epoch=0.717, learning_rate=3.71e-6]\u001b[A\n",
      " 72%|███████▏  | 3029/4220 [3:14:08<1:14:59,  3.78s/it, loss=3.1, epoch=0.718, learning_rate=3.7e-6]  \u001b[A\n",
      " 72%|███████▏  | 3030/4220 [3:14:11<1:14:56,  3.78s/it, loss=3.1, epoch=0.718, learning_rate=3.7e-6]\u001b[A\n",
      " 72%|███████▏  | 3030/4220 [3:14:11<1:14:56,  3.78s/it, loss=2.9, epoch=0.718, learning_rate=3.7e-6]\u001b[A\n",
      " 72%|███████▏  | 3031/4220 [3:14:15<1:14:51,  3.78s/it, loss=2.9, epoch=0.718, learning_rate=3.7e-6]\u001b[A\n",
      " 72%|███████▏  | 3031/4220 [3:14:15<1:14:51,  3.78s/it, loss=2.88, epoch=0.718, learning_rate=3.69e-6]\u001b[A\n",
      " 72%|███████▏  | 3032/4220 [3:14:19<1:14:48,  3.78s/it, loss=2.88, epoch=0.718, learning_rate=3.69e-6]\u001b[A\n",
      " 72%|███████▏  | 3032/4220 [3:14:19<1:14:48,  3.78s/it, loss=3.13, epoch=0.718, learning_rate=3.68e-6]\u001b[A\n",
      " 72%|███████▏  | 3033/4220 [3:14:23<1:14:43,  3.78s/it, loss=3.13, epoch=0.718, learning_rate=3.68e-6]\u001b[A\n",
      " 72%|███████▏  | 3033/4220 [3:14:23<1:14:43,  3.78s/it, loss=2.76, epoch=0.718, learning_rate=3.68e-6]\u001b[A\n",
      " 72%|███████▏  | 3034/4220 [3:14:26<1:14:40,  3.78s/it, loss=2.76, epoch=0.718, learning_rate=3.68e-6]\u001b[A\n",
      " 72%|███████▏  | 3034/4220 [3:14:26<1:14:40,  3.78s/it, loss=2.67, epoch=0.719, learning_rate=3.67e-6]\u001b[A\n",
      " 72%|███████▏  | 3035/4220 [3:14:30<1:14:36,  3.78s/it, loss=2.67, epoch=0.719, learning_rate=3.67e-6]\u001b[A\n",
      " 72%|███████▏  | 3035/4220 [3:14:30<1:14:36,  3.78s/it, loss=2.66, epoch=0.719, learning_rate=3.67e-6]\u001b[A\n",
      " 72%|███████▏  | 3036/4220 [3:14:34<1:14:33,  3.78s/it, loss=2.66, epoch=0.719, learning_rate=3.67e-6]\u001b[A\n",
      " 72%|███████▏  | 3036/4220 [3:14:34<1:14:33,  3.78s/it, loss=2.83, epoch=0.719, learning_rate=3.66e-6]\u001b[A\n",
      " 72%|███████▏  | 3037/4220 [3:14:38<1:14:30,  3.78s/it, loss=2.83, epoch=0.719, learning_rate=3.66e-6]\u001b[A\n",
      " 72%|███████▏  | 3037/4220 [3:14:38<1:14:30,  3.78s/it, loss=3.22, epoch=0.719, learning_rate=3.66e-6]\u001b[A\n",
      " 72%|███████▏  | 3038/4220 [3:14:42<1:14:28,  3.78s/it, loss=3.22, epoch=0.719, learning_rate=3.66e-6]\u001b[A\n",
      " 72%|███████▏  | 3038/4220 [3:14:42<1:14:28,  3.78s/it, loss=2.81, epoch=0.72, learning_rate=3.65e-6] \u001b[A\n",
      " 72%|███████▏  | 3039/4220 [3:14:45<1:14:22,  3.78s/it, loss=2.81, epoch=0.72, learning_rate=3.65e-6]\u001b[A\n",
      " 72%|███████▏  | 3039/4220 [3:14:45<1:14:22,  3.78s/it, loss=3.23, epoch=0.72, learning_rate=3.64e-6]\u001b[A\n",
      " 72%|███████▏  | 3040/4220 [3:14:49<1:14:19,  3.78s/it, loss=3.23, epoch=0.72, learning_rate=3.64e-6]\u001b[A\n",
      " 72%|███████▏  | 3040/4220 [3:14:49<1:14:19,  3.78s/it, loss=2.7, epoch=0.72, learning_rate=3.64e-6] \u001b[A\n",
      " 72%|███████▏  | 3041/4220 [3:14:53<1:14:16,  3.78s/it, loss=2.7, epoch=0.72, learning_rate=3.64e-6]\u001b[A\n",
      " 72%|███████▏  | 3041/4220 [3:14:53<1:14:16,  3.78s/it, loss=3.11, epoch=0.72, learning_rate=3.63e-6]\u001b[A\n",
      " 72%|███████▏  | 3042/4220 [3:14:57<1:14:12,  3.78s/it, loss=3.11, epoch=0.72, learning_rate=3.63e-6]\u001b[A\n",
      " 72%|███████▏  | 3042/4220 [3:14:57<1:14:12,  3.78s/it, loss=2.87, epoch=0.721, learning_rate=3.63e-6]\u001b[A\n",
      " 72%|███████▏  | 3043/4220 [3:15:01<1:14:08,  3.78s/it, loss=2.87, epoch=0.721, learning_rate=3.63e-6]\u001b[A\n",
      " 72%|███████▏  | 3043/4220 [3:15:01<1:14:08,  3.78s/it, loss=2.64, epoch=0.721, learning_rate=3.62e-6]\u001b[A\n",
      " 72%|███████▏  | 3044/4220 [3:15:04<1:14:04,  3.78s/it, loss=2.64, epoch=0.721, learning_rate=3.62e-6]\u001b[A\n",
      " 72%|███████▏  | 3044/4220 [3:15:04<1:14:04,  3.78s/it, loss=3.42, epoch=0.721, learning_rate=3.62e-6]\u001b[A\n",
      " 72%|███████▏  | 3045/4220 [3:15:08<1:13:59,  3.78s/it, loss=3.42, epoch=0.721, learning_rate=3.62e-6]\u001b[A\n",
      " 72%|███████▏  | 3045/4220 [3:15:08<1:13:59,  3.78s/it, loss=2.85, epoch=0.721, learning_rate=3.61e-6]\u001b[A\n",
      " 72%|███████▏  | 3046/4220 [3:15:12<1:13:56,  3.78s/it, loss=2.85, epoch=0.721, learning_rate=3.61e-6]\u001b[A\n",
      " 72%|███████▏  | 3046/4220 [3:15:12<1:13:56,  3.78s/it, loss=2.7, epoch=0.722, learning_rate=3.6e-6]  \u001b[A\n",
      " 72%|███████▏  | 3047/4220 [3:15:16<1:13:53,  3.78s/it, loss=2.7, epoch=0.722, learning_rate=3.6e-6]\u001b[A\n",
      " 72%|███████▏  | 3047/4220 [3:15:16<1:13:53,  3.78s/it, loss=2.69, epoch=0.722, learning_rate=3.6e-6]\u001b[A\n",
      " 72%|███████▏  | 3048/4220 [3:15:19<1:13:51,  3.78s/it, loss=2.69, epoch=0.722, learning_rate=3.6e-6]\u001b[A\n",
      " 72%|███████▏  | 3048/4220 [3:15:19<1:13:51,  3.78s/it, loss=2.73, epoch=0.722, learning_rate=3.59e-6]\u001b[A\n",
      " 72%|███████▏  | 3049/4220 [3:15:23<1:13:45,  3.78s/it, loss=2.73, epoch=0.722, learning_rate=3.59e-6]\u001b[A\n",
      " 72%|███████▏  | 3049/4220 [3:15:23<1:13:45,  3.78s/it, loss=2.9, epoch=0.722, learning_rate=3.59e-6] \u001b[A\n",
      " 72%|███████▏  | 3050/4220 [3:15:27<1:13:44,  3.78s/it, loss=2.9, epoch=0.722, learning_rate=3.59e-6]\u001b[A\n",
      " 72%|███████▏  | 3050/4220 [3:15:27<1:13:44,  3.78s/it, loss=3.1, epoch=0.723, learning_rate=3.58e-6]\u001b[A\n",
      " 72%|███████▏  | 3051/4220 [3:15:31<1:13:39,  3.78s/it, loss=3.1, epoch=0.723, learning_rate=3.58e-6]\u001b[A\n",
      " 72%|███████▏  | 3051/4220 [3:15:31<1:13:39,  3.78s/it, loss=2.53, epoch=0.723, learning_rate=3.58e-6]\u001b[A\n",
      " 72%|███████▏  | 3052/4220 [3:15:35<1:13:36,  3.78s/it, loss=2.53, epoch=0.723, learning_rate=3.58e-6]\u001b[A\n",
      " 72%|███████▏  | 3052/4220 [3:15:35<1:13:36,  3.78s/it, loss=2.54, epoch=0.723, learning_rate=3.57e-6]\u001b[A\n",
      " 72%|███████▏  | 3053/4220 [3:15:38<1:13:32,  3.78s/it, loss=2.54, epoch=0.723, learning_rate=3.57e-6]\u001b[A\n",
      " 72%|███████▏  | 3053/4220 [3:15:38<1:13:32,  3.78s/it, loss=2.46, epoch=0.723, learning_rate=3.56e-6]\u001b[A\n",
      " 72%|███████▏  | 3054/4220 [3:15:42<1:13:28,  3.78s/it, loss=2.46, epoch=0.723, learning_rate=3.56e-6]\u001b[A\n",
      " 72%|███████▏  | 3054/4220 [3:15:42<1:13:28,  3.78s/it, loss=2.66, epoch=0.723, learning_rate=3.56e-6]\u001b[A\n",
      " 72%|███████▏  | 3055/4220 [3:15:46<1:13:23,  3.78s/it, loss=2.66, epoch=0.723, learning_rate=3.56e-6]\u001b[A\n",
      " 72%|███████▏  | 3055/4220 [3:15:46<1:13:23,  3.78s/it, loss=2.63, epoch=0.724, learning_rate=3.55e-6]\u001b[A\n",
      " 72%|███████▏  | 3056/4220 [3:15:50<1:13:18,  3.78s/it, loss=2.63, epoch=0.724, learning_rate=3.55e-6]\u001b[A\n",
      " 72%|███████▏  | 3056/4220 [3:15:50<1:13:18,  3.78s/it, loss=2.54, epoch=0.724, learning_rate=3.55e-6]\u001b[A\n",
      " 72%|███████▏  | 3057/4220 [3:15:53<1:13:17,  3.78s/it, loss=2.54, epoch=0.724, learning_rate=3.55e-6]\u001b[A\n",
      " 72%|███████▏  | 3057/4220 [3:15:53<1:13:17,  3.78s/it, loss=2.29, epoch=0.724, learning_rate=3.54e-6]\u001b[A\n",
      " 72%|███████▏  | 3058/4220 [3:15:57<1:13:14,  3.78s/it, loss=2.29, epoch=0.724, learning_rate=3.54e-6]\u001b[A\n",
      " 72%|███████▏  | 3058/4220 [3:15:57<1:13:14,  3.78s/it, loss=2.94, epoch=0.724, learning_rate=3.54e-6]\u001b[A\n",
      " 72%|███████▏  | 3059/4220 [3:16:01<1:13:08,  3.78s/it, loss=2.94, epoch=0.724, learning_rate=3.54e-6]\u001b[A\n",
      " 72%|███████▏  | 3059/4220 [3:16:01<1:13:08,  3.78s/it, loss=2.65, epoch=0.725, learning_rate=3.53e-6]\u001b[A\n",
      " 73%|███████▎  | 3060/4220 [3:16:05<1:13:03,  3.78s/it, loss=2.65, epoch=0.725, learning_rate=3.53e-6]\u001b[A\n",
      " 73%|███████▎  | 3060/4220 [3:16:05<1:13:03,  3.78s/it, loss=2.85, epoch=0.725, learning_rate=3.52e-6]\u001b[A\n",
      " 73%|███████▎  | 3061/4220 [3:16:09<1:12:58,  3.78s/it, loss=2.85, epoch=0.725, learning_rate=3.52e-6]\u001b[A\n",
      " 73%|███████▎  | 3061/4220 [3:16:09<1:12:58,  3.78s/it, loss=2.81, epoch=0.725, learning_rate=3.52e-6]\u001b[A\n",
      " 73%|███████▎  | 3062/4220 [3:16:12<1:12:57,  3.78s/it, loss=2.81, epoch=0.725, learning_rate=3.52e-6]\u001b[A\n",
      " 73%|███████▎  | 3062/4220 [3:16:12<1:12:57,  3.78s/it, loss=2.88, epoch=0.725, learning_rate=3.51e-6]\u001b[A\n",
      " 73%|███████▎  | 3063/4220 [3:16:16<1:12:53,  3.78s/it, loss=2.88, epoch=0.725, learning_rate=3.51e-6]\u001b[A\n",
      " 73%|███████▎  | 3063/4220 [3:16:16<1:12:53,  3.78s/it, loss=2.58, epoch=0.726, learning_rate=3.51e-6]\u001b[A\n",
      " 73%|███████▎  | 3064/4220 [3:16:20<1:12:50,  3.78s/it, loss=2.58, epoch=0.726, learning_rate=3.51e-6]\u001b[A\n",
      " 73%|███████▎  | 3064/4220 [3:16:20<1:12:50,  3.78s/it, loss=2.48, epoch=0.726, learning_rate=3.5e-6] \u001b[A\n",
      " 73%|███████▎  | 3065/4220 [3:16:24<1:12:47,  3.78s/it, loss=2.48, epoch=0.726, learning_rate=3.5e-6]\u001b[A\n",
      " 73%|███████▎  | 3065/4220 [3:16:24<1:12:47,  3.78s/it, loss=3.29, epoch=0.726, learning_rate=3.5e-6]\u001b[A\n",
      " 73%|███████▎  | 3066/4220 [3:16:27<1:12:41,  3.78s/it, loss=3.29, epoch=0.726, learning_rate=3.5e-6]\u001b[A\n",
      " 73%|███████▎  | 3066/4220 [3:16:27<1:12:41,  3.78s/it, loss=3, epoch=0.726, learning_rate=3.49e-6]  \u001b[A\n",
      " 73%|███████▎  | 3067/4220 [3:16:31<1:12:38,  3.78s/it, loss=3, epoch=0.726, learning_rate=3.49e-6]\u001b[A\n",
      " 73%|███████▎  | 3067/4220 [3:16:31<1:12:38,  3.78s/it, loss=2.66, epoch=0.727, learning_rate=3.48e-6]\u001b[A\n",
      " 73%|███████▎  | 3068/4220 [3:16:35<1:12:34,  3.78s/it, loss=2.66, epoch=0.727, learning_rate=3.48e-6]\u001b[A\n",
      " 73%|███████▎  | 3068/4220 [3:16:35<1:12:34,  3.78s/it, loss=2.92, epoch=0.727, learning_rate=3.48e-6]\u001b[A\n",
      " 73%|███████▎  | 3069/4220 [3:16:39<1:12:31,  3.78s/it, loss=2.92, epoch=0.727, learning_rate=3.48e-6]\u001b[A\n",
      " 73%|███████▎  | 3069/4220 [3:16:39<1:12:31,  3.78s/it, loss=2.5, epoch=0.727, learning_rate=3.47e-6] \u001b[A\n",
      " 73%|███████▎  | 3070/4220 [3:16:43<1:12:26,  3.78s/it, loss=2.5, epoch=0.727, learning_rate=3.47e-6]\u001b[A\n",
      " 73%|███████▎  | 3070/4220 [3:16:43<1:12:26,  3.78s/it, loss=2.95, epoch=0.727, learning_rate=3.47e-6]\u001b[A\n",
      " 73%|███████▎  | 3071/4220 [3:16:46<1:12:23,  3.78s/it, loss=2.95, epoch=0.727, learning_rate=3.47e-6]\u001b[A\n",
      " 73%|███████▎  | 3071/4220 [3:16:46<1:12:23,  3.78s/it, loss=2.95, epoch=0.727, learning_rate=3.46e-6]\u001b[A\n",
      " 73%|███████▎  | 3072/4220 [3:16:50<1:12:20,  3.78s/it, loss=2.95, epoch=0.727, learning_rate=3.46e-6]\u001b[A\n",
      " 73%|███████▎  | 3072/4220 [3:16:50<1:12:20,  3.78s/it, loss=2.9, epoch=0.728, learning_rate=3.46e-6] \u001b[A\n",
      " 73%|███████▎  | 3073/4220 [3:16:54<1:12:18,  3.78s/it, loss=2.9, epoch=0.728, learning_rate=3.46e-6]\u001b[A\n",
      " 73%|███████▎  | 3073/4220 [3:16:54<1:12:18,  3.78s/it, loss=2.33, epoch=0.728, learning_rate=3.45e-6]\u001b[A\n",
      " 73%|███████▎  | 3074/4220 [3:16:58<1:12:15,  3.78s/it, loss=2.33, epoch=0.728, learning_rate=3.45e-6]\u001b[A\n",
      " 73%|███████▎  | 3074/4220 [3:16:58<1:12:15,  3.78s/it, loss=2.48, epoch=0.728, learning_rate=3.44e-6]\u001b[A\n",
      " 73%|███████▎  | 3075/4220 [3:17:01<1:12:09,  3.78s/it, loss=2.48, epoch=0.728, learning_rate=3.44e-6]\u001b[A\n",
      " 73%|███████▎  | 3075/4220 [3:17:01<1:12:09,  3.78s/it, loss=2.67, epoch=0.728, learning_rate=3.44e-6]\u001b[A\n",
      " 73%|███████▎  | 3076/4220 [3:17:05<1:12:04,  3.78s/it, loss=2.67, epoch=0.728, learning_rate=3.44e-6]\u001b[A\n",
      " 73%|███████▎  | 3076/4220 [3:17:05<1:12:04,  3.78s/it, loss=2.7, epoch=0.729, learning_rate=3.43e-6] \u001b[A\n",
      " 73%|███████▎  | 3077/4220 [3:17:09<1:11:59,  3.78s/it, loss=2.7, epoch=0.729, learning_rate=3.43e-6]\u001b[A\n",
      " 73%|███████▎  | 3077/4220 [3:17:09<1:11:59,  3.78s/it, loss=2.9, epoch=0.729, learning_rate=3.43e-6]\u001b[A\n",
      " 73%|███████▎  | 3078/4220 [3:17:13<1:11:55,  3.78s/it, loss=2.9, epoch=0.729, learning_rate=3.43e-6]\u001b[A\n",
      " 73%|███████▎  | 3078/4220 [3:17:13<1:11:55,  3.78s/it, loss=2.65, epoch=0.729, learning_rate=3.42e-6]\u001b[A\n",
      " 73%|███████▎  | 3079/4220 [3:17:17<1:11:53,  3.78s/it, loss=2.65, epoch=0.729, learning_rate=3.42e-6]\u001b[A\n",
      " 73%|███████▎  | 3079/4220 [3:17:17<1:11:53,  3.78s/it, loss=2.71, epoch=0.729, learning_rate=3.42e-6]\u001b[A\n",
      " 73%|███████▎  | 3080/4220 [3:17:20<1:11:48,  3.78s/it, loss=2.71, epoch=0.729, learning_rate=3.42e-6]\u001b[A\n",
      " 73%|███████▎  | 3080/4220 [3:17:20<1:11:48,  3.78s/it, loss=2.77, epoch=0.73, learning_rate=3.41e-6] \u001b[A\n",
      " 73%|███████▎  | 3081/4220 [3:17:24<1:11:44,  3.78s/it, loss=2.77, epoch=0.73, learning_rate=3.41e-6]\u001b[A\n",
      " 73%|███████▎  | 3081/4220 [3:17:24<1:11:44,  3.78s/it, loss=2.78, epoch=0.73, learning_rate=3.41e-6]\u001b[A\n",
      " 73%|███████▎  | 3082/4220 [3:17:28<1:11:42,  3.78s/it, loss=2.78, epoch=0.73, learning_rate=3.41e-6]\u001b[A\n",
      " 73%|███████▎  | 3082/4220 [3:17:28<1:11:42,  3.78s/it, loss=3.11, epoch=0.73, learning_rate=3.4e-6] \u001b[A\n",
      " 73%|███████▎  | 3083/4220 [3:17:32<1:11:37,  3.78s/it, loss=3.11, epoch=0.73, learning_rate=3.4e-6]\u001b[A\n",
      " 73%|███████▎  | 3083/4220 [3:17:32<1:11:37,  3.78s/it, loss=3.24, epoch=0.73, learning_rate=3.39e-6]\u001b[A\n",
      " 73%|███████▎  | 3084/4220 [3:17:35<1:11:32,  3.78s/it, loss=3.24, epoch=0.73, learning_rate=3.39e-6]\u001b[A\n",
      " 73%|███████▎  | 3084/4220 [3:17:35<1:11:32,  3.78s/it, loss=2.61, epoch=0.731, learning_rate=3.39e-6]\u001b[A\n",
      " 73%|███████▎  | 3085/4220 [3:17:39<1:11:28,  3.78s/it, loss=2.61, epoch=0.731, learning_rate=3.39e-6]\u001b[A\n",
      " 73%|███████▎  | 3085/4220 [3:17:39<1:11:28,  3.78s/it, loss=2.72, epoch=0.731, learning_rate=3.38e-6]\u001b[A\n",
      " 73%|███████▎  | 3086/4220 [3:17:43<1:11:24,  3.78s/it, loss=2.72, epoch=0.731, learning_rate=3.38e-6]\u001b[A\n",
      " 73%|███████▎  | 3086/4220 [3:17:43<1:11:24,  3.78s/it, loss=2.86, epoch=0.731, learning_rate=3.38e-6]\u001b[A\n",
      " 73%|███████▎  | 3087/4220 [3:17:47<1:11:20,  3.78s/it, loss=2.86, epoch=0.731, learning_rate=3.38e-6]\u001b[A\n",
      " 73%|███████▎  | 3087/4220 [3:17:47<1:11:20,  3.78s/it, loss=2.72, epoch=0.731, learning_rate=3.37e-6]\u001b[A\n",
      " 73%|███████▎  | 3088/4220 [3:17:51<1:11:17,  3.78s/it, loss=2.72, epoch=0.731, learning_rate=3.37e-6]\u001b[A\n",
      " 73%|███████▎  | 3088/4220 [3:17:51<1:11:17,  3.78s/it, loss=2.8, epoch=0.732, learning_rate=3.37e-6] \u001b[A\n",
      " 73%|███████▎  | 3089/4220 [3:17:54<1:11:15,  3.78s/it, loss=2.8, epoch=0.732, learning_rate=3.37e-6]\u001b[A\n",
      " 73%|███████▎  | 3089/4220 [3:17:54<1:11:15,  3.78s/it, loss=3.03, epoch=0.732, learning_rate=3.36e-6]\u001b[A\n",
      " 73%|███████▎  | 3090/4220 [3:17:58<1:11:12,  3.78s/it, loss=3.03, epoch=0.732, learning_rate=3.36e-6]\u001b[A\n",
      " 73%|███████▎  | 3090/4220 [3:17:58<1:11:12,  3.78s/it, loss=2.41, epoch=0.732, learning_rate=3.36e-6]\u001b[A\n",
      " 73%|███████▎  | 3091/4220 [3:18:02<1:11:08,  3.78s/it, loss=2.41, epoch=0.732, learning_rate=3.36e-6]\u001b[A\n",
      " 73%|███████▎  | 3091/4220 [3:18:02<1:11:08,  3.78s/it, loss=2.86, epoch=0.732, learning_rate=3.35e-6]\u001b[A\n",
      " 73%|███████▎  | 3092/4220 [3:18:06<1:11:02,  3.78s/it, loss=2.86, epoch=0.732, learning_rate=3.35e-6]\u001b[A\n",
      " 73%|███████▎  | 3092/4220 [3:18:06<1:11:02,  3.78s/it, loss=3.18, epoch=0.732, learning_rate=3.34e-6]\u001b[A\n",
      " 73%|███████▎  | 3093/4220 [3:18:09<1:10:58,  3.78s/it, loss=3.18, epoch=0.732, learning_rate=3.34e-6]\u001b[A\n",
      " 73%|███████▎  | 3093/4220 [3:18:10<1:10:58,  3.78s/it, loss=3.09, epoch=0.733, learning_rate=3.34e-6]\u001b[A\n",
      " 73%|███████▎  | 3094/4220 [3:18:13<1:10:54,  3.78s/it, loss=3.09, epoch=0.733, learning_rate=3.34e-6]\u001b[A\n",
      " 73%|███████▎  | 3094/4220 [3:18:13<1:10:54,  3.78s/it, loss=2.85, epoch=0.733, learning_rate=3.33e-6]\u001b[A\n",
      " 73%|███████▎  | 3095/4220 [3:18:17<1:10:52,  3.78s/it, loss=2.85, epoch=0.733, learning_rate=3.33e-6]\u001b[A\n",
      " 73%|███████▎  | 3095/4220 [3:18:17<1:10:52,  3.78s/it, loss=2.99, epoch=0.733, learning_rate=3.33e-6]\u001b[A\n",
      " 73%|███████▎  | 3096/4220 [3:18:21<1:10:46,  3.78s/it, loss=2.99, epoch=0.733, learning_rate=3.33e-6]\u001b[A\n",
      " 73%|███████▎  | 3096/4220 [3:18:21<1:10:46,  3.78s/it, loss=2.67, epoch=0.733, learning_rate=3.32e-6]\u001b[A\n",
      " 73%|███████▎  | 3097/4220 [3:18:25<1:10:43,  3.78s/it, loss=2.67, epoch=0.733, learning_rate=3.32e-6]\u001b[A\n",
      " 73%|███████▎  | 3097/4220 [3:18:25<1:10:43,  3.78s/it, loss=2.77, epoch=0.734, learning_rate=3.32e-6]\u001b[A\n",
      " 73%|███████▎  | 3098/4220 [3:18:28<1:10:41,  3.78s/it, loss=2.77, epoch=0.734, learning_rate=3.32e-6]\u001b[A\n",
      " 73%|███████▎  | 3098/4220 [3:18:28<1:10:41,  3.78s/it, loss=2.35, epoch=0.734, learning_rate=3.31e-6]\u001b[A\n",
      " 73%|███████▎  | 3099/4220 [3:18:32<1:10:38,  3.78s/it, loss=2.35, epoch=0.734, learning_rate=3.31e-6]\u001b[A\n",
      " 73%|███████▎  | 3099/4220 [3:18:32<1:10:38,  3.78s/it, loss=2.84, epoch=0.734, learning_rate=3.3e-6] \u001b[A\n",
      " 73%|███████▎  | 3100/4220 [3:18:36<1:10:34,  3.78s/it, loss=2.84, epoch=0.734, learning_rate=3.3e-6]\u001b[A\n",
      " 73%|███████▎  | 3100/4220 [3:18:36<1:10:34,  3.78s/it, loss=2.4, epoch=0.734, learning_rate=3.3e-6] \u001b[A\n",
      " 73%|███████▎  | 3101/4220 [3:18:40<1:10:30,  3.78s/it, loss=2.4, epoch=0.734, learning_rate=3.3e-6]\u001b[A\n",
      " 73%|███████▎  | 3101/4220 [3:18:40<1:10:30,  3.78s/it, loss=3.1, epoch=0.735, learning_rate=3.29e-6]\u001b[A\n",
      " 74%|███████▎  | 3102/4220 [3:18:44<1:10:26,  3.78s/it, loss=3.1, epoch=0.735, learning_rate=3.29e-6]\u001b[A\n",
      " 74%|███████▎  | 3102/4220 [3:18:44<1:10:26,  3.78s/it, loss=2.52, epoch=0.735, learning_rate=3.29e-6]\u001b[A\n",
      " 74%|███████▎  | 3103/4220 [3:18:47<1:10:23,  3.78s/it, loss=2.52, epoch=0.735, learning_rate=3.29e-6]\u001b[A\n",
      " 74%|███████▎  | 3103/4220 [3:18:47<1:10:23,  3.78s/it, loss=2.66, epoch=0.735, learning_rate=3.28e-6]\u001b[A\n",
      " 74%|███████▎  | 3104/4220 [3:18:51<1:10:18,  3.78s/it, loss=2.66, epoch=0.735, learning_rate=3.28e-6]\u001b[A\n",
      " 74%|███████▎  | 3104/4220 [3:18:51<1:10:18,  3.78s/it, loss=3.37, epoch=0.735, learning_rate=3.28e-6]\u001b[A\n",
      " 74%|███████▎  | 3105/4220 [3:18:55<1:10:15,  3.78s/it, loss=3.37, epoch=0.735, learning_rate=3.28e-6]\u001b[A\n",
      " 74%|███████▎  | 3105/4220 [3:18:55<1:10:15,  3.78s/it, loss=2.73, epoch=0.736, learning_rate=3.27e-6]\u001b[A\n",
      " 74%|███████▎  | 3106/4220 [3:18:59<1:10:11,  3.78s/it, loss=2.73, epoch=0.736, learning_rate=3.27e-6]\u001b[A\n",
      " 74%|███████▎  | 3106/4220 [3:18:59<1:10:11,  3.78s/it, loss=2.52, epoch=0.736, learning_rate=3.27e-6]\u001b[A\n",
      " 74%|███████▎  | 3107/4220 [3:19:02<1:10:08,  3.78s/it, loss=2.52, epoch=0.736, learning_rate=3.27e-6]\u001b[A\n",
      " 74%|███████▎  | 3107/4220 [3:19:02<1:10:08,  3.78s/it, loss=2.82, epoch=0.736, learning_rate=3.26e-6]\u001b[A\n",
      " 74%|███████▎  | 3108/4220 [3:19:06<1:10:03,  3.78s/it, loss=2.82, epoch=0.736, learning_rate=3.26e-6]\u001b[A\n",
      " 74%|███████▎  | 3108/4220 [3:19:06<1:10:03,  3.78s/it, loss=2.78, epoch=0.736, learning_rate=3.26e-6]\u001b[A\n",
      " 74%|███████▎  | 3109/4220 [3:19:10<1:10:00,  3.78s/it, loss=2.78, epoch=0.736, learning_rate=3.26e-6]\u001b[A\n",
      " 74%|███████▎  | 3109/4220 [3:19:10<1:10:00,  3.78s/it, loss=3.06, epoch=0.736, learning_rate=3.25e-6]\u001b[A\n",
      " 74%|███████▎  | 3110/4220 [3:19:14<1:09:58,  3.78s/it, loss=3.06, epoch=0.736, learning_rate=3.25e-6]\u001b[A\n",
      " 74%|███████▎  | 3110/4220 [3:19:14<1:09:58,  3.78s/it, loss=2.71, epoch=0.737, learning_rate=3.24e-6]\u001b[A\n",
      " 74%|███████▎  | 3111/4220 [3:19:18<1:09:54,  3.78s/it, loss=2.71, epoch=0.737, learning_rate=3.24e-6]\u001b[A\n",
      " 74%|███████▎  | 3111/4220 [3:19:18<1:09:54,  3.78s/it, loss=2.96, epoch=0.737, learning_rate=3.24e-6]\u001b[A\n",
      " 74%|███████▎  | 3112/4220 [3:19:21<1:09:51,  3.78s/it, loss=2.96, epoch=0.737, learning_rate=3.24e-6]\u001b[A\n",
      " 74%|███████▎  | 3112/4220 [3:19:21<1:09:51,  3.78s/it, loss=2.84, epoch=0.737, learning_rate=3.23e-6]\u001b[A\n",
      " 74%|███████▍  | 3113/4220 [3:19:25<1:09:45,  3.78s/it, loss=2.84, epoch=0.737, learning_rate=3.23e-6]\u001b[A\n",
      " 74%|███████▍  | 3113/4220 [3:19:25<1:09:45,  3.78s/it, loss=2.78, epoch=0.737, learning_rate=3.23e-6]\u001b[A\n",
      " 74%|███████▍  | 3114/4220 [3:19:29<1:09:40,  3.78s/it, loss=2.78, epoch=0.737, learning_rate=3.23e-6]\u001b[A\n",
      " 74%|███████▍  | 3114/4220 [3:19:29<1:09:40,  3.78s/it, loss=2.95, epoch=0.738, learning_rate=3.22e-6]\u001b[A\n",
      " 74%|███████▍  | 3115/4220 [3:19:33<1:09:37,  3.78s/it, loss=2.95, epoch=0.738, learning_rate=3.22e-6]\u001b[A\n",
      " 74%|███████▍  | 3115/4220 [3:19:33<1:09:37,  3.78s/it, loss=2.62, epoch=0.738, learning_rate=3.22e-6]\u001b[A\n",
      " 74%|███████▍  | 3116/4220 [3:19:36<1:09:33,  3.78s/it, loss=2.62, epoch=0.738, learning_rate=3.22e-6]\u001b[A\n",
      " 74%|███████▍  | 3116/4220 [3:19:36<1:09:33,  3.78s/it, loss=3.06, epoch=0.738, learning_rate=3.21e-6]\u001b[A\n",
      " 74%|███████▍  | 3117/4220 [3:19:40<1:09:28,  3.78s/it, loss=3.06, epoch=0.738, learning_rate=3.21e-6]\u001b[A\n",
      " 74%|███████▍  | 3117/4220 [3:19:40<1:09:28,  3.78s/it, loss=3.02, epoch=0.738, learning_rate=3.21e-6]\u001b[A\n",
      " 74%|███████▍  | 3118/4220 [3:19:44<1:09:25,  3.78s/it, loss=3.02, epoch=0.738, learning_rate=3.21e-6]\u001b[A\n",
      " 74%|███████▍  | 3118/4220 [3:19:44<1:09:25,  3.78s/it, loss=2.87, epoch=0.739, learning_rate=3.2e-6] \u001b[A\n",
      " 74%|███████▍  | 3119/4220 [3:19:48<1:09:23,  3.78s/it, loss=2.87, epoch=0.739, learning_rate=3.2e-6]\u001b[A\n",
      " 74%|███████▍  | 3119/4220 [3:19:48<1:09:23,  3.78s/it, loss=2.52, epoch=0.739, learning_rate=3.19e-6]\u001b[A\n",
      " 74%|███████▍  | 3120/4220 [3:19:52<1:09:19,  3.78s/it, loss=2.52, epoch=0.739, learning_rate=3.19e-6]\u001b[A\n",
      " 74%|███████▍  | 3120/4220 [3:19:52<1:09:19,  3.78s/it, loss=3.06, epoch=0.739, learning_rate=3.19e-6]\u001b[A\n",
      " 74%|███████▍  | 3121/4220 [3:19:55<1:09:14,  3.78s/it, loss=3.06, epoch=0.739, learning_rate=3.19e-6]\u001b[A\n",
      " 74%|███████▍  | 3121/4220 [3:19:55<1:09:14,  3.78s/it, loss=3.03, epoch=0.739, learning_rate=3.18e-6]\u001b[A\n",
      " 74%|███████▍  | 3122/4220 [3:19:59<1:09:11,  3.78s/it, loss=3.03, epoch=0.739, learning_rate=3.18e-6]\u001b[A\n",
      " 74%|███████▍  | 3122/4220 [3:19:59<1:09:11,  3.78s/it, loss=2.87, epoch=0.74, learning_rate=3.18e-6] \u001b[A\n",
      " 74%|███████▍  | 3123/4220 [3:20:03<1:09:06,  3.78s/it, loss=2.87, epoch=0.74, learning_rate=3.18e-6]\u001b[A\n",
      " 74%|███████▍  | 3123/4220 [3:20:03<1:09:06,  3.78s/it, loss=2.98, epoch=0.74, learning_rate=3.17e-6]\u001b[A\n",
      " 74%|███████▍  | 3124/4220 [3:20:07<1:09:03,  3.78s/it, loss=2.98, epoch=0.74, learning_rate=3.17e-6]\u001b[A\n",
      " 74%|███████▍  | 3124/4220 [3:20:07<1:09:03,  3.78s/it, loss=2.49, epoch=0.74, learning_rate=3.17e-6]\u001b[A\n",
      " 74%|███████▍  | 3125/4220 [3:20:10<1:09:01,  3.78s/it, loss=2.49, epoch=0.74, learning_rate=3.17e-6]\u001b[A\n",
      " 74%|███████▍  | 3125/4220 [3:20:10<1:09:01,  3.78s/it, loss=2.85, epoch=0.74, learning_rate=3.16e-6]\u001b[A\n",
      " 74%|███████▍  | 3126/4220 [3:20:14<1:08:57,  3.78s/it, loss=2.85, epoch=0.74, learning_rate=3.16e-6]\u001b[A\n",
      " 74%|███████▍  | 3126/4220 [3:20:14<1:08:57,  3.78s/it, loss=3.21, epoch=0.741, learning_rate=3.16e-6]\u001b[A\n",
      " 74%|███████▍  | 3127/4220 [3:20:18<1:08:55,  3.78s/it, loss=3.21, epoch=0.741, learning_rate=3.16e-6]\u001b[A\n",
      " 74%|███████▍  | 3127/4220 [3:20:18<1:08:55,  3.78s/it, loss=3.04, epoch=0.741, learning_rate=3.15e-6]\u001b[A\n",
      " 74%|███████▍  | 3128/4220 [3:20:22<1:08:51,  3.78s/it, loss=3.04, epoch=0.741, learning_rate=3.15e-6]\u001b[A\n",
      " 74%|███████▍  | 3128/4220 [3:20:22<1:08:51,  3.78s/it, loss=3.05, epoch=0.741, learning_rate=3.15e-6]\u001b[A\n",
      " 74%|███████▍  | 3129/4220 [3:20:26<1:08:47,  3.78s/it, loss=3.05, epoch=0.741, learning_rate=3.15e-6]\u001b[A\n",
      " 74%|███████▍  | 3129/4220 [3:20:26<1:08:47,  3.78s/it, loss=3.05, epoch=0.741, learning_rate=3.14e-6]\u001b[A\n",
      " 74%|███████▍  | 3130/4220 [3:20:29<1:08:40,  3.78s/it, loss=3.05, epoch=0.741, learning_rate=3.14e-6]\u001b[A\n",
      " 74%|███████▍  | 3130/4220 [3:20:29<1:08:40,  3.78s/it, loss=3.07, epoch=0.741, learning_rate=3.13e-6]\u001b[A\n",
      " 74%|███████▍  | 3131/4220 [3:20:33<1:08:37,  3.78s/it, loss=3.07, epoch=0.741, learning_rate=3.13e-6]\u001b[A\n",
      " 74%|███████▍  | 3131/4220 [3:20:33<1:08:37,  3.78s/it, loss=2.62, epoch=0.742, learning_rate=3.13e-6]\u001b[A\n",
      " 74%|███████▍  | 3132/4220 [3:20:37<1:08:32,  3.78s/it, loss=2.62, epoch=0.742, learning_rate=3.13e-6]\u001b[A\n",
      " 74%|███████▍  | 3132/4220 [3:20:37<1:08:32,  3.78s/it, loss=2.8, epoch=0.742, learning_rate=3.12e-6] \u001b[A\n",
      " 74%|███████▍  | 3133/4220 [3:20:41<1:08:27,  3.78s/it, loss=2.8, epoch=0.742, learning_rate=3.12e-6]\u001b[A\n",
      " 74%|███████▍  | 3133/4220 [3:20:41<1:08:27,  3.78s/it, loss=2.83, epoch=0.742, learning_rate=3.12e-6]\u001b[A\n",
      " 74%|███████▍  | 3134/4220 [3:20:45<1:08:24,  3.78s/it, loss=2.83, epoch=0.742, learning_rate=3.12e-6]\u001b[A\n",
      " 74%|███████▍  | 3134/4220 [3:20:45<1:08:24,  3.78s/it, loss=2.46, epoch=0.742, learning_rate=3.11e-6]\u001b[A\n",
      " 74%|███████▍  | 3135/4220 [3:20:48<1:08:21,  3.78s/it, loss=2.46, epoch=0.742, learning_rate=3.11e-6]\u001b[A\n",
      " 74%|███████▍  | 3135/4220 [3:20:48<1:08:21,  3.78s/it, loss=2.76, epoch=0.743, learning_rate=3.11e-6]\u001b[A\n",
      " 74%|███████▍  | 3136/4220 [3:20:52<1:08:18,  3.78s/it, loss=2.76, epoch=0.743, learning_rate=3.11e-6]\u001b[A\n",
      " 74%|███████▍  | 3136/4220 [3:20:52<1:08:18,  3.78s/it, loss=2.96, epoch=0.743, learning_rate=3.1e-6] \u001b[A\n",
      " 74%|███████▍  | 3137/4220 [3:20:56<1:08:14,  3.78s/it, loss=2.96, epoch=0.743, learning_rate=3.1e-6]\u001b[A\n",
      " 74%|███████▍  | 3137/4220 [3:20:56<1:08:14,  3.78s/it, loss=2.74, epoch=0.743, learning_rate=3.1e-6]\u001b[A\n",
      " 74%|███████▍  | 3138/4220 [3:21:00<1:08:09,  3.78s/it, loss=2.74, epoch=0.743, learning_rate=3.1e-6]\u001b[A\n",
      " 74%|███████▍  | 3138/4220 [3:21:00<1:08:09,  3.78s/it, loss=2.64, epoch=0.743, learning_rate=3.09e-6]\u001b[A\n",
      " 74%|███████▍  | 3139/4220 [3:21:03<1:08:06,  3.78s/it, loss=2.64, epoch=0.743, learning_rate=3.09e-6]\u001b[A\n",
      " 74%|███████▍  | 3139/4220 [3:21:03<1:08:06,  3.78s/it, loss=2.76, epoch=0.744, learning_rate=3.09e-6]\u001b[A\n",
      " 74%|███████▍  | 3140/4220 [3:21:07<1:08:03,  3.78s/it, loss=2.76, epoch=0.744, learning_rate=3.09e-6]\u001b[A\n",
      " 74%|███████▍  | 3140/4220 [3:21:07<1:08:03,  3.78s/it, loss=2.76, epoch=0.744, learning_rate=3.08e-6]\u001b[A\n",
      " 74%|███████▍  | 3141/4220 [3:21:11<1:07:58,  3.78s/it, loss=2.76, epoch=0.744, learning_rate=3.08e-6]\u001b[A\n",
      " 74%|███████▍  | 3141/4220 [3:21:11<1:07:58,  3.78s/it, loss=2.26, epoch=0.744, learning_rate=3.08e-6]\u001b[A\n",
      " 74%|███████▍  | 3142/4220 [3:21:15<1:07:54,  3.78s/it, loss=2.26, epoch=0.744, learning_rate=3.08e-6]\u001b[A\n",
      " 74%|███████▍  | 3142/4220 [3:21:15<1:07:54,  3.78s/it, loss=2.74, epoch=0.744, learning_rate=3.07e-6]\u001b[A\n",
      " 74%|███████▍  | 3143/4220 [3:21:19<1:07:50,  3.78s/it, loss=2.74, epoch=0.744, learning_rate=3.07e-6]\u001b[A\n",
      " 74%|███████▍  | 3143/4220 [3:21:19<1:07:50,  3.78s/it, loss=2.91, epoch=0.745, learning_rate=3.06e-6]\u001b[A\n",
      " 75%|███████▍  | 3144/4220 [3:21:22<1:07:46,  3.78s/it, loss=2.91, epoch=0.745, learning_rate=3.06e-6]\u001b[A\n",
      " 75%|███████▍  | 3144/4220 [3:21:22<1:07:46,  3.78s/it, loss=2.66, epoch=0.745, learning_rate=3.06e-6]\u001b[A\n",
      " 75%|███████▍  | 3145/4220 [3:21:26<1:07:42,  3.78s/it, loss=2.66, epoch=0.745, learning_rate=3.06e-6]\u001b[A\n",
      " 75%|███████▍  | 3145/4220 [3:21:26<1:07:42,  3.78s/it, loss=2.71, epoch=0.745, learning_rate=3.05e-6]\u001b[A\n",
      " 75%|███████▍  | 3146/4220 [3:21:30<1:07:39,  3.78s/it, loss=2.71, epoch=0.745, learning_rate=3.05e-6]\u001b[A\n",
      " 75%|███████▍  | 3146/4220 [3:21:30<1:07:39,  3.78s/it, loss=2.63, epoch=0.745, learning_rate=3.05e-6]\u001b[A\n",
      " 75%|███████▍  | 3147/4220 [3:21:34<1:07:36,  3.78s/it, loss=2.63, epoch=0.745, learning_rate=3.05e-6]\u001b[A\n",
      " 75%|███████▍  | 3147/4220 [3:21:34<1:07:36,  3.78s/it, loss=2.36, epoch=0.745, learning_rate=3.04e-6]\u001b[A\n",
      " 75%|███████▍  | 3148/4220 [3:21:37<1:07:31,  3.78s/it, loss=2.36, epoch=0.745, learning_rate=3.04e-6]\u001b[A\n",
      " 75%|███████▍  | 3148/4220 [3:21:37<1:07:31,  3.78s/it, loss=2.46, epoch=0.746, learning_rate=3.04e-6]\u001b[A\n",
      " 75%|███████▍  | 3149/4220 [3:21:41<1:08:37,  3.84s/it, loss=2.46, epoch=0.746, learning_rate=3.04e-6]\u001b[A\n",
      " 75%|███████▍  | 3149/4220 [3:21:41<1:08:37,  3.84s/it, loss=2.37, epoch=0.746, learning_rate=3.03e-6]\u001b[A\n",
      " 75%|███████▍  | 3150/4220 [3:21:45<1:08:11,  3.82s/it, loss=2.37, epoch=0.746, learning_rate=3.03e-6]\u001b[A\n",
      " 75%|███████▍  | 3150/4220 [3:21:45<1:08:11,  3.82s/it, loss=2.77, epoch=0.746, learning_rate=3.03e-6]\u001b[A\n",
      " 75%|███████▍  | 3151/4220 [3:21:49<1:07:55,  3.81s/it, loss=2.77, epoch=0.746, learning_rate=3.03e-6]\u001b[A\n",
      " 75%|███████▍  | 3151/4220 [3:21:49<1:07:55,  3.81s/it, loss=3.01, epoch=0.746, learning_rate=3.02e-6]\u001b[A\n",
      " 75%|███████▍  | 3152/4220 [3:21:53<1:07:42,  3.80s/it, loss=3.01, epoch=0.746, learning_rate=3.02e-6]\u001b[A\n",
      " 75%|███████▍  | 3152/4220 [3:21:53<1:07:42,  3.80s/it, loss=2.79, epoch=0.747, learning_rate=3.02e-6]\u001b[A\n",
      " 75%|███████▍  | 3153/4220 [3:21:57<1:07:32,  3.80s/it, loss=2.79, epoch=0.747, learning_rate=3.02e-6]\u001b[A\n",
      " 75%|███████▍  | 3153/4220 [3:21:57<1:07:32,  3.80s/it, loss=2.9, epoch=0.747, learning_rate=3.01e-6] \u001b[A\n",
      " 75%|███████▍  | 3154/4220 [3:22:00<1:07:24,  3.79s/it, loss=2.9, epoch=0.747, learning_rate=3.01e-6]\u001b[A\n",
      " 75%|███████▍  | 3154/4220 [3:22:00<1:07:24,  3.79s/it, loss=2.39, epoch=0.747, learning_rate=3.01e-6]\u001b[A\n",
      " 75%|███████▍  | 3155/4220 [3:22:04<1:07:18,  3.79s/it, loss=2.39, epoch=0.747, learning_rate=3.01e-6]\u001b[A\n",
      " 75%|███████▍  | 3155/4220 [3:22:04<1:07:18,  3.79s/it, loss=2.88, epoch=0.747, learning_rate=3e-6]   \u001b[A\n",
      " 75%|███████▍  | 3156/4220 [3:22:08<1:07:12,  3.79s/it, loss=2.88, epoch=0.747, learning_rate=3e-6]\u001b[A\n",
      " 75%|███████▍  | 3156/4220 [3:22:08<1:07:12,  3.79s/it, loss=2.79, epoch=0.748, learning_rate=3e-6]\u001b[A\n",
      " 75%|███████▍  | 3157/4220 [3:22:12<1:07:07,  3.79s/it, loss=2.79, epoch=0.748, learning_rate=3e-6]\u001b[A\n",
      " 75%|███████▍  | 3157/4220 [3:22:12<1:07:07,  3.79s/it, loss=2.81, epoch=0.748, learning_rate=2.99e-6]\u001b[A\n",
      " 75%|███████▍  | 3158/4220 [3:22:15<1:07:02,  3.79s/it, loss=2.81, epoch=0.748, learning_rate=2.99e-6]\u001b[A\n",
      " 75%|███████▍  | 3158/4220 [3:22:15<1:07:02,  3.79s/it, loss=3.17, epoch=0.748, learning_rate=2.98e-6]\u001b[A\n",
      " 75%|███████▍  | 3159/4220 [3:22:19<1:06:57,  3.79s/it, loss=3.17, epoch=0.748, learning_rate=2.98e-6]\u001b[A\n",
      " 75%|███████▍  | 3159/4220 [3:22:19<1:06:57,  3.79s/it, loss=2.97, epoch=0.748, learning_rate=2.98e-6]\u001b[A\n",
      " 75%|███████▍  | 3160/4220 [3:22:23<1:06:52,  3.79s/it, loss=2.97, epoch=0.748, learning_rate=2.98e-6]\u001b[A\n",
      " 75%|███████▍  | 3160/4220 [3:22:23<1:06:52,  3.79s/it, loss=3.04, epoch=0.749, learning_rate=2.97e-6]\u001b[A\n",
      " 75%|███████▍  | 3161/4220 [3:22:27<1:06:48,  3.79s/it, loss=3.04, epoch=0.749, learning_rate=2.97e-6]\u001b[A\n",
      " 75%|███████▍  | 3161/4220 [3:22:27<1:06:48,  3.79s/it, loss=2.71, epoch=0.749, learning_rate=2.97e-6]\u001b[A\n",
      " 75%|███████▍  | 3162/4220 [3:22:31<1:06:43,  3.78s/it, loss=2.71, epoch=0.749, learning_rate=2.97e-6]\u001b[A\n",
      " 75%|███████▍  | 3162/4220 [3:22:31<1:06:43,  3.78s/it, loss=3.09, epoch=0.749, learning_rate=2.96e-6]\u001b[A\n",
      " 75%|███████▍  | 3163/4220 [3:22:34<1:06:41,  3.79s/it, loss=3.09, epoch=0.749, learning_rate=2.96e-6]\u001b[A\n",
      " 75%|███████▍  | 3163/4220 [3:22:34<1:06:41,  3.79s/it, loss=2.56, epoch=0.749, learning_rate=2.96e-6]\u001b[A\n",
      " 75%|███████▍  | 3164/4220 [3:22:38<1:06:37,  3.79s/it, loss=2.56, epoch=0.749, learning_rate=2.96e-6]\u001b[A\n",
      " 75%|███████▍  | 3164/4220 [3:22:38<1:06:37,  3.79s/it, loss=2.92, epoch=0.75, learning_rate=2.95e-6] \u001b[A\n",
      " 75%|███████▌  | 3165/4220 [3:22:42<1:06:31,  3.78s/it, loss=2.92, epoch=0.75, learning_rate=2.95e-6]\u001b[A\n",
      " 75%|███████▌  | 3165/4220 [3:22:42<1:06:31,  3.78s/it, loss=2.71, epoch=0.75, learning_rate=2.95e-6]\u001b[A\n",
      " 75%|███████▌  | 3166/4220 [3:22:46<1:06:28,  3.78s/it, loss=2.71, epoch=0.75, learning_rate=2.95e-6]\u001b[A\n",
      " 75%|███████▌  | 3166/4220 [3:22:46<1:06:28,  3.78s/it, loss=3.04, epoch=0.75, learning_rate=2.94e-6]\u001b[A\n",
      " 75%|███████▌  | 3167/4220 [3:22:50<1:06:23,  3.78s/it, loss=3.04, epoch=0.75, learning_rate=2.94e-6]\u001b[A\n",
      " 75%|███████▌  | 3167/4220 [3:22:50<1:06:23,  3.78s/it, loss=2.82, epoch=0.75, learning_rate=2.94e-6]\u001b[A\n",
      " 75%|███████▌  | 3168/4220 [3:22:53<1:06:20,  3.78s/it, loss=2.82, epoch=0.75, learning_rate=2.94e-6]\u001b[A\n",
      " 75%|███████▌  | 3168/4220 [3:22:53<1:06:20,  3.78s/it, loss=2.83, epoch=0.75, learning_rate=2.93e-6]\u001b[A\n",
      " 75%|███████▌  | 3169/4220 [3:22:57<1:06:16,  3.78s/it, loss=2.83, epoch=0.75, learning_rate=2.93e-6]\u001b[A\n",
      " 75%|███████▌  | 3169/4220 [3:22:57<1:06:16,  3.78s/it, loss=2.91, epoch=0.751, learning_rate=2.93e-6]\u001b[A\n",
      " 75%|███████▌  | 3170/4220 [3:23:01<1:06:13,  3.78s/it, loss=2.91, epoch=0.751, learning_rate=2.93e-6]\u001b[A\n",
      " 75%|███████▌  | 3170/4220 [3:23:01<1:06:13,  3.78s/it, loss=2.62, epoch=0.751, learning_rate=2.92e-6]\u001b[A\n",
      " 75%|███████▌  | 3171/4220 [3:23:05<1:06:09,  3.78s/it, loss=2.62, epoch=0.751, learning_rate=2.92e-6]\u001b[A\n",
      " 75%|███████▌  | 3171/4220 [3:23:05<1:06:09,  3.78s/it, loss=2.91, epoch=0.751, learning_rate=2.92e-6]\u001b[A\n",
      " 75%|███████▌  | 3172/4220 [3:23:08<1:06:04,  3.78s/it, loss=2.91, epoch=0.751, learning_rate=2.92e-6]\u001b[A\n",
      " 75%|███████▌  | 3172/4220 [3:23:08<1:06:04,  3.78s/it, loss=2.55, epoch=0.751, learning_rate=2.91e-6]\u001b[A\n",
      " 75%|███████▌  | 3173/4220 [3:23:12<1:06:00,  3.78s/it, loss=2.55, epoch=0.751, learning_rate=2.91e-6]\u001b[A\n",
      " 75%|███████▌  | 3173/4220 [3:23:12<1:06:00,  3.78s/it, loss=2.81, epoch=0.752, learning_rate=2.91e-6]\u001b[A\n",
      " 75%|███████▌  | 3174/4220 [3:23:16<1:05:57,  3.78s/it, loss=2.81, epoch=0.752, learning_rate=2.91e-6]\u001b[A\n",
      " 75%|███████▌  | 3174/4220 [3:23:16<1:05:57,  3.78s/it, loss=2.55, epoch=0.752, learning_rate=2.9e-6] \u001b[A\n",
      " 75%|███████▌  | 3175/4220 [3:23:20<1:05:54,  3.78s/it, loss=2.55, epoch=0.752, learning_rate=2.9e-6]\u001b[A\n",
      " 75%|███████▌  | 3175/4220 [3:23:20<1:05:54,  3.78s/it, loss=2.55, epoch=0.752, learning_rate=2.89e-6]\u001b[A\n",
      " 75%|███████▌  | 3176/4220 [3:23:24<1:05:48,  3.78s/it, loss=2.55, epoch=0.752, learning_rate=2.89e-6]\u001b[A\n",
      " 75%|███████▌  | 3176/4220 [3:23:24<1:05:48,  3.78s/it, loss=2.72, epoch=0.752, learning_rate=2.89e-6]\u001b[A\n",
      " 75%|███████▌  | 3177/4220 [3:23:27<1:05:45,  3.78s/it, loss=2.72, epoch=0.752, learning_rate=2.89e-6]\u001b[A\n",
      " 75%|███████▌  | 3177/4220 [3:23:27<1:05:45,  3.78s/it, loss=2.94, epoch=0.753, learning_rate=2.88e-6]\u001b[A\n",
      " 75%|███████▌  | 3178/4220 [3:23:31<1:05:42,  3.78s/it, loss=2.94, epoch=0.753, learning_rate=2.88e-6]\u001b[A\n",
      " 75%|███████▌  | 3178/4220 [3:23:31<1:05:42,  3.78s/it, loss=3.13, epoch=0.753, learning_rate=2.88e-6]\u001b[A\n",
      " 75%|███████▌  | 3179/4220 [3:23:35<1:05:38,  3.78s/it, loss=3.13, epoch=0.753, learning_rate=2.88e-6]\u001b[A\n",
      " 75%|███████▌  | 3179/4220 [3:23:35<1:05:38,  3.78s/it, loss=3.23, epoch=0.753, learning_rate=2.87e-6]\u001b[A\n",
      " 75%|███████▌  | 3180/4220 [3:23:39<1:05:34,  3.78s/it, loss=3.23, epoch=0.753, learning_rate=2.87e-6]\u001b[A\n",
      " 75%|███████▌  | 3180/4220 [3:23:39<1:05:34,  3.78s/it, loss=2.87, epoch=0.753, learning_rate=2.87e-6]\u001b[A\n",
      " 75%|███████▌  | 3181/4220 [3:23:42<1:05:30,  3.78s/it, loss=2.87, epoch=0.753, learning_rate=2.87e-6]\u001b[A\n",
      " 75%|███████▌  | 3181/4220 [3:23:43<1:05:30,  3.78s/it, loss=2.71, epoch=0.754, learning_rate=2.86e-6]\u001b[A\n",
      " 75%|███████▌  | 3182/4220 [3:23:46<1:05:28,  3.78s/it, loss=2.71, epoch=0.754, learning_rate=2.86e-6]\u001b[A\n",
      " 75%|███████▌  | 3182/4220 [3:23:46<1:05:28,  3.78s/it, loss=2.93, epoch=0.754, learning_rate=2.86e-6]\u001b[A\n",
      " 75%|███████▌  | 3183/4220 [3:23:50<1:05:24,  3.78s/it, loss=2.93, epoch=0.754, learning_rate=2.86e-6]\u001b[A\n",
      " 75%|███████▌  | 3183/4220 [3:23:50<1:05:24,  3.78s/it, loss=2.86, epoch=0.754, learning_rate=2.85e-6]\u001b[A\n",
      " 75%|███████▌  | 3184/4220 [3:23:54<1:05:20,  3.78s/it, loss=2.86, epoch=0.754, learning_rate=2.85e-6]\u001b[A\n",
      " 75%|███████▌  | 3184/4220 [3:23:54<1:05:20,  3.78s/it, loss=3.09, epoch=0.754, learning_rate=2.85e-6]\u001b[A\n",
      " 75%|███████▌  | 3185/4220 [3:23:58<1:05:15,  3.78s/it, loss=3.09, epoch=0.754, learning_rate=2.85e-6]\u001b[A\n",
      " 75%|███████▌  | 3185/4220 [3:23:58<1:05:15,  3.78s/it, loss=3.26, epoch=0.755, learning_rate=2.84e-6]\u001b[A\n",
      " 75%|███████▌  | 3186/4220 [3:24:01<1:05:12,  3.78s/it, loss=3.26, epoch=0.755, learning_rate=2.84e-6]\u001b[A\n",
      " 75%|███████▌  | 3186/4220 [3:24:01<1:05:12,  3.78s/it, loss=3.01, epoch=0.755, learning_rate=2.84e-6]\u001b[A\n",
      " 76%|███████▌  | 3187/4220 [3:24:05<1:05:09,  3.78s/it, loss=3.01, epoch=0.755, learning_rate=2.84e-6]\u001b[A\n",
      " 76%|███████▌  | 3187/4220 [3:24:05<1:05:09,  3.78s/it, loss=2.94, epoch=0.755, learning_rate=2.83e-6]\u001b[A\n",
      " 76%|███████▌  | 3188/4220 [3:24:09<1:05:05,  3.78s/it, loss=2.94, epoch=0.755, learning_rate=2.83e-6]\u001b[A\n",
      " 76%|███████▌  | 3188/4220 [3:24:09<1:05:05,  3.78s/it, loss=2.83, epoch=0.755, learning_rate=2.83e-6]\u001b[A\n",
      " 76%|███████▌  | 3189/4220 [3:24:13<1:05:02,  3.78s/it, loss=2.83, epoch=0.755, learning_rate=2.83e-6]\u001b[A\n",
      " 76%|███████▌  | 3189/4220 [3:24:13<1:05:02,  3.78s/it, loss=2.5, epoch=0.755, learning_rate=2.82e-6] \u001b[A\n",
      " 76%|███████▌  | 3190/4220 [3:24:17<1:04:58,  3.79s/it, loss=2.5, epoch=0.755, learning_rate=2.82e-6]\u001b[A\n",
      " 76%|███████▌  | 3190/4220 [3:24:17<1:04:58,  3.79s/it, loss=3.19, epoch=0.756, learning_rate=2.82e-6]\u001b[A\n",
      " 76%|███████▌  | 3191/4220 [3:24:20<1:04:55,  3.79s/it, loss=3.19, epoch=0.756, learning_rate=2.82e-6]\u001b[A\n",
      " 76%|███████▌  | 3191/4220 [3:24:20<1:04:55,  3.79s/it, loss=2.84, epoch=0.756, learning_rate=2.81e-6]\u001b[A\n",
      " 76%|███████▌  | 3192/4220 [3:24:24<1:04:52,  3.79s/it, loss=2.84, epoch=0.756, learning_rate=2.81e-6]\u001b[A\n",
      " 76%|███████▌  | 3192/4220 [3:24:24<1:04:52,  3.79s/it, loss=2.67, epoch=0.756, learning_rate=2.81e-6]\u001b[A\n",
      " 76%|███████▌  | 3193/4220 [3:24:28<1:04:48,  3.79s/it, loss=2.67, epoch=0.756, learning_rate=2.81e-6]\u001b[A\n",
      " 76%|███████▌  | 3193/4220 [3:24:28<1:04:48,  3.79s/it, loss=3.02, epoch=0.756, learning_rate=2.8e-6] \u001b[A\n",
      " 76%|███████▌  | 3194/4220 [3:24:32<1:04:44,  3.79s/it, loss=3.02, epoch=0.756, learning_rate=2.8e-6]\u001b[A\n",
      " 76%|███████▌  | 3194/4220 [3:24:32<1:04:44,  3.79s/it, loss=2.88, epoch=0.757, learning_rate=2.8e-6]\u001b[A\n",
      " 76%|███████▌  | 3195/4220 [3:24:35<1:04:40,  3.79s/it, loss=2.88, epoch=0.757, learning_rate=2.8e-6]\u001b[A\n",
      " 76%|███████▌  | 3195/4220 [3:24:35<1:04:40,  3.79s/it, loss=2.42, epoch=0.757, learning_rate=2.79e-6]\u001b[A\n",
      " 76%|███████▌  | 3196/4220 [3:24:39<1:04:36,  3.79s/it, loss=2.42, epoch=0.757, learning_rate=2.79e-6]\u001b[A\n",
      " 76%|███████▌  | 3196/4220 [3:24:39<1:04:36,  3.79s/it, loss=2.59, epoch=0.757, learning_rate=2.79e-6]\u001b[A\n",
      " 76%|███████▌  | 3197/4220 [3:24:43<1:04:30,  3.78s/it, loss=2.59, epoch=0.757, learning_rate=2.79e-6]\u001b[A\n",
      " 76%|███████▌  | 3197/4220 [3:24:43<1:04:30,  3.78s/it, loss=3.09, epoch=0.757, learning_rate=2.78e-6]\u001b[A\n",
      " 76%|███████▌  | 3198/4220 [3:24:47<1:04:26,  3.78s/it, loss=3.09, epoch=0.757, learning_rate=2.78e-6]\u001b[A\n",
      " 76%|███████▌  | 3198/4220 [3:24:47<1:04:26,  3.78s/it, loss=2.62, epoch=0.758, learning_rate=2.77e-6]\u001b[A\n",
      " 76%|███████▌  | 3199/4220 [3:24:51<1:04:21,  3.78s/it, loss=2.62, epoch=0.758, learning_rate=2.77e-6]\u001b[A\n",
      " 76%|███████▌  | 3199/4220 [3:24:51<1:04:21,  3.78s/it, loss=2.62, epoch=0.758, learning_rate=2.77e-6]\u001b[A\n",
      " 76%|███████▌  | 3200/4220 [3:24:54<1:04:18,  3.78s/it, loss=2.62, epoch=0.758, learning_rate=2.77e-6]\u001b[A\n",
      " 76%|███████▌  | 3200/4220 [3:24:54<1:04:18,  3.78s/it, loss=2.78, epoch=0.758, learning_rate=2.76e-6]\u001b[A\n",
      " 76%|███████▌  | 3201/4220 [3:24:58<1:04:15,  3.78s/it, loss=2.78, epoch=0.758, learning_rate=2.76e-6]\u001b[A\n",
      " 76%|███████▌  | 3201/4220 [3:24:58<1:04:15,  3.78s/it, loss=2.71, epoch=0.758, learning_rate=2.76e-6]\u001b[A\n",
      " 76%|███████▌  | 3202/4220 [3:25:02<1:04:13,  3.79s/it, loss=2.71, epoch=0.758, learning_rate=2.76e-6]\u001b[A\n",
      " 76%|███████▌  | 3202/4220 [3:25:02<1:04:13,  3.79s/it, loss=2.74, epoch=0.759, learning_rate=2.75e-6]\u001b[A\n",
      " 76%|███████▌  | 3203/4220 [3:25:06<1:04:09,  3.79s/it, loss=2.74, epoch=0.759, learning_rate=2.75e-6]\u001b[A\n",
      " 76%|███████▌  | 3203/4220 [3:25:06<1:04:09,  3.79s/it, loss=3.37, epoch=0.759, learning_rate=2.75e-6]\u001b[A\n",
      " 76%|███████▌  | 3204/4220 [3:25:10<1:04:03,  3.78s/it, loss=3.37, epoch=0.759, learning_rate=2.75e-6]\u001b[A\n",
      " 76%|███████▌  | 3204/4220 [3:25:10<1:04:03,  3.78s/it, loss=3.02, epoch=0.759, learning_rate=2.74e-6]\u001b[A\n",
      " 76%|███████▌  | 3205/4220 [3:25:13<1:03:59,  3.78s/it, loss=3.02, epoch=0.759, learning_rate=2.74e-6]\u001b[A\n",
      " 76%|███████▌  | 3205/4220 [3:25:13<1:03:59,  3.78s/it, loss=2.92, epoch=0.759, learning_rate=2.74e-6]\u001b[A\n",
      " 76%|███████▌  | 3206/4220 [3:25:17<1:03:56,  3.78s/it, loss=2.92, epoch=0.759, learning_rate=2.74e-6]\u001b[A\n",
      " 76%|███████▌  | 3206/4220 [3:25:17<1:03:56,  3.78s/it, loss=2.71, epoch=0.759, learning_rate=2.73e-6]\u001b[A\n",
      " 76%|███████▌  | 3207/4220 [3:25:21<1:03:52,  3.78s/it, loss=2.71, epoch=0.759, learning_rate=2.73e-6]\u001b[A\n",
      " 76%|███████▌  | 3207/4220 [3:25:21<1:03:52,  3.78s/it, loss=2.62, epoch=0.76, learning_rate=2.73e-6] \u001b[A\n",
      " 76%|███████▌  | 3208/4220 [3:25:25<1:03:49,  3.78s/it, loss=2.62, epoch=0.76, learning_rate=2.73e-6]\u001b[A\n",
      " 76%|███████▌  | 3208/4220 [3:25:25<1:03:49,  3.78s/it, loss=2.27, epoch=0.76, learning_rate=2.72e-6]\u001b[A\n",
      " 76%|███████▌  | 3209/4220 [3:25:28<1:03:46,  3.79s/it, loss=2.27, epoch=0.76, learning_rate=2.72e-6]\u001b[A\n",
      " 76%|███████▌  | 3209/4220 [3:25:28<1:03:46,  3.79s/it, loss=3.03, epoch=0.76, learning_rate=2.72e-6]\u001b[A\n",
      " 76%|███████▌  | 3210/4220 [3:25:32<1:03:42,  3.79s/it, loss=3.03, epoch=0.76, learning_rate=2.72e-6]\u001b[A\n",
      " 76%|███████▌  | 3210/4220 [3:25:32<1:03:42,  3.79s/it, loss=2.61, epoch=0.76, learning_rate=2.71e-6]\u001b[A\n",
      " 76%|███████▌  | 3211/4220 [3:25:36<1:03:39,  3.79s/it, loss=2.61, epoch=0.76, learning_rate=2.71e-6]\u001b[A\n",
      " 76%|███████▌  | 3211/4220 [3:25:36<1:03:39,  3.79s/it, loss=3, epoch=0.761, learning_rate=2.71e-6]  \u001b[A\n",
      " 76%|███████▌  | 3212/4220 [3:25:40<1:03:34,  3.78s/it, loss=3, epoch=0.761, learning_rate=2.71e-6]\u001b[A\n",
      " 76%|███████▌  | 3212/4220 [3:25:40<1:03:34,  3.78s/it, loss=3.17, epoch=0.761, learning_rate=2.7e-6]\u001b[A\n",
      " 76%|███████▌  | 3213/4220 [3:25:44<1:03:30,  3.78s/it, loss=3.17, epoch=0.761, learning_rate=2.7e-6]\u001b[A\n",
      " 76%|███████▌  | 3213/4220 [3:25:44<1:03:30,  3.78s/it, loss=2.78, epoch=0.761, learning_rate=2.7e-6]\u001b[A\n",
      " 76%|███████▌  | 3214/4220 [3:25:47<1:03:25,  3.78s/it, loss=2.78, epoch=0.761, learning_rate=2.7e-6]\u001b[A\n",
      " 76%|███████▌  | 3214/4220 [3:25:47<1:03:25,  3.78s/it, loss=3.02, epoch=0.761, learning_rate=2.69e-6]\u001b[A\n",
      " 76%|███████▌  | 3215/4220 [3:25:51<1:03:24,  3.79s/it, loss=3.02, epoch=0.761, learning_rate=2.69e-6]\u001b[A\n",
      " 76%|███████▌  | 3215/4220 [3:25:51<1:03:24,  3.79s/it, loss=3.31, epoch=0.762, learning_rate=2.69e-6]\u001b[A\n",
      " 76%|███████▌  | 3216/4220 [3:25:55<1:03:20,  3.79s/it, loss=3.31, epoch=0.762, learning_rate=2.69e-6]\u001b[A\n",
      " 76%|███████▌  | 3216/4220 [3:25:55<1:03:20,  3.79s/it, loss=3.31, epoch=0.762, learning_rate=2.68e-6]\u001b[A\n",
      " 76%|███████▌  | 3217/4220 [3:25:59<1:03:16,  3.79s/it, loss=3.31, epoch=0.762, learning_rate=2.68e-6]\u001b[A\n",
      " 76%|███████▌  | 3217/4220 [3:25:59<1:03:16,  3.79s/it, loss=3.36, epoch=0.762, learning_rate=2.68e-6]\u001b[A\n",
      " 76%|███████▋  | 3218/4220 [3:26:03<1:03:12,  3.78s/it, loss=3.36, epoch=0.762, learning_rate=2.68e-6]\u001b[A\n",
      " 76%|███████▋  | 3218/4220 [3:26:03<1:03:12,  3.78s/it, loss=2.72, epoch=0.762, learning_rate=2.67e-6]\u001b[A\n",
      " 76%|███████▋  | 3219/4220 [3:26:06<1:03:08,  3.78s/it, loss=2.72, epoch=0.762, learning_rate=2.67e-6]\u001b[A\n",
      " 76%|███████▋  | 3219/4220 [3:26:06<1:03:08,  3.78s/it, loss=3.05, epoch=0.763, learning_rate=2.67e-6]\u001b[A\n",
      " 76%|███████▋  | 3220/4220 [3:26:10<1:03:03,  3.78s/it, loss=3.05, epoch=0.763, learning_rate=2.67e-6]\u001b[A\n",
      " 76%|███████▋  | 3220/4220 [3:26:10<1:03:03,  3.78s/it, loss=2.91, epoch=0.763, learning_rate=2.66e-6]\u001b[A\n",
      " 76%|███████▋  | 3221/4220 [3:26:14<1:02:57,  3.78s/it, loss=2.91, epoch=0.763, learning_rate=2.66e-6]\u001b[A\n",
      " 76%|███████▋  | 3221/4220 [3:26:14<1:02:57,  3.78s/it, loss=2.36, epoch=0.763, learning_rate=2.66e-6]\u001b[A\n",
      " 76%|███████▋  | 3222/4220 [3:26:18<1:02:54,  3.78s/it, loss=2.36, epoch=0.763, learning_rate=2.66e-6]\u001b[A\n",
      " 76%|███████▋  | 3222/4220 [3:26:18<1:02:54,  3.78s/it, loss=3.03, epoch=0.763, learning_rate=2.65e-6]\u001b[A\n",
      " 76%|███████▋  | 3223/4220 [3:26:21<1:02:51,  3.78s/it, loss=3.03, epoch=0.763, learning_rate=2.65e-6]\u001b[A\n",
      " 76%|███████▋  | 3223/4220 [3:26:21<1:02:51,  3.78s/it, loss=2.71, epoch=0.764, learning_rate=2.65e-6]\u001b[A\n",
      " 76%|███████▋  | 3224/4220 [3:26:25<1:02:48,  3.78s/it, loss=2.71, epoch=0.764, learning_rate=2.65e-6]\u001b[A\n",
      " 76%|███████▋  | 3224/4220 [3:26:25<1:02:48,  3.78s/it, loss=2.8, epoch=0.764, learning_rate=2.64e-6] \u001b[A\n",
      " 76%|███████▋  | 3225/4220 [3:26:29<1:02:44,  3.78s/it, loss=2.8, epoch=0.764, learning_rate=2.64e-6]\u001b[A\n",
      " 76%|███████▋  | 3225/4220 [3:26:29<1:02:44,  3.78s/it, loss=2.61, epoch=0.764, learning_rate=2.64e-6]\u001b[A\n",
      " 76%|███████▋  | 3226/4220 [3:26:33<1:02:41,  3.78s/it, loss=2.61, epoch=0.764, learning_rate=2.64e-6]\u001b[A\n",
      " 76%|███████▋  | 3226/4220 [3:26:33<1:02:41,  3.78s/it, loss=2.79, epoch=0.764, learning_rate=2.63e-6]\u001b[A\n",
      " 76%|███████▋  | 3227/4220 [3:26:37<1:02:36,  3.78s/it, loss=2.79, epoch=0.764, learning_rate=2.63e-6]\u001b[A\n",
      " 76%|███████▋  | 3227/4220 [3:26:37<1:02:36,  3.78s/it, loss=2.78, epoch=0.764, learning_rate=2.63e-6]\u001b[A\n",
      " 76%|███████▋  | 3228/4220 [3:26:40<1:02:31,  3.78s/it, loss=2.78, epoch=0.764, learning_rate=2.63e-6]\u001b[A\n",
      " 76%|███████▋  | 3228/4220 [3:26:40<1:02:31,  3.78s/it, loss=3.07, epoch=0.765, learning_rate=2.62e-6]\u001b[A\n",
      " 77%|███████▋  | 3229/4220 [3:26:44<1:02:29,  3.78s/it, loss=3.07, epoch=0.765, learning_rate=2.62e-6]\u001b[A\n",
      " 77%|███████▋  | 3229/4220 [3:26:44<1:02:29,  3.78s/it, loss=2.97, epoch=0.765, learning_rate=2.62e-6]\u001b[A\n",
      " 77%|███████▋  | 3230/4220 [3:26:48<1:02:23,  3.78s/it, loss=2.97, epoch=0.765, learning_rate=2.62e-6]\u001b[A\n",
      " 77%|███████▋  | 3230/4220 [3:26:48<1:02:23,  3.78s/it, loss=2.76, epoch=0.765, learning_rate=2.61e-6]\u001b[A\n",
      " 77%|███████▋  | 3231/4220 [3:26:52<1:02:18,  3.78s/it, loss=2.76, epoch=0.765, learning_rate=2.61e-6]\u001b[A\n",
      " 77%|███████▋  | 3231/4220 [3:26:52<1:02:18,  3.78s/it, loss=2.81, epoch=0.765, learning_rate=2.61e-6]\u001b[A\n",
      " 77%|███████▋  | 3232/4220 [3:26:55<1:02:16,  3.78s/it, loss=2.81, epoch=0.765, learning_rate=2.61e-6]\u001b[A\n",
      " 77%|███████▋  | 3232/4220 [3:26:55<1:02:16,  3.78s/it, loss=2.56, epoch=0.766, learning_rate=2.6e-6] \u001b[A\n",
      " 77%|███████▋  | 3233/4220 [3:26:59<1:02:13,  3.78s/it, loss=2.56, epoch=0.766, learning_rate=2.6e-6]\u001b[A\n",
      " 77%|███████▋  | 3233/4220 [3:26:59<1:02:13,  3.78s/it, loss=2.64, epoch=0.766, learning_rate=2.6e-6]\u001b[A\n",
      " 77%|███████▋  | 3234/4220 [3:27:03<1:02:09,  3.78s/it, loss=2.64, epoch=0.766, learning_rate=2.6e-6]\u001b[A\n",
      " 77%|███████▋  | 3234/4220 [3:27:03<1:02:09,  3.78s/it, loss=2.76, epoch=0.766, learning_rate=2.59e-6]\u001b[A\n",
      " 77%|███████▋  | 3235/4220 [3:27:07<1:02:05,  3.78s/it, loss=2.76, epoch=0.766, learning_rate=2.59e-6]\u001b[A\n",
      " 77%|███████▋  | 3235/4220 [3:27:07<1:02:05,  3.78s/it, loss=2.48, epoch=0.766, learning_rate=2.59e-6]\u001b[A\n",
      " 77%|███████▋  | 3236/4220 [3:27:11<1:02:02,  3.78s/it, loss=2.48, epoch=0.766, learning_rate=2.59e-6]\u001b[A\n",
      " 77%|███████▋  | 3236/4220 [3:27:11<1:02:02,  3.78s/it, loss=3.07, epoch=0.767, learning_rate=2.58e-6]\u001b[A\n",
      " 77%|███████▋  | 3237/4220 [3:27:14<1:02:00,  3.79s/it, loss=3.07, epoch=0.767, learning_rate=2.58e-6]\u001b[A\n",
      " 77%|███████▋  | 3237/4220 [3:27:14<1:02:00,  3.79s/it, loss=3.39, epoch=0.767, learning_rate=2.58e-6]\u001b[A\n",
      " 77%|███████▋  | 3238/4220 [3:27:18<1:01:57,  3.79s/it, loss=3.39, epoch=0.767, learning_rate=2.58e-6]\u001b[A\n",
      " 77%|███████▋  | 3238/4220 [3:27:18<1:01:57,  3.79s/it, loss=2.5, epoch=0.767, learning_rate=2.57e-6] \u001b[A\n",
      " 77%|███████▋  | 3239/4220 [3:27:22<1:01:52,  3.78s/it, loss=2.5, epoch=0.767, learning_rate=2.57e-6]\u001b[A\n",
      " 77%|███████▋  | 3239/4220 [3:27:22<1:01:52,  3.78s/it, loss=3.08, epoch=0.767, learning_rate=2.57e-6]\u001b[A\n",
      " 77%|███████▋  | 3240/4220 [3:27:26<1:01:48,  3.78s/it, loss=3.08, epoch=0.767, learning_rate=2.57e-6]\u001b[A\n",
      " 77%|███████▋  | 3240/4220 [3:27:26<1:01:48,  3.78s/it, loss=2.67, epoch=0.768, learning_rate=2.56e-6]\u001b[A\n",
      " 77%|███████▋  | 3241/4220 [3:27:30<1:01:44,  3.78s/it, loss=2.67, epoch=0.768, learning_rate=2.56e-6]\u001b[A\n",
      " 77%|███████▋  | 3241/4220 [3:27:30<1:01:44,  3.78s/it, loss=2.74, epoch=0.768, learning_rate=2.56e-6]\u001b[A\n",
      " 77%|███████▋  | 3242/4220 [3:27:33<1:01:40,  3.78s/it, loss=2.74, epoch=0.768, learning_rate=2.56e-6]\u001b[A\n",
      " 77%|███████▋  | 3242/4220 [3:27:33<1:01:40,  3.78s/it, loss=3.22, epoch=0.768, learning_rate=2.55e-6]\u001b[A\n",
      " 77%|███████▋  | 3243/4220 [3:27:37<1:01:36,  3.78s/it, loss=3.22, epoch=0.768, learning_rate=2.55e-6]\u001b[A\n",
      " 77%|███████▋  | 3243/4220 [3:27:37<1:01:36,  3.78s/it, loss=2.42, epoch=0.768, learning_rate=2.55e-6]\u001b[A\n",
      " 77%|███████▋  | 3244/4220 [3:27:41<1:01:33,  3.78s/it, loss=2.42, epoch=0.768, learning_rate=2.55e-6]\u001b[A\n",
      " 77%|███████▋  | 3244/4220 [3:27:41<1:01:33,  3.78s/it, loss=3.05, epoch=0.768, learning_rate=2.54e-6]\u001b[A\n",
      " 77%|███████▋  | 3245/4220 [3:27:45<1:01:28,  3.78s/it, loss=3.05, epoch=0.768, learning_rate=2.54e-6]\u001b[A\n",
      " 77%|███████▋  | 3245/4220 [3:27:45<1:01:28,  3.78s/it, loss=2.84, epoch=0.769, learning_rate=2.54e-6]\u001b[A\n",
      " 77%|███████▋  | 3246/4220 [3:27:48<1:01:25,  3.78s/it, loss=2.84, epoch=0.769, learning_rate=2.54e-6]\u001b[A\n",
      " 77%|███████▋  | 3246/4220 [3:27:48<1:01:25,  3.78s/it, loss=2.93, epoch=0.769, learning_rate=2.53e-6]\u001b[A\n",
      " 77%|███████▋  | 3247/4220 [3:27:52<1:01:20,  3.78s/it, loss=2.93, epoch=0.769, learning_rate=2.53e-6]\u001b[A\n",
      " 77%|███████▋  | 3247/4220 [3:27:52<1:01:20,  3.78s/it, loss=2.24, epoch=0.769, learning_rate=2.53e-6]\u001b[A\n",
      " 77%|███████▋  | 3248/4220 [3:27:56<1:01:16,  3.78s/it, loss=2.24, epoch=0.769, learning_rate=2.53e-6]\u001b[A\n",
      " 77%|███████▋  | 3248/4220 [3:27:56<1:01:16,  3.78s/it, loss=3.22, epoch=0.769, learning_rate=2.52e-6]\u001b[A\n",
      " 77%|███████▋  | 3249/4220 [3:28:00<1:01:13,  3.78s/it, loss=3.22, epoch=0.769, learning_rate=2.52e-6]\u001b[A\n",
      " 77%|███████▋  | 3249/4220 [3:28:00<1:01:13,  3.78s/it, loss=3.12, epoch=0.77, learning_rate=2.52e-6] \u001b[A\n",
      " 77%|███████▋  | 3250/4220 [3:28:04<1:01:10,  3.78s/it, loss=3.12, epoch=0.77, learning_rate=2.52e-6]\u001b[A\n",
      " 77%|███████▋  | 3250/4220 [3:28:04<1:01:10,  3.78s/it, loss=2.83, epoch=0.77, learning_rate=2.51e-6]\u001b[A\n",
      " 77%|███████▋  | 3251/4220 [3:28:07<1:01:06,  3.78s/it, loss=2.83, epoch=0.77, learning_rate=2.51e-6]\u001b[A\n",
      " 77%|███████▋  | 3251/4220 [3:28:07<1:01:06,  3.78s/it, loss=2.76, epoch=0.77, learning_rate=2.51e-6]\u001b[A\n",
      " 77%|███████▋  | 3252/4220 [3:28:11<1:01:03,  3.78s/it, loss=2.76, epoch=0.77, learning_rate=2.51e-6]\u001b[A\n",
      " 77%|███████▋  | 3252/4220 [3:28:11<1:01:03,  3.78s/it, loss=3.1, epoch=0.77, learning_rate=2.5e-6]  \u001b[A\n",
      " 77%|███████▋  | 3253/4220 [3:28:15<1:00:59,  3.78s/it, loss=3.1, epoch=0.77, learning_rate=2.5e-6]\u001b[A\n",
      " 77%|███████▋  | 3253/4220 [3:28:15<1:00:59,  3.78s/it, loss=2.26, epoch=0.771, learning_rate=2.5e-6]\u001b[A\n",
      " 77%|███████▋  | 3254/4220 [3:28:19<1:00:55,  3.78s/it, loss=2.26, epoch=0.771, learning_rate=2.5e-6]\u001b[A\n",
      " 77%|███████▋  | 3254/4220 [3:28:19<1:00:55,  3.78s/it, loss=3.24, epoch=0.771, learning_rate=2.49e-6]\u001b[A\n",
      " 77%|███████▋  | 3255/4220 [3:28:23<1:00:51,  3.78s/it, loss=3.24, epoch=0.771, learning_rate=2.49e-6]\u001b[A\n",
      " 77%|███████▋  | 3255/4220 [3:28:23<1:00:51,  3.78s/it, loss=2.79, epoch=0.771, learning_rate=2.49e-6]\u001b[A\n",
      " 77%|███████▋  | 3256/4220 [3:28:26<1:00:48,  3.78s/it, loss=2.79, epoch=0.771, learning_rate=2.49e-6]\u001b[A\n",
      " 77%|███████▋  | 3256/4220 [3:28:26<1:00:48,  3.78s/it, loss=3.09, epoch=0.771, learning_rate=2.48e-6]\u001b[A\n",
      " 77%|███████▋  | 3257/4220 [3:28:30<1:00:43,  3.78s/it, loss=3.09, epoch=0.771, learning_rate=2.48e-6]\u001b[A\n",
      " 77%|███████▋  | 3257/4220 [3:28:30<1:00:43,  3.78s/it, loss=3.05, epoch=0.772, learning_rate=2.48e-6]\u001b[A\n",
      " 77%|███████▋  | 3258/4220 [3:28:34<1:00:40,  3.78s/it, loss=3.05, epoch=0.772, learning_rate=2.48e-6]\u001b[A\n",
      " 77%|███████▋  | 3258/4220 [3:28:34<1:00:40,  3.78s/it, loss=2.87, epoch=0.772, learning_rate=2.47e-6]\u001b[A\n",
      " 77%|███████▋  | 3259/4220 [3:28:38<1:00:36,  3.78s/it, loss=2.87, epoch=0.772, learning_rate=2.47e-6]\u001b[A\n",
      " 77%|███████▋  | 3259/4220 [3:28:38<1:00:36,  3.78s/it, loss=2.82, epoch=0.772, learning_rate=2.47e-6]\u001b[A\n",
      " 77%|███████▋  | 3260/4220 [3:28:41<1:00:33,  3.78s/it, loss=2.82, epoch=0.772, learning_rate=2.47e-6]\u001b[A\n",
      " 77%|███████▋  | 3260/4220 [3:28:41<1:00:33,  3.78s/it, loss=2.98, epoch=0.772, learning_rate=2.46e-6]\u001b[A\n",
      " 77%|███████▋  | 3261/4220 [3:28:45<1:00:29,  3.78s/it, loss=2.98, epoch=0.772, learning_rate=2.46e-6]\u001b[A\n",
      " 77%|███████▋  | 3261/4220 [3:28:45<1:00:29,  3.78s/it, loss=2.63, epoch=0.773, learning_rate=2.46e-6]\u001b[A\n",
      " 77%|███████▋  | 3262/4220 [3:28:49<1:00:25,  3.78s/it, loss=2.63, epoch=0.773, learning_rate=2.46e-6]\u001b[A\n",
      " 77%|███████▋  | 3262/4220 [3:28:49<1:00:25,  3.78s/it, loss=2.75, epoch=0.773, learning_rate=2.45e-6]\u001b[A\n",
      " 77%|███████▋  | 3263/4220 [3:28:53<1:00:23,  3.79s/it, loss=2.75, epoch=0.773, learning_rate=2.45e-6]\u001b[A\n",
      " 77%|███████▋  | 3263/4220 [3:28:53<1:00:23,  3.79s/it, loss=3.71, epoch=0.773, learning_rate=2.45e-6]\u001b[A\n",
      " 77%|███████▋  | 3264/4220 [3:28:57<1:00:19,  3.79s/it, loss=3.71, epoch=0.773, learning_rate=2.45e-6]\u001b[A\n",
      " 77%|███████▋  | 3264/4220 [3:28:57<1:00:19,  3.79s/it, loss=3.04, epoch=0.773, learning_rate=2.44e-6]\u001b[A\n",
      " 77%|███████▋  | 3265/4220 [3:29:00<1:00:13,  3.78s/it, loss=3.04, epoch=0.773, learning_rate=2.44e-6]\u001b[A\n",
      " 77%|███████▋  | 3265/4220 [3:29:00<1:00:13,  3.78s/it, loss=3.33, epoch=0.773, learning_rate=2.44e-6]\u001b[A\n",
      " 77%|███████▋  | 3266/4220 [3:29:04<1:00:08,  3.78s/it, loss=3.33, epoch=0.773, learning_rate=2.44e-6]\u001b[A\n",
      " 77%|███████▋  | 3266/4220 [3:29:04<1:00:08,  3.78s/it, loss=2.76, epoch=0.774, learning_rate=2.43e-6]\u001b[A\n",
      " 77%|███████▋  | 3267/4220 [3:29:08<1:00:04,  3.78s/it, loss=2.76, epoch=0.774, learning_rate=2.43e-6]\u001b[A\n",
      " 77%|███████▋  | 3267/4220 [3:29:08<1:00:04,  3.78s/it, loss=3.21, epoch=0.774, learning_rate=2.43e-6]\u001b[A\n",
      " 77%|███████▋  | 3268/4220 [3:29:12<1:00:00,  3.78s/it, loss=3.21, epoch=0.774, learning_rate=2.43e-6]\u001b[A\n",
      " 77%|███████▋  | 3268/4220 [3:29:12<1:00:00,  3.78s/it, loss=3.24, epoch=0.774, learning_rate=2.42e-6]\u001b[A\n",
      " 77%|███████▋  | 3269/4220 [3:29:15<59:56,  3.78s/it, loss=3.24, epoch=0.774, learning_rate=2.42e-6]  \u001b[A\n",
      " 77%|███████▋  | 3269/4220 [3:29:15<59:56,  3.78s/it, loss=2.98, epoch=0.774, learning_rate=2.42e-6]\u001b[A\n",
      " 77%|███████▋  | 3270/4220 [3:29:19<59:53,  3.78s/it, loss=2.98, epoch=0.774, learning_rate=2.42e-6]\u001b[A\n",
      " 77%|███████▋  | 3270/4220 [3:29:19<59:53,  3.78s/it, loss=2.79, epoch=0.775, learning_rate=2.41e-6]\u001b[A\n",
      " 78%|███████▊  | 3271/4220 [3:29:23<59:50,  3.78s/it, loss=2.79, epoch=0.775, learning_rate=2.41e-6]\u001b[A\n",
      " 78%|███████▊  | 3271/4220 [3:29:23<59:50,  3.78s/it, loss=2.65, epoch=0.775, learning_rate=2.41e-6]\u001b[A\n",
      " 78%|███████▊  | 3272/4220 [3:29:27<59:47,  3.78s/it, loss=2.65, epoch=0.775, learning_rate=2.41e-6]\u001b[A\n",
      " 78%|███████▊  | 3272/4220 [3:29:27<59:47,  3.78s/it, loss=2.82, epoch=0.775, learning_rate=2.4e-6] \u001b[A\n",
      " 78%|███████▊  | 3273/4220 [3:29:31<59:43,  3.78s/it, loss=2.82, epoch=0.775, learning_rate=2.4e-6]\u001b[A\n",
      " 78%|███████▊  | 3273/4220 [3:29:31<59:43,  3.78s/it, loss=2.8, epoch=0.775, learning_rate=2.4e-6] \u001b[A\n",
      " 78%|███████▊  | 3274/4220 [3:29:34<59:38,  3.78s/it, loss=2.8, epoch=0.775, learning_rate=2.4e-6]\u001b[A\n",
      " 78%|███████▊  | 3274/4220 [3:29:34<59:38,  3.78s/it, loss=2.54, epoch=0.776, learning_rate=2.39e-6]\u001b[A\n",
      " 78%|███████▊  | 3275/4220 [3:29:38<59:34,  3.78s/it, loss=2.54, epoch=0.776, learning_rate=2.39e-6]\u001b[A\n",
      " 78%|███████▊  | 3275/4220 [3:29:38<59:34,  3.78s/it, loss=3.2, epoch=0.776, learning_rate=2.39e-6] \u001b[A\n",
      " 78%|███████▊  | 3276/4220 [3:29:42<59:30,  3.78s/it, loss=3.2, epoch=0.776, learning_rate=2.39e-6]\u001b[A\n",
      " 78%|███████▊  | 3276/4220 [3:29:42<59:30,  3.78s/it, loss=2.42, epoch=0.776, learning_rate=2.39e-6]\u001b[A\n",
      " 78%|███████▊  | 3277/4220 [3:29:46<59:26,  3.78s/it, loss=2.42, epoch=0.776, learning_rate=2.39e-6]\u001b[A\n",
      " 78%|███████▊  | 3277/4220 [3:29:46<59:26,  3.78s/it, loss=2.71, epoch=0.776, learning_rate=2.38e-6]\u001b[A\n",
      " 78%|███████▊  | 3278/4220 [3:29:50<59:23,  3.78s/it, loss=2.71, epoch=0.776, learning_rate=2.38e-6]\u001b[A\n",
      " 78%|███████▊  | 3278/4220 [3:29:50<59:23,  3.78s/it, loss=2.67, epoch=0.777, learning_rate=2.38e-6]\u001b[A\n",
      " 78%|███████▊  | 3279/4220 [3:29:53<59:20,  3.78s/it, loss=2.67, epoch=0.777, learning_rate=2.38e-6]\u001b[A\n",
      " 78%|███████▊  | 3279/4220 [3:29:53<59:20,  3.78s/it, loss=3.06, epoch=0.777, learning_rate=2.37e-6]\u001b[A\n",
      " 78%|███████▊  | 3280/4220 [3:29:57<59:17,  3.79s/it, loss=3.06, epoch=0.777, learning_rate=2.37e-6]\u001b[A\n",
      " 78%|███████▊  | 3280/4220 [3:29:57<59:17,  3.79s/it, loss=2.46, epoch=0.777, learning_rate=2.37e-6]\u001b[A\n",
      " 78%|███████▊  | 3281/4220 [3:30:01<59:12,  3.78s/it, loss=2.46, epoch=0.777, learning_rate=2.37e-6]\u001b[A\n",
      " 78%|███████▊  | 3281/4220 [3:30:01<59:12,  3.78s/it, loss=3.01, epoch=0.777, learning_rate=2.36e-6]\u001b[A\n",
      " 78%|███████▊  | 3282/4220 [3:30:05<59:09,  3.78s/it, loss=3.01, epoch=0.777, learning_rate=2.36e-6]\u001b[A\n",
      " 78%|███████▊  | 3282/4220 [3:30:05<59:09,  3.78s/it, loss=3, epoch=0.777, learning_rate=2.36e-6]   \u001b[A\n",
      " 78%|███████▊  | 3283/4220 [3:30:08<59:06,  3.78s/it, loss=3, epoch=0.777, learning_rate=2.36e-6]\u001b[A\n",
      " 78%|███████▊  | 3283/4220 [3:30:08<59:06,  3.78s/it, loss=2.64, epoch=0.778, learning_rate=2.35e-6]\u001b[A\n",
      " 78%|███████▊  | 3284/4220 [3:30:12<59:01,  3.78s/it, loss=2.64, epoch=0.778, learning_rate=2.35e-6]\u001b[A\n",
      " 78%|███████▊  | 3284/4220 [3:30:12<59:01,  3.78s/it, loss=2.98, epoch=0.778, learning_rate=2.35e-6]\u001b[A\n",
      " 78%|███████▊  | 3285/4220 [3:30:16<58:58,  3.78s/it, loss=2.98, epoch=0.778, learning_rate=2.35e-6]\u001b[A\n",
      " 78%|███████▊  | 3285/4220 [3:30:16<58:58,  3.78s/it, loss=2.59, epoch=0.778, learning_rate=2.34e-6]\u001b[A\n",
      " 78%|███████▊  | 3286/4220 [3:30:20<58:54,  3.78s/it, loss=2.59, epoch=0.778, learning_rate=2.34e-6]\u001b[A\n",
      " 78%|███████▊  | 3286/4220 [3:30:20<58:54,  3.78s/it, loss=2.81, epoch=0.778, learning_rate=2.34e-6]\u001b[A\n",
      " 78%|███████▊  | 3287/4220 [3:30:24<58:50,  3.78s/it, loss=2.81, epoch=0.778, learning_rate=2.34e-6]\u001b[A\n",
      " 78%|███████▊  | 3287/4220 [3:30:24<58:50,  3.78s/it, loss=2.45, epoch=0.779, learning_rate=2.33e-6]\u001b[A\n",
      " 78%|███████▊  | 3288/4220 [3:30:27<58:46,  3.78s/it, loss=2.45, epoch=0.779, learning_rate=2.33e-6]\u001b[A\n",
      " 78%|███████▊  | 3288/4220 [3:30:27<58:46,  3.78s/it, loss=3.07, epoch=0.779, learning_rate=2.33e-6]\u001b[A\n",
      " 78%|███████▊  | 3289/4220 [3:30:31<58:42,  3.78s/it, loss=3.07, epoch=0.779, learning_rate=2.33e-6]\u001b[A\n",
      " 78%|███████▊  | 3289/4220 [3:30:31<58:42,  3.78s/it, loss=3.29, epoch=0.779, learning_rate=2.32e-6]\u001b[A\n",
      " 78%|███████▊  | 3290/4220 [3:30:35<58:38,  3.78s/it, loss=3.29, epoch=0.779, learning_rate=2.32e-6]\u001b[A\n",
      " 78%|███████▊  | 3290/4220 [3:30:35<58:38,  3.78s/it, loss=2.86, epoch=0.779, learning_rate=2.32e-6]\u001b[A\n",
      " 78%|███████▊  | 3291/4220 [3:30:39<58:35,  3.78s/it, loss=2.86, epoch=0.779, learning_rate=2.32e-6]\u001b[A\n",
      " 78%|███████▊  | 3291/4220 [3:30:39<58:35,  3.78s/it, loss=3.07, epoch=0.78, learning_rate=2.31e-6] \u001b[A\n",
      " 78%|███████▊  | 3292/4220 [3:30:43<58:31,  3.78s/it, loss=3.07, epoch=0.78, learning_rate=2.31e-6]\u001b[A\n",
      " 78%|███████▊  | 3292/4220 [3:30:43<58:31,  3.78s/it, loss=2.49, epoch=0.78, learning_rate=2.31e-6]\u001b[A\n",
      " 78%|███████▊  | 3293/4220 [3:30:46<58:26,  3.78s/it, loss=2.49, epoch=0.78, learning_rate=2.31e-6]\u001b[A\n",
      " 78%|███████▊  | 3293/4220 [3:30:46<58:26,  3.78s/it, loss=2.58, epoch=0.78, learning_rate=2.3e-6] \u001b[A\n",
      " 78%|███████▊  | 3294/4220 [3:30:50<58:22,  3.78s/it, loss=2.58, epoch=0.78, learning_rate=2.3e-6]\u001b[A\n",
      " 78%|███████▊  | 3294/4220 [3:30:50<58:22,  3.78s/it, loss=2.72, epoch=0.78, learning_rate=2.3e-6]\u001b[A\n",
      " 78%|███████▊  | 3295/4220 [3:30:54<58:17,  3.78s/it, loss=2.72, epoch=0.78, learning_rate=2.3e-6]\u001b[A\n",
      " 78%|███████▊  | 3295/4220 [3:30:54<58:17,  3.78s/it, loss=2.67, epoch=0.781, learning_rate=2.29e-6]\u001b[A\n",
      " 78%|███████▊  | 3296/4220 [3:30:58<58:13,  3.78s/it, loss=2.67, epoch=0.781, learning_rate=2.29e-6]\u001b[A\n",
      " 78%|███████▊  | 3296/4220 [3:30:58<58:13,  3.78s/it, loss=2.81, epoch=0.781, learning_rate=2.29e-6]\u001b[A\n",
      " 78%|███████▊  | 3297/4220 [3:31:01<58:10,  3.78s/it, loss=2.81, epoch=0.781, learning_rate=2.29e-6]\u001b[A\n",
      " 78%|███████▊  | 3297/4220 [3:31:01<58:10,  3.78s/it, loss=3.08, epoch=0.781, learning_rate=2.28e-6]\u001b[A\n",
      " 78%|███████▊  | 3298/4220 [3:31:05<58:07,  3.78s/it, loss=3.08, epoch=0.781, learning_rate=2.28e-6]\u001b[A\n",
      " 78%|███████▊  | 3298/4220 [3:31:05<58:07,  3.78s/it, loss=2.64, epoch=0.781, learning_rate=2.28e-6]\u001b[A\n",
      " 78%|███████▊  | 3299/4220 [3:31:09<58:02,  3.78s/it, loss=2.64, epoch=0.781, learning_rate=2.28e-6]\u001b[A\n",
      " 78%|███████▊  | 3299/4220 [3:31:09<58:02,  3.78s/it, loss=2.88, epoch=0.782, learning_rate=2.27e-6]\u001b[A\n",
      " 78%|███████▊  | 3300/4220 [3:31:13<57:59,  3.78s/it, loss=2.88, epoch=0.782, learning_rate=2.27e-6]\u001b[A\n",
      " 78%|███████▊  | 3300/4220 [3:31:13<57:59,  3.78s/it, loss=2.65, epoch=0.782, learning_rate=2.27e-6]\u001b[A\n",
      " 78%|███████▊  | 3301/4220 [3:31:17<57:55,  3.78s/it, loss=2.65, epoch=0.782, learning_rate=2.27e-6]\u001b[A\n",
      " 78%|███████▊  | 3301/4220 [3:31:17<57:55,  3.78s/it, loss=2.52, epoch=0.782, learning_rate=2.27e-6]\u001b[A\n",
      " 78%|███████▊  | 3302/4220 [3:31:20<57:52,  3.78s/it, loss=2.52, epoch=0.782, learning_rate=2.27e-6]\u001b[A\n",
      " 78%|███████▊  | 3302/4220 [3:31:20<57:52,  3.78s/it, loss=2.73, epoch=0.782, learning_rate=2.26e-6]\u001b[A\n",
      " 78%|███████▊  | 3303/4220 [3:31:24<57:48,  3.78s/it, loss=2.73, epoch=0.782, learning_rate=2.26e-6]\u001b[A\n",
      " 78%|███████▊  | 3303/4220 [3:31:24<57:48,  3.78s/it, loss=2.37, epoch=0.782, learning_rate=2.26e-6]\u001b[A\n",
      " 78%|███████▊  | 3304/4220 [3:31:28<57:44,  3.78s/it, loss=2.37, epoch=0.782, learning_rate=2.26e-6]\u001b[A\n",
      " 78%|███████▊  | 3304/4220 [3:31:28<57:44,  3.78s/it, loss=3.06, epoch=0.783, learning_rate=2.25e-6]\u001b[A\n",
      " 78%|███████▊  | 3305/4220 [3:31:32<57:40,  3.78s/it, loss=3.06, epoch=0.783, learning_rate=2.25e-6]\u001b[A\n",
      " 78%|███████▊  | 3305/4220 [3:31:32<57:40,  3.78s/it, loss=3.14, epoch=0.783, learning_rate=2.25e-6]\u001b[A\n",
      " 78%|███████▊  | 3306/4220 [3:31:35<57:37,  3.78s/it, loss=3.14, epoch=0.783, learning_rate=2.25e-6]\u001b[A\n",
      " 78%|███████▊  | 3306/4220 [3:31:35<57:37,  3.78s/it, loss=2.54, epoch=0.783, learning_rate=2.24e-6]\u001b[A\n",
      " 78%|███████▊  | 3307/4220 [3:31:39<57:32,  3.78s/it, loss=2.54, epoch=0.783, learning_rate=2.24e-6]\u001b[A\n",
      " 78%|███████▊  | 3307/4220 [3:31:39<57:32,  3.78s/it, loss=2.44, epoch=0.783, learning_rate=2.24e-6]\u001b[A\n",
      " 78%|███████▊  | 3308/4220 [3:31:43<57:29,  3.78s/it, loss=2.44, epoch=0.783, learning_rate=2.24e-6]\u001b[A\n",
      " 78%|███████▊  | 3308/4220 [3:31:43<57:29,  3.78s/it, loss=2.98, epoch=0.784, learning_rate=2.23e-6]\u001b[A\n",
      " 78%|███████▊  | 3309/4220 [3:31:47<57:27,  3.78s/it, loss=2.98, epoch=0.784, learning_rate=2.23e-6]\u001b[A\n",
      " 78%|███████▊  | 3309/4220 [3:31:47<57:27,  3.78s/it, loss=3.03, epoch=0.784, learning_rate=2.23e-6]\u001b[A\n",
      " 78%|███████▊  | 3310/4220 [3:31:51<57:22,  3.78s/it, loss=3.03, epoch=0.784, learning_rate=2.23e-6]\u001b[A\n",
      " 78%|███████▊  | 3310/4220 [3:31:51<57:22,  3.78s/it, loss=3.21, epoch=0.784, learning_rate=2.22e-6]\u001b[A\n",
      " 78%|███████▊  | 3311/4220 [3:31:54<57:18,  3.78s/it, loss=3.21, epoch=0.784, learning_rate=2.22e-6]\u001b[A\n",
      " 78%|███████▊  | 3311/4220 [3:31:54<57:18,  3.78s/it, loss=2.74, epoch=0.784, learning_rate=2.22e-6]\u001b[A\n",
      " 78%|███████▊  | 3312/4220 [3:31:58<57:15,  3.78s/it, loss=2.74, epoch=0.784, learning_rate=2.22e-6]\u001b[A\n",
      " 78%|███████▊  | 3312/4220 [3:31:58<57:15,  3.78s/it, loss=2.66, epoch=0.785, learning_rate=2.21e-6]\u001b[A\n",
      " 79%|███████▊  | 3313/4220 [3:32:02<57:11,  3.78s/it, loss=2.66, epoch=0.785, learning_rate=2.21e-6]\u001b[A\n",
      " 79%|███████▊  | 3313/4220 [3:32:02<57:11,  3.78s/it, loss=3.1, epoch=0.785, learning_rate=2.21e-6] \u001b[A\n",
      " 79%|███████▊  | 3314/4220 [3:32:06<57:07,  3.78s/it, loss=3.1, epoch=0.785, learning_rate=2.21e-6]\u001b[A\n",
      " 79%|███████▊  | 3314/4220 [3:32:06<57:07,  3.78s/it, loss=2.46, epoch=0.785, learning_rate=2.2e-6]\u001b[A\n",
      " 79%|███████▊  | 3315/4220 [3:32:09<57:03,  3.78s/it, loss=2.46, epoch=0.785, learning_rate=2.2e-6]\u001b[A\n",
      " 79%|███████▊  | 3315/4220 [3:32:09<57:03,  3.78s/it, loss=2.38, epoch=0.785, learning_rate=2.2e-6]\u001b[A\n",
      " 79%|███████▊  | 3316/4220 [3:32:13<56:58,  3.78s/it, loss=2.38, epoch=0.785, learning_rate=2.2e-6]\u001b[A\n",
      " 79%|███████▊  | 3316/4220 [3:32:13<56:58,  3.78s/it, loss=2.51, epoch=0.786, learning_rate=2.19e-6]\u001b[A\n",
      " 79%|███████▊  | 3317/4220 [3:32:17<56:56,  3.78s/it, loss=2.51, epoch=0.786, learning_rate=2.19e-6]\u001b[A\n",
      " 79%|███████▊  | 3317/4220 [3:32:17<56:56,  3.78s/it, loss=3.17, epoch=0.786, learning_rate=2.19e-6]\u001b[A\n",
      " 79%|███████▊  | 3318/4220 [3:32:21<56:52,  3.78s/it, loss=3.17, epoch=0.786, learning_rate=2.19e-6]\u001b[A\n",
      " 79%|███████▊  | 3318/4220 [3:32:21<56:52,  3.78s/it, loss=2.66, epoch=0.786, learning_rate=2.19e-6]\u001b[A\n",
      " 79%|███████▊  | 3319/4220 [3:32:25<56:48,  3.78s/it, loss=2.66, epoch=0.786, learning_rate=2.19e-6]\u001b[A\n",
      " 79%|███████▊  | 3319/4220 [3:32:25<56:48,  3.78s/it, loss=3.17, epoch=0.786, learning_rate=2.18e-6]\u001b[A\n",
      " 79%|███████▊  | 3320/4220 [3:32:28<56:44,  3.78s/it, loss=3.17, epoch=0.786, learning_rate=2.18e-6]\u001b[A\n",
      " 79%|███████▊  | 3320/4220 [3:32:28<56:44,  3.78s/it, loss=3.01, epoch=0.786, learning_rate=2.18e-6]\u001b[A\n",
      " 79%|███████▊  | 3321/4220 [3:32:32<56:39,  3.78s/it, loss=3.01, epoch=0.786, learning_rate=2.18e-6]\u001b[A\n",
      " 79%|███████▊  | 3321/4220 [3:32:32<56:39,  3.78s/it, loss=3.16, epoch=0.787, learning_rate=2.17e-6]\u001b[A\n",
      " 79%|███████▊  | 3322/4220 [3:32:36<56:36,  3.78s/it, loss=3.16, epoch=0.787, learning_rate=2.17e-6]\u001b[A\n",
      " 79%|███████▊  | 3322/4220 [3:32:36<56:36,  3.78s/it, loss=2.29, epoch=0.787, learning_rate=2.17e-6]\u001b[A\n",
      " 79%|███████▊  | 3323/4220 [3:32:40<56:33,  3.78s/it, loss=2.29, epoch=0.787, learning_rate=2.17e-6]\u001b[A\n",
      " 79%|███████▊  | 3323/4220 [3:32:40<56:33,  3.78s/it, loss=2.54, epoch=0.787, learning_rate=2.16e-6]\u001b[A\n",
      " 79%|███████▉  | 3324/4220 [3:32:44<56:30,  3.78s/it, loss=2.54, epoch=0.787, learning_rate=2.16e-6]\u001b[A\n",
      " 79%|███████▉  | 3324/4220 [3:32:44<56:30,  3.78s/it, loss=2.68, epoch=0.787, learning_rate=2.16e-6]\u001b[A\n",
      " 79%|███████▉  | 3325/4220 [3:32:47<56:26,  3.78s/it, loss=2.68, epoch=0.787, learning_rate=2.16e-6]\u001b[A\n",
      " 79%|███████▉  | 3325/4220 [3:32:47<56:26,  3.78s/it, loss=2.56, epoch=0.788, learning_rate=2.15e-6]\u001b[A\n",
      " 79%|███████▉  | 3326/4220 [3:32:51<56:23,  3.78s/it, loss=2.56, epoch=0.788, learning_rate=2.15e-6]\u001b[A\n",
      " 79%|███████▉  | 3326/4220 [3:32:51<56:23,  3.78s/it, loss=2.68, epoch=0.788, learning_rate=2.15e-6]\u001b[A\n",
      " 79%|███████▉  | 3327/4220 [3:32:55<56:19,  3.78s/it, loss=2.68, epoch=0.788, learning_rate=2.15e-6]\u001b[A\n",
      " 79%|███████▉  | 3327/4220 [3:32:55<56:19,  3.78s/it, loss=3.19, epoch=0.788, learning_rate=2.14e-6]\u001b[A\n",
      " 79%|███████▉  | 3328/4220 [3:32:59<56:14,  3.78s/it, loss=3.19, epoch=0.788, learning_rate=2.14e-6]\u001b[A\n",
      " 79%|███████▉  | 3328/4220 [3:32:59<56:14,  3.78s/it, loss=2.47, epoch=0.788, learning_rate=2.14e-6]\u001b[A\n",
      " 79%|███████▉  | 3329/4220 [3:33:02<56:11,  3.78s/it, loss=2.47, epoch=0.788, learning_rate=2.14e-6]\u001b[A\n",
      " 79%|███████▉  | 3329/4220 [3:33:02<56:11,  3.78s/it, loss=2.34, epoch=0.789, learning_rate=2.13e-6]\u001b[A\n",
      " 79%|███████▉  | 3330/4220 [3:33:06<56:06,  3.78s/it, loss=2.34, epoch=0.789, learning_rate=2.13e-6]\u001b[A\n",
      " 79%|███████▉  | 3330/4220 [3:33:06<56:06,  3.78s/it, loss=2.61, epoch=0.789, learning_rate=2.13e-6]\u001b[A\n",
      " 79%|███████▉  | 3331/4220 [3:33:10<56:03,  3.78s/it, loss=2.61, epoch=0.789, learning_rate=2.13e-6]\u001b[A\n",
      " 79%|███████▉  | 3331/4220 [3:33:10<56:03,  3.78s/it, loss=3.24, epoch=0.789, learning_rate=2.13e-6]\u001b[A\n",
      " 79%|███████▉  | 3332/4220 [3:33:14<55:58,  3.78s/it, loss=3.24, epoch=0.789, learning_rate=2.13e-6]\u001b[A\n",
      " 79%|███████▉  | 3332/4220 [3:33:14<55:58,  3.78s/it, loss=3.06, epoch=0.789, learning_rate=2.12e-6]\u001b[A\n",
      " 79%|███████▉  | 3333/4220 [3:33:18<55:53,  3.78s/it, loss=3.06, epoch=0.789, learning_rate=2.12e-6]\u001b[A\n",
      " 79%|███████▉  | 3333/4220 [3:33:18<55:53,  3.78s/it, loss=2.93, epoch=0.79, learning_rate=2.12e-6] \u001b[A\n",
      " 79%|███████▉  | 3334/4220 [3:33:21<55:51,  3.78s/it, loss=2.93, epoch=0.79, learning_rate=2.12e-6]\u001b[A\n",
      " 79%|███████▉  | 3334/4220 [3:33:21<55:51,  3.78s/it, loss=2.6, epoch=0.79, learning_rate=2.11e-6] \u001b[A\n",
      " 79%|███████▉  | 3335/4220 [3:33:25<55:48,  3.78s/it, loss=2.6, epoch=0.79, learning_rate=2.11e-6]\u001b[A\n",
      " 79%|███████▉  | 3335/4220 [3:33:25<55:48,  3.78s/it, loss=2.7, epoch=0.79, learning_rate=2.11e-6]\u001b[A\n",
      " 79%|███████▉  | 3336/4220 [3:33:29<55:48,  3.79s/it, loss=2.7, epoch=0.79, learning_rate=2.11e-6]\u001b[A\n",
      " 79%|███████▉  | 3336/4220 [3:33:29<55:48,  3.79s/it, loss=3.19, epoch=0.79, learning_rate=2.1e-6]\u001b[A\n",
      " 79%|███████▉  | 3337/4220 [3:33:33<55:43,  3.79s/it, loss=3.19, epoch=0.79, learning_rate=2.1e-6]\u001b[A\n",
      " 79%|███████▉  | 3337/4220 [3:33:33<55:43,  3.79s/it, loss=2.8, epoch=0.791, learning_rate=2.1e-6]\u001b[A\n",
      " 79%|███████▉  | 3338/4220 [3:33:37<55:38,  3.79s/it, loss=2.8, epoch=0.791, learning_rate=2.1e-6]\u001b[A\n",
      " 79%|███████▉  | 3338/4220 [3:33:37<55:38,  3.79s/it, loss=2.8, epoch=0.791, learning_rate=2.09e-6]\u001b[A\n",
      " 79%|███████▉  | 3339/4220 [3:33:40<55:32,  3.78s/it, loss=2.8, epoch=0.791, learning_rate=2.09e-6]\u001b[A\n",
      " 79%|███████▉  | 3339/4220 [3:33:40<55:32,  3.78s/it, loss=2.81, epoch=0.791, learning_rate=2.09e-6]\u001b[A\n",
      " 79%|███████▉  | 3340/4220 [3:33:44<55:27,  3.78s/it, loss=2.81, epoch=0.791, learning_rate=2.09e-6]\u001b[A\n",
      " 79%|███████▉  | 3340/4220 [3:33:44<55:27,  3.78s/it, loss=2.48, epoch=0.791, learning_rate=2.08e-6]\u001b[A\n",
      " 79%|███████▉  | 3341/4220 [3:33:48<55:23,  3.78s/it, loss=2.48, epoch=0.791, learning_rate=2.08e-6]\u001b[A\n",
      " 79%|███████▉  | 3341/4220 [3:33:48<55:23,  3.78s/it, loss=2.39, epoch=0.791, learning_rate=2.08e-6]\u001b[A\n",
      " 79%|███████▉  | 3342/4220 [3:33:52<55:18,  3.78s/it, loss=2.39, epoch=0.791, learning_rate=2.08e-6]\u001b[A\n",
      " 79%|███████▉  | 3342/4220 [3:33:52<55:18,  3.78s/it, loss=2.94, epoch=0.792, learning_rate=2.08e-6]\u001b[A\n",
      " 79%|███████▉  | 3343/4220 [3:33:55<55:14,  3.78s/it, loss=2.94, epoch=0.792, learning_rate=2.08e-6]\u001b[A\n",
      " 79%|███████▉  | 3343/4220 [3:33:55<55:14,  3.78s/it, loss=3.02, epoch=0.792, learning_rate=2.07e-6]\u001b[A\n",
      " 79%|███████▉  | 3344/4220 [3:33:59<55:12,  3.78s/it, loss=3.02, epoch=0.792, learning_rate=2.07e-6]\u001b[A\n",
      " 79%|███████▉  | 3344/4220 [3:33:59<55:12,  3.78s/it, loss=3.2, epoch=0.792, learning_rate=2.07e-6] \u001b[A\n",
      " 79%|███████▉  | 3345/4220 [3:34:03<55:08,  3.78s/it, loss=3.2, epoch=0.792, learning_rate=2.07e-6]\u001b[A\n",
      " 79%|███████▉  | 3345/4220 [3:34:03<55:08,  3.78s/it, loss=3.32, epoch=0.792, learning_rate=2.06e-6]\u001b[A\n",
      " 79%|███████▉  | 3346/4220 [3:34:07<55:05,  3.78s/it, loss=3.32, epoch=0.792, learning_rate=2.06e-6]\u001b[A\n",
      " 79%|███████▉  | 3346/4220 [3:34:07<55:05,  3.78s/it, loss=3.12, epoch=0.793, learning_rate=2.06e-6]\u001b[A\n",
      " 79%|███████▉  | 3347/4220 [3:34:11<55:01,  3.78s/it, loss=3.12, epoch=0.793, learning_rate=2.06e-6]\u001b[A\n",
      " 79%|███████▉  | 3347/4220 [3:34:11<55:01,  3.78s/it, loss=2.86, epoch=0.793, learning_rate=2.05e-6]\u001b[A\n",
      " 79%|███████▉  | 3348/4220 [3:34:14<54:57,  3.78s/it, loss=2.86, epoch=0.793, learning_rate=2.05e-6]\u001b[A\n",
      " 79%|███████▉  | 3348/4220 [3:34:14<54:57,  3.78s/it, loss=2.6, epoch=0.793, learning_rate=2.05e-6] \u001b[A\n",
      " 79%|███████▉  | 3349/4220 [3:34:18<54:53,  3.78s/it, loss=2.6, epoch=0.793, learning_rate=2.05e-6]\u001b[A\n",
      " 79%|███████▉  | 3349/4220 [3:34:18<54:53,  3.78s/it, loss=3.11, epoch=0.793, learning_rate=2.04e-6]\u001b[A\n",
      " 79%|███████▉  | 3350/4220 [3:34:22<54:50,  3.78s/it, loss=3.11, epoch=0.793, learning_rate=2.04e-6]\u001b[A\n",
      " 79%|███████▉  | 3350/4220 [3:34:22<54:50,  3.78s/it, loss=2.67, epoch=0.794, learning_rate=2.04e-6]\u001b[A\n",
      " 79%|███████▉  | 3351/4220 [3:34:26<54:47,  3.78s/it, loss=2.67, epoch=0.794, learning_rate=2.04e-6]\u001b[A\n",
      " 79%|███████▉  | 3351/4220 [3:34:26<54:47,  3.78s/it, loss=3.22, epoch=0.794, learning_rate=2.03e-6]\u001b[A\n",
      " 79%|███████▉  | 3352/4220 [3:34:29<54:43,  3.78s/it, loss=3.22, epoch=0.794, learning_rate=2.03e-6]\u001b[A\n",
      " 79%|███████▉  | 3352/4220 [3:34:29<54:43,  3.78s/it, loss=2.92, epoch=0.794, learning_rate=2.03e-6]\u001b[A\n",
      " 79%|███████▉  | 3353/4220 [3:34:33<54:38,  3.78s/it, loss=2.92, epoch=0.794, learning_rate=2.03e-6]\u001b[A\n",
      " 79%|███████▉  | 3353/4220 [3:34:33<54:38,  3.78s/it, loss=2.6, epoch=0.794, learning_rate=2.03e-6] \u001b[A\n",
      " 79%|███████▉  | 3354/4220 [3:34:37<54:34,  3.78s/it, loss=2.6, epoch=0.794, learning_rate=2.03e-6]\u001b[A\n",
      " 79%|███████▉  | 3354/4220 [3:34:37<54:34,  3.78s/it, loss=3.33, epoch=0.795, learning_rate=2.02e-6]\u001b[A\n",
      " 80%|███████▉  | 3355/4220 [3:34:41<54:31,  3.78s/it, loss=3.33, epoch=0.795, learning_rate=2.02e-6]\u001b[A\n",
      " 80%|███████▉  | 3355/4220 [3:34:41<54:31,  3.78s/it, loss=3.04, epoch=0.795, learning_rate=2.02e-6]\u001b[A\n",
      " 80%|███████▉  | 3356/4220 [3:34:45<54:28,  3.78s/it, loss=3.04, epoch=0.795, learning_rate=2.02e-6]\u001b[A\n",
      " 80%|███████▉  | 3356/4220 [3:34:45<54:28,  3.78s/it, loss=3.28, epoch=0.795, learning_rate=2.01e-6]\u001b[A\n",
      " 80%|███████▉  | 3357/4220 [3:34:48<54:25,  3.78s/it, loss=3.28, epoch=0.795, learning_rate=2.01e-6]\u001b[A\n",
      " 80%|███████▉  | 3357/4220 [3:34:48<54:25,  3.78s/it, loss=2.31, epoch=0.795, learning_rate=2.01e-6]\u001b[A\n",
      " 80%|███████▉  | 3358/4220 [3:34:52<54:20,  3.78s/it, loss=2.31, epoch=0.795, learning_rate=2.01e-6]\u001b[A\n",
      " 80%|███████▉  | 3358/4220 [3:34:52<54:20,  3.78s/it, loss=3.16, epoch=0.795, learning_rate=2e-6]   \u001b[A\n",
      " 80%|███████▉  | 3359/4220 [3:34:56<54:16,  3.78s/it, loss=3.16, epoch=0.795, learning_rate=2e-6]\u001b[A\n",
      " 80%|███████▉  | 3359/4220 [3:34:56<54:16,  3.78s/it, loss=2.86, epoch=0.796, learning_rate=2e-6]\u001b[A\n",
      " 80%|███████▉  | 3360/4220 [3:35:00<54:13,  3.78s/it, loss=2.86, epoch=0.796, learning_rate=2e-6]\u001b[A\n",
      " 80%|███████▉  | 3360/4220 [3:35:00<54:13,  3.78s/it, loss=2.5, epoch=0.796, learning_rate=1.99e-6]\u001b[A\n",
      " 80%|███████▉  | 3361/4220 [3:35:04<54:09,  3.78s/it, loss=2.5, epoch=0.796, learning_rate=1.99e-6]\u001b[A\n",
      " 80%|███████▉  | 3361/4220 [3:35:04<54:09,  3.78s/it, loss=2.92, epoch=0.796, learning_rate=1.99e-6]\u001b[A\n",
      " 80%|███████▉  | 3362/4220 [3:35:07<54:07,  3.78s/it, loss=2.92, epoch=0.796, learning_rate=1.99e-6]\u001b[A\n",
      " 80%|███████▉  | 3362/4220 [3:35:07<54:07,  3.78s/it, loss=2.75, epoch=0.796, learning_rate=1.99e-6]\u001b[A\n",
      " 80%|███████▉  | 3363/4220 [3:35:11<54:03,  3.78s/it, loss=2.75, epoch=0.796, learning_rate=1.99e-6]\u001b[A\n",
      " 80%|███████▉  | 3363/4220 [3:35:11<54:03,  3.78s/it, loss=2.55, epoch=0.797, learning_rate=1.98e-6]\u001b[A\n",
      " 80%|███████▉  | 3364/4220 [3:35:15<53:58,  3.78s/it, loss=2.55, epoch=0.797, learning_rate=1.98e-6]\u001b[A\n",
      " 80%|███████▉  | 3364/4220 [3:35:15<53:58,  3.78s/it, loss=3.05, epoch=0.797, learning_rate=1.98e-6]\u001b[A\n",
      " 80%|███████▉  | 3365/4220 [3:35:19<53:55,  3.78s/it, loss=3.05, epoch=0.797, learning_rate=1.98e-6]\u001b[A\n",
      " 80%|███████▉  | 3365/4220 [3:35:19<53:55,  3.78s/it, loss=2.78, epoch=0.797, learning_rate=1.97e-6]\u001b[A\n",
      " 80%|███████▉  | 3366/4220 [3:35:22<53:51,  3.78s/it, loss=2.78, epoch=0.797, learning_rate=1.97e-6]\u001b[A\n",
      " 80%|███████▉  | 3366/4220 [3:35:22<53:51,  3.78s/it, loss=3.04, epoch=0.797, learning_rate=1.97e-6]\u001b[A\n",
      " 80%|███████▉  | 3367/4220 [3:35:26<53:46,  3.78s/it, loss=3.04, epoch=0.797, learning_rate=1.97e-6]\u001b[A\n",
      " 80%|███████▉  | 3367/4220 [3:35:26<53:46,  3.78s/it, loss=2.87, epoch=0.798, learning_rate=1.96e-6]\u001b[A\n",
      " 80%|███████▉  | 3368/4220 [3:35:30<53:42,  3.78s/it, loss=2.87, epoch=0.798, learning_rate=1.96e-6]\u001b[A\n",
      " 80%|███████▉  | 3368/4220 [3:35:30<53:42,  3.78s/it, loss=2.9, epoch=0.798, learning_rate=1.96e-6] \u001b[A\n",
      " 80%|███████▉  | 3369/4220 [3:35:34<53:39,  3.78s/it, loss=2.9, epoch=0.798, learning_rate=1.96e-6]\u001b[A\n",
      " 80%|███████▉  | 3369/4220 [3:35:34<53:39,  3.78s/it, loss=2.88, epoch=0.798, learning_rate=1.95e-6]\u001b[A\n",
      " 80%|███████▉  | 3370/4220 [3:35:38<53:35,  3.78s/it, loss=2.88, epoch=0.798, learning_rate=1.95e-6]\u001b[A\n",
      " 80%|███████▉  | 3370/4220 [3:35:38<53:35,  3.78s/it, loss=2.57, epoch=0.798, learning_rate=1.95e-6]\u001b[A\n",
      " 80%|███████▉  | 3371/4220 [3:35:41<53:32,  3.78s/it, loss=2.57, epoch=0.798, learning_rate=1.95e-6]\u001b[A\n",
      " 80%|███████▉  | 3371/4220 [3:35:41<53:32,  3.78s/it, loss=2.77, epoch=0.799, learning_rate=1.95e-6]\u001b[A\n",
      " 80%|███████▉  | 3372/4220 [3:35:45<53:28,  3.78s/it, loss=2.77, epoch=0.799, learning_rate=1.95e-6]\u001b[A\n",
      " 80%|███████▉  | 3372/4220 [3:35:45<53:28,  3.78s/it, loss=2.8, epoch=0.799, learning_rate=1.94e-6] \u001b[A\n",
      " 80%|███████▉  | 3373/4220 [3:35:49<53:24,  3.78s/it, loss=2.8, epoch=0.799, learning_rate=1.94e-6]\u001b[A\n",
      " 80%|███████▉  | 3373/4220 [3:35:49<53:24,  3.78s/it, loss=2.69, epoch=0.799, learning_rate=1.94e-6]\u001b[A\n",
      " 80%|███████▉  | 3374/4220 [3:35:53<53:19,  3.78s/it, loss=2.69, epoch=0.799, learning_rate=1.94e-6]\u001b[A\n",
      " 80%|███████▉  | 3374/4220 [3:35:53<53:19,  3.78s/it, loss=2.57, epoch=0.799, learning_rate=1.93e-6]\u001b[A\n",
      " 80%|███████▉  | 3375/4220 [3:35:56<53:16,  3.78s/it, loss=2.57, epoch=0.799, learning_rate=1.93e-6]\u001b[A\n",
      " 80%|███████▉  | 3375/4220 [3:35:56<53:16,  3.78s/it, loss=3.71, epoch=0.8, learning_rate=1.93e-6]  \u001b[A\n",
      " 80%|████████  | 3376/4220 [3:36:00<53:12,  3.78s/it, loss=3.71, epoch=0.8, learning_rate=1.93e-6]\u001b[A\n",
      " 80%|████████  | 3376/4220 [3:36:00<53:12,  3.78s/it, loss=2.88, epoch=0.8, learning_rate=1.92e-6]\u001b[A\n",
      " 80%|████████  | 3377/4220 [3:36:04<53:09,  3.78s/it, loss=2.88, epoch=0.8, learning_rate=1.92e-6]\u001b[A\n",
      " 80%|████████  | 3377/4220 [3:36:04<53:09,  3.78s/it, loss=2.86, epoch=0.8, learning_rate=1.92e-6]\u001b[A\n",
      " 80%|████████  | 3378/4220 [3:36:08<53:05,  3.78s/it, loss=2.86, epoch=0.8, learning_rate=1.92e-6]\u001b[A\n",
      " 80%|████████  | 3378/4220 [3:36:08<53:05,  3.78s/it, loss=2.7, epoch=0.8, learning_rate=1.91e-6] \u001b[A\n",
      " 80%|████████  | 3379/4220 [3:36:12<53:01,  3.78s/it, loss=2.7, epoch=0.8, learning_rate=1.91e-6]\u001b[A\n",
      " 80%|████████  | 3379/4220 [3:36:12<53:01,  3.78s/it, loss=3.05, epoch=0.8, learning_rate=1.91e-6]\u001b[A\n",
      " 80%|████████  | 3380/4220 [3:36:15<52:56,  3.78s/it, loss=3.05, epoch=0.8, learning_rate=1.91e-6]\u001b[A\n",
      " 80%|████████  | 3380/4220 [3:36:15<52:56,  3.78s/it, loss=2.55, epoch=0.801, learning_rate=1.91e-6]\u001b[A\n",
      " 80%|████████  | 3381/4220 [3:36:19<52:52,  3.78s/it, loss=2.55, epoch=0.801, learning_rate=1.91e-6]\u001b[A\n",
      " 80%|████████  | 3381/4220 [3:36:19<52:52,  3.78s/it, loss=2.26, epoch=0.801, learning_rate=1.9e-6] \u001b[A\n",
      " 80%|████████  | 3382/4220 [3:36:23<52:48,  3.78s/it, loss=2.26, epoch=0.801, learning_rate=1.9e-6]\u001b[A\n",
      " 80%|████████  | 3382/4220 [3:36:23<52:48,  3.78s/it, loss=2.8, epoch=0.801, learning_rate=1.9e-6] \u001b[A\n",
      " 80%|████████  | 3383/4220 [3:36:27<52:45,  3.78s/it, loss=2.8, epoch=0.801, learning_rate=1.9e-6]\u001b[A\n",
      " 80%|████████  | 3383/4220 [3:36:27<52:45,  3.78s/it, loss=2.53, epoch=0.801, learning_rate=1.89e-6]\u001b[A\n",
      " 80%|████████  | 3384/4220 [3:36:31<52:42,  3.78s/it, loss=2.53, epoch=0.801, learning_rate=1.89e-6]\u001b[A\n",
      " 80%|████████  | 3384/4220 [3:36:31<52:42,  3.78s/it, loss=2.98, epoch=0.802, learning_rate=1.89e-6]\u001b[A\n",
      " 80%|████████  | 3385/4220 [3:36:34<52:38,  3.78s/it, loss=2.98, epoch=0.802, learning_rate=1.89e-6]\u001b[A\n",
      " 80%|████████  | 3385/4220 [3:36:34<52:38,  3.78s/it, loss=2.44, epoch=0.802, learning_rate=1.88e-6]\u001b[A\n",
      " 80%|████████  | 3386/4220 [3:36:38<52:34,  3.78s/it, loss=2.44, epoch=0.802, learning_rate=1.88e-6]\u001b[A\n",
      " 80%|████████  | 3386/4220 [3:36:38<52:34,  3.78s/it, loss=3.26, epoch=0.802, learning_rate=1.88e-6]\u001b[A\n",
      " 80%|████████  | 3387/4220 [3:36:42<52:30,  3.78s/it, loss=3.26, epoch=0.802, learning_rate=1.88e-6]\u001b[A\n",
      " 80%|████████  | 3387/4220 [3:36:42<52:30,  3.78s/it, loss=2.77, epoch=0.802, learning_rate=1.87e-6]\u001b[A\n",
      " 80%|████████  | 3388/4220 [3:36:46<52:26,  3.78s/it, loss=2.77, epoch=0.802, learning_rate=1.87e-6]\u001b[A\n",
      " 80%|████████  | 3388/4220 [3:36:46<52:26,  3.78s/it, loss=3.49, epoch=0.803, learning_rate=1.87e-6]\u001b[A\n",
      " 80%|████████  | 3389/4220 [3:36:49<52:23,  3.78s/it, loss=3.49, epoch=0.803, learning_rate=1.87e-6]\u001b[A\n",
      " 80%|████████  | 3389/4220 [3:36:49<52:23,  3.78s/it, loss=3.04, epoch=0.803, learning_rate=1.87e-6]\u001b[A\n",
      " 80%|████████  | 3390/4220 [3:36:53<52:20,  3.78s/it, loss=3.04, epoch=0.803, learning_rate=1.87e-6]\u001b[A\n",
      " 80%|████████  | 3390/4220 [3:36:53<52:20,  3.78s/it, loss=2.83, epoch=0.803, learning_rate=1.86e-6]\u001b[A\n",
      " 80%|████████  | 3391/4220 [3:36:57<52:15,  3.78s/it, loss=2.83, epoch=0.803, learning_rate=1.86e-6]\u001b[A\n",
      " 80%|████████  | 3391/4220 [3:36:57<52:15,  3.78s/it, loss=3.01, epoch=0.803, learning_rate=1.86e-6]\u001b[A\n",
      " 80%|████████  | 3392/4220 [3:37:01<52:12,  3.78s/it, loss=3.01, epoch=0.803, learning_rate=1.86e-6]\u001b[A\n",
      " 80%|████████  | 3392/4220 [3:37:01<52:12,  3.78s/it, loss=2.88, epoch=0.804, learning_rate=1.85e-6]\u001b[A\n",
      " 80%|████████  | 3393/4220 [3:37:05<52:08,  3.78s/it, loss=2.88, epoch=0.804, learning_rate=1.85e-6]\u001b[A\n",
      " 80%|████████  | 3393/4220 [3:37:05<52:08,  3.78s/it, loss=2.68, epoch=0.804, learning_rate=1.85e-6]\u001b[A\n",
      " 80%|████████  | 3394/4220 [3:37:08<52:04,  3.78s/it, loss=2.68, epoch=0.804, learning_rate=1.85e-6]\u001b[A\n",
      " 80%|████████  | 3394/4220 [3:37:08<52:04,  3.78s/it, loss=2.55, epoch=0.804, learning_rate=1.84e-6]\u001b[A\n",
      " 80%|████████  | 3395/4220 [3:37:12<52:01,  3.78s/it, loss=2.55, epoch=0.804, learning_rate=1.84e-6]\u001b[A\n",
      " 80%|████████  | 3395/4220 [3:37:12<52:01,  3.78s/it, loss=2.96, epoch=0.804, learning_rate=1.84e-6]\u001b[A\n",
      " 80%|████████  | 3396/4220 [3:37:16<51:57,  3.78s/it, loss=2.96, epoch=0.804, learning_rate=1.84e-6]\u001b[A\n",
      " 80%|████████  | 3396/4220 [3:37:16<51:57,  3.78s/it, loss=3.11, epoch=0.805, learning_rate=1.84e-6]\u001b[A\n",
      " 80%|████████  | 3397/4220 [3:37:20<51:53,  3.78s/it, loss=3.11, epoch=0.805, learning_rate=1.84e-6]\u001b[A\n",
      " 80%|████████  | 3397/4220 [3:37:20<51:53,  3.78s/it, loss=2.62, epoch=0.805, learning_rate=1.83e-6]\u001b[A\n",
      " 81%|████████  | 3398/4220 [3:37:23<51:49,  3.78s/it, loss=2.62, epoch=0.805, learning_rate=1.83e-6]\u001b[A\n",
      " 81%|████████  | 3398/4220 [3:37:23<51:49,  3.78s/it, loss=3.26, epoch=0.805, learning_rate=1.83e-6]\u001b[A\n",
      " 81%|████████  | 3399/4220 [3:37:27<51:44,  3.78s/it, loss=3.26, epoch=0.805, learning_rate=1.83e-6]\u001b[A\n",
      " 81%|████████  | 3399/4220 [3:37:27<51:44,  3.78s/it, loss=3.19, epoch=0.805, learning_rate=1.82e-6]\u001b[A\n",
      " 81%|████████  | 3400/4220 [3:37:31<51:42,  3.78s/it, loss=3.19, epoch=0.805, learning_rate=1.82e-6]\u001b[A\n",
      " 81%|████████  | 3400/4220 [3:37:31<51:42,  3.78s/it, loss=2.86, epoch=0.805, learning_rate=1.82e-6]\u001b[A\n",
      " 81%|████████  | 3401/4220 [3:37:35<51:38,  3.78s/it, loss=2.86, epoch=0.805, learning_rate=1.82e-6]\u001b[A\n",
      " 81%|████████  | 3401/4220 [3:37:35<51:38,  3.78s/it, loss=2.98, epoch=0.806, learning_rate=1.81e-6]\u001b[A\n",
      " 81%|████████  | 3402/4220 [3:37:39<51:34,  3.78s/it, loss=2.98, epoch=0.806, learning_rate=1.81e-6]\u001b[A\n",
      " 81%|████████  | 3402/4220 [3:37:39<51:34,  3.78s/it, loss=3.34, epoch=0.806, learning_rate=1.81e-6]\u001b[A\n",
      " 81%|████████  | 3403/4220 [3:37:42<51:30,  3.78s/it, loss=3.34, epoch=0.806, learning_rate=1.81e-6]\u001b[A\n",
      " 81%|████████  | 3403/4220 [3:37:42<51:30,  3.78s/it, loss=3.16, epoch=0.806, learning_rate=1.81e-6]\u001b[A\n",
      " 81%|████████  | 3404/4220 [3:37:46<51:25,  3.78s/it, loss=3.16, epoch=0.806, learning_rate=1.81e-6]\u001b[A\n",
      " 81%|████████  | 3404/4220 [3:37:46<51:25,  3.78s/it, loss=2.94, epoch=0.806, learning_rate=1.8e-6] \u001b[A\n",
      " 81%|████████  | 3405/4220 [3:37:50<51:21,  3.78s/it, loss=2.94, epoch=0.806, learning_rate=1.8e-6]\u001b[A\n",
      " 81%|████████  | 3405/4220 [3:37:50<51:21,  3.78s/it, loss=2.51, epoch=0.807, learning_rate=1.8e-6]\u001b[A\n",
      " 81%|████████  | 3406/4220 [3:37:54<51:18,  3.78s/it, loss=2.51, epoch=0.807, learning_rate=1.8e-6]\u001b[A\n",
      " 81%|████████  | 3406/4220 [3:37:54<51:18,  3.78s/it, loss=3.02, epoch=0.807, learning_rate=1.79e-6]\u001b[A\n",
      " 81%|████████  | 3407/4220 [3:37:58<51:14,  3.78s/it, loss=3.02, epoch=0.807, learning_rate=1.79e-6]\u001b[A\n",
      " 81%|████████  | 3407/4220 [3:37:58<51:14,  3.78s/it, loss=2.59, epoch=0.807, learning_rate=1.79e-6]\u001b[A\n",
      " 81%|████████  | 3408/4220 [3:38:01<51:11,  3.78s/it, loss=2.59, epoch=0.807, learning_rate=1.79e-6]\u001b[A\n",
      " 81%|████████  | 3408/4220 [3:38:01<51:11,  3.78s/it, loss=2.68, epoch=0.807, learning_rate=1.78e-6]\u001b[A\n",
      " 81%|████████  | 3409/4220 [3:38:05<51:07,  3.78s/it, loss=2.68, epoch=0.807, learning_rate=1.78e-6]\u001b[A\n",
      " 81%|████████  | 3409/4220 [3:38:05<51:07,  3.78s/it, loss=2.79, epoch=0.808, learning_rate=1.78e-6]\u001b[A\n",
      " 81%|████████  | 3410/4220 [3:38:09<51:03,  3.78s/it, loss=2.79, epoch=0.808, learning_rate=1.78e-6]\u001b[A\n",
      " 81%|████████  | 3410/4220 [3:38:09<51:03,  3.78s/it, loss=2.84, epoch=0.808, learning_rate=1.78e-6]\u001b[A\n",
      " 81%|████████  | 3411/4220 [3:38:13<50:59,  3.78s/it, loss=2.84, epoch=0.808, learning_rate=1.78e-6]\u001b[A\n",
      " 81%|████████  | 3411/4220 [3:38:13<50:59,  3.78s/it, loss=2.94, epoch=0.808, learning_rate=1.77e-6]\u001b[A\n",
      " 81%|████████  | 3412/4220 [3:38:16<50:55,  3.78s/it, loss=2.94, epoch=0.808, learning_rate=1.77e-6]\u001b[A\n",
      " 81%|████████  | 3412/4220 [3:38:16<50:55,  3.78s/it, loss=2.79, epoch=0.808, learning_rate=1.77e-6]\u001b[A\n",
      " 81%|████████  | 3413/4220 [3:38:20<50:52,  3.78s/it, loss=2.79, epoch=0.808, learning_rate=1.77e-6]\u001b[A\n",
      " 81%|████████  | 3413/4220 [3:38:20<50:52,  3.78s/it, loss=2.6, epoch=0.809, learning_rate=1.76e-6] \u001b[A\n",
      " 81%|████████  | 3414/4220 [3:38:24<50:48,  3.78s/it, loss=2.6, epoch=0.809, learning_rate=1.76e-6]\u001b[A\n",
      " 81%|████████  | 3414/4220 [3:38:24<50:48,  3.78s/it, loss=3.02, epoch=0.809, learning_rate=1.76e-6]\u001b[A\n",
      " 81%|████████  | 3415/4220 [3:38:28<50:45,  3.78s/it, loss=3.02, epoch=0.809, learning_rate=1.76e-6]\u001b[A\n",
      " 81%|████████  | 3415/4220 [3:38:28<50:45,  3.78s/it, loss=2.69, epoch=0.809, learning_rate=1.75e-6]\u001b[A\n",
      " 81%|████████  | 3416/4220 [3:38:32<50:40,  3.78s/it, loss=2.69, epoch=0.809, learning_rate=1.75e-6]\u001b[A\n",
      " 81%|████████  | 3416/4220 [3:38:32<50:40,  3.78s/it, loss=2.7, epoch=0.809, learning_rate=1.75e-6] \u001b[A\n",
      " 81%|████████  | 3417/4220 [3:38:35<50:37,  3.78s/it, loss=2.7, epoch=0.809, learning_rate=1.75e-6]\u001b[A\n",
      " 81%|████████  | 3417/4220 [3:38:35<50:37,  3.78s/it, loss=2.63, epoch=0.809, learning_rate=1.75e-6]\u001b[A\n",
      " 81%|████████  | 3418/4220 [3:38:39<50:32,  3.78s/it, loss=2.63, epoch=0.809, learning_rate=1.75e-6]\u001b[A\n",
      " 81%|████████  | 3418/4220 [3:38:39<50:32,  3.78s/it, loss=2.6, epoch=0.81, learning_rate=1.74e-6]  \u001b[A\n",
      " 81%|████████  | 3419/4220 [3:38:43<50:30,  3.78s/it, loss=2.6, epoch=0.81, learning_rate=1.74e-6]\u001b[A\n",
      " 81%|████████  | 3419/4220 [3:38:43<50:30,  3.78s/it, loss=2.58, epoch=0.81, learning_rate=1.74e-6]\u001b[A\n",
      " 81%|████████  | 3420/4220 [3:38:47<50:26,  3.78s/it, loss=2.58, epoch=0.81, learning_rate=1.74e-6]\u001b[A\n",
      " 81%|████████  | 3420/4220 [3:38:47<50:26,  3.78s/it, loss=3.01, epoch=0.81, learning_rate=1.73e-6]\u001b[A\n",
      " 81%|████████  | 3421/4220 [3:38:50<50:23,  3.78s/it, loss=3.01, epoch=0.81, learning_rate=1.73e-6]\u001b[A\n",
      " 81%|████████  | 3421/4220 [3:38:50<50:23,  3.78s/it, loss=2.28, epoch=0.81, learning_rate=1.73e-6]\u001b[A\n",
      " 81%|████████  | 3422/4220 [3:38:54<50:19,  3.78s/it, loss=2.28, epoch=0.81, learning_rate=1.73e-6]\u001b[A\n",
      " 81%|████████  | 3422/4220 [3:38:54<50:19,  3.78s/it, loss=3, epoch=0.811, learning_rate=1.73e-6]  \u001b[A\n",
      " 81%|████████  | 3423/4220 [3:38:58<50:15,  3.78s/it, loss=3, epoch=0.811, learning_rate=1.73e-6]\u001b[A\n",
      " 81%|████████  | 3423/4220 [3:38:58<50:15,  3.78s/it, loss=2.97, epoch=0.811, learning_rate=1.72e-6]\u001b[A\n",
      " 81%|████████  | 3424/4220 [3:39:02<50:10,  3.78s/it, loss=2.97, epoch=0.811, learning_rate=1.72e-6]\u001b[A\n",
      " 81%|████████  | 3424/4220 [3:39:02<50:10,  3.78s/it, loss=2.98, epoch=0.811, learning_rate=1.72e-6]\u001b[A\n",
      " 81%|████████  | 3425/4220 [3:39:06<50:06,  3.78s/it, loss=2.98, epoch=0.811, learning_rate=1.72e-6]\u001b[A\n",
      " 81%|████████  | 3425/4220 [3:39:06<50:06,  3.78s/it, loss=3, epoch=0.811, learning_rate=1.71e-6]   \u001b[A\n",
      " 81%|████████  | 3426/4220 [3:39:09<50:03,  3.78s/it, loss=3, epoch=0.811, learning_rate=1.71e-6]\u001b[A\n",
      " 81%|████████  | 3426/4220 [3:39:09<50:03,  3.78s/it, loss=2.56, epoch=0.812, learning_rate=1.71e-6]\u001b[A\n",
      " 81%|████████  | 3427/4220 [3:39:13<50:00,  3.78s/it, loss=2.56, epoch=0.812, learning_rate=1.71e-6]\u001b[A\n",
      " 81%|████████  | 3427/4220 [3:39:13<50:00,  3.78s/it, loss=2.4, epoch=0.812, learning_rate=1.7e-6]  \u001b[A\n",
      " 81%|████████  | 3428/4220 [3:39:17<49:57,  3.79s/it, loss=2.4, epoch=0.812, learning_rate=1.7e-6]\u001b[A\n",
      " 81%|████████  | 3428/4220 [3:39:17<49:57,  3.79s/it, loss=2.98, epoch=0.812, learning_rate=1.7e-6]\u001b[A\n",
      " 81%|████████▏ | 3429/4220 [3:39:21<49:53,  3.78s/it, loss=2.98, epoch=0.812, learning_rate=1.7e-6]\u001b[A\n",
      " 81%|████████▏ | 3429/4220 [3:39:21<49:53,  3.78s/it, loss=2.68, epoch=0.812, learning_rate=1.7e-6]\u001b[A\n",
      " 81%|████████▏ | 3430/4220 [3:39:25<49:49,  3.78s/it, loss=2.68, epoch=0.812, learning_rate=1.7e-6]\u001b[A\n",
      " 81%|████████▏ | 3430/4220 [3:39:25<49:49,  3.78s/it, loss=2.75, epoch=0.813, learning_rate=1.69e-6]\u001b[A\n",
      " 81%|████████▏ | 3431/4220 [3:39:28<49:45,  3.78s/it, loss=2.75, epoch=0.813, learning_rate=1.69e-6]\u001b[A\n",
      " 81%|████████▏ | 3431/4220 [3:39:28<49:45,  3.78s/it, loss=2.67, epoch=0.813, learning_rate=1.69e-6]\u001b[A\n",
      " 81%|████████▏ | 3432/4220 [3:39:32<49:42,  3.79s/it, loss=2.67, epoch=0.813, learning_rate=1.69e-6]\u001b[A\n",
      " 81%|████████▏ | 3432/4220 [3:39:32<49:42,  3.79s/it, loss=2.67, epoch=0.813, learning_rate=1.68e-6]\u001b[A\n",
      " 81%|████████▏ | 3433/4220 [3:39:36<49:37,  3.78s/it, loss=2.67, epoch=0.813, learning_rate=1.68e-6]\u001b[A\n",
      " 81%|████████▏ | 3433/4220 [3:39:36<49:37,  3.78s/it, loss=2.88, epoch=0.813, learning_rate=1.68e-6]\u001b[A\n",
      " 81%|████████▏ | 3434/4220 [3:39:40<49:31,  3.78s/it, loss=2.88, epoch=0.813, learning_rate=1.68e-6]\u001b[A\n",
      " 81%|████████▏ | 3434/4220 [3:39:40<49:31,  3.78s/it, loss=2.52, epoch=0.814, learning_rate=1.68e-6]\u001b[A\n",
      " 81%|████████▏ | 3435/4220 [3:39:43<49:28,  3.78s/it, loss=2.52, epoch=0.814, learning_rate=1.68e-6]\u001b[A\n",
      " 81%|████████▏ | 3435/4220 [3:39:43<49:28,  3.78s/it, loss=2.88, epoch=0.814, learning_rate=1.67e-6]\u001b[A\n",
      " 81%|████████▏ | 3436/4220 [3:39:47<49:24,  3.78s/it, loss=2.88, epoch=0.814, learning_rate=1.67e-6]\u001b[A\n",
      " 81%|████████▏ | 3436/4220 [3:39:47<49:24,  3.78s/it, loss=2.78, epoch=0.814, learning_rate=1.67e-6]\u001b[A\n",
      " 81%|████████▏ | 3437/4220 [3:39:51<49:21,  3.78s/it, loss=2.78, epoch=0.814, learning_rate=1.67e-6]\u001b[A\n",
      " 81%|████████▏ | 3437/4220 [3:39:51<49:21,  3.78s/it, loss=2.87, epoch=0.814, learning_rate=1.66e-6]\u001b[A\n",
      " 81%|████████▏ | 3438/4220 [3:39:55<49:18,  3.78s/it, loss=2.87, epoch=0.814, learning_rate=1.66e-6]\u001b[A\n",
      " 81%|████████▏ | 3438/4220 [3:39:55<49:18,  3.78s/it, loss=2.96, epoch=0.814, learning_rate=1.66e-6]\u001b[A\n",
      " 81%|████████▏ | 3439/4220 [3:39:59<49:13,  3.78s/it, loss=2.96, epoch=0.814, learning_rate=1.66e-6]\u001b[A\n",
      " 81%|████████▏ | 3439/4220 [3:39:59<49:13,  3.78s/it, loss=2.43, epoch=0.815, learning_rate=1.65e-6]\u001b[A\n",
      " 82%|████████▏ | 3440/4220 [3:40:02<49:09,  3.78s/it, loss=2.43, epoch=0.815, learning_rate=1.65e-6]\u001b[A\n",
      " 82%|████████▏ | 3440/4220 [3:40:02<49:09,  3.78s/it, loss=2.95, epoch=0.815, learning_rate=1.65e-6]\u001b[A\n",
      " 82%|████████▏ | 3441/4220 [3:40:06<49:05,  3.78s/it, loss=2.95, epoch=0.815, learning_rate=1.65e-6]\u001b[A\n",
      " 82%|████████▏ | 3441/4220 [3:40:06<49:05,  3.78s/it, loss=2.54, epoch=0.815, learning_rate=1.65e-6]\u001b[A\n",
      " 82%|████████▏ | 3442/4220 [3:40:10<49:02,  3.78s/it, loss=2.54, epoch=0.815, learning_rate=1.65e-6]\u001b[A\n",
      " 82%|████████▏ | 3442/4220 [3:40:10<49:02,  3.78s/it, loss=2.73, epoch=0.815, learning_rate=1.64e-6]\u001b[A\n",
      " 82%|████████▏ | 3443/4220 [3:40:14<48:59,  3.78s/it, loss=2.73, epoch=0.815, learning_rate=1.64e-6]\u001b[A\n",
      " 82%|████████▏ | 3443/4220 [3:40:14<48:59,  3.78s/it, loss=3.48, epoch=0.816, learning_rate=1.64e-6]\u001b[A\n",
      " 82%|████████▏ | 3444/4220 [3:40:17<48:54,  3.78s/it, loss=3.48, epoch=0.816, learning_rate=1.64e-6]\u001b[A\n",
      " 82%|████████▏ | 3444/4220 [3:40:17<48:54,  3.78s/it, loss=2.9, epoch=0.816, learning_rate=1.63e-6] \u001b[A\n",
      " 82%|████████▏ | 3445/4220 [3:40:21<48:50,  3.78s/it, loss=2.9, epoch=0.816, learning_rate=1.63e-6]\u001b[A\n",
      " 82%|████████▏ | 3445/4220 [3:40:21<48:50,  3.78s/it, loss=2.59, epoch=0.816, learning_rate=1.63e-6]\u001b[A\n",
      " 82%|████████▏ | 3446/4220 [3:40:25<48:47,  3.78s/it, loss=2.59, epoch=0.816, learning_rate=1.63e-6]\u001b[A\n",
      " 82%|████████▏ | 3446/4220 [3:40:25<48:47,  3.78s/it, loss=2.93, epoch=0.816, learning_rate=1.63e-6]\u001b[A\n",
      " 82%|████████▏ | 3447/4220 [3:40:29<48:45,  3.78s/it, loss=2.93, epoch=0.816, learning_rate=1.63e-6]\u001b[A\n",
      " 82%|████████▏ | 3447/4220 [3:40:29<48:45,  3.78s/it, loss=3.41, epoch=0.817, learning_rate=1.62e-6]\u001b[A\n",
      " 82%|████████▏ | 3448/4220 [3:40:33<48:40,  3.78s/it, loss=3.41, epoch=0.817, learning_rate=1.62e-6]\u001b[A\n",
      " 82%|████████▏ | 3448/4220 [3:40:33<48:40,  3.78s/it, loss=2.68, epoch=0.817, learning_rate=1.62e-6]\u001b[A\n",
      " 82%|████████▏ | 3449/4220 [3:40:36<48:36,  3.78s/it, loss=2.68, epoch=0.817, learning_rate=1.62e-6]\u001b[A\n",
      " 82%|████████▏ | 3449/4220 [3:40:36<48:36,  3.78s/it, loss=2.55, epoch=0.817, learning_rate=1.61e-6]\u001b[A\n",
      " 82%|████████▏ | 3450/4220 [3:40:40<48:33,  3.78s/it, loss=2.55, epoch=0.817, learning_rate=1.61e-6]\u001b[A\n",
      " 82%|████████▏ | 3450/4220 [3:40:40<48:33,  3.78s/it, loss=2.58, epoch=0.817, learning_rate=1.61e-6]\u001b[A\n",
      " 82%|████████▏ | 3451/4220 [3:40:44<48:30,  3.78s/it, loss=2.58, epoch=0.817, learning_rate=1.61e-6]\u001b[A\n",
      " 82%|████████▏ | 3451/4220 [3:40:44<48:30,  3.78s/it, loss=2.54, epoch=0.818, learning_rate=1.61e-6]\u001b[A\n",
      " 82%|████████▏ | 3452/4220 [3:40:48<48:25,  3.78s/it, loss=2.54, epoch=0.818, learning_rate=1.61e-6]\u001b[A\n",
      " 82%|████████▏ | 3452/4220 [3:40:48<48:25,  3.78s/it, loss=3.11, epoch=0.818, learning_rate=1.6e-6] \u001b[A\n",
      " 82%|████████▏ | 3453/4220 [3:40:52<48:21,  3.78s/it, loss=3.11, epoch=0.818, learning_rate=1.6e-6]\u001b[A\n",
      " 82%|████████▏ | 3453/4220 [3:40:52<48:21,  3.78s/it, loss=2.8, epoch=0.818, learning_rate=1.6e-6] \u001b[A\n",
      " 82%|████████▏ | 3454/4220 [3:40:56<49:07,  3.85s/it, loss=2.8, epoch=0.818, learning_rate=1.6e-6]\u001b[A\n",
      " 82%|████████▏ | 3454/4220 [3:40:56<49:07,  3.85s/it, loss=2.97, epoch=0.818, learning_rate=1.59e-6]\u001b[A\n",
      " 82%|████████▏ | 3455/4220 [3:40:59<48:47,  3.83s/it, loss=2.97, epoch=0.818, learning_rate=1.59e-6]\u001b[A\n",
      " 82%|████████▏ | 3455/4220 [3:40:59<48:47,  3.83s/it, loss=3.39, epoch=0.818, learning_rate=1.59e-6]\u001b[A\n",
      " 82%|████████▏ | 3456/4220 [3:41:03<48:33,  3.81s/it, loss=3.39, epoch=0.818, learning_rate=1.59e-6]\u001b[A\n",
      " 82%|████████▏ | 3456/4220 [3:41:03<48:33,  3.81s/it, loss=3.24, epoch=0.819, learning_rate=1.59e-6]\u001b[A\n",
      " 82%|████████▏ | 3457/4220 [3:41:07<48:23,  3.80s/it, loss=3.24, epoch=0.819, learning_rate=1.59e-6]\u001b[A\n",
      " 82%|████████▏ | 3457/4220 [3:41:07<48:23,  3.80s/it, loss=2.85, epoch=0.819, learning_rate=1.58e-6]\u001b[A\n",
      " 82%|████████▏ | 3458/4220 [3:41:11<48:15,  3.80s/it, loss=2.85, epoch=0.819, learning_rate=1.58e-6]\u001b[A\n",
      " 82%|████████▏ | 3458/4220 [3:41:11<48:15,  3.80s/it, loss=2.68, epoch=0.819, learning_rate=1.58e-6]\u001b[A\n",
      " 82%|████████▏ | 3459/4220 [3:41:14<48:07,  3.79s/it, loss=2.68, epoch=0.819, learning_rate=1.58e-6]\u001b[A\n",
      " 82%|████████▏ | 3459/4220 [3:41:14<48:07,  3.79s/it, loss=2.65, epoch=0.819, learning_rate=1.57e-6]\u001b[A\n",
      " 82%|████████▏ | 3460/4220 [3:41:18<48:01,  3.79s/it, loss=2.65, epoch=0.819, learning_rate=1.57e-6]\u001b[A\n",
      " 82%|████████▏ | 3460/4220 [3:41:18<48:01,  3.79s/it, loss=2.58, epoch=0.82, learning_rate=1.57e-6] \u001b[A\n",
      " 82%|████████▏ | 3461/4220 [3:41:22<47:56,  3.79s/it, loss=2.58, epoch=0.82, learning_rate=1.57e-6]\u001b[A\n",
      " 82%|████████▏ | 3461/4220 [3:41:22<47:56,  3.79s/it, loss=2.69, epoch=0.82, learning_rate=1.57e-6]\u001b[A\n",
      " 82%|████████▏ | 3462/4220 [3:41:26<47:51,  3.79s/it, loss=2.69, epoch=0.82, learning_rate=1.57e-6]\u001b[A\n",
      " 82%|████████▏ | 3462/4220 [3:41:26<47:51,  3.79s/it, loss=2.56, epoch=0.82, learning_rate=1.56e-6]\u001b[A\n",
      " 82%|████████▏ | 3463/4220 [3:41:30<47:46,  3.79s/it, loss=2.56, epoch=0.82, learning_rate=1.56e-6]\u001b[A\n",
      " 82%|████████▏ | 3463/4220 [3:41:30<47:46,  3.79s/it, loss=2.29, epoch=0.82, learning_rate=1.56e-6]\u001b[A\n",
      " 82%|████████▏ | 3464/4220 [3:41:33<47:42,  3.79s/it, loss=2.29, epoch=0.82, learning_rate=1.56e-6]\u001b[A\n",
      " 82%|████████▏ | 3464/4220 [3:41:33<47:42,  3.79s/it, loss=3.24, epoch=0.821, learning_rate=1.55e-6]\u001b[A\n",
      " 82%|████████▏ | 3465/4220 [3:41:37<47:37,  3.78s/it, loss=3.24, epoch=0.821, learning_rate=1.55e-6]\u001b[A\n",
      " 82%|████████▏ | 3465/4220 [3:41:37<47:37,  3.78s/it, loss=3.14, epoch=0.821, learning_rate=1.55e-6]\u001b[A\n",
      " 82%|████████▏ | 3466/4220 [3:41:41<47:33,  3.78s/it, loss=3.14, epoch=0.821, learning_rate=1.55e-6]\u001b[A\n",
      " 82%|████████▏ | 3466/4220 [3:41:41<47:33,  3.78s/it, loss=2.92, epoch=0.821, learning_rate=1.55e-6]\u001b[A\n",
      " 82%|████████▏ | 3467/4220 [3:41:45<47:29,  3.78s/it, loss=2.92, epoch=0.821, learning_rate=1.55e-6]\u001b[A\n",
      " 82%|████████▏ | 3467/4220 [3:41:45<47:29,  3.78s/it, loss=3, epoch=0.821, learning_rate=1.54e-6]   \u001b[A\n",
      " 82%|████████▏ | 3468/4220 [3:41:48<47:24,  3.78s/it, loss=3, epoch=0.821, learning_rate=1.54e-6]\u001b[A\n",
      " 82%|████████▏ | 3468/4220 [3:41:48<47:24,  3.78s/it, loss=2.83, epoch=0.822, learning_rate=1.54e-6]\u001b[A\n",
      " 82%|████████▏ | 3469/4220 [3:41:52<47:20,  3.78s/it, loss=2.83, epoch=0.822, learning_rate=1.54e-6]\u001b[A\n",
      " 82%|████████▏ | 3469/4220 [3:41:52<47:20,  3.78s/it, loss=2.84, epoch=0.822, learning_rate=1.53e-6]\u001b[A\n",
      " 82%|████████▏ | 3470/4220 [3:41:56<47:18,  3.78s/it, loss=2.84, epoch=0.822, learning_rate=1.53e-6]\u001b[A\n",
      " 82%|████████▏ | 3470/4220 [3:41:56<47:18,  3.78s/it, loss=2.42, epoch=0.822, learning_rate=1.53e-6]\u001b[A\n",
      " 82%|████████▏ | 3471/4220 [3:42:00<47:13,  3.78s/it, loss=2.42, epoch=0.822, learning_rate=1.53e-6]\u001b[A\n",
      " 82%|████████▏ | 3471/4220 [3:42:00<47:13,  3.78s/it, loss=2.89, epoch=0.822, learning_rate=1.53e-6]\u001b[A\n",
      " 82%|████████▏ | 3472/4220 [3:42:04<47:10,  3.78s/it, loss=2.89, epoch=0.822, learning_rate=1.53e-6]\u001b[A\n",
      " 82%|████████▏ | 3472/4220 [3:42:04<47:10,  3.78s/it, loss=3.32, epoch=0.823, learning_rate=1.52e-6]\u001b[A\n",
      " 82%|████████▏ | 3473/4220 [3:42:07<47:07,  3.79s/it, loss=3.32, epoch=0.823, learning_rate=1.52e-6]\u001b[A\n",
      " 82%|████████▏ | 3473/4220 [3:42:07<47:07,  3.79s/it, loss=2.89, epoch=0.823, learning_rate=1.52e-6]\u001b[A\n",
      " 82%|████████▏ | 3474/4220 [3:42:11<47:03,  3.79s/it, loss=2.89, epoch=0.823, learning_rate=1.52e-6]\u001b[A\n",
      " 82%|████████▏ | 3474/4220 [3:42:11<47:03,  3.79s/it, loss=2.84, epoch=0.823, learning_rate=1.51e-6]\u001b[A\n",
      " 82%|████████▏ | 3475/4220 [3:42:15<46:59,  3.78s/it, loss=2.84, epoch=0.823, learning_rate=1.51e-6]\u001b[A\n",
      " 82%|████████▏ | 3475/4220 [3:42:15<46:59,  3.78s/it, loss=3.03, epoch=0.823, learning_rate=1.51e-6]\u001b[A\n",
      " 82%|████████▏ | 3476/4220 [3:42:19<46:55,  3.78s/it, loss=3.03, epoch=0.823, learning_rate=1.51e-6]\u001b[A\n",
      " 82%|████████▏ | 3476/4220 [3:42:19<46:55,  3.78s/it, loss=2.97, epoch=0.823, learning_rate=1.51e-6]\u001b[A\n",
      " 82%|████████▏ | 3477/4220 [3:42:23<46:52,  3.79s/it, loss=2.97, epoch=0.823, learning_rate=1.51e-6]\u001b[A\n",
      " 82%|████████▏ | 3477/4220 [3:42:23<46:52,  3.79s/it, loss=2.52, epoch=0.824, learning_rate=1.5e-6] \u001b[A\n",
      " 82%|████████▏ | 3478/4220 [3:42:26<46:46,  3.78s/it, loss=2.52, epoch=0.824, learning_rate=1.5e-6]\u001b[A\n",
      " 82%|████████▏ | 3478/4220 [3:42:26<46:46,  3.78s/it, loss=2.93, epoch=0.824, learning_rate=1.5e-6]\u001b[A\n",
      " 82%|████████▏ | 3479/4220 [3:42:30<46:43,  3.78s/it, loss=2.93, epoch=0.824, learning_rate=1.5e-6]\u001b[A\n",
      " 82%|████████▏ | 3479/4220 [3:42:30<46:43,  3.78s/it, loss=3.25, epoch=0.824, learning_rate=1.49e-6]\u001b[A\n",
      " 82%|████████▏ | 3480/4220 [3:42:34<46:40,  3.78s/it, loss=3.25, epoch=0.824, learning_rate=1.49e-6]\u001b[A\n",
      " 82%|████████▏ | 3480/4220 [3:42:34<46:40,  3.78s/it, loss=3.08, epoch=0.824, learning_rate=1.49e-6]\u001b[A\n",
      " 82%|████████▏ | 3481/4220 [3:42:38<46:36,  3.78s/it, loss=3.08, epoch=0.824, learning_rate=1.49e-6]\u001b[A\n",
      " 82%|████████▏ | 3481/4220 [3:42:38<46:36,  3.78s/it, loss=2.88, epoch=0.825, learning_rate=1.49e-6]\u001b[A\n",
      " 83%|████████▎ | 3482/4220 [3:42:41<46:32,  3.78s/it, loss=2.88, epoch=0.825, learning_rate=1.49e-6]\u001b[A\n",
      " 83%|████████▎ | 3482/4220 [3:42:41<46:32,  3.78s/it, loss=2.98, epoch=0.825, learning_rate=1.48e-6]\u001b[A\n",
      " 83%|████████▎ | 3483/4220 [3:42:45<46:27,  3.78s/it, loss=2.98, epoch=0.825, learning_rate=1.48e-6]\u001b[A\n",
      " 83%|████████▎ | 3483/4220 [3:42:45<46:27,  3.78s/it, loss=2.74, epoch=0.825, learning_rate=1.48e-6]\u001b[A\n",
      " 83%|████████▎ | 3484/4220 [3:42:49<46:23,  3.78s/it, loss=2.74, epoch=0.825, learning_rate=1.48e-6]\u001b[A\n",
      " 83%|████████▎ | 3484/4220 [3:42:49<46:23,  3.78s/it, loss=2.96, epoch=0.825, learning_rate=1.47e-6]\u001b[A\n",
      " 83%|████████▎ | 3485/4220 [3:42:53<46:20,  3.78s/it, loss=2.96, epoch=0.825, learning_rate=1.47e-6]\u001b[A\n",
      " 83%|████████▎ | 3485/4220 [3:42:53<46:20,  3.78s/it, loss=3.15, epoch=0.826, learning_rate=1.47e-6]\u001b[A\n",
      " 83%|████████▎ | 3486/4220 [3:42:57<46:16,  3.78s/it, loss=3.15, epoch=0.826, learning_rate=1.47e-6]\u001b[A\n",
      " 83%|████████▎ | 3486/4220 [3:42:57<46:16,  3.78s/it, loss=2.94, epoch=0.826, learning_rate=1.47e-6]\u001b[A\n",
      " 83%|████████▎ | 3487/4220 [3:43:00<46:13,  3.78s/it, loss=2.94, epoch=0.826, learning_rate=1.47e-6]\u001b[A\n",
      " 83%|████████▎ | 3487/4220 [3:43:00<46:13,  3.78s/it, loss=2.63, epoch=0.826, learning_rate=1.46e-6]\u001b[A\n",
      " 83%|████████▎ | 3488/4220 [3:43:04<46:08,  3.78s/it, loss=2.63, epoch=0.826, learning_rate=1.46e-6]\u001b[A\n",
      " 83%|████████▎ | 3488/4220 [3:43:04<46:08,  3.78s/it, loss=2.52, epoch=0.826, learning_rate=1.46e-6]\u001b[A\n",
      " 83%|████████▎ | 3489/4220 [3:43:08<46:03,  3.78s/it, loss=2.52, epoch=0.826, learning_rate=1.46e-6]\u001b[A\n",
      " 83%|████████▎ | 3489/4220 [3:43:08<46:03,  3.78s/it, loss=3.13, epoch=0.827, learning_rate=1.46e-6]\u001b[A\n",
      " 83%|████████▎ | 3490/4220 [3:43:12<46:00,  3.78s/it, loss=3.13, epoch=0.827, learning_rate=1.46e-6]\u001b[A\n",
      " 83%|████████▎ | 3490/4220 [3:43:12<46:00,  3.78s/it, loss=2.69, epoch=0.827, learning_rate=1.45e-6]\u001b[A\n",
      " 83%|████████▎ | 3491/4220 [3:43:15<45:56,  3.78s/it, loss=2.69, epoch=0.827, learning_rate=1.45e-6]\u001b[A\n",
      " 83%|████████▎ | 3491/4220 [3:43:15<45:56,  3.78s/it, loss=2.41, epoch=0.827, learning_rate=1.45e-6]\u001b[A\n",
      " 83%|████████▎ | 3492/4220 [3:43:19<45:51,  3.78s/it, loss=2.41, epoch=0.827, learning_rate=1.45e-6]\u001b[A\n",
      " 83%|████████▎ | 3492/4220 [3:43:19<45:51,  3.78s/it, loss=3.12, epoch=0.827, learning_rate=1.44e-6]\u001b[A\n",
      " 83%|████████▎ | 3493/4220 [3:43:23<45:49,  3.78s/it, loss=3.12, epoch=0.827, learning_rate=1.44e-6]\u001b[A\n",
      " 83%|████████▎ | 3493/4220 [3:43:23<45:49,  3.78s/it, loss=2.65, epoch=0.827, learning_rate=1.44e-6]\u001b[A\n",
      " 83%|████████▎ | 3494/4220 [3:43:27<45:45,  3.78s/it, loss=2.65, epoch=0.827, learning_rate=1.44e-6]\u001b[A\n",
      " 83%|████████▎ | 3494/4220 [3:43:27<45:45,  3.78s/it, loss=2.87, epoch=0.828, learning_rate=1.44e-6]\u001b[A\n",
      " 83%|████████▎ | 3495/4220 [3:43:31<45:42,  3.78s/it, loss=2.87, epoch=0.828, learning_rate=1.44e-6]\u001b[A\n",
      " 83%|████████▎ | 3495/4220 [3:43:31<45:42,  3.78s/it, loss=2.73, epoch=0.828, learning_rate=1.43e-6]\u001b[A\n",
      " 83%|████████▎ | 3496/4220 [3:43:34<45:39,  3.78s/it, loss=2.73, epoch=0.828, learning_rate=1.43e-6]\u001b[A\n",
      " 83%|████████▎ | 3496/4220 [3:43:34<45:39,  3.78s/it, loss=2.77, epoch=0.828, learning_rate=1.43e-6]\u001b[A\n",
      " 83%|████████▎ | 3497/4220 [3:43:38<45:34,  3.78s/it, loss=2.77, epoch=0.828, learning_rate=1.43e-6]\u001b[A\n",
      " 83%|████████▎ | 3497/4220 [3:43:38<45:34,  3.78s/it, loss=2.6, epoch=0.828, learning_rate=1.42e-6] \u001b[A\n",
      " 83%|████████▎ | 3498/4220 [3:43:42<45:31,  3.78s/it, loss=2.6, epoch=0.828, learning_rate=1.42e-6]\u001b[A\n",
      " 83%|████████▎ | 3498/4220 [3:43:42<45:31,  3.78s/it, loss=3.18, epoch=0.829, learning_rate=1.42e-6]\u001b[A\n",
      " 83%|████████▎ | 3499/4220 [3:43:46<45:27,  3.78s/it, loss=3.18, epoch=0.829, learning_rate=1.42e-6]\u001b[A\n",
      " 83%|████████▎ | 3499/4220 [3:43:46<45:27,  3.78s/it, loss=2.78, epoch=0.829, learning_rate=1.42e-6]\u001b[A\n",
      " 83%|████████▎ | 3500/4220 [3:43:50<45:24,  3.78s/it, loss=2.78, epoch=0.829, learning_rate=1.42e-6]\u001b[A\n",
      " 83%|████████▎ | 3500/4220 [3:43:50<45:24,  3.78s/it, loss=2.85, epoch=0.829, learning_rate=1.41e-6]\u001b[A\n",
      " 83%|████████▎ | 3501/4220 [3:43:53<45:20,  3.78s/it, loss=2.85, epoch=0.829, learning_rate=1.41e-6]\u001b[A\n",
      " 83%|████████▎ | 3501/4220 [3:43:53<45:20,  3.78s/it, loss=3.16, epoch=0.829, learning_rate=1.41e-6]\u001b[A\n",
      " 83%|████████▎ | 3502/4220 [3:43:57<45:17,  3.78s/it, loss=3.16, epoch=0.829, learning_rate=1.41e-6]\u001b[A\n",
      " 83%|████████▎ | 3502/4220 [3:43:57<45:17,  3.78s/it, loss=2.5, epoch=0.83, learning_rate=1.41e-6]  \u001b[A\n",
      " 83%|████████▎ | 3503/4220 [3:44:01<45:13,  3.78s/it, loss=2.5, epoch=0.83, learning_rate=1.41e-6]\u001b[A\n",
      " 83%|████████▎ | 3503/4220 [3:44:01<45:13,  3.78s/it, loss=2.92, epoch=0.83, learning_rate=1.4e-6]\u001b[A\n",
      " 83%|████████▎ | 3504/4220 [3:44:05<45:08,  3.78s/it, loss=2.92, epoch=0.83, learning_rate=1.4e-6]\u001b[A\n",
      " 83%|████████▎ | 3504/4220 [3:44:05<45:08,  3.78s/it, loss=2.83, epoch=0.83, learning_rate=1.4e-6]\u001b[A\n",
      " 83%|████████▎ | 3505/4220 [3:44:08<45:04,  3.78s/it, loss=2.83, epoch=0.83, learning_rate=1.4e-6]\u001b[A\n",
      " 83%|████████▎ | 3505/4220 [3:44:08<45:04,  3.78s/it, loss=2.96, epoch=0.83, learning_rate=1.39e-6]\u001b[A\n",
      " 83%|████████▎ | 3506/4220 [3:44:12<44:59,  3.78s/it, loss=2.96, epoch=0.83, learning_rate=1.39e-6]\u001b[A\n",
      " 83%|████████▎ | 3506/4220 [3:44:12<44:59,  3.78s/it, loss=2.44, epoch=0.831, learning_rate=1.39e-6]\u001b[A\n",
      " 83%|████████▎ | 3507/4220 [3:44:16<44:56,  3.78s/it, loss=2.44, epoch=0.831, learning_rate=1.39e-6]\u001b[A\n",
      " 83%|████████▎ | 3507/4220 [3:44:16<44:56,  3.78s/it, loss=2.53, epoch=0.831, learning_rate=1.39e-6]\u001b[A\n",
      " 83%|████████▎ | 3508/4220 [3:44:20<44:52,  3.78s/it, loss=2.53, epoch=0.831, learning_rate=1.39e-6]\u001b[A\n",
      " 83%|████████▎ | 3508/4220 [3:44:20<44:52,  3.78s/it, loss=2.12, epoch=0.831, learning_rate=1.38e-6]\u001b[A\n",
      " 83%|████████▎ | 3509/4220 [3:44:24<44:49,  3.78s/it, loss=2.12, epoch=0.831, learning_rate=1.38e-6]\u001b[A\n",
      " 83%|████████▎ | 3509/4220 [3:44:24<44:49,  3.78s/it, loss=3.17, epoch=0.831, learning_rate=1.38e-6]\u001b[A\n",
      " 83%|████████▎ | 3510/4220 [3:44:27<44:45,  3.78s/it, loss=3.17, epoch=0.831, learning_rate=1.38e-6]\u001b[A\n",
      " 83%|████████▎ | 3510/4220 [3:44:27<44:45,  3.78s/it, loss=2.79, epoch=0.832, learning_rate=1.37e-6]\u001b[A\n",
      " 83%|████████▎ | 3511/4220 [3:44:31<44:41,  3.78s/it, loss=2.79, epoch=0.832, learning_rate=1.37e-6]\u001b[A\n",
      " 83%|████████▎ | 3511/4220 [3:44:31<44:41,  3.78s/it, loss=2.59, epoch=0.832, learning_rate=1.37e-6]\u001b[A\n",
      " 83%|████████▎ | 3512/4220 [3:44:35<44:38,  3.78s/it, loss=2.59, epoch=0.832, learning_rate=1.37e-6]\u001b[A\n",
      " 83%|████████▎ | 3512/4220 [3:44:35<44:38,  3.78s/it, loss=2.7, epoch=0.832, learning_rate=1.37e-6] \u001b[A\n",
      " 83%|████████▎ | 3513/4220 [3:44:39<44:35,  3.78s/it, loss=2.7, epoch=0.832, learning_rate=1.37e-6]\u001b[A\n",
      " 83%|████████▎ | 3513/4220 [3:44:39<44:35,  3.78s/it, loss=3.08, epoch=0.832, learning_rate=1.36e-6]\u001b[A\n",
      " 83%|████████▎ | 3514/4220 [3:44:43<44:31,  3.78s/it, loss=3.08, epoch=0.832, learning_rate=1.36e-6]\u001b[A\n",
      " 83%|████████▎ | 3514/4220 [3:44:43<44:31,  3.78s/it, loss=2.81, epoch=0.832, learning_rate=1.36e-6]\u001b[A\n",
      " 83%|████████▎ | 3515/4220 [3:44:46<44:26,  3.78s/it, loss=2.81, epoch=0.832, learning_rate=1.36e-6]\u001b[A\n",
      " 83%|████████▎ | 3515/4220 [3:44:46<44:26,  3.78s/it, loss=3.09, epoch=0.833, learning_rate=1.36e-6]\u001b[A\n",
      " 83%|████████▎ | 3516/4220 [3:44:50<44:24,  3.78s/it, loss=3.09, epoch=0.833, learning_rate=1.36e-6]\u001b[A\n",
      " 83%|████████▎ | 3516/4220 [3:44:50<44:24,  3.78s/it, loss=2.66, epoch=0.833, learning_rate=1.35e-6]\u001b[A\n",
      " 83%|████████▎ | 3517/4220 [3:44:54<44:19,  3.78s/it, loss=2.66, epoch=0.833, learning_rate=1.35e-6]\u001b[A\n",
      " 83%|████████▎ | 3517/4220 [3:44:54<44:19,  3.78s/it, loss=3.04, epoch=0.833, learning_rate=1.35e-6]\u001b[A\n",
      " 83%|████████▎ | 3518/4220 [3:44:58<44:15,  3.78s/it, loss=3.04, epoch=0.833, learning_rate=1.35e-6]\u001b[A\n",
      " 83%|████████▎ | 3518/4220 [3:44:58<44:15,  3.78s/it, loss=3.22, epoch=0.833, learning_rate=1.34e-6]\u001b[A\n",
      " 83%|████████▎ | 3519/4220 [3:45:01<44:11,  3.78s/it, loss=3.22, epoch=0.833, learning_rate=1.34e-6]\u001b[A\n",
      " 83%|████████▎ | 3519/4220 [3:45:01<44:11,  3.78s/it, loss=3.13, epoch=0.834, learning_rate=1.34e-6]\u001b[A\n",
      " 83%|████████▎ | 3520/4220 [3:45:05<44:07,  3.78s/it, loss=3.13, epoch=0.834, learning_rate=1.34e-6]\u001b[A\n",
      " 83%|████████▎ | 3520/4220 [3:45:05<44:07,  3.78s/it, loss=2.95, epoch=0.834, learning_rate=1.34e-6]\u001b[A\n",
      " 83%|████████▎ | 3521/4220 [3:45:09<44:03,  3.78s/it, loss=2.95, epoch=0.834, learning_rate=1.34e-6]\u001b[A\n",
      " 83%|████████▎ | 3521/4220 [3:45:09<44:03,  3.78s/it, loss=2.9, epoch=0.834, learning_rate=1.33e-6] \u001b[A\n",
      " 83%|████████▎ | 3522/4220 [3:45:13<44:01,  3.78s/it, loss=2.9, epoch=0.834, learning_rate=1.33e-6]\u001b[A\n",
      " 83%|████████▎ | 3522/4220 [3:45:13<44:01,  3.78s/it, loss=3.28, epoch=0.834, learning_rate=1.33e-6]\u001b[A\n",
      " 83%|████████▎ | 3523/4220 [3:45:17<43:57,  3.78s/it, loss=3.28, epoch=0.834, learning_rate=1.33e-6]\u001b[A\n",
      " 83%|████████▎ | 3523/4220 [3:45:17<43:57,  3.78s/it, loss=2.8, epoch=0.835, learning_rate=1.33e-6] \u001b[A\n",
      " 84%|████████▎ | 3524/4220 [3:45:20<43:51,  3.78s/it, loss=2.8, epoch=0.835, learning_rate=1.33e-6]\u001b[A\n",
      " 84%|████████▎ | 3524/4220 [3:45:20<43:51,  3.78s/it, loss=2.69, epoch=0.835, learning_rate=1.32e-6]\u001b[A\n",
      " 84%|████████▎ | 3525/4220 [3:45:24<43:48,  3.78s/it, loss=2.69, epoch=0.835, learning_rate=1.32e-6]\u001b[A\n",
      " 84%|████████▎ | 3525/4220 [3:45:24<43:48,  3.78s/it, loss=2.95, epoch=0.835, learning_rate=1.32e-6]\u001b[A\n",
      " 84%|████████▎ | 3526/4220 [3:45:28<43:43,  3.78s/it, loss=2.95, epoch=0.835, learning_rate=1.32e-6]\u001b[A\n",
      " 84%|████████▎ | 3526/4220 [3:45:28<43:43,  3.78s/it, loss=2.95, epoch=0.835, learning_rate=1.31e-6]\u001b[A\n",
      " 84%|████████▎ | 3527/4220 [3:45:32<43:40,  3.78s/it, loss=2.95, epoch=0.835, learning_rate=1.31e-6]\u001b[A\n",
      " 84%|████████▎ | 3527/4220 [3:45:32<43:40,  3.78s/it, loss=2.75, epoch=0.836, learning_rate=1.31e-6]\u001b[A\n",
      " 84%|████████▎ | 3528/4220 [3:45:35<43:37,  3.78s/it, loss=2.75, epoch=0.836, learning_rate=1.31e-6]\u001b[A\n",
      " 84%|████████▎ | 3528/4220 [3:45:35<43:37,  3.78s/it, loss=2.9, epoch=0.836, learning_rate=1.31e-6] \u001b[A\n",
      " 84%|████████▎ | 3529/4220 [3:45:39<43:34,  3.78s/it, loss=2.9, epoch=0.836, learning_rate=1.31e-6]\u001b[A\n",
      " 84%|████████▎ | 3529/4220 [3:45:39<43:34,  3.78s/it, loss=2.55, epoch=0.836, learning_rate=1.3e-6]\u001b[A\n",
      " 84%|████████▎ | 3530/4220 [3:45:43<43:30,  3.78s/it, loss=2.55, epoch=0.836, learning_rate=1.3e-6]\u001b[A\n",
      " 84%|████████▎ | 3530/4220 [3:45:43<43:30,  3.78s/it, loss=2.48, epoch=0.836, learning_rate=1.3e-6]\u001b[A\n",
      " 84%|████████▎ | 3531/4220 [3:45:47<43:25,  3.78s/it, loss=2.48, epoch=0.836, learning_rate=1.3e-6]\u001b[A\n",
      " 84%|████████▎ | 3531/4220 [3:45:47<43:25,  3.78s/it, loss=2.74, epoch=0.836, learning_rate=1.3e-6]\u001b[A\n",
      " 84%|████████▎ | 3532/4220 [3:45:51<43:21,  3.78s/it, loss=2.74, epoch=0.836, learning_rate=1.3e-6]\u001b[A\n",
      " 84%|████████▎ | 3532/4220 [3:45:51<43:21,  3.78s/it, loss=2.95, epoch=0.837, learning_rate=1.29e-6]\u001b[A\n",
      " 84%|████████▎ | 3533/4220 [3:45:54<43:17,  3.78s/it, loss=2.95, epoch=0.837, learning_rate=1.29e-6]\u001b[A\n",
      " 84%|████████▎ | 3533/4220 [3:45:54<43:17,  3.78s/it, loss=3.01, epoch=0.837, learning_rate=1.29e-6]\u001b[A\n",
      " 84%|████████▎ | 3534/4220 [3:45:58<43:13,  3.78s/it, loss=3.01, epoch=0.837, learning_rate=1.29e-6]\u001b[A\n",
      " 84%|████████▎ | 3534/4220 [3:45:58<43:13,  3.78s/it, loss=2.99, epoch=0.837, learning_rate=1.29e-6]\u001b[A\n",
      " 84%|████████▍ | 3535/4220 [3:46:02<43:09,  3.78s/it, loss=2.99, epoch=0.837, learning_rate=1.29e-6]\u001b[A\n",
      " 84%|████████▍ | 3535/4220 [3:46:02<43:09,  3.78s/it, loss=2.67, epoch=0.837, learning_rate=1.28e-6]\u001b[A\n",
      " 84%|████████▍ | 3536/4220 [3:46:06<43:05,  3.78s/it, loss=2.67, epoch=0.837, learning_rate=1.28e-6]\u001b[A\n",
      " 84%|████████▍ | 3536/4220 [3:46:06<43:05,  3.78s/it, loss=3.2, epoch=0.838, learning_rate=1.28e-6] \u001b[A\n",
      " 84%|████████▍ | 3537/4220 [3:46:09<43:02,  3.78s/it, loss=3.2, epoch=0.838, learning_rate=1.28e-6]\u001b[A\n",
      " 84%|████████▍ | 3537/4220 [3:46:09<43:02,  3.78s/it, loss=3.01, epoch=0.838, learning_rate=1.27e-6]\u001b[A\n",
      " 84%|████████▍ | 3538/4220 [3:46:13<42:57,  3.78s/it, loss=3.01, epoch=0.838, learning_rate=1.27e-6]\u001b[A\n",
      " 84%|████████▍ | 3538/4220 [3:46:13<42:57,  3.78s/it, loss=2.43, epoch=0.838, learning_rate=1.27e-6]\u001b[A\n",
      " 84%|████████▍ | 3539/4220 [3:46:17<42:54,  3.78s/it, loss=2.43, epoch=0.838, learning_rate=1.27e-6]\u001b[A\n",
      " 84%|████████▍ | 3539/4220 [3:46:17<42:54,  3.78s/it, loss=2.7, epoch=0.838, learning_rate=1.27e-6] \u001b[A\n",
      " 84%|████████▍ | 3540/4220 [3:46:21<42:50,  3.78s/it, loss=2.7, epoch=0.838, learning_rate=1.27e-6]\u001b[A\n",
      " 84%|████████▍ | 3540/4220 [3:46:21<42:50,  3.78s/it, loss=2.81, epoch=0.839, learning_rate=1.26e-6]\u001b[A\n",
      " 84%|████████▍ | 3541/4220 [3:46:25<42:46,  3.78s/it, loss=2.81, epoch=0.839, learning_rate=1.26e-6]\u001b[A\n",
      " 84%|████████▍ | 3541/4220 [3:46:25<42:46,  3.78s/it, loss=2.89, epoch=0.839, learning_rate=1.26e-6]\u001b[A\n",
      " 84%|████████▍ | 3542/4220 [3:46:28<42:43,  3.78s/it, loss=2.89, epoch=0.839, learning_rate=1.26e-6]\u001b[A\n",
      " 84%|████████▍ | 3542/4220 [3:46:28<42:43,  3.78s/it, loss=2.48, epoch=0.839, learning_rate=1.26e-6]\u001b[A\n",
      " 84%|████████▍ | 3543/4220 [3:46:32<42:39,  3.78s/it, loss=2.48, epoch=0.839, learning_rate=1.26e-6]\u001b[A\n",
      " 84%|████████▍ | 3543/4220 [3:46:32<42:39,  3.78s/it, loss=2.62, epoch=0.839, learning_rate=1.25e-6]\u001b[A\n",
      " 84%|████████▍ | 3544/4220 [3:46:36<42:35,  3.78s/it, loss=2.62, epoch=0.839, learning_rate=1.25e-6]\u001b[A\n",
      " 84%|████████▍ | 3544/4220 [3:46:36<42:35,  3.78s/it, loss=2.59, epoch=0.84, learning_rate=1.25e-6] \u001b[A\n",
      " 84%|████████▍ | 3545/4220 [3:46:40<42:31,  3.78s/it, loss=2.59, epoch=0.84, learning_rate=1.25e-6]\u001b[A\n",
      " 84%|████████▍ | 3545/4220 [3:46:40<42:31,  3.78s/it, loss=2.4, epoch=0.84, learning_rate=1.25e-6] \u001b[A\n",
      " 84%|████████▍ | 3546/4220 [3:46:44<42:27,  3.78s/it, loss=2.4, epoch=0.84, learning_rate=1.25e-6]\u001b[A\n",
      " 84%|████████▍ | 3546/4220 [3:46:44<42:27,  3.78s/it, loss=2.61, epoch=0.84, learning_rate=1.24e-6]\u001b[A\n",
      " 84%|████████▍ | 3547/4220 [3:46:47<42:24,  3.78s/it, loss=2.61, epoch=0.84, learning_rate=1.24e-6]\u001b[A\n",
      " 84%|████████▍ | 3547/4220 [3:46:47<42:24,  3.78s/it, loss=2.89, epoch=0.84, learning_rate=1.24e-6]\u001b[A\n",
      " 84%|████████▍ | 3548/4220 [3:46:51<42:20,  3.78s/it, loss=2.89, epoch=0.84, learning_rate=1.24e-6]\u001b[A\n",
      " 84%|████████▍ | 3548/4220 [3:46:51<42:20,  3.78s/it, loss=2.91, epoch=0.841, learning_rate=1.23e-6]\u001b[A\n",
      " 84%|████████▍ | 3549/4220 [3:46:55<42:16,  3.78s/it, loss=2.91, epoch=0.841, learning_rate=1.23e-6]\u001b[A\n",
      " 84%|████████▍ | 3549/4220 [3:46:55<42:16,  3.78s/it, loss=2.67, epoch=0.841, learning_rate=1.23e-6]\u001b[A\n",
      " 84%|████████▍ | 3550/4220 [3:46:59<42:55,  3.84s/it, loss=2.67, epoch=0.841, learning_rate=1.23e-6]\u001b[A\n",
      " 84%|████████▍ | 3550/4220 [3:46:59<42:55,  3.84s/it, loss=2.94, epoch=0.841, learning_rate=1.23e-6]\u001b[A\n",
      " 84%|████████▍ | 3551/4220 [3:47:03<42:38,  3.82s/it, loss=2.94, epoch=0.841, learning_rate=1.23e-6]\u001b[A\n",
      " 84%|████████▍ | 3551/4220 [3:47:03<42:38,  3.82s/it, loss=3.28, epoch=0.841, learning_rate=1.22e-6]\u001b[A\n",
      " 84%|████████▍ | 3552/4220 [3:47:06<42:25,  3.81s/it, loss=3.28, epoch=0.841, learning_rate=1.22e-6]\u001b[A\n",
      " 84%|████████▍ | 3552/4220 [3:47:06<42:25,  3.81s/it, loss=2.41, epoch=0.841, learning_rate=1.22e-6]\u001b[A\n",
      " 84%|████████▍ | 3553/4220 [3:47:10<42:15,  3.80s/it, loss=2.41, epoch=0.841, learning_rate=1.22e-6]\u001b[A\n",
      " 84%|████████▍ | 3553/4220 [3:47:10<42:15,  3.80s/it, loss=3.27, epoch=0.842, learning_rate=1.22e-6]\u001b[A\n",
      " 84%|████████▍ | 3554/4220 [3:47:14<42:07,  3.79s/it, loss=3.27, epoch=0.842, learning_rate=1.22e-6]\u001b[A\n",
      " 84%|████████▍ | 3554/4220 [3:47:14<42:07,  3.79s/it, loss=3.07, epoch=0.842, learning_rate=1.21e-6]\u001b[A\n",
      " 84%|████████▍ | 3555/4220 [3:47:18<42:00,  3.79s/it, loss=3.07, epoch=0.842, learning_rate=1.21e-6]\u001b[A\n",
      " 84%|████████▍ | 3555/4220 [3:47:18<42:00,  3.79s/it, loss=2.38, epoch=0.842, learning_rate=1.21e-6]\u001b[A\n",
      " 84%|████████▍ | 3556/4220 [3:47:22<41:55,  3.79s/it, loss=2.38, epoch=0.842, learning_rate=1.21e-6]\u001b[A\n",
      " 84%|████████▍ | 3556/4220 [3:47:22<41:55,  3.79s/it, loss=2.5, epoch=0.842, learning_rate=1.21e-6] \u001b[A\n",
      " 84%|████████▍ | 3557/4220 [3:47:25<41:50,  3.79s/it, loss=2.5, epoch=0.842, learning_rate=1.21e-6]\u001b[A\n",
      " 84%|████████▍ | 3557/4220 [3:47:25<41:50,  3.79s/it, loss=2.7, epoch=0.843, learning_rate=1.2e-6] \u001b[A\n",
      " 84%|████████▍ | 3558/4220 [3:47:29<41:44,  3.78s/it, loss=2.7, epoch=0.843, learning_rate=1.2e-6]\u001b[A\n",
      " 84%|████████▍ | 3558/4220 [3:47:29<41:44,  3.78s/it, loss=2.66, epoch=0.843, learning_rate=1.2e-6]\u001b[A\n",
      " 84%|████████▍ | 3559/4220 [3:47:33<41:41,  3.78s/it, loss=2.66, epoch=0.843, learning_rate=1.2e-6]\u001b[A\n",
      " 84%|████████▍ | 3559/4220 [3:47:33<41:41,  3.78s/it, loss=2.74, epoch=0.843, learning_rate=1.2e-6]\u001b[A\n",
      " 84%|████████▍ | 3560/4220 [3:47:37<41:36,  3.78s/it, loss=2.74, epoch=0.843, learning_rate=1.2e-6]\u001b[A\n",
      " 84%|████████▍ | 3560/4220 [3:47:37<41:36,  3.78s/it, loss=2.67, epoch=0.843, learning_rate=1.19e-6]\u001b[A\n",
      " 84%|████████▍ | 3561/4220 [3:47:40<41:31,  3.78s/it, loss=2.67, epoch=0.843, learning_rate=1.19e-6]\u001b[A\n",
      " 84%|████████▍ | 3561/4220 [3:47:40<41:31,  3.78s/it, loss=2.24, epoch=0.844, learning_rate=1.19e-6]\u001b[A\n",
      " 84%|████████▍ | 3562/4220 [3:47:44<41:27,  3.78s/it, loss=2.24, epoch=0.844, learning_rate=1.19e-6]\u001b[A\n",
      " 84%|████████▍ | 3562/4220 [3:47:44<41:27,  3.78s/it, loss=2.8, epoch=0.844, learning_rate=1.18e-6] \u001b[A\n",
      " 84%|████████▍ | 3563/4220 [3:47:48<41:23,  3.78s/it, loss=2.8, epoch=0.844, learning_rate=1.18e-6]\u001b[A\n",
      " 84%|████████▍ | 3563/4220 [3:47:48<41:23,  3.78s/it, loss=2.85, epoch=0.844, learning_rate=1.18e-6]\u001b[A\n",
      " 84%|████████▍ | 3564/4220 [3:47:52<41:19,  3.78s/it, loss=2.85, epoch=0.844, learning_rate=1.18e-6]\u001b[A\n",
      " 84%|████████▍ | 3564/4220 [3:47:52<41:19,  3.78s/it, loss=3.3, epoch=0.844, learning_rate=1.18e-6] \u001b[A\n",
      " 84%|████████▍ | 3565/4220 [3:47:56<41:16,  3.78s/it, loss=3.3, epoch=0.844, learning_rate=1.18e-6]\u001b[A\n",
      " 84%|████████▍ | 3565/4220 [3:47:56<41:16,  3.78s/it, loss=2.74, epoch=0.845, learning_rate=1.17e-6]\u001b[A\n",
      " 85%|████████▍ | 3566/4220 [3:47:59<41:13,  3.78s/it, loss=2.74, epoch=0.845, learning_rate=1.17e-6]\u001b[A\n",
      " 85%|████████▍ | 3566/4220 [3:47:59<41:13,  3.78s/it, loss=2.75, epoch=0.845, learning_rate=1.17e-6]\u001b[A\n",
      " 85%|████████▍ | 3567/4220 [3:48:03<41:08,  3.78s/it, loss=2.75, epoch=0.845, learning_rate=1.17e-6]\u001b[A\n",
      " 85%|████████▍ | 3567/4220 [3:48:03<41:08,  3.78s/it, loss=2.28, epoch=0.845, learning_rate=1.17e-6]\u001b[A\n",
      " 85%|████████▍ | 3568/4220 [3:48:07<41:04,  3.78s/it, loss=2.28, epoch=0.845, learning_rate=1.17e-6]\u001b[A\n",
      " 85%|████████▍ | 3568/4220 [3:48:07<41:04,  3.78s/it, loss=2.6, epoch=0.845, learning_rate=1.16e-6] \u001b[A\n",
      " 85%|████████▍ | 3569/4220 [3:48:11<40:59,  3.78s/it, loss=2.6, epoch=0.845, learning_rate=1.16e-6]\u001b[A\n",
      " 85%|████████▍ | 3569/4220 [3:48:11<40:59,  3.78s/it, loss=2.95, epoch=0.845, learning_rate=1.16e-6]\u001b[A\n",
      " 85%|████████▍ | 3570/4220 [3:48:14<40:57,  3.78s/it, loss=2.95, epoch=0.845, learning_rate=1.16e-6]\u001b[A\n",
      " 85%|████████▍ | 3570/4220 [3:48:14<40:57,  3.78s/it, loss=3.44, epoch=0.846, learning_rate=1.16e-6]\u001b[A\n",
      " 85%|████████▍ | 3571/4220 [3:48:18<40:54,  3.78s/it, loss=3.44, epoch=0.846, learning_rate=1.16e-6]\u001b[A\n",
      " 85%|████████▍ | 3571/4220 [3:48:18<40:54,  3.78s/it, loss=2.71, epoch=0.846, learning_rate=1.15e-6]\u001b[A\n",
      " 85%|████████▍ | 3572/4220 [3:48:22<40:50,  3.78s/it, loss=2.71, epoch=0.846, learning_rate=1.15e-6]\u001b[A\n",
      " 85%|████████▍ | 3572/4220 [3:48:22<40:50,  3.78s/it, loss=3.12, epoch=0.846, learning_rate=1.15e-6]\u001b[A\n",
      " 85%|████████▍ | 3573/4220 [3:48:26<40:47,  3.78s/it, loss=3.12, epoch=0.846, learning_rate=1.15e-6]\u001b[A\n",
      " 85%|████████▍ | 3573/4220 [3:48:26<40:47,  3.78s/it, loss=2.93, epoch=0.846, learning_rate=1.15e-6]\u001b[A\n",
      " 85%|████████▍ | 3574/4220 [3:48:30<40:42,  3.78s/it, loss=2.93, epoch=0.846, learning_rate=1.15e-6]\u001b[A\n",
      " 85%|████████▍ | 3574/4220 [3:48:30<40:42,  3.78s/it, loss=3.14, epoch=0.847, learning_rate=1.14e-6]\u001b[A\n",
      " 85%|████████▍ | 3575/4220 [3:48:33<40:37,  3.78s/it, loss=3.14, epoch=0.847, learning_rate=1.14e-6]\u001b[A\n",
      " 85%|████████▍ | 3575/4220 [3:48:33<40:37,  3.78s/it, loss=2.72, epoch=0.847, learning_rate=1.14e-6]\u001b[A\n",
      " 85%|████████▍ | 3576/4220 [3:48:37<40:35,  3.78s/it, loss=2.72, epoch=0.847, learning_rate=1.14e-6]\u001b[A\n",
      " 85%|████████▍ | 3576/4220 [3:48:37<40:35,  3.78s/it, loss=3.21, epoch=0.847, learning_rate=1.14e-6]\u001b[A\n",
      " 85%|████████▍ | 3577/4220 [3:48:41<40:30,  3.78s/it, loss=3.21, epoch=0.847, learning_rate=1.14e-6]\u001b[A\n",
      " 85%|████████▍ | 3577/4220 [3:48:41<40:30,  3.78s/it, loss=2.99, epoch=0.847, learning_rate=1.13e-6]\u001b[A\n",
      " 85%|████████▍ | 3578/4220 [3:48:45<40:26,  3.78s/it, loss=2.99, epoch=0.847, learning_rate=1.13e-6]\u001b[A\n",
      " 85%|████████▍ | 3578/4220 [3:48:45<40:26,  3.78s/it, loss=2.89, epoch=0.848, learning_rate=1.13e-6]\u001b[A\n",
      " 85%|████████▍ | 3579/4220 [3:48:48<40:22,  3.78s/it, loss=2.89, epoch=0.848, learning_rate=1.13e-6]\u001b[A\n",
      " 85%|████████▍ | 3579/4220 [3:48:48<40:22,  3.78s/it, loss=2.81, epoch=0.848, learning_rate=1.13e-6]\u001b[A\n",
      " 85%|████████▍ | 3580/4220 [3:48:52<40:18,  3.78s/it, loss=2.81, epoch=0.848, learning_rate=1.13e-6]\u001b[A\n",
      " 85%|████████▍ | 3580/4220 [3:48:52<40:18,  3.78s/it, loss=2.46, epoch=0.848, learning_rate=1.12e-6]\u001b[A\n",
      " 85%|████████▍ | 3581/4220 [3:48:56<40:15,  3.78s/it, loss=2.46, epoch=0.848, learning_rate=1.12e-6]\u001b[A\n",
      " 85%|████████▍ | 3581/4220 [3:48:56<40:15,  3.78s/it, loss=2.28, epoch=0.848, learning_rate=1.12e-6]\u001b[A\n",
      " 85%|████████▍ | 3582/4220 [3:49:00<40:10,  3.78s/it, loss=2.28, epoch=0.848, learning_rate=1.12e-6]\u001b[A\n",
      " 85%|████████▍ | 3582/4220 [3:49:00<40:10,  3.78s/it, loss=3.25, epoch=0.849, learning_rate=1.12e-6]\u001b[A\n",
      " 85%|████████▍ | 3583/4220 [3:49:04<40:08,  3.78s/it, loss=3.25, epoch=0.849, learning_rate=1.12e-6]\u001b[A\n",
      " 85%|████████▍ | 3583/4220 [3:49:04<40:08,  3.78s/it, loss=2.73, epoch=0.849, learning_rate=1.11e-6]\u001b[A\n",
      " 85%|████████▍ | 3584/4220 [3:49:07<40:05,  3.78s/it, loss=2.73, epoch=0.849, learning_rate=1.11e-6]\u001b[A\n",
      " 85%|████████▍ | 3584/4220 [3:49:07<40:05,  3.78s/it, loss=2.34, epoch=0.849, learning_rate=1.11e-6]\u001b[A\n",
      " 85%|████████▍ | 3585/4220 [3:49:11<40:00,  3.78s/it, loss=2.34, epoch=0.849, learning_rate=1.11e-6]\u001b[A\n",
      " 85%|████████▍ | 3585/4220 [3:49:11<40:00,  3.78s/it, loss=3.16, epoch=0.849, learning_rate=1.11e-6]\u001b[A\n",
      " 85%|████████▍ | 3586/4220 [3:49:15<39:55,  3.78s/it, loss=3.16, epoch=0.849, learning_rate=1.11e-6]\u001b[A\n",
      " 85%|████████▍ | 3586/4220 [3:49:15<39:55,  3.78s/it, loss=2.12, epoch=0.85, learning_rate=1.1e-6]  \u001b[A\n",
      " 85%|████████▌ | 3587/4220 [3:49:19<39:51,  3.78s/it, loss=2.12, epoch=0.85, learning_rate=1.1e-6]\u001b[A\n",
      " 85%|████████▌ | 3587/4220 [3:49:19<39:51,  3.78s/it, loss=2.57, epoch=0.85, learning_rate=1.1e-6]\u001b[A\n",
      " 85%|████████▌ | 3588/4220 [3:49:22<39:49,  3.78s/it, loss=2.57, epoch=0.85, learning_rate=1.1e-6]\u001b[A\n",
      " 85%|████████▌ | 3588/4220 [3:49:22<39:49,  3.78s/it, loss=2.74, epoch=0.85, learning_rate=1.1e-6]\u001b[A\n",
      " 85%|████████▌ | 3589/4220 [3:49:26<39:46,  3.78s/it, loss=2.74, epoch=0.85, learning_rate=1.1e-6]\u001b[A\n",
      " 85%|████████▌ | 3589/4220 [3:49:26<39:46,  3.78s/it, loss=2.99, epoch=0.85, learning_rate=1.09e-6]\u001b[A\n",
      " 85%|████████▌ | 3590/4220 [3:49:30<39:43,  3.78s/it, loss=2.99, epoch=0.85, learning_rate=1.09e-6]\u001b[A\n",
      " 85%|████████▌ | 3590/4220 [3:49:30<39:43,  3.78s/it, loss=3.12, epoch=0.85, learning_rate=1.09e-6]\u001b[A\n",
      " 85%|████████▌ | 3591/4220 [3:49:34<39:39,  3.78s/it, loss=3.12, epoch=0.85, learning_rate=1.09e-6]\u001b[A\n",
      " 85%|████████▌ | 3591/4220 [3:49:34<39:39,  3.78s/it, loss=2.62, epoch=0.851, learning_rate=1.08e-6]\u001b[A\n",
      " 85%|████████▌ | 3592/4220 [3:49:38<39:36,  3.78s/it, loss=2.62, epoch=0.851, learning_rate=1.08e-6]\u001b[A\n",
      " 85%|████████▌ | 3592/4220 [3:49:38<39:36,  3.78s/it, loss=3.22, epoch=0.851, learning_rate=1.08e-6]\u001b[A\n",
      " 85%|████████▌ | 3593/4220 [3:49:41<39:32,  3.78s/it, loss=3.22, epoch=0.851, learning_rate=1.08e-6]\u001b[A\n",
      " 85%|████████▌ | 3593/4220 [3:49:41<39:32,  3.78s/it, loss=3.01, epoch=0.851, learning_rate=1.08e-6]\u001b[A\n",
      " 85%|████████▌ | 3594/4220 [3:49:45<39:27,  3.78s/it, loss=3.01, epoch=0.851, learning_rate=1.08e-6]\u001b[A\n",
      " 85%|████████▌ | 3594/4220 [3:49:45<39:27,  3.78s/it, loss=3.05, epoch=0.851, learning_rate=1.07e-6]\u001b[A\n",
      " 85%|████████▌ | 3595/4220 [3:49:49<39:22,  3.78s/it, loss=3.05, epoch=0.851, learning_rate=1.07e-6]\u001b[A\n",
      " 85%|████████▌ | 3595/4220 [3:49:49<39:22,  3.78s/it, loss=2.34, epoch=0.852, learning_rate=1.07e-6]\u001b[A\n",
      " 85%|████████▌ | 3596/4220 [3:49:53<39:19,  3.78s/it, loss=2.34, epoch=0.852, learning_rate=1.07e-6]\u001b[A\n",
      " 85%|████████▌ | 3596/4220 [3:49:53<39:19,  3.78s/it, loss=3.07, epoch=0.852, learning_rate=1.07e-6]\u001b[A\n",
      " 85%|████████▌ | 3597/4220 [3:49:57<39:14,  3.78s/it, loss=3.07, epoch=0.852, learning_rate=1.07e-6]\u001b[A\n",
      " 85%|████████▌ | 3597/4220 [3:49:57<39:14,  3.78s/it, loss=2.76, epoch=0.852, learning_rate=1.06e-6]\u001b[A\n",
      " 85%|████████▌ | 3598/4220 [3:50:00<39:11,  3.78s/it, loss=2.76, epoch=0.852, learning_rate=1.06e-6]\u001b[A\n",
      " 85%|████████▌ | 3598/4220 [3:50:00<39:11,  3.78s/it, loss=3.15, epoch=0.852, learning_rate=1.06e-6]\u001b[A\n",
      " 85%|████████▌ | 3599/4220 [3:50:04<39:07,  3.78s/it, loss=3.15, epoch=0.852, learning_rate=1.06e-6]\u001b[A\n",
      " 85%|████████▌ | 3599/4220 [3:50:04<39:07,  3.78s/it, loss=2.62, epoch=0.853, learning_rate=1.06e-6]\u001b[A\n",
      " 85%|████████▌ | 3600/4220 [3:50:08<39:04,  3.78s/it, loss=2.62, epoch=0.853, learning_rate=1.06e-6]\u001b[A\n",
      " 85%|████████▌ | 3600/4220 [3:50:08<39:04,  3.78s/it, loss=2.75, epoch=0.853, learning_rate=1.05e-6]\u001b[A\n",
      " 85%|████████▌ | 3601/4220 [3:50:12<39:01,  3.78s/it, loss=2.75, epoch=0.853, learning_rate=1.05e-6]\u001b[A\n",
      " 85%|████████▌ | 3601/4220 [3:50:12<39:01,  3.78s/it, loss=3.25, epoch=0.853, learning_rate=1.05e-6]\u001b[A\n",
      " 85%|████████▌ | 3602/4220 [3:50:15<38:57,  3.78s/it, loss=3.25, epoch=0.853, learning_rate=1.05e-6]\u001b[A\n",
      " 85%|████████▌ | 3602/4220 [3:50:15<38:57,  3.78s/it, loss=2.87, epoch=0.853, learning_rate=1.05e-6]\u001b[A\n",
      " 85%|████████▌ | 3603/4220 [3:50:19<38:53,  3.78s/it, loss=2.87, epoch=0.853, learning_rate=1.05e-6]\u001b[A\n",
      " 85%|████████▌ | 3603/4220 [3:50:19<38:53,  3.78s/it, loss=2.57, epoch=0.854, learning_rate=1.04e-6]\u001b[A\n",
      " 85%|████████▌ | 3604/4220 [3:50:23<38:49,  3.78s/it, loss=2.57, epoch=0.854, learning_rate=1.04e-6]\u001b[A\n",
      " 85%|████████▌ | 3604/4220 [3:50:23<38:49,  3.78s/it, loss=2.83, epoch=0.854, learning_rate=1.04e-6]\u001b[A\n",
      " 85%|████████▌ | 3605/4220 [3:50:27<38:46,  3.78s/it, loss=2.83, epoch=0.854, learning_rate=1.04e-6]\u001b[A\n",
      " 85%|████████▌ | 3605/4220 [3:50:27<38:46,  3.78s/it, loss=2.56, epoch=0.854, learning_rate=1.04e-6]\u001b[A\n",
      " 85%|████████▌ | 3606/4220 [3:50:31<38:42,  3.78s/it, loss=2.56, epoch=0.854, learning_rate=1.04e-6]\u001b[A\n",
      " 85%|████████▌ | 3606/4220 [3:50:31<38:42,  3.78s/it, loss=2.81, epoch=0.854, learning_rate=1.03e-6]\u001b[A\n",
      " 85%|████████▌ | 3607/4220 [3:50:34<38:37,  3.78s/it, loss=2.81, epoch=0.854, learning_rate=1.03e-6]\u001b[A\n",
      " 85%|████████▌ | 3607/4220 [3:50:34<38:37,  3.78s/it, loss=2.88, epoch=0.855, learning_rate=1.03e-6]\u001b[A\n",
      " 85%|████████▌ | 3608/4220 [3:50:38<38:33,  3.78s/it, loss=2.88, epoch=0.855, learning_rate=1.03e-6]\u001b[A\n",
      " 85%|████████▌ | 3608/4220 [3:50:38<38:33,  3.78s/it, loss=2.46, epoch=0.855, learning_rate=1.03e-6]\u001b[A\n",
      " 86%|████████▌ | 3609/4220 [3:50:42<38:30,  3.78s/it, loss=2.46, epoch=0.855, learning_rate=1.03e-6]\u001b[A\n",
      " 86%|████████▌ | 3609/4220 [3:50:42<38:30,  3.78s/it, loss=2.44, epoch=0.855, learning_rate=1.02e-6]\u001b[A\n",
      " 86%|████████▌ | 3610/4220 [3:50:46<38:27,  3.78s/it, loss=2.44, epoch=0.855, learning_rate=1.02e-6]\u001b[A\n",
      " 86%|████████▌ | 3610/4220 [3:50:46<38:27,  3.78s/it, loss=2.71, epoch=0.855, learning_rate=1.02e-6]\u001b[A\n",
      " 86%|████████▌ | 3611/4220 [3:50:49<38:23,  3.78s/it, loss=2.71, epoch=0.855, learning_rate=1.02e-6]\u001b[A\n",
      " 86%|████████▌ | 3611/4220 [3:50:49<38:23,  3.78s/it, loss=2.8, epoch=0.855, learning_rate=1.02e-6] \u001b[A\n",
      " 86%|████████▌ | 3612/4220 [3:50:53<38:18,  3.78s/it, loss=2.8, epoch=0.855, learning_rate=1.02e-6]\u001b[A\n",
      " 86%|████████▌ | 3612/4220 [3:50:53<38:18,  3.78s/it, loss=2.59, epoch=0.856, learning_rate=1.01e-6]\u001b[A\n",
      " 86%|████████▌ | 3613/4220 [3:50:57<38:15,  3.78s/it, loss=2.59, epoch=0.856, learning_rate=1.01e-6]\u001b[A\n",
      " 86%|████████▌ | 3613/4220 [3:50:57<38:15,  3.78s/it, loss=2.63, epoch=0.856, learning_rate=1.01e-6]\u001b[A\n",
      " 86%|████████▌ | 3614/4220 [3:51:01<38:10,  3.78s/it, loss=2.63, epoch=0.856, learning_rate=1.01e-6]\u001b[A\n",
      " 86%|████████▌ | 3614/4220 [3:51:01<38:10,  3.78s/it, loss=3.1, epoch=0.856, learning_rate=1.01e-6] \u001b[A\n",
      " 86%|████████▌ | 3615/4220 [3:51:05<38:08,  3.78s/it, loss=3.1, epoch=0.856, learning_rate=1.01e-6]\u001b[A\n",
      " 86%|████████▌ | 3615/4220 [3:51:05<38:08,  3.78s/it, loss=2.59, epoch=0.856, learning_rate=1.01e-6]\u001b[A\n",
      " 86%|████████▌ | 3616/4220 [3:51:08<38:04,  3.78s/it, loss=2.59, epoch=0.856, learning_rate=1.01e-6]\u001b[A\n",
      " 86%|████████▌ | 3616/4220 [3:51:08<38:04,  3.78s/it, loss=2.4, epoch=0.857, learning_rate=1e-6]    \u001b[A\n",
      " 86%|████████▌ | 3617/4220 [3:51:12<38:01,  3.78s/it, loss=2.4, epoch=0.857, learning_rate=1e-6]\u001b[A\n",
      " 86%|████████▌ | 3617/4220 [3:51:12<38:01,  3.78s/it, loss=2.57, epoch=0.857, learning_rate=9.99e-7]\u001b[A\n",
      " 86%|████████▌ | 3618/4220 [3:51:16<37:57,  3.78s/it, loss=2.57, epoch=0.857, learning_rate=9.99e-7]\u001b[A\n",
      " 86%|████████▌ | 3618/4220 [3:51:16<37:57,  3.78s/it, loss=3.04, epoch=0.857, learning_rate=9.95e-7]\u001b[A\n",
      " 86%|████████▌ | 3619/4220 [3:51:20<37:54,  3.78s/it, loss=3.04, epoch=0.857, learning_rate=9.95e-7]\u001b[A\n",
      " 86%|████████▌ | 3619/4220 [3:51:20<37:54,  3.78s/it, loss=3.34, epoch=0.857, learning_rate=9.92e-7]\u001b[A\n",
      " 86%|████████▌ | 3620/4220 [3:51:24<37:50,  3.78s/it, loss=3.34, epoch=0.857, learning_rate=9.92e-7]\u001b[A\n",
      " 86%|████████▌ | 3620/4220 [3:51:24<37:50,  3.78s/it, loss=2.82, epoch=0.858, learning_rate=9.89e-7]\u001b[A\n",
      " 86%|████████▌ | 3621/4220 [3:51:27<37:45,  3.78s/it, loss=2.82, epoch=0.858, learning_rate=9.89e-7]\u001b[A\n",
      " 86%|████████▌ | 3621/4220 [3:51:27<37:45,  3.78s/it, loss=2.97, epoch=0.858, learning_rate=9.86e-7]\u001b[A\n",
      " 86%|████████▌ | 3622/4220 [3:51:31<37:42,  3.78s/it, loss=2.97, epoch=0.858, learning_rate=9.86e-7]\u001b[A\n",
      " 86%|████████▌ | 3622/4220 [3:51:31<37:42,  3.78s/it, loss=2.76, epoch=0.858, learning_rate=9.82e-7]\u001b[A\n",
      " 86%|████████▌ | 3623/4220 [3:51:35<37:38,  3.78s/it, loss=2.76, epoch=0.858, learning_rate=9.82e-7]\u001b[A\n",
      " 86%|████████▌ | 3623/4220 [3:51:35<37:38,  3.78s/it, loss=3.32, epoch=0.858, learning_rate=9.79e-7]\u001b[A\n",
      " 86%|████████▌ | 3624/4220 [3:51:39<37:32,  3.78s/it, loss=3.32, epoch=0.858, learning_rate=9.79e-7]\u001b[A\n",
      " 86%|████████▌ | 3624/4220 [3:51:39<37:32,  3.78s/it, loss=2.77, epoch=0.859, learning_rate=9.76e-7]\u001b[A\n",
      " 86%|████████▌ | 3625/4220 [3:51:42<37:29,  3.78s/it, loss=2.77, epoch=0.859, learning_rate=9.76e-7]\u001b[A\n",
      " 86%|████████▌ | 3625/4220 [3:51:42<37:29,  3.78s/it, loss=2.95, epoch=0.859, learning_rate=9.73e-7]\u001b[A\n",
      " 86%|████████▌ | 3626/4220 [3:51:46<37:25,  3.78s/it, loss=2.95, epoch=0.859, learning_rate=9.73e-7]\u001b[A\n",
      " 86%|████████▌ | 3626/4220 [3:51:46<37:25,  3.78s/it, loss=3.03, epoch=0.859, learning_rate=9.7e-7] \u001b[A\n",
      " 86%|████████▌ | 3627/4220 [3:51:50<37:23,  3.78s/it, loss=3.03, epoch=0.859, learning_rate=9.7e-7]\u001b[A\n",
      " 86%|████████▌ | 3627/4220 [3:51:50<37:23,  3.78s/it, loss=3.09, epoch=0.859, learning_rate=9.66e-7]\u001b[A\n",
      " 86%|████████▌ | 3628/4220 [3:51:54<37:19,  3.78s/it, loss=3.09, epoch=0.859, learning_rate=9.66e-7]\u001b[A\n",
      " 86%|████████▌ | 3628/4220 [3:51:54<37:19,  3.78s/it, loss=3.08, epoch=0.859, learning_rate=9.63e-7]\u001b[A\n",
      " 86%|████████▌ | 3629/4220 [3:51:58<37:15,  3.78s/it, loss=3.08, epoch=0.859, learning_rate=9.63e-7]\u001b[A\n",
      " 86%|████████▌ | 3629/4220 [3:51:58<37:15,  3.78s/it, loss=3.11, epoch=0.86, learning_rate=9.6e-7]  \u001b[A\n",
      " 86%|████████▌ | 3630/4220 [3:52:01<37:11,  3.78s/it, loss=3.11, epoch=0.86, learning_rate=9.6e-7]\u001b[A\n",
      " 86%|████████▌ | 3630/4220 [3:52:01<37:11,  3.78s/it, loss=2.49, epoch=0.86, learning_rate=9.57e-7]\u001b[A\n",
      " 86%|████████▌ | 3631/4220 [3:52:05<37:06,  3.78s/it, loss=2.49, epoch=0.86, learning_rate=9.57e-7]\u001b[A\n",
      " 86%|████████▌ | 3631/4220 [3:52:05<37:06,  3.78s/it, loss=2.76, epoch=0.86, learning_rate=9.54e-7]\u001b[A\n",
      " 86%|████████▌ | 3632/4220 [3:52:09<37:03,  3.78s/it, loss=2.76, epoch=0.86, learning_rate=9.54e-7]\u001b[A\n",
      " 86%|████████▌ | 3632/4220 [3:52:09<37:03,  3.78s/it, loss=2.53, epoch=0.86, learning_rate=9.5e-7] \u001b[A\n",
      " 86%|████████▌ | 3633/4220 [3:52:13<37:00,  3.78s/it, loss=2.53, epoch=0.86, learning_rate=9.5e-7]\u001b[A\n",
      " 86%|████████▌ | 3633/4220 [3:52:13<37:00,  3.78s/it, loss=2.82, epoch=0.861, learning_rate=9.47e-7]\u001b[A\n",
      " 86%|████████▌ | 3634/4220 [3:52:16<36:57,  3.78s/it, loss=2.82, epoch=0.861, learning_rate=9.47e-7]\u001b[A\n",
      " 86%|████████▌ | 3634/4220 [3:52:16<36:57,  3.78s/it, loss=2.67, epoch=0.861, learning_rate=9.44e-7]\u001b[A\n",
      " 86%|████████▌ | 3635/4220 [3:52:20<36:52,  3.78s/it, loss=2.67, epoch=0.861, learning_rate=9.44e-7]\u001b[A\n",
      " 86%|████████▌ | 3635/4220 [3:52:20<36:52,  3.78s/it, loss=2.72, epoch=0.861, learning_rate=9.41e-7]\u001b[A\n",
      " 86%|████████▌ | 3636/4220 [3:52:24<36:49,  3.78s/it, loss=2.72, epoch=0.861, learning_rate=9.41e-7]\u001b[A\n",
      " 86%|████████▌ | 3636/4220 [3:52:24<36:49,  3.78s/it, loss=3.3, epoch=0.861, learning_rate=9.38e-7] \u001b[A\n",
      " 86%|████████▌ | 3637/4220 [3:52:28<36:45,  3.78s/it, loss=3.3, epoch=0.861, learning_rate=9.38e-7]\u001b[A\n",
      " 86%|████████▌ | 3637/4220 [3:52:28<36:45,  3.78s/it, loss=2.48, epoch=0.862, learning_rate=9.35e-7]\u001b[A\n",
      " 86%|████████▌ | 3638/4220 [3:52:32<36:40,  3.78s/it, loss=2.48, epoch=0.862, learning_rate=9.35e-7]\u001b[A\n",
      " 86%|████████▌ | 3638/4220 [3:52:32<36:40,  3.78s/it, loss=2.77, epoch=0.862, learning_rate=9.31e-7]\u001b[A\n",
      " 86%|████████▌ | 3639/4220 [3:52:35<36:37,  3.78s/it, loss=2.77, epoch=0.862, learning_rate=9.31e-7]\u001b[A\n",
      " 86%|████████▌ | 3639/4220 [3:52:35<36:37,  3.78s/it, loss=2.66, epoch=0.862, learning_rate=9.28e-7]\u001b[A\n",
      " 86%|████████▋ | 3640/4220 [3:52:39<36:34,  3.78s/it, loss=2.66, epoch=0.862, learning_rate=9.28e-7]\u001b[A\n",
      " 86%|████████▋ | 3640/4220 [3:52:39<36:34,  3.78s/it, loss=2.87, epoch=0.862, learning_rate=9.25e-7]\u001b[A\n",
      " 86%|████████▋ | 3641/4220 [3:52:43<36:29,  3.78s/it, loss=2.87, epoch=0.862, learning_rate=9.25e-7]\u001b[A\n",
      " 86%|████████▋ | 3641/4220 [3:52:43<36:29,  3.78s/it, loss=2.78, epoch=0.863, learning_rate=9.22e-7]\u001b[A\n",
      " 86%|████████▋ | 3642/4220 [3:52:47<36:25,  3.78s/it, loss=2.78, epoch=0.863, learning_rate=9.22e-7]\u001b[A\n",
      " 86%|████████▋ | 3642/4220 [3:52:47<36:25,  3.78s/it, loss=2.81, epoch=0.863, learning_rate=9.19e-7]\u001b[A\n",
      " 86%|████████▋ | 3643/4220 [3:52:51<36:22,  3.78s/it, loss=2.81, epoch=0.863, learning_rate=9.19e-7]\u001b[A\n",
      " 86%|████████▋ | 3643/4220 [3:52:51<36:22,  3.78s/it, loss=2.97, epoch=0.863, learning_rate=9.16e-7]\u001b[A\n",
      " 86%|████████▋ | 3644/4220 [3:52:54<36:18,  3.78s/it, loss=2.97, epoch=0.863, learning_rate=9.16e-7]\u001b[A\n",
      " 86%|████████▋ | 3644/4220 [3:52:54<36:18,  3.78s/it, loss=2.8, epoch=0.863, learning_rate=9.13e-7] \u001b[A\n",
      " 86%|████████▋ | 3645/4220 [3:52:58<36:15,  3.78s/it, loss=2.8, epoch=0.863, learning_rate=9.13e-7]\u001b[A\n",
      " 86%|████████▋ | 3645/4220 [3:52:58<36:15,  3.78s/it, loss=2.72, epoch=0.864, learning_rate=9.1e-7]\u001b[A\n",
      " 86%|████████▋ | 3646/4220 [3:53:02<36:11,  3.78s/it, loss=2.72, epoch=0.864, learning_rate=9.1e-7]\u001b[A\n",
      " 86%|████████▋ | 3646/4220 [3:53:02<36:11,  3.78s/it, loss=2.68, epoch=0.864, learning_rate=9.07e-7]\u001b[A\n",
      " 86%|████████▋ | 3647/4220 [3:53:06<36:07,  3.78s/it, loss=2.68, epoch=0.864, learning_rate=9.07e-7]\u001b[A\n",
      " 86%|████████▋ | 3647/4220 [3:53:06<36:07,  3.78s/it, loss=2.91, epoch=0.864, learning_rate=9.03e-7]\u001b[A\n",
      " 86%|████████▋ | 3648/4220 [3:53:09<36:03,  3.78s/it, loss=2.91, epoch=0.864, learning_rate=9.03e-7]\u001b[A\n",
      " 86%|████████▋ | 3648/4220 [3:53:09<36:03,  3.78s/it, loss=2.48, epoch=0.864, learning_rate=9e-7]   \u001b[A\n",
      " 86%|████████▋ | 3649/4220 [3:53:13<35:58,  3.78s/it, loss=2.48, epoch=0.864, learning_rate=9e-7]\u001b[A\n",
      " 86%|████████▋ | 3649/4220 [3:53:13<35:58,  3.78s/it, loss=2.99, epoch=0.864, learning_rate=8.97e-7]\u001b[A\n",
      " 86%|████████▋ | 3650/4220 [3:53:17<35:53,  3.78s/it, loss=2.99, epoch=0.864, learning_rate=8.97e-7]\u001b[A\n",
      " 86%|████████▋ | 3650/4220 [3:53:17<35:53,  3.78s/it, loss=2.54, epoch=0.865, learning_rate=8.94e-7]\u001b[A\n",
      " 87%|████████▋ | 3651/4220 [3:53:21<35:50,  3.78s/it, loss=2.54, epoch=0.865, learning_rate=8.94e-7]\u001b[A\n",
      " 87%|████████▋ | 3651/4220 [3:53:21<35:50,  3.78s/it, loss=3.24, epoch=0.865, learning_rate=8.91e-7]\u001b[A\n",
      " 87%|████████▋ | 3652/4220 [3:53:25<35:46,  3.78s/it, loss=3.24, epoch=0.865, learning_rate=8.91e-7]\u001b[A\n",
      " 87%|████████▋ | 3652/4220 [3:53:25<35:46,  3.78s/it, loss=2.37, epoch=0.865, learning_rate=8.88e-7]\u001b[A\n",
      " 87%|████████▋ | 3653/4220 [3:53:28<35:43,  3.78s/it, loss=2.37, epoch=0.865, learning_rate=8.88e-7]\u001b[A\n",
      " 87%|████████▋ | 3653/4220 [3:53:28<35:43,  3.78s/it, loss=2.63, epoch=0.865, learning_rate=8.85e-7]\u001b[A\n",
      " 87%|████████▋ | 3654/4220 [3:53:32<35:39,  3.78s/it, loss=2.63, epoch=0.865, learning_rate=8.85e-7]\u001b[A\n",
      " 87%|████████▋ | 3654/4220 [3:53:32<35:39,  3.78s/it, loss=2.83, epoch=0.866, learning_rate=8.82e-7]\u001b[A\n",
      " 87%|████████▋ | 3655/4220 [3:53:36<35:35,  3.78s/it, loss=2.83, epoch=0.866, learning_rate=8.82e-7]\u001b[A\n",
      " 87%|████████▋ | 3655/4220 [3:53:36<35:35,  3.78s/it, loss=2.5, epoch=0.866, learning_rate=8.79e-7] \u001b[A\n",
      " 87%|████████▋ | 3656/4220 [3:53:40<35:31,  3.78s/it, loss=2.5, epoch=0.866, learning_rate=8.79e-7]\u001b[A\n",
      " 87%|████████▋ | 3656/4220 [3:53:40<35:31,  3.78s/it, loss=2.53, epoch=0.866, learning_rate=8.76e-7]\u001b[A\n",
      " 87%|████████▋ | 3657/4220 [3:53:43<35:28,  3.78s/it, loss=2.53, epoch=0.866, learning_rate=8.76e-7]\u001b[A\n",
      " 87%|████████▋ | 3657/4220 [3:53:43<35:28,  3.78s/it, loss=2.84, epoch=0.866, learning_rate=8.73e-7]\u001b[A\n",
      " 87%|████████▋ | 3658/4220 [3:53:47<35:25,  3.78s/it, loss=2.84, epoch=0.866, learning_rate=8.73e-7]\u001b[A\n",
      " 87%|████████▋ | 3658/4220 [3:53:47<35:25,  3.78s/it, loss=2.42, epoch=0.867, learning_rate=8.7e-7] \u001b[A\n",
      " 87%|████████▋ | 3659/4220 [3:53:51<35:21,  3.78s/it, loss=2.42, epoch=0.867, learning_rate=8.7e-7]\u001b[A\n",
      " 87%|████████▋ | 3659/4220 [3:53:51<35:21,  3.78s/it, loss=3.23, epoch=0.867, learning_rate=8.67e-7]\u001b[A\n",
      " 87%|████████▋ | 3660/4220 [3:53:55<35:18,  3.78s/it, loss=3.23, epoch=0.867, learning_rate=8.67e-7]\u001b[A\n",
      " 87%|████████▋ | 3660/4220 [3:53:55<35:18,  3.78s/it, loss=3.29, epoch=0.867, learning_rate=8.64e-7]\u001b[A\n",
      " 87%|████████▋ | 3661/4220 [3:53:59<35:14,  3.78s/it, loss=3.29, epoch=0.867, learning_rate=8.64e-7]\u001b[A\n",
      " 87%|████████▋ | 3661/4220 [3:53:59<35:14,  3.78s/it, loss=3.36, epoch=0.867, learning_rate=8.61e-7]\u001b[A\n",
      " 87%|████████▋ | 3662/4220 [3:54:02<35:10,  3.78s/it, loss=3.36, epoch=0.867, learning_rate=8.61e-7]\u001b[A\n",
      " 87%|████████▋ | 3662/4220 [3:54:02<35:10,  3.78s/it, loss=2.66, epoch=0.868, learning_rate=8.57e-7]\u001b[A\n",
      " 87%|████████▋ | 3663/4220 [3:54:06<35:07,  3.78s/it, loss=2.66, epoch=0.868, learning_rate=8.57e-7]\u001b[A\n",
      " 87%|████████▋ | 3663/4220 [3:54:06<35:07,  3.78s/it, loss=2.93, epoch=0.868, learning_rate=8.54e-7]\u001b[A\n",
      " 87%|████████▋ | 3664/4220 [3:54:10<35:03,  3.78s/it, loss=2.93, epoch=0.868, learning_rate=8.54e-7]\u001b[A\n",
      " 87%|████████▋ | 3664/4220 [3:54:10<35:03,  3.78s/it, loss=2.59, epoch=0.868, learning_rate=8.51e-7]\u001b[A\n",
      " 87%|████████▋ | 3665/4220 [3:54:14<34:58,  3.78s/it, loss=2.59, epoch=0.868, learning_rate=8.51e-7]\u001b[A\n",
      " 87%|████████▋ | 3665/4220 [3:54:14<34:58,  3.78s/it, loss=2.75, epoch=0.868, learning_rate=8.48e-7]\u001b[A\n",
      " 87%|████████▋ | 3666/4220 [3:54:17<34:54,  3.78s/it, loss=2.75, epoch=0.868, learning_rate=8.48e-7]\u001b[A\n",
      " 87%|████████▋ | 3666/4220 [3:54:17<34:54,  3.78s/it, loss=2.88, epoch=0.868, learning_rate=8.45e-7]\u001b[A\n",
      " 87%|████████▋ | 3667/4220 [3:54:21<34:50,  3.78s/it, loss=2.88, epoch=0.868, learning_rate=8.45e-7]\u001b[A\n",
      " 87%|████████▋ | 3667/4220 [3:54:21<34:50,  3.78s/it, loss=3.05, epoch=0.869, learning_rate=8.42e-7]\u001b[A\n",
      " 87%|████████▋ | 3668/4220 [3:54:25<34:46,  3.78s/it, loss=3.05, epoch=0.869, learning_rate=8.42e-7]\u001b[A\n",
      " 87%|████████▋ | 3668/4220 [3:54:25<34:46,  3.78s/it, loss=2.72, epoch=0.869, learning_rate=8.39e-7]\u001b[A\n",
      " 87%|████████▋ | 3669/4220 [3:54:29<34:43,  3.78s/it, loss=2.72, epoch=0.869, learning_rate=8.39e-7]\u001b[A\n",
      " 87%|████████▋ | 3669/4220 [3:54:29<34:43,  3.78s/it, loss=2.41, epoch=0.869, learning_rate=8.36e-7]\u001b[A\n",
      " 87%|████████▋ | 3670/4220 [3:54:33<34:40,  3.78s/it, loss=2.41, epoch=0.869, learning_rate=8.36e-7]\u001b[A\n",
      " 87%|████████▋ | 3670/4220 [3:54:33<34:40,  3.78s/it, loss=3.22, epoch=0.869, learning_rate=8.33e-7]\u001b[A\n",
      " 87%|████████▋ | 3671/4220 [3:54:36<34:36,  3.78s/it, loss=3.22, epoch=0.869, learning_rate=8.33e-7]\u001b[A\n",
      " 87%|████████▋ | 3671/4220 [3:54:36<34:36,  3.78s/it, loss=2.54, epoch=0.87, learning_rate=8.3e-7]  \u001b[A\n",
      " 87%|████████▋ | 3672/4220 [3:54:40<34:33,  3.78s/it, loss=2.54, epoch=0.87, learning_rate=8.3e-7]\u001b[A\n",
      " 87%|████████▋ | 3672/4220 [3:54:40<34:33,  3.78s/it, loss=2.56, epoch=0.87, learning_rate=8.27e-7]\u001b[A\n",
      " 87%|████████▋ | 3673/4220 [3:54:44<34:29,  3.78s/it, loss=2.56, epoch=0.87, learning_rate=8.27e-7]\u001b[A\n",
      " 87%|████████▋ | 3673/4220 [3:54:44<34:29,  3.78s/it, loss=2.33, epoch=0.87, learning_rate=8.25e-7]\u001b[A\n",
      " 87%|████████▋ | 3674/4220 [3:54:48<34:25,  3.78s/it, loss=2.33, epoch=0.87, learning_rate=8.25e-7]\u001b[A\n",
      " 87%|████████▋ | 3674/4220 [3:54:48<34:25,  3.78s/it, loss=3.11, epoch=0.87, learning_rate=8.22e-7]\u001b[A\n",
      " 87%|████████▋ | 3675/4220 [3:54:52<34:22,  3.78s/it, loss=3.11, epoch=0.87, learning_rate=8.22e-7]\u001b[A\n",
      " 87%|████████▋ | 3675/4220 [3:54:52<34:22,  3.78s/it, loss=3.3, epoch=0.871, learning_rate=8.19e-7]\u001b[A\n",
      " 87%|████████▋ | 3676/4220 [3:54:55<34:18,  3.78s/it, loss=3.3, epoch=0.871, learning_rate=8.19e-7]\u001b[A\n",
      " 87%|████████▋ | 3676/4220 [3:54:55<34:18,  3.78s/it, loss=2.44, epoch=0.871, learning_rate=8.16e-7]\u001b[A\n",
      " 87%|████████▋ | 3677/4220 [3:54:59<34:14,  3.78s/it, loss=2.44, epoch=0.871, learning_rate=8.16e-7]\u001b[A\n",
      " 87%|████████▋ | 3677/4220 [3:54:59<34:14,  3.78s/it, loss=2.23, epoch=0.871, learning_rate=8.13e-7]\u001b[A\n",
      " 87%|████████▋ | 3678/4220 [3:55:03<34:10,  3.78s/it, loss=2.23, epoch=0.871, learning_rate=8.13e-7]\u001b[A\n",
      " 87%|████████▋ | 3678/4220 [3:55:03<34:10,  3.78s/it, loss=2.94, epoch=0.871, learning_rate=8.1e-7] \u001b[A\n",
      " 87%|████████▋ | 3679/4220 [3:55:07<34:06,  3.78s/it, loss=2.94, epoch=0.871, learning_rate=8.1e-7]\u001b[A\n",
      " 87%|████████▋ | 3679/4220 [3:55:07<34:06,  3.78s/it, loss=2.49, epoch=0.872, learning_rate=8.07e-7]\u001b[A\n",
      " 87%|████████▋ | 3680/4220 [3:55:10<34:03,  3.78s/it, loss=2.49, epoch=0.872, learning_rate=8.07e-7]\u001b[A\n",
      " 87%|████████▋ | 3680/4220 [3:55:10<34:03,  3.78s/it, loss=2.48, epoch=0.872, learning_rate=8.04e-7]\u001b[A\n",
      " 87%|████████▋ | 3681/4220 [3:55:14<33:59,  3.78s/it, loss=2.48, epoch=0.872, learning_rate=8.04e-7]\u001b[A\n",
      " 87%|████████▋ | 3681/4220 [3:55:14<33:59,  3.78s/it, loss=2.91, epoch=0.872, learning_rate=8.01e-7]\u001b[A\n",
      " 87%|████████▋ | 3682/4220 [3:55:18<33:54,  3.78s/it, loss=2.91, epoch=0.872, learning_rate=8.01e-7]\u001b[A\n",
      " 87%|████████▋ | 3682/4220 [3:55:18<33:54,  3.78s/it, loss=3.16, epoch=0.872, learning_rate=7.98e-7]\u001b[A\n",
      " 87%|████████▋ | 3683/4220 [3:55:22<33:51,  3.78s/it, loss=3.16, epoch=0.872, learning_rate=7.98e-7]\u001b[A\n",
      " 87%|████████▋ | 3683/4220 [3:55:22<33:51,  3.78s/it, loss=2.54, epoch=0.873, learning_rate=7.95e-7]\u001b[A\n",
      " 87%|████████▋ | 3684/4220 [3:55:26<33:46,  3.78s/it, loss=2.54, epoch=0.873, learning_rate=7.95e-7]\u001b[A\n",
      " 87%|████████▋ | 3684/4220 [3:55:26<33:46,  3.78s/it, loss=2.43, epoch=0.873, learning_rate=7.92e-7]\u001b[A\n",
      " 87%|████████▋ | 3685/4220 [3:55:29<33:43,  3.78s/it, loss=2.43, epoch=0.873, learning_rate=7.92e-7]\u001b[A\n",
      " 87%|████████▋ | 3685/4220 [3:55:29<33:43,  3.78s/it, loss=3.11, epoch=0.873, learning_rate=7.89e-7]\u001b[A\n",
      " 87%|████████▋ | 3686/4220 [3:55:33<33:39,  3.78s/it, loss=3.11, epoch=0.873, learning_rate=7.89e-7]\u001b[A\n",
      " 87%|████████▋ | 3686/4220 [3:55:33<33:39,  3.78s/it, loss=2.59, epoch=0.873, learning_rate=7.86e-7]\u001b[A\n",
      " 87%|████████▋ | 3687/4220 [3:55:37<33:35,  3.78s/it, loss=2.59, epoch=0.873, learning_rate=7.86e-7]\u001b[A\n",
      " 87%|████████▋ | 3687/4220 [3:55:37<33:35,  3.78s/it, loss=2.77, epoch=0.873, learning_rate=7.83e-7]\u001b[A\n",
      " 87%|████████▋ | 3688/4220 [3:55:41<33:32,  3.78s/it, loss=2.77, epoch=0.873, learning_rate=7.83e-7]\u001b[A\n",
      " 87%|████████▋ | 3688/4220 [3:55:41<33:32,  3.78s/it, loss=2.65, epoch=0.874, learning_rate=7.81e-7]\u001b[A\n",
      " 87%|████████▋ | 3689/4220 [3:55:44<33:28,  3.78s/it, loss=2.65, epoch=0.874, learning_rate=7.81e-7]\u001b[A\n",
      " 87%|████████▋ | 3689/4220 [3:55:44<33:28,  3.78s/it, loss=2.92, epoch=0.874, learning_rate=7.78e-7]\u001b[A\n",
      " 87%|████████▋ | 3690/4220 [3:55:48<33:25,  3.78s/it, loss=2.92, epoch=0.874, learning_rate=7.78e-7]\u001b[A\n",
      " 87%|████████▋ | 3690/4220 [3:55:48<33:25,  3.78s/it, loss=2.81, epoch=0.874, learning_rate=7.75e-7]\u001b[A\n",
      " 87%|████████▋ | 3691/4220 [3:55:52<33:21,  3.78s/it, loss=2.81, epoch=0.874, learning_rate=7.75e-7]\u001b[A\n",
      " 87%|████████▋ | 3691/4220 [3:55:52<33:21,  3.78s/it, loss=2.78, epoch=0.874, learning_rate=7.72e-7]\u001b[A\n",
      " 87%|████████▋ | 3692/4220 [3:55:56<33:17,  3.78s/it, loss=2.78, epoch=0.874, learning_rate=7.72e-7]\u001b[A\n",
      " 87%|████████▋ | 3692/4220 [3:55:56<33:17,  3.78s/it, loss=2.67, epoch=0.875, learning_rate=7.69e-7]\u001b[A\n",
      " 88%|████████▊ | 3693/4220 [3:56:00<33:13,  3.78s/it, loss=2.67, epoch=0.875, learning_rate=7.69e-7]\u001b[A\n",
      " 88%|████████▊ | 3693/4220 [3:56:00<33:13,  3.78s/it, loss=3.19, epoch=0.875, learning_rate=7.66e-7]\u001b[A\n",
      " 88%|████████▊ | 3694/4220 [3:56:03<33:09,  3.78s/it, loss=3.19, epoch=0.875, learning_rate=7.66e-7]\u001b[A\n",
      " 88%|████████▊ | 3694/4220 [3:56:03<33:09,  3.78s/it, loss=2.66, epoch=0.875, learning_rate=7.63e-7]\u001b[A\n",
      " 88%|████████▊ | 3695/4220 [3:56:07<33:05,  3.78s/it, loss=2.66, epoch=0.875, learning_rate=7.63e-7]\u001b[A\n",
      " 88%|████████▊ | 3695/4220 [3:56:07<33:05,  3.78s/it, loss=2.78, epoch=0.875, learning_rate=7.6e-7] \u001b[A\n",
      " 88%|████████▊ | 3696/4220 [3:56:11<33:01,  3.78s/it, loss=2.78, epoch=0.875, learning_rate=7.6e-7]\u001b[A\n",
      " 88%|████████▊ | 3696/4220 [3:56:11<33:01,  3.78s/it, loss=2.48, epoch=0.876, learning_rate=7.58e-7]\u001b[A\n",
      " 88%|████████▊ | 3697/4220 [3:56:15<32:57,  3.78s/it, loss=2.48, epoch=0.876, learning_rate=7.58e-7]\u001b[A\n",
      " 88%|████████▊ | 3697/4220 [3:56:15<32:57,  3.78s/it, loss=2.32, epoch=0.876, learning_rate=7.55e-7]\u001b[A\n",
      " 88%|████████▊ | 3698/4220 [3:56:19<32:53,  3.78s/it, loss=2.32, epoch=0.876, learning_rate=7.55e-7]\u001b[A\n",
      " 88%|████████▊ | 3698/4220 [3:56:19<32:53,  3.78s/it, loss=2.97, epoch=0.876, learning_rate=7.52e-7]\u001b[A\n",
      " 88%|████████▊ | 3699/4220 [3:56:22<32:50,  3.78s/it, loss=2.97, epoch=0.876, learning_rate=7.52e-7]\u001b[A\n",
      " 88%|████████▊ | 3699/4220 [3:56:22<32:50,  3.78s/it, loss=2.95, epoch=0.876, learning_rate=7.49e-7]\u001b[A\n",
      " 88%|████████▊ | 3700/4220 [3:56:26<32:45,  3.78s/it, loss=2.95, epoch=0.876, learning_rate=7.49e-7]\u001b[A\n",
      " 88%|████████▊ | 3700/4220 [3:56:26<32:45,  3.78s/it, loss=2.95, epoch=0.877, learning_rate=7.46e-7]\u001b[A\n",
      " 88%|████████▊ | 3701/4220 [3:56:30<32:42,  3.78s/it, loss=2.95, epoch=0.877, learning_rate=7.46e-7]\u001b[A\n",
      " 88%|████████▊ | 3701/4220 [3:56:30<32:42,  3.78s/it, loss=2.89, epoch=0.877, learning_rate=7.43e-7]\u001b[A\n",
      " 88%|████████▊ | 3702/4220 [3:56:34<32:39,  3.78s/it, loss=2.89, epoch=0.877, learning_rate=7.43e-7]\u001b[A\n",
      " 88%|████████▊ | 3702/4220 [3:56:34<32:39,  3.78s/it, loss=2.74, epoch=0.877, learning_rate=7.41e-7]\u001b[A\n",
      " 88%|████████▊ | 3703/4220 [3:56:37<32:34,  3.78s/it, loss=2.74, epoch=0.877, learning_rate=7.41e-7]\u001b[A\n",
      " 88%|████████▊ | 3703/4220 [3:56:37<32:34,  3.78s/it, loss=2.36, epoch=0.877, learning_rate=7.38e-7]\u001b[A\n",
      " 88%|████████▊ | 3704/4220 [3:56:41<32:31,  3.78s/it, loss=2.36, epoch=0.877, learning_rate=7.38e-7]\u001b[A\n",
      " 88%|████████▊ | 3704/4220 [3:56:41<32:31,  3.78s/it, loss=2.46, epoch=0.877, learning_rate=7.35e-7]\u001b[A\n",
      " 88%|████████▊ | 3705/4220 [3:56:45<32:26,  3.78s/it, loss=2.46, epoch=0.877, learning_rate=7.35e-7]\u001b[A\n",
      " 88%|████████▊ | 3705/4220 [3:56:45<32:26,  3.78s/it, loss=2.42, epoch=0.878, learning_rate=7.32e-7]\u001b[A\n",
      " 88%|████████▊ | 3706/4220 [3:56:49<32:23,  3.78s/it, loss=2.42, epoch=0.878, learning_rate=7.32e-7]\u001b[A\n",
      " 88%|████████▊ | 3706/4220 [3:56:49<32:23,  3.78s/it, loss=2.56, epoch=0.878, learning_rate=7.29e-7]\u001b[A\n",
      " 88%|████████▊ | 3707/4220 [3:56:53<32:19,  3.78s/it, loss=2.56, epoch=0.878, learning_rate=7.29e-7]\u001b[A\n",
      " 88%|████████▊ | 3707/4220 [3:56:53<32:19,  3.78s/it, loss=3.03, epoch=0.878, learning_rate=7.27e-7]\u001b[A\n",
      " 88%|████████▊ | 3708/4220 [3:56:56<32:16,  3.78s/it, loss=3.03, epoch=0.878, learning_rate=7.27e-7]\u001b[A\n",
      " 88%|████████▊ | 3708/4220 [3:56:56<32:16,  3.78s/it, loss=3.29, epoch=0.878, learning_rate=7.24e-7]\u001b[A\n",
      " 88%|████████▊ | 3709/4220 [3:57:00<32:12,  3.78s/it, loss=3.29, epoch=0.878, learning_rate=7.24e-7]\u001b[A\n",
      " 88%|████████▊ | 3709/4220 [3:57:00<32:12,  3.78s/it, loss=2.64, epoch=0.879, learning_rate=7.21e-7]\u001b[A\n",
      " 88%|████████▊ | 3710/4220 [3:57:04<32:08,  3.78s/it, loss=2.64, epoch=0.879, learning_rate=7.21e-7]\u001b[A\n",
      " 88%|████████▊ | 3710/4220 [3:57:04<32:08,  3.78s/it, loss=3.01, epoch=0.879, learning_rate=7.18e-7]\u001b[A\n",
      " 88%|████████▊ | 3711/4220 [3:57:08<32:04,  3.78s/it, loss=3.01, epoch=0.879, learning_rate=7.18e-7]\u001b[A\n",
      " 88%|████████▊ | 3711/4220 [3:57:08<32:04,  3.78s/it, loss=2.54, epoch=0.879, learning_rate=7.15e-7]\u001b[A\n",
      " 88%|████████▊ | 3712/4220 [3:57:11<32:00,  3.78s/it, loss=2.54, epoch=0.879, learning_rate=7.15e-7]\u001b[A\n",
      " 88%|████████▊ | 3712/4220 [3:57:11<32:00,  3.78s/it, loss=2.39, epoch=0.879, learning_rate=7.13e-7]\u001b[A\n",
      " 88%|████████▊ | 3713/4220 [3:57:15<31:56,  3.78s/it, loss=2.39, epoch=0.879, learning_rate=7.13e-7]\u001b[A\n",
      " 88%|████████▊ | 3713/4220 [3:57:15<31:56,  3.78s/it, loss=2.58, epoch=0.88, learning_rate=7.1e-7]  \u001b[A\n",
      " 88%|████████▊ | 3714/4220 [3:57:19<31:53,  3.78s/it, loss=2.58, epoch=0.88, learning_rate=7.1e-7]\u001b[A\n",
      " 88%|████████▊ | 3714/4220 [3:57:19<31:53,  3.78s/it, loss=2.43, epoch=0.88, learning_rate=7.07e-7]\u001b[A\n",
      " 88%|████████▊ | 3715/4220 [3:57:23<31:50,  3.78s/it, loss=2.43, epoch=0.88, learning_rate=7.07e-7]\u001b[A\n",
      " 88%|████████▊ | 3715/4220 [3:57:23<31:50,  3.78s/it, loss=2.87, epoch=0.88, learning_rate=7.04e-7]\u001b[A\n",
      " 88%|████████▊ | 3716/4220 [3:57:27<31:46,  3.78s/it, loss=2.87, epoch=0.88, learning_rate=7.04e-7]\u001b[A\n",
      " 88%|████████▊ | 3716/4220 [3:57:27<31:46,  3.78s/it, loss=2.78, epoch=0.88, learning_rate=7.02e-7]\u001b[A\n",
      " 88%|████████▊ | 3717/4220 [3:57:30<31:42,  3.78s/it, loss=2.78, epoch=0.88, learning_rate=7.02e-7]\u001b[A\n",
      " 88%|████████▊ | 3717/4220 [3:57:30<31:42,  3.78s/it, loss=3.19, epoch=0.881, learning_rate=6.99e-7]\u001b[A\n",
      " 88%|████████▊ | 3718/4220 [3:57:34<31:38,  3.78s/it, loss=3.19, epoch=0.881, learning_rate=6.99e-7]\u001b[A\n",
      " 88%|████████▊ | 3718/4220 [3:57:34<31:38,  3.78s/it, loss=3.05, epoch=0.881, learning_rate=6.96e-7]\u001b[A\n",
      " 88%|████████▊ | 3719/4220 [3:57:38<31:34,  3.78s/it, loss=3.05, epoch=0.881, learning_rate=6.96e-7]\u001b[A\n",
      " 88%|████████▊ | 3719/4220 [3:57:38<31:34,  3.78s/it, loss=2.96, epoch=0.881, learning_rate=6.93e-7]\u001b[A\n",
      " 88%|████████▊ | 3720/4220 [3:57:42<31:30,  3.78s/it, loss=2.96, epoch=0.881, learning_rate=6.93e-7]\u001b[A\n",
      " 88%|████████▊ | 3720/4220 [3:57:42<31:30,  3.78s/it, loss=2.77, epoch=0.881, learning_rate=6.91e-7]\u001b[A\n",
      " 88%|████████▊ | 3721/4220 [3:57:45<31:27,  3.78s/it, loss=2.77, epoch=0.881, learning_rate=6.91e-7]\u001b[A\n",
      " 88%|████████▊ | 3721/4220 [3:57:45<31:27,  3.78s/it, loss=2.72, epoch=0.882, learning_rate=6.88e-7]\u001b[A\n",
      " 88%|████████▊ | 3722/4220 [3:57:49<31:22,  3.78s/it, loss=2.72, epoch=0.882, learning_rate=6.88e-7]\u001b[A\n",
      " 88%|████████▊ | 3722/4220 [3:57:49<31:22,  3.78s/it, loss=2.72, epoch=0.882, learning_rate=6.85e-7]\u001b[A\n",
      " 88%|████████▊ | 3723/4220 [3:57:53<31:19,  3.78s/it, loss=2.72, epoch=0.882, learning_rate=6.85e-7]\u001b[A\n",
      " 88%|████████▊ | 3723/4220 [3:57:53<31:19,  3.78s/it, loss=3.11, epoch=0.882, learning_rate=6.83e-7]\u001b[A\n",
      " 88%|████████▊ | 3724/4220 [3:57:57<31:15,  3.78s/it, loss=3.11, epoch=0.882, learning_rate=6.83e-7]\u001b[A\n",
      " 88%|████████▊ | 3724/4220 [3:57:57<31:15,  3.78s/it, loss=2.88, epoch=0.882, learning_rate=6.8e-7] \u001b[A\n",
      " 88%|████████▊ | 3725/4220 [3:58:01<31:12,  3.78s/it, loss=2.88, epoch=0.882, learning_rate=6.8e-7]\u001b[A\n",
      " 88%|████████▊ | 3725/4220 [3:58:01<31:12,  3.78s/it, loss=2.82, epoch=0.882, learning_rate=6.77e-7]\u001b[A\n",
      " 88%|████████▊ | 3726/4220 [3:58:04<31:07,  3.78s/it, loss=2.82, epoch=0.882, learning_rate=6.77e-7]\u001b[A\n",
      " 88%|████████▊ | 3726/4220 [3:58:04<31:07,  3.78s/it, loss=2.87, epoch=0.883, learning_rate=6.74e-7]\u001b[A\n",
      " 88%|████████▊ | 3727/4220 [3:58:08<31:04,  3.78s/it, loss=2.87, epoch=0.883, learning_rate=6.74e-7]\u001b[A\n",
      " 88%|████████▊ | 3727/4220 [3:58:08<31:04,  3.78s/it, loss=2.74, epoch=0.883, learning_rate=6.72e-7]\u001b[A\n",
      " 88%|████████▊ | 3728/4220 [3:58:12<31:01,  3.78s/it, loss=2.74, epoch=0.883, learning_rate=6.72e-7]\u001b[A\n",
      " 88%|████████▊ | 3728/4220 [3:58:12<31:01,  3.78s/it, loss=2.46, epoch=0.883, learning_rate=6.69e-7]\u001b[A\n",
      " 88%|████████▊ | 3729/4220 [3:58:16<30:57,  3.78s/it, loss=2.46, epoch=0.883, learning_rate=6.69e-7]\u001b[A\n",
      " 88%|████████▊ | 3729/4220 [3:58:16<30:57,  3.78s/it, loss=2.77, epoch=0.883, learning_rate=6.66e-7]\u001b[A\n",
      " 88%|████████▊ | 3730/4220 [3:58:20<30:53,  3.78s/it, loss=2.77, epoch=0.883, learning_rate=6.66e-7]\u001b[A\n",
      " 88%|████████▊ | 3730/4220 [3:58:20<30:53,  3.78s/it, loss=2.77, epoch=0.884, learning_rate=6.64e-7]\u001b[A\n",
      " 88%|████████▊ | 3731/4220 [3:58:23<30:50,  3.78s/it, loss=2.77, epoch=0.884, learning_rate=6.64e-7]\u001b[A\n",
      " 88%|████████▊ | 3731/4220 [3:58:23<30:50,  3.78s/it, loss=2.8, epoch=0.884, learning_rate=6.61e-7] \u001b[A\n",
      " 88%|████████▊ | 3732/4220 [3:58:27<30:46,  3.78s/it, loss=2.8, epoch=0.884, learning_rate=6.61e-7]\u001b[A\n",
      " 88%|████████▊ | 3732/4220 [3:58:27<30:46,  3.78s/it, loss=2.91, epoch=0.884, learning_rate=6.58e-7]\u001b[A\n",
      " 88%|████████▊ | 3733/4220 [3:58:31<30:42,  3.78s/it, loss=2.91, epoch=0.884, learning_rate=6.58e-7]\u001b[A\n",
      " 88%|████████▊ | 3733/4220 [3:58:31<30:42,  3.78s/it, loss=3.05, epoch=0.884, learning_rate=6.56e-7]\u001b[A\n",
      " 88%|████████▊ | 3734/4220 [3:58:35<30:39,  3.78s/it, loss=3.05, epoch=0.884, learning_rate=6.56e-7]\u001b[A\n",
      " 88%|████████▊ | 3734/4220 [3:58:35<30:39,  3.78s/it, loss=3.36, epoch=0.885, learning_rate=6.53e-7]\u001b[A\n",
      " 89%|████████▊ | 3735/4220 [3:58:38<30:34,  3.78s/it, loss=3.36, epoch=0.885, learning_rate=6.53e-7]\u001b[A\n",
      " 89%|████████▊ | 3735/4220 [3:58:38<30:34,  3.78s/it, loss=3.1, epoch=0.885, learning_rate=6.5e-7]  \u001b[A\n",
      " 89%|████████▊ | 3736/4220 [3:58:42<30:31,  3.78s/it, loss=3.1, epoch=0.885, learning_rate=6.5e-7]\u001b[A\n",
      " 89%|████████▊ | 3736/4220 [3:58:42<30:31,  3.78s/it, loss=3.25, epoch=0.885, learning_rate=6.48e-7]\u001b[A\n",
      " 89%|████████▊ | 3737/4220 [3:58:46<30:27,  3.78s/it, loss=3.25, epoch=0.885, learning_rate=6.48e-7]\u001b[A\n",
      " 89%|████████▊ | 3737/4220 [3:58:46<30:27,  3.78s/it, loss=3.44, epoch=0.885, learning_rate=6.45e-7]\u001b[A\n",
      " 89%|████████▊ | 3738/4220 [3:58:50<30:23,  3.78s/it, loss=3.44, epoch=0.885, learning_rate=6.45e-7]\u001b[A\n",
      " 89%|████████▊ | 3738/4220 [3:58:50<30:23,  3.78s/it, loss=2.59, epoch=0.886, learning_rate=6.43e-7]\u001b[A\n",
      " 89%|████████▊ | 3739/4220 [3:58:54<30:19,  3.78s/it, loss=2.59, epoch=0.886, learning_rate=6.43e-7]\u001b[A\n",
      " 89%|████████▊ | 3739/4220 [3:58:54<30:19,  3.78s/it, loss=2.69, epoch=0.886, learning_rate=6.4e-7] \u001b[A\n",
      " 89%|████████▊ | 3740/4220 [3:58:57<30:15,  3.78s/it, loss=2.69, epoch=0.886, learning_rate=6.4e-7]\u001b[A\n",
      " 89%|████████▊ | 3740/4220 [3:58:57<30:15,  3.78s/it, loss=2.92, epoch=0.886, learning_rate=6.37e-7]\u001b[A\n",
      " 89%|████████▊ | 3741/4220 [3:59:01<30:11,  3.78s/it, loss=2.92, epoch=0.886, learning_rate=6.37e-7]\u001b[A\n",
      " 89%|████████▊ | 3741/4220 [3:59:01<30:11,  3.78s/it, loss=2.83, epoch=0.886, learning_rate=6.35e-7]\u001b[A\n",
      " 89%|████████▊ | 3742/4220 [3:59:05<30:08,  3.78s/it, loss=2.83, epoch=0.886, learning_rate=6.35e-7]\u001b[A\n",
      " 89%|████████▊ | 3742/4220 [3:59:05<30:08,  3.78s/it, loss=2.79, epoch=0.886, learning_rate=6.32e-7]\u001b[A\n",
      " 89%|████████▊ | 3743/4220 [3:59:09<30:05,  3.78s/it, loss=2.79, epoch=0.886, learning_rate=6.32e-7]\u001b[A\n",
      " 89%|████████▊ | 3743/4220 [3:59:09<30:05,  3.78s/it, loss=3.05, epoch=0.887, learning_rate=6.29e-7]\u001b[A\n",
      " 89%|████████▊ | 3744/4220 [3:59:12<30:01,  3.78s/it, loss=3.05, epoch=0.887, learning_rate=6.29e-7]\u001b[A\n",
      " 89%|████████▊ | 3744/4220 [3:59:12<30:01,  3.78s/it, loss=3.12, epoch=0.887, learning_rate=6.27e-7]\u001b[A\n",
      " 89%|████████▊ | 3745/4220 [3:59:16<29:57,  3.78s/it, loss=3.12, epoch=0.887, learning_rate=6.27e-7]\u001b[A\n",
      " 89%|████████▊ | 3745/4220 [3:59:16<29:57,  3.78s/it, loss=2.75, epoch=0.887, learning_rate=6.24e-7]\u001b[A\n",
      " 89%|████████▉ | 3746/4220 [3:59:20<29:52,  3.78s/it, loss=2.75, epoch=0.887, learning_rate=6.24e-7]\u001b[A\n",
      " 89%|████████▉ | 3746/4220 [3:59:20<29:52,  3.78s/it, loss=2.53, epoch=0.887, learning_rate=6.22e-7]\u001b[A\n",
      " 89%|████████▉ | 3747/4220 [3:59:24<29:49,  3.78s/it, loss=2.53, epoch=0.887, learning_rate=6.22e-7]\u001b[A\n",
      " 89%|████████▉ | 3747/4220 [3:59:24<29:49,  3.78s/it, loss=2.46, epoch=0.888, learning_rate=6.19e-7]\u001b[A\n",
      " 89%|████████▉ | 3748/4220 [3:59:28<29:45,  3.78s/it, loss=2.46, epoch=0.888, learning_rate=6.19e-7]\u001b[A\n",
      " 89%|████████▉ | 3748/4220 [3:59:28<29:45,  3.78s/it, loss=2.8, epoch=0.888, learning_rate=6.16e-7] \u001b[A\n",
      " 89%|████████▉ | 3749/4220 [3:59:31<29:41,  3.78s/it, loss=2.8, epoch=0.888, learning_rate=6.16e-7]\u001b[A\n",
      " 89%|████████▉ | 3749/4220 [3:59:31<29:41,  3.78s/it, loss=2.82, epoch=0.888, learning_rate=6.14e-7]\u001b[A\n",
      " 89%|████████▉ | 3750/4220 [3:59:35<29:38,  3.78s/it, loss=2.82, epoch=0.888, learning_rate=6.14e-7]\u001b[A\n",
      " 89%|████████▉ | 3750/4220 [3:59:35<29:38,  3.78s/it, loss=2.62, epoch=0.888, learning_rate=6.11e-7]\u001b[A\n",
      " 89%|████████▉ | 3751/4220 [3:59:39<29:34,  3.78s/it, loss=2.62, epoch=0.888, learning_rate=6.11e-7]\u001b[A\n",
      " 89%|████████▉ | 3751/4220 [3:59:39<29:34,  3.78s/it, loss=2.57, epoch=0.889, learning_rate=6.09e-7]\u001b[A\n",
      " 89%|████████▉ | 3752/4220 [3:59:43<29:30,  3.78s/it, loss=2.57, epoch=0.889, learning_rate=6.09e-7]\u001b[A\n",
      " 89%|████████▉ | 3752/4220 [3:59:43<29:30,  3.78s/it, loss=2.64, epoch=0.889, learning_rate=6.06e-7]\u001b[A\n",
      " 89%|████████▉ | 3753/4220 [3:59:47<29:25,  3.78s/it, loss=2.64, epoch=0.889, learning_rate=6.06e-7]\u001b[A\n",
      " 89%|████████▉ | 3753/4220 [3:59:47<29:25,  3.78s/it, loss=3.07, epoch=0.889, learning_rate=6.04e-7]\u001b[A\n",
      " 89%|████████▉ | 3754/4220 [3:59:50<29:22,  3.78s/it, loss=3.07, epoch=0.889, learning_rate=6.04e-7]\u001b[A\n",
      " 89%|████████▉ | 3754/4220 [3:59:50<29:22,  3.78s/it, loss=2.38, epoch=0.889, learning_rate=6.01e-7]\u001b[A\n",
      " 89%|████████▉ | 3755/4220 [3:59:54<29:17,  3.78s/it, loss=2.38, epoch=0.889, learning_rate=6.01e-7]\u001b[A\n",
      " 89%|████████▉ | 3755/4220 [3:59:54<29:17,  3.78s/it, loss=2.53, epoch=0.89, learning_rate=5.99e-7] \u001b[A\n",
      " 89%|████████▉ | 3756/4220 [3:59:58<29:14,  3.78s/it, loss=2.53, epoch=0.89, learning_rate=5.99e-7]\u001b[A\n",
      " 89%|████████▉ | 3756/4220 [3:59:58<29:14,  3.78s/it, loss=2.63, epoch=0.89, learning_rate=5.96e-7]\u001b[A\n",
      " 89%|████████▉ | 3757/4220 [4:00:02<29:10,  3.78s/it, loss=2.63, epoch=0.89, learning_rate=5.96e-7]\u001b[A\n",
      " 89%|████████▉ | 3757/4220 [4:00:02<29:10,  3.78s/it, loss=2.74, epoch=0.89, learning_rate=5.93e-7]\u001b[A\n",
      " 89%|████████▉ | 3758/4220 [4:00:05<29:07,  3.78s/it, loss=2.74, epoch=0.89, learning_rate=5.93e-7]\u001b[A\n",
      " 89%|████████▉ | 3758/4220 [4:00:05<29:07,  3.78s/it, loss=2.58, epoch=0.89, learning_rate=5.91e-7]\u001b[A\n",
      " 89%|████████▉ | 3759/4220 [4:00:09<29:03,  3.78s/it, loss=2.58, epoch=0.89, learning_rate=5.91e-7]\u001b[A\n",
      " 89%|████████▉ | 3759/4220 [4:00:09<29:03,  3.78s/it, loss=2.72, epoch=0.891, learning_rate=5.88e-7]\u001b[A\n",
      " 89%|████████▉ | 3760/4220 [4:00:13<29:00,  3.78s/it, loss=2.72, epoch=0.891, learning_rate=5.88e-7]\u001b[A\n",
      " 89%|████████▉ | 3760/4220 [4:00:13<29:00,  3.78s/it, loss=2.91, epoch=0.891, learning_rate=5.86e-7]\u001b[A\n",
      " 89%|████████▉ | 3761/4220 [4:00:17<28:56,  3.78s/it, loss=2.91, epoch=0.891, learning_rate=5.86e-7]\u001b[A\n",
      " 89%|████████▉ | 3761/4220 [4:00:17<28:56,  3.78s/it, loss=2.77, epoch=0.891, learning_rate=5.83e-7]\u001b[A\n",
      " 89%|████████▉ | 3762/4220 [4:00:21<28:52,  3.78s/it, loss=2.77, epoch=0.891, learning_rate=5.83e-7]\u001b[A\n",
      " 89%|████████▉ | 3762/4220 [4:00:21<28:52,  3.78s/it, loss=2.59, epoch=0.891, learning_rate=5.81e-7]\u001b[A\n",
      " 89%|████████▉ | 3763/4220 [4:00:24<28:47,  3.78s/it, loss=2.59, epoch=0.891, learning_rate=5.81e-7]\u001b[A\n",
      " 89%|████████▉ | 3763/4220 [4:00:24<28:47,  3.78s/it, loss=2.9, epoch=0.891, learning_rate=5.78e-7] \u001b[A\n",
      " 89%|████████▉ | 3764/4220 [4:00:28<28:44,  3.78s/it, loss=2.9, epoch=0.891, learning_rate=5.78e-7]\u001b[A\n",
      " 89%|████████▉ | 3764/4220 [4:00:28<28:44,  3.78s/it, loss=2.7, epoch=0.892, learning_rate=5.76e-7]\u001b[A\n",
      " 89%|████████▉ | 3765/4220 [4:00:32<28:40,  3.78s/it, loss=2.7, epoch=0.892, learning_rate=5.76e-7]\u001b[A\n",
      " 89%|████████▉ | 3765/4220 [4:00:32<28:40,  3.78s/it, loss=2.9, epoch=0.892, learning_rate=5.73e-7]\u001b[A\n",
      " 89%|████████▉ | 3766/4220 [4:00:36<28:36,  3.78s/it, loss=2.9, epoch=0.892, learning_rate=5.73e-7]\u001b[A\n",
      " 89%|████████▉ | 3766/4220 [4:00:36<28:36,  3.78s/it, loss=2.82, epoch=0.892, learning_rate=5.71e-7]\u001b[A\n",
      " 89%|████████▉ | 3767/4220 [4:00:39<28:32,  3.78s/it, loss=2.82, epoch=0.892, learning_rate=5.71e-7]\u001b[A\n",
      " 89%|████████▉ | 3767/4220 [4:00:39<28:32,  3.78s/it, loss=3.17, epoch=0.892, learning_rate=5.68e-7]\u001b[A\n",
      " 89%|████████▉ | 3768/4220 [4:00:43<28:28,  3.78s/it, loss=3.17, epoch=0.892, learning_rate=5.68e-7]\u001b[A\n",
      " 89%|████████▉ | 3768/4220 [4:00:43<28:28,  3.78s/it, loss=2.65, epoch=0.893, learning_rate=5.66e-7]\u001b[A\n",
      " 89%|████████▉ | 3769/4220 [4:00:47<28:25,  3.78s/it, loss=2.65, epoch=0.893, learning_rate=5.66e-7]\u001b[A\n",
      " 89%|████████▉ | 3769/4220 [4:00:47<28:25,  3.78s/it, loss=3.03, epoch=0.893, learning_rate=5.63e-7]\u001b[A\n",
      " 89%|████████▉ | 3770/4220 [4:00:51<28:20,  3.78s/it, loss=3.03, epoch=0.893, learning_rate=5.63e-7]\u001b[A\n",
      " 89%|████████▉ | 3770/4220 [4:00:51<28:20,  3.78s/it, loss=2.89, epoch=0.893, learning_rate=5.61e-7]\u001b[A\n",
      " 89%|████████▉ | 3771/4220 [4:00:55<28:16,  3.78s/it, loss=2.89, epoch=0.893, learning_rate=5.61e-7]\u001b[A\n",
      " 89%|████████▉ | 3771/4220 [4:00:55<28:16,  3.78s/it, loss=2.92, epoch=0.893, learning_rate=5.59e-7]\u001b[A\n",
      " 89%|████████▉ | 3772/4220 [4:00:58<28:13,  3.78s/it, loss=2.92, epoch=0.893, learning_rate=5.59e-7]\u001b[A\n",
      " 89%|████████▉ | 3772/4220 [4:00:58<28:13,  3.78s/it, loss=2.7, epoch=0.894, learning_rate=5.56e-7] \u001b[A\n",
      " 89%|████████▉ | 3773/4220 [4:01:02<28:09,  3.78s/it, loss=2.7, epoch=0.894, learning_rate=5.56e-7]\u001b[A\n",
      " 89%|████████▉ | 3773/4220 [4:01:02<28:09,  3.78s/it, loss=2.99, epoch=0.894, learning_rate=5.54e-7]\u001b[A\n",
      " 89%|████████▉ | 3774/4220 [4:01:06<28:06,  3.78s/it, loss=2.99, epoch=0.894, learning_rate=5.54e-7]\u001b[A\n",
      " 89%|████████▉ | 3774/4220 [4:01:06<28:06,  3.78s/it, loss=2.8, epoch=0.894, learning_rate=5.51e-7] \u001b[A\n",
      " 89%|████████▉ | 3775/4220 [4:01:10<28:01,  3.78s/it, loss=2.8, epoch=0.894, learning_rate=5.51e-7]\u001b[A\n",
      " 89%|████████▉ | 3775/4220 [4:01:10<28:01,  3.78s/it, loss=2.74, epoch=0.894, learning_rate=5.49e-7]\u001b[A\n",
      " 89%|████████▉ | 3776/4220 [4:01:13<27:58,  3.78s/it, loss=2.74, epoch=0.894, learning_rate=5.49e-7]\u001b[A\n",
      " 89%|████████▉ | 3776/4220 [4:01:14<27:58,  3.78s/it, loss=3.08, epoch=0.895, learning_rate=5.46e-7]\u001b[A\n",
      " 90%|████████▉ | 3777/4220 [4:01:17<27:54,  3.78s/it, loss=3.08, epoch=0.895, learning_rate=5.46e-7]\u001b[A\n",
      " 90%|████████▉ | 3777/4220 [4:01:17<27:54,  3.78s/it, loss=2.58, epoch=0.895, learning_rate=5.44e-7]\u001b[A\n",
      " 90%|████████▉ | 3778/4220 [4:01:21<27:50,  3.78s/it, loss=2.58, epoch=0.895, learning_rate=5.44e-7]\u001b[A\n",
      " 90%|████████▉ | 3778/4220 [4:01:21<27:50,  3.78s/it, loss=2.65, epoch=0.895, learning_rate=5.41e-7]\u001b[A\n",
      " 90%|████████▉ | 3779/4220 [4:01:25<27:47,  3.78s/it, loss=2.65, epoch=0.895, learning_rate=5.41e-7]\u001b[A\n",
      " 90%|████████▉ | 3779/4220 [4:01:25<27:47,  3.78s/it, loss=2.74, epoch=0.895, learning_rate=5.39e-7]\u001b[A\n",
      " 90%|████████▉ | 3780/4220 [4:01:29<27:43,  3.78s/it, loss=2.74, epoch=0.895, learning_rate=5.39e-7]\u001b[A\n",
      " 90%|████████▉ | 3780/4220 [4:01:29<27:43,  3.78s/it, loss=2.92, epoch=0.895, learning_rate=5.37e-7]\u001b[A\n",
      " 90%|████████▉ | 3781/4220 [4:01:32<27:40,  3.78s/it, loss=2.92, epoch=0.895, learning_rate=5.37e-7]\u001b[A\n",
      " 90%|████████▉ | 3781/4220 [4:01:32<27:40,  3.78s/it, loss=3, epoch=0.896, learning_rate=5.34e-7]   \u001b[A\n",
      " 90%|████████▉ | 3782/4220 [4:01:36<27:35,  3.78s/it, loss=3, epoch=0.896, learning_rate=5.34e-7]\u001b[A\n",
      " 90%|████████▉ | 3782/4220 [4:01:36<27:35,  3.78s/it, loss=2.8, epoch=0.896, learning_rate=5.32e-7]\u001b[A\n",
      " 90%|████████▉ | 3783/4220 [4:01:40<27:32,  3.78s/it, loss=2.8, epoch=0.896, learning_rate=5.32e-7]\u001b[A\n",
      " 90%|████████▉ | 3783/4220 [4:01:40<27:32,  3.78s/it, loss=2.55, epoch=0.896, learning_rate=5.29e-7]\u001b[A\n",
      " 90%|████████▉ | 3784/4220 [4:01:44<27:29,  3.78s/it, loss=2.55, epoch=0.896, learning_rate=5.29e-7]\u001b[A\n",
      " 90%|████████▉ | 3784/4220 [4:01:44<27:29,  3.78s/it, loss=2.97, epoch=0.896, learning_rate=5.27e-7]\u001b[A\n",
      " 90%|████████▉ | 3785/4220 [4:01:48<27:25,  3.78s/it, loss=2.97, epoch=0.896, learning_rate=5.27e-7]\u001b[A\n",
      " 90%|████████▉ | 3785/4220 [4:01:48<27:25,  3.78s/it, loss=2.78, epoch=0.897, learning_rate=5.25e-7]\u001b[A\n",
      " 90%|████████▉ | 3786/4220 [4:01:51<27:21,  3.78s/it, loss=2.78, epoch=0.897, learning_rate=5.25e-7]\u001b[A\n",
      " 90%|████████▉ | 3786/4220 [4:01:51<27:21,  3.78s/it, loss=2.91, epoch=0.897, learning_rate=5.22e-7]\u001b[A\n",
      " 90%|████████▉ | 3787/4220 [4:01:55<27:17,  3.78s/it, loss=2.91, epoch=0.897, learning_rate=5.22e-7]\u001b[A\n",
      " 90%|████████▉ | 3787/4220 [4:01:55<27:17,  3.78s/it, loss=2.51, epoch=0.897, learning_rate=5.2e-7] \u001b[A\n",
      " 90%|████████▉ | 3788/4220 [4:01:59<27:14,  3.78s/it, loss=2.51, epoch=0.897, learning_rate=5.2e-7]\u001b[A\n",
      " 90%|████████▉ | 3788/4220 [4:01:59<27:14,  3.78s/it, loss=2.52, epoch=0.897, learning_rate=5.17e-7]\u001b[A\n",
      " 90%|████████▉ | 3789/4220 [4:02:03<27:10,  3.78s/it, loss=2.52, epoch=0.897, learning_rate=5.17e-7]\u001b[A\n",
      " 90%|████████▉ | 3789/4220 [4:02:03<27:10,  3.78s/it, loss=2.66, epoch=0.898, learning_rate=5.15e-7]\u001b[A\n",
      " 90%|████████▉ | 3790/4220 [4:02:06<27:05,  3.78s/it, loss=2.66, epoch=0.898, learning_rate=5.15e-7]\u001b[A\n",
      " 90%|████████▉ | 3790/4220 [4:02:06<27:05,  3.78s/it, loss=2.89, epoch=0.898, learning_rate=5.13e-7]\u001b[A\n",
      " 90%|████████▉ | 3791/4220 [4:02:10<27:02,  3.78s/it, loss=2.89, epoch=0.898, learning_rate=5.13e-7]\u001b[A\n",
      " 90%|████████▉ | 3791/4220 [4:02:10<27:02,  3.78s/it, loss=2.61, epoch=0.898, learning_rate=5.1e-7] \u001b[A\n",
      " 90%|████████▉ | 3792/4220 [4:02:14<26:58,  3.78s/it, loss=2.61, epoch=0.898, learning_rate=5.1e-7]\u001b[A\n",
      " 90%|████████▉ | 3792/4220 [4:02:14<26:58,  3.78s/it, loss=2.81, epoch=0.898, learning_rate=5.08e-7]\u001b[A\n",
      " 90%|████████▉ | 3793/4220 [4:02:18<26:55,  3.78s/it, loss=2.81, epoch=0.898, learning_rate=5.08e-7]\u001b[A\n",
      " 90%|████████▉ | 3793/4220 [4:02:18<26:55,  3.78s/it, loss=2.79, epoch=0.899, learning_rate=5.06e-7]\u001b[A\n",
      " 90%|████████▉ | 3794/4220 [4:02:22<26:51,  3.78s/it, loss=2.79, epoch=0.899, learning_rate=5.06e-7]\u001b[A\n",
      " 90%|████████▉ | 3794/4220 [4:02:22<26:51,  3.78s/it, loss=2.96, epoch=0.899, learning_rate=5.03e-7]\u001b[A\n",
      " 90%|████████▉ | 3795/4220 [4:02:25<26:47,  3.78s/it, loss=2.96, epoch=0.899, learning_rate=5.03e-7]\u001b[A\n",
      " 90%|████████▉ | 3795/4220 [4:02:25<26:47,  3.78s/it, loss=2.63, epoch=0.899, learning_rate=5.01e-7]\u001b[A\n",
      " 90%|████████▉ | 3796/4220 [4:02:29<26:43,  3.78s/it, loss=2.63, epoch=0.899, learning_rate=5.01e-7]\u001b[A\n",
      " 90%|████████▉ | 3796/4220 [4:02:29<26:43,  3.78s/it, loss=2.62, epoch=0.899, learning_rate=4.99e-7]\u001b[A\n",
      " 90%|████████▉ | 3797/4220 [4:02:33<26:39,  3.78s/it, loss=2.62, epoch=0.899, learning_rate=4.99e-7]\u001b[A\n",
      " 90%|████████▉ | 3797/4220 [4:02:33<26:39,  3.78s/it, loss=2.99, epoch=0.9, learning_rate=4.96e-7]  \u001b[A\n",
      " 90%|█████████ | 3798/4220 [4:02:37<26:36,  3.78s/it, loss=2.99, epoch=0.9, learning_rate=4.96e-7]\u001b[A\n",
      " 90%|█████████ | 3798/4220 [4:02:37<26:36,  3.78s/it, loss=2.41, epoch=0.9, learning_rate=4.94e-7]\u001b[A\n",
      " 90%|█████████ | 3799/4220 [4:02:40<26:31,  3.78s/it, loss=2.41, epoch=0.9, learning_rate=4.94e-7]\u001b[A\n",
      " 90%|█████████ | 3799/4220 [4:02:40<26:31,  3.78s/it, loss=2.49, epoch=0.9, learning_rate=4.92e-7]\u001b[A\n",
      " 90%|█████████ | 3800/4220 [4:02:44<26:28,  3.78s/it, loss=2.49, epoch=0.9, learning_rate=4.92e-7]\u001b[A\n",
      " 90%|█████████ | 3800/4220 [4:02:44<26:28,  3.78s/it, loss=2.89, epoch=0.9, learning_rate=4.89e-7]\u001b[A\n",
      " 90%|█████████ | 3801/4220 [4:02:48<26:23,  3.78s/it, loss=2.89, epoch=0.9, learning_rate=4.89e-7]\u001b[A\n",
      " 90%|█████████ | 3801/4220 [4:02:48<26:23,  3.78s/it, loss=2.66, epoch=0.9, learning_rate=4.87e-7]\u001b[A\n",
      " 90%|█████████ | 3802/4220 [4:02:52<26:20,  3.78s/it, loss=2.66, epoch=0.9, learning_rate=4.87e-7]\u001b[A\n",
      " 90%|█████████ | 3802/4220 [4:02:52<26:20,  3.78s/it, loss=2.65, epoch=0.901, learning_rate=4.85e-7]\u001b[A\n",
      " 90%|█████████ | 3803/4220 [4:02:56<26:16,  3.78s/it, loss=2.65, epoch=0.901, learning_rate=4.85e-7]\u001b[A\n",
      " 90%|█████████ | 3803/4220 [4:02:56<26:16,  3.78s/it, loss=3.01, epoch=0.901, learning_rate=4.83e-7]\u001b[A\n",
      " 90%|█████████ | 3804/4220 [4:02:59<26:13,  3.78s/it, loss=3.01, epoch=0.901, learning_rate=4.83e-7]\u001b[A\n",
      " 90%|█████████ | 3804/4220 [4:02:59<26:13,  3.78s/it, loss=2.73, epoch=0.901, learning_rate=4.8e-7] \u001b[A\n",
      " 90%|█████████ | 3805/4220 [4:03:03<26:09,  3.78s/it, loss=2.73, epoch=0.901, learning_rate=4.8e-7]\u001b[A\n",
      " 90%|█████████ | 3805/4220 [4:03:03<26:09,  3.78s/it, loss=2.8, epoch=0.901, learning_rate=4.78e-7]\u001b[A\n",
      " 90%|█████████ | 3806/4220 [4:03:07<26:05,  3.78s/it, loss=2.8, epoch=0.901, learning_rate=4.78e-7]\u001b[A\n",
      " 90%|█████████ | 3806/4220 [4:03:07<26:05,  3.78s/it, loss=2.71, epoch=0.902, learning_rate=4.76e-7]\u001b[A\n",
      " 90%|█████████ | 3807/4220 [4:03:11<26:01,  3.78s/it, loss=2.71, epoch=0.902, learning_rate=4.76e-7]\u001b[A\n",
      " 90%|█████████ | 3807/4220 [4:03:11<26:01,  3.78s/it, loss=3.29, epoch=0.902, learning_rate=4.73e-7]\u001b[A\n",
      " 90%|█████████ | 3808/4220 [4:03:15<25:58,  3.78s/it, loss=3.29, epoch=0.902, learning_rate=4.73e-7]\u001b[A\n",
      " 90%|█████████ | 3808/4220 [4:03:15<25:58,  3.78s/it, loss=2.75, epoch=0.902, learning_rate=4.71e-7]\u001b[A\n",
      " 90%|█████████ | 3809/4220 [4:03:18<25:54,  3.78s/it, loss=2.75, epoch=0.902, learning_rate=4.71e-7]\u001b[A\n",
      " 90%|█████████ | 3809/4220 [4:03:18<25:54,  3.78s/it, loss=2.65, epoch=0.902, learning_rate=4.69e-7]\u001b[A\n",
      " 90%|█████████ | 3810/4220 [4:03:22<25:51,  3.78s/it, loss=2.65, epoch=0.902, learning_rate=4.69e-7]\u001b[A\n",
      " 90%|█████████ | 3810/4220 [4:03:22<25:51,  3.78s/it, loss=3.37, epoch=0.903, learning_rate=4.67e-7]\u001b[A\n",
      " 90%|█████████ | 3811/4220 [4:03:26<25:46,  3.78s/it, loss=3.37, epoch=0.903, learning_rate=4.67e-7]\u001b[A\n",
      " 90%|█████████ | 3811/4220 [4:03:26<25:46,  3.78s/it, loss=2.79, epoch=0.903, learning_rate=4.64e-7]\u001b[A\n",
      " 90%|█████████ | 3812/4220 [4:03:30<25:42,  3.78s/it, loss=2.79, epoch=0.903, learning_rate=4.64e-7]\u001b[A\n",
      " 90%|█████████ | 3812/4220 [4:03:30<25:42,  3.78s/it, loss=3.18, epoch=0.903, learning_rate=4.62e-7]\u001b[A\n",
      " 90%|█████████ | 3813/4220 [4:03:33<25:39,  3.78s/it, loss=3.18, epoch=0.903, learning_rate=4.62e-7]\u001b[A\n",
      " 90%|█████████ | 3813/4220 [4:03:33<25:39,  3.78s/it, loss=3.04, epoch=0.903, learning_rate=4.6e-7] \u001b[A\n",
      " 90%|█████████ | 3814/4220 [4:03:37<25:35,  3.78s/it, loss=3.04, epoch=0.903, learning_rate=4.6e-7]\u001b[A\n",
      " 90%|█████████ | 3814/4220 [4:03:37<25:35,  3.78s/it, loss=2.96, epoch=0.904, learning_rate=4.58e-7]\u001b[A\n",
      " 90%|█████████ | 3815/4220 [4:03:41<25:31,  3.78s/it, loss=2.96, epoch=0.904, learning_rate=4.58e-7]\u001b[A\n",
      " 90%|█████████ | 3815/4220 [4:03:41<25:31,  3.78s/it, loss=2.54, epoch=0.904, learning_rate=4.55e-7]\u001b[A\n",
      " 90%|█████████ | 3816/4220 [4:03:45<25:27,  3.78s/it, loss=2.54, epoch=0.904, learning_rate=4.55e-7]\u001b[A\n",
      " 90%|█████████ | 3816/4220 [4:03:45<25:27,  3.78s/it, loss=2.33, epoch=0.904, learning_rate=4.53e-7]\u001b[A\n",
      " 90%|█████████ | 3817/4220 [4:03:49<25:24,  3.78s/it, loss=2.33, epoch=0.904, learning_rate=4.53e-7]\u001b[A\n",
      " 90%|█████████ | 3817/4220 [4:03:49<25:24,  3.78s/it, loss=2.76, epoch=0.904, learning_rate=4.51e-7]\u001b[A\n",
      " 90%|█████████ | 3818/4220 [4:03:52<25:19,  3.78s/it, loss=2.76, epoch=0.904, learning_rate=4.51e-7]\u001b[A\n",
      " 90%|█████████ | 3818/4220 [4:03:52<25:19,  3.78s/it, loss=2.79, epoch=0.905, learning_rate=4.49e-7]\u001b[A\n",
      " 90%|█████████ | 3819/4220 [4:03:56<25:16,  3.78s/it, loss=2.79, epoch=0.905, learning_rate=4.49e-7]\u001b[A\n",
      " 90%|█████████ | 3819/4220 [4:03:56<25:16,  3.78s/it, loss=3.33, epoch=0.905, learning_rate=4.47e-7]\u001b[A\n",
      " 91%|█████████ | 3820/4220 [4:04:00<25:12,  3.78s/it, loss=3.33, epoch=0.905, learning_rate=4.47e-7]\u001b[A\n",
      " 91%|█████████ | 3820/4220 [4:04:00<25:12,  3.78s/it, loss=2.98, epoch=0.905, learning_rate=4.44e-7]\u001b[A\n",
      " 91%|█████████ | 3821/4220 [4:04:04<25:08,  3.78s/it, loss=2.98, epoch=0.905, learning_rate=4.44e-7]\u001b[A\n",
      " 91%|█████████ | 3821/4220 [4:04:04<25:08,  3.78s/it, loss=2.68, epoch=0.905, learning_rate=4.42e-7]\u001b[A\n",
      " 91%|█████████ | 3822/4220 [4:04:07<25:04,  3.78s/it, loss=2.68, epoch=0.905, learning_rate=4.42e-7]\u001b[A\n",
      " 91%|█████████ | 3822/4220 [4:04:07<25:04,  3.78s/it, loss=3.03, epoch=0.905, learning_rate=4.4e-7] \u001b[A\n",
      " 91%|█████████ | 3823/4220 [4:04:11<25:01,  3.78s/it, loss=3.03, epoch=0.905, learning_rate=4.4e-7]\u001b[A\n",
      " 91%|█████████ | 3823/4220 [4:04:11<25:01,  3.78s/it, loss=2.33, epoch=0.906, learning_rate=4.38e-7]\u001b[A\n",
      " 91%|█████████ | 3824/4220 [4:04:15<24:57,  3.78s/it, loss=2.33, epoch=0.906, learning_rate=4.38e-7]\u001b[A\n",
      " 91%|█████████ | 3824/4220 [4:04:15<24:57,  3.78s/it, loss=2.63, epoch=0.906, learning_rate=4.36e-7]\u001b[A\n",
      " 91%|█████████ | 3825/4220 [4:04:19<24:53,  3.78s/it, loss=2.63, epoch=0.906, learning_rate=4.36e-7]\u001b[A\n",
      " 91%|█████████ | 3825/4220 [4:04:19<24:53,  3.78s/it, loss=3.09, epoch=0.906, learning_rate=4.33e-7]\u001b[A\n",
      " 91%|█████████ | 3826/4220 [4:04:23<24:50,  3.78s/it, loss=3.09, epoch=0.906, learning_rate=4.33e-7]\u001b[A\n",
      " 91%|█████████ | 3826/4220 [4:04:23<24:50,  3.78s/it, loss=3.4, epoch=0.906, learning_rate=4.31e-7] \u001b[A\n",
      " 91%|█████████ | 3827/4220 [4:04:26<24:46,  3.78s/it, loss=3.4, epoch=0.906, learning_rate=4.31e-7]\u001b[A\n",
      " 91%|█████████ | 3827/4220 [4:04:26<24:46,  3.78s/it, loss=2.49, epoch=0.907, learning_rate=4.29e-7]\u001b[A\n",
      " 91%|█████████ | 3828/4220 [4:04:30<24:42,  3.78s/it, loss=2.49, epoch=0.907, learning_rate=4.29e-7]\u001b[A\n",
      " 91%|█████████ | 3828/4220 [4:04:30<24:42,  3.78s/it, loss=2.81, epoch=0.907, learning_rate=4.27e-7]\u001b[A\n",
      " 91%|█████████ | 3829/4220 [4:04:34<24:38,  3.78s/it, loss=2.81, epoch=0.907, learning_rate=4.27e-7]\u001b[A\n",
      " 91%|█████████ | 3829/4220 [4:04:34<24:38,  3.78s/it, loss=3.36, epoch=0.907, learning_rate=4.25e-7]\u001b[A\n",
      " 91%|█████████ | 3830/4220 [4:04:38<24:34,  3.78s/it, loss=3.36, epoch=0.907, learning_rate=4.25e-7]\u001b[A\n",
      " 91%|█████████ | 3830/4220 [4:04:38<24:34,  3.78s/it, loss=2.26, epoch=0.907, learning_rate=4.23e-7]\u001b[A\n",
      " 91%|█████████ | 3831/4220 [4:04:41<24:30,  3.78s/it, loss=2.26, epoch=0.907, learning_rate=4.23e-7]\u001b[A\n",
      " 91%|█████████ | 3831/4220 [4:04:41<24:30,  3.78s/it, loss=2.48, epoch=0.908, learning_rate=4.21e-7]\u001b[A\n",
      " 91%|█████████ | 3832/4220 [4:04:45<24:26,  3.78s/it, loss=2.48, epoch=0.908, learning_rate=4.21e-7]\u001b[A\n",
      " 91%|█████████ | 3832/4220 [4:04:45<24:26,  3.78s/it, loss=2.68, epoch=0.908, learning_rate=4.18e-7]\u001b[A\n",
      " 91%|█████████ | 3833/4220 [4:04:49<24:23,  3.78s/it, loss=2.68, epoch=0.908, learning_rate=4.18e-7]\u001b[A\n",
      " 91%|█████████ | 3833/4220 [4:04:49<24:23,  3.78s/it, loss=2.86, epoch=0.908, learning_rate=4.16e-7]\u001b[A\n",
      " 91%|█████████ | 3834/4220 [4:04:53<24:20,  3.78s/it, loss=2.86, epoch=0.908, learning_rate=4.16e-7]\u001b[A\n",
      " 91%|█████████ | 3834/4220 [4:04:53<24:20,  3.78s/it, loss=2.81, epoch=0.908, learning_rate=4.14e-7]\u001b[A\n",
      " 91%|█████████ | 3835/4220 [4:04:57<24:16,  3.78s/it, loss=2.81, epoch=0.908, learning_rate=4.14e-7]\u001b[A\n",
      " 91%|█████████ | 3835/4220 [4:04:57<24:16,  3.78s/it, loss=2.66, epoch=0.909, learning_rate=4.12e-7]\u001b[A\n",
      " 91%|█████████ | 3836/4220 [4:05:00<24:12,  3.78s/it, loss=2.66, epoch=0.909, learning_rate=4.12e-7]\u001b[A\n",
      " 91%|█████████ | 3836/4220 [4:05:00<24:12,  3.78s/it, loss=2.92, epoch=0.909, learning_rate=4.1e-7] \u001b[A\n",
      " 91%|█████████ | 3837/4220 [4:05:04<24:08,  3.78s/it, loss=2.92, epoch=0.909, learning_rate=4.1e-7]\u001b[A\n",
      " 91%|█████████ | 3837/4220 [4:05:04<24:08,  3.78s/it, loss=2.74, epoch=0.909, learning_rate=4.08e-7]\u001b[A\n",
      " 91%|█████████ | 3838/4220 [4:05:08<24:04,  3.78s/it, loss=2.74, epoch=0.909, learning_rate=4.08e-7]\u001b[A\n",
      " 91%|█████████ | 3838/4220 [4:05:08<24:04,  3.78s/it, loss=2.88, epoch=0.909, learning_rate=4.06e-7]\u001b[A\n",
      " 91%|█████████ | 3839/4220 [4:05:12<24:00,  3.78s/it, loss=2.88, epoch=0.909, learning_rate=4.06e-7]\u001b[A\n",
      " 91%|█████████ | 3839/4220 [4:05:12<24:00,  3.78s/it, loss=2.38, epoch=0.909, learning_rate=4.04e-7]\u001b[A\n",
      " 91%|█████████ | 3840/4220 [4:05:16<23:56,  3.78s/it, loss=2.38, epoch=0.909, learning_rate=4.04e-7]\u001b[A\n",
      " 91%|█████████ | 3840/4220 [4:05:16<23:56,  3.78s/it, loss=3.2, epoch=0.91, learning_rate=4.01e-7]  \u001b[A\n",
      " 91%|█████████ | 3841/4220 [4:05:19<23:53,  3.78s/it, loss=3.2, epoch=0.91, learning_rate=4.01e-7]\u001b[A\n",
      " 91%|█████████ | 3841/4220 [4:05:19<23:53,  3.78s/it, loss=2.28, epoch=0.91, learning_rate=3.99e-7]\u001b[A\n",
      " 91%|█████████ | 3842/4220 [4:05:23<23:49,  3.78s/it, loss=2.28, epoch=0.91, learning_rate=3.99e-7]\u001b[A\n",
      " 91%|█████████ | 3842/4220 [4:05:23<23:49,  3.78s/it, loss=3.25, epoch=0.91, learning_rate=3.97e-7]\u001b[A\n",
      " 91%|█████████ | 3843/4220 [4:05:27<23:45,  3.78s/it, loss=3.25, epoch=0.91, learning_rate=3.97e-7]\u001b[A\n",
      " 91%|█████████ | 3843/4220 [4:05:27<23:45,  3.78s/it, loss=2.92, epoch=0.91, learning_rate=3.95e-7]\u001b[A\n",
      " 91%|█████████ | 3844/4220 [4:05:31<23:40,  3.78s/it, loss=2.92, epoch=0.91, learning_rate=3.95e-7]\u001b[A\n",
      " 91%|█████████ | 3844/4220 [4:05:31<23:40,  3.78s/it, loss=3.01, epoch=0.911, learning_rate=3.93e-7]\u001b[A\n",
      " 91%|█████████ | 3845/4220 [4:05:34<23:37,  3.78s/it, loss=3.01, epoch=0.911, learning_rate=3.93e-7]\u001b[A\n",
      " 91%|█████████ | 3845/4220 [4:05:34<23:37,  3.78s/it, loss=3.12, epoch=0.911, learning_rate=3.91e-7]\u001b[A\n",
      " 91%|█████████ | 3846/4220 [4:05:38<23:34,  3.78s/it, loss=3.12, epoch=0.911, learning_rate=3.91e-7]\u001b[A\n",
      " 91%|█████████ | 3846/4220 [4:05:38<23:34,  3.78s/it, loss=2.94, epoch=0.911, learning_rate=3.89e-7]\u001b[A\n",
      " 91%|█████████ | 3847/4220 [4:05:42<23:30,  3.78s/it, loss=2.94, epoch=0.911, learning_rate=3.89e-7]\u001b[A\n",
      " 91%|█████████ | 3847/4220 [4:05:42<23:30,  3.78s/it, loss=3.07, epoch=0.911, learning_rate=3.87e-7]\u001b[A\n",
      " 91%|█████████ | 3848/4220 [4:05:46<23:26,  3.78s/it, loss=3.07, epoch=0.911, learning_rate=3.87e-7]\u001b[A\n",
      " 91%|█████████ | 3848/4220 [4:05:46<23:26,  3.78s/it, loss=2.58, epoch=0.912, learning_rate=3.85e-7]\u001b[A\n",
      " 91%|█████████ | 3849/4220 [4:05:50<23:22,  3.78s/it, loss=2.58, epoch=0.912, learning_rate=3.85e-7]\u001b[A\n",
      " 91%|█████████ | 3849/4220 [4:05:50<23:22,  3.78s/it, loss=2.83, epoch=0.912, learning_rate=3.83e-7]\u001b[A\n",
      " 91%|█████████ | 3850/4220 [4:05:53<23:19,  3.78s/it, loss=2.83, epoch=0.912, learning_rate=3.83e-7]\u001b[A\n",
      " 91%|█████████ | 3850/4220 [4:05:53<23:19,  3.78s/it, loss=2.29, epoch=0.912, learning_rate=3.81e-7]\u001b[A\n",
      " 91%|█████████▏| 3851/4220 [4:05:57<23:15,  3.78s/it, loss=2.29, epoch=0.912, learning_rate=3.81e-7]\u001b[A\n",
      " 91%|█████████▏| 3851/4220 [4:05:57<23:15,  3.78s/it, loss=2.61, epoch=0.912, learning_rate=3.79e-7]\u001b[A\n",
      " 91%|█████████▏| 3852/4220 [4:06:01<23:12,  3.78s/it, loss=2.61, epoch=0.912, learning_rate=3.79e-7]\u001b[A\n",
      " 91%|█████████▏| 3852/4220 [4:06:01<23:12,  3.78s/it, loss=2.76, epoch=0.913, learning_rate=3.77e-7]\u001b[A\n",
      " 91%|█████████▏| 3853/4220 [4:06:05<23:07,  3.78s/it, loss=2.76, epoch=0.913, learning_rate=3.77e-7]\u001b[A\n",
      " 91%|█████████▏| 3853/4220 [4:06:05<23:07,  3.78s/it, loss=2.46, epoch=0.913, learning_rate=3.75e-7]\u001b[A\n",
      " 91%|█████████▏| 3854/4220 [4:06:08<23:04,  3.78s/it, loss=2.46, epoch=0.913, learning_rate=3.75e-7]\u001b[A\n",
      " 91%|█████████▏| 3854/4220 [4:06:08<23:04,  3.78s/it, loss=3.07, epoch=0.913, learning_rate=3.73e-7]\u001b[A\n",
      " 91%|█████████▏| 3855/4220 [4:06:12<23:00,  3.78s/it, loss=3.07, epoch=0.913, learning_rate=3.73e-7]\u001b[A\n",
      " 91%|█████████▏| 3855/4220 [4:06:12<23:00,  3.78s/it, loss=2.55, epoch=0.913, learning_rate=3.71e-7]\u001b[A\n",
      " 91%|█████████▏| 3856/4220 [4:06:16<22:57,  3.78s/it, loss=2.55, epoch=0.913, learning_rate=3.71e-7]\u001b[A\n",
      " 91%|█████████▏| 3856/4220 [4:06:16<22:57,  3.78s/it, loss=2.83, epoch=0.914, learning_rate=3.69e-7]\u001b[A\n",
      " 91%|█████████▏| 3857/4220 [4:06:20<22:53,  3.78s/it, loss=2.83, epoch=0.914, learning_rate=3.69e-7]\u001b[A\n",
      " 91%|█████████▏| 3857/4220 [4:06:20<22:53,  3.78s/it, loss=2.89, epoch=0.914, learning_rate=3.67e-7]\u001b[A\n",
      " 91%|█████████▏| 3858/4220 [4:06:24<22:49,  3.78s/it, loss=2.89, epoch=0.914, learning_rate=3.67e-7]\u001b[A\n",
      " 91%|█████████▏| 3858/4220 [4:06:24<22:49,  3.78s/it, loss=2.63, epoch=0.914, learning_rate=3.65e-7]\u001b[A\n",
      " 91%|█████████▏| 3859/4220 [4:06:27<22:45,  3.78s/it, loss=2.63, epoch=0.914, learning_rate=3.65e-7]\u001b[A\n",
      " 91%|█████████▏| 3859/4220 [4:06:27<22:45,  3.78s/it, loss=3.22, epoch=0.914, learning_rate=3.63e-7]\u001b[A\n",
      " 91%|█████████▏| 3860/4220 [4:06:31<22:41,  3.78s/it, loss=3.22, epoch=0.914, learning_rate=3.63e-7]\u001b[A\n",
      " 91%|█████████▏| 3860/4220 [4:06:31<22:41,  3.78s/it, loss=3.35, epoch=0.914, learning_rate=3.61e-7]\u001b[A\n",
      " 91%|█████████▏| 3861/4220 [4:06:35<22:38,  3.78s/it, loss=3.35, epoch=0.914, learning_rate=3.61e-7]\u001b[A\n",
      " 91%|█████████▏| 3861/4220 [4:06:35<22:38,  3.78s/it, loss=3.23, epoch=0.915, learning_rate=3.59e-7]\u001b[A\n",
      " 92%|█████████▏| 3862/4220 [4:06:39<22:33,  3.78s/it, loss=3.23, epoch=0.915, learning_rate=3.59e-7]\u001b[A\n",
      " 92%|█████████▏| 3862/4220 [4:06:39<22:33,  3.78s/it, loss=2.38, epoch=0.915, learning_rate=3.57e-7]\u001b[A\n",
      " 92%|█████████▏| 3863/4220 [4:06:43<22:29,  3.78s/it, loss=2.38, epoch=0.915, learning_rate=3.57e-7]\u001b[A\n",
      " 92%|█████████▏| 3863/4220 [4:06:43<22:29,  3.78s/it, loss=3.03, epoch=0.915, learning_rate=3.55e-7]\u001b[A\n",
      " 92%|█████████▏| 3864/4220 [4:06:46<22:26,  3.78s/it, loss=3.03, epoch=0.915, learning_rate=3.55e-7]\u001b[A\n",
      " 92%|█████████▏| 3864/4220 [4:06:46<22:26,  3.78s/it, loss=2.6, epoch=0.915, learning_rate=3.53e-7] \u001b[A\n",
      " 92%|█████████▏| 3865/4220 [4:06:50<22:22,  3.78s/it, loss=2.6, epoch=0.915, learning_rate=3.53e-7]\u001b[A\n",
      " 92%|█████████▏| 3865/4220 [4:06:50<22:22,  3.78s/it, loss=2.63, epoch=0.916, learning_rate=3.51e-7]\u001b[A\n",
      " 92%|█████████▏| 3866/4220 [4:06:54<22:17,  3.78s/it, loss=2.63, epoch=0.916, learning_rate=3.51e-7]\u001b[A\n",
      " 92%|█████████▏| 3866/4220 [4:06:54<22:17,  3.78s/it, loss=2.59, epoch=0.916, learning_rate=3.49e-7]\u001b[A\n",
      " 92%|█████████▏| 3867/4220 [4:06:58<22:14,  3.78s/it, loss=2.59, epoch=0.916, learning_rate=3.49e-7]\u001b[A\n",
      " 92%|█████████▏| 3867/4220 [4:06:58<22:14,  3.78s/it, loss=2.79, epoch=0.916, learning_rate=3.47e-7]\u001b[A\n",
      " 92%|█████████▏| 3868/4220 [4:07:01<22:10,  3.78s/it, loss=2.79, epoch=0.916, learning_rate=3.47e-7]\u001b[A\n",
      " 92%|█████████▏| 3868/4220 [4:07:01<22:10,  3.78s/it, loss=3.04, epoch=0.916, learning_rate=3.45e-7]\u001b[A\n",
      " 92%|█████████▏| 3869/4220 [4:07:05<22:07,  3.78s/it, loss=3.04, epoch=0.916, learning_rate=3.45e-7]\u001b[A\n",
      " 92%|█████████▏| 3869/4220 [4:07:05<22:07,  3.78s/it, loss=2.82, epoch=0.917, learning_rate=3.43e-7]\u001b[A\n",
      " 92%|█████████▏| 3870/4220 [4:07:09<22:03,  3.78s/it, loss=2.82, epoch=0.917, learning_rate=3.43e-7]\u001b[A\n",
      " 92%|█████████▏| 3870/4220 [4:07:09<22:03,  3.78s/it, loss=3.24, epoch=0.917, learning_rate=3.41e-7]\u001b[A\n",
      " 92%|█████████▏| 3871/4220 [4:07:13<22:00,  3.78s/it, loss=3.24, epoch=0.917, learning_rate=3.41e-7]\u001b[A\n",
      " 92%|█████████▏| 3871/4220 [4:07:13<22:00,  3.78s/it, loss=2.74, epoch=0.917, learning_rate=3.39e-7]\u001b[A\n",
      " 92%|█████████▏| 3872/4220 [4:07:17<21:55,  3.78s/it, loss=2.74, epoch=0.917, learning_rate=3.39e-7]\u001b[A\n",
      " 92%|█████████▏| 3872/4220 [4:07:17<21:55,  3.78s/it, loss=2.5, epoch=0.917, learning_rate=3.37e-7] \u001b[A\n",
      " 92%|█████████▏| 3873/4220 [4:07:20<21:52,  3.78s/it, loss=2.5, epoch=0.917, learning_rate=3.37e-7]\u001b[A\n",
      " 92%|█████████▏| 3873/4220 [4:07:20<21:52,  3.78s/it, loss=2.96, epoch=0.918, learning_rate=3.35e-7]\u001b[A\n",
      " 92%|█████████▏| 3874/4220 [4:07:24<21:48,  3.78s/it, loss=2.96, epoch=0.918, learning_rate=3.35e-7]\u001b[A\n",
      " 92%|█████████▏| 3874/4220 [4:07:24<21:48,  3.78s/it, loss=2.81, epoch=0.918, learning_rate=3.33e-7]\u001b[A\n",
      " 92%|█████████▏| 3875/4220 [4:07:28<21:44,  3.78s/it, loss=2.81, epoch=0.918, learning_rate=3.33e-7]\u001b[A\n",
      " 92%|█████████▏| 3875/4220 [4:07:28<21:44,  3.78s/it, loss=2.92, epoch=0.918, learning_rate=3.31e-7]\u001b[A\n",
      " 92%|█████████▏| 3876/4220 [4:07:32<21:41,  3.78s/it, loss=2.92, epoch=0.918, learning_rate=3.31e-7]\u001b[A\n",
      " 92%|█████████▏| 3876/4220 [4:07:32<21:41,  3.78s/it, loss=2.28, epoch=0.918, learning_rate=3.3e-7] \u001b[A\n",
      " 92%|█████████▏| 3877/4220 [4:07:35<21:36,  3.78s/it, loss=2.28, epoch=0.918, learning_rate=3.3e-7]\u001b[A\n",
      " 92%|█████████▏| 3877/4220 [4:07:35<21:36,  3.78s/it, loss=3.06, epoch=0.918, learning_rate=3.28e-7]\u001b[A\n",
      " 92%|█████████▏| 3878/4220 [4:07:39<21:32,  3.78s/it, loss=3.06, epoch=0.918, learning_rate=3.28e-7]\u001b[A\n",
      " 92%|█████████▏| 3878/4220 [4:07:39<21:32,  3.78s/it, loss=2.64, epoch=0.919, learning_rate=3.26e-7]\u001b[A\n",
      " 92%|█████████▏| 3879/4220 [4:07:43<21:29,  3.78s/it, loss=2.64, epoch=0.919, learning_rate=3.26e-7]\u001b[A\n",
      " 92%|█████████▏| 3879/4220 [4:07:43<21:29,  3.78s/it, loss=2.61, epoch=0.919, learning_rate=3.24e-7]\u001b[A\n",
      " 92%|█████████▏| 3880/4220 [4:07:47<21:24,  3.78s/it, loss=2.61, epoch=0.919, learning_rate=3.24e-7]\u001b[A\n",
      " 92%|█████████▏| 3880/4220 [4:07:47<21:24,  3.78s/it, loss=2.8, epoch=0.919, learning_rate=3.22e-7] \u001b[A\n",
      " 92%|█████████▏| 3881/4220 [4:07:51<21:21,  3.78s/it, loss=2.8, epoch=0.919, learning_rate=3.22e-7]\u001b[A\n",
      " 92%|█████████▏| 3881/4220 [4:07:51<21:21,  3.78s/it, loss=2.88, epoch=0.919, learning_rate=3.2e-7]\u001b[A\n",
      " 92%|█████████▏| 3882/4220 [4:07:54<21:17,  3.78s/it, loss=2.88, epoch=0.919, learning_rate=3.2e-7]\u001b[A\n",
      " 92%|█████████▏| 3882/4220 [4:07:54<21:17,  3.78s/it, loss=2.86, epoch=0.92, learning_rate=3.18e-7]\u001b[A\n",
      " 92%|█████████▏| 3883/4220 [4:07:58<21:13,  3.78s/it, loss=2.86, epoch=0.92, learning_rate=3.18e-7]\u001b[A\n",
      " 92%|█████████▏| 3883/4220 [4:07:58<21:13,  3.78s/it, loss=2.6, epoch=0.92, learning_rate=3.16e-7] \u001b[A\n",
      " 92%|█████████▏| 3884/4220 [4:08:02<21:09,  3.78s/it, loss=2.6, epoch=0.92, learning_rate=3.16e-7]\u001b[A\n",
      " 92%|█████████▏| 3884/4220 [4:08:02<21:09,  3.78s/it, loss=2.6, epoch=0.92, learning_rate=3.15e-7]\u001b[A\n",
      " 92%|█████████▏| 3885/4220 [4:08:06<21:06,  3.78s/it, loss=2.6, epoch=0.92, learning_rate=3.15e-7]\u001b[A\n",
      " 92%|█████████▏| 3885/4220 [4:08:06<21:06,  3.78s/it, loss=2.72, epoch=0.92, learning_rate=3.13e-7]\u001b[A\n",
      " 92%|█████████▏| 3886/4220 [4:08:09<21:02,  3.78s/it, loss=2.72, epoch=0.92, learning_rate=3.13e-7]\u001b[A\n",
      " 92%|█████████▏| 3886/4220 [4:08:09<21:02,  3.78s/it, loss=2.59, epoch=0.921, learning_rate=3.11e-7]\u001b[A\n",
      " 92%|█████████▏| 3887/4220 [4:08:13<20:59,  3.78s/it, loss=2.59, epoch=0.921, learning_rate=3.11e-7]\u001b[A\n",
      " 92%|█████████▏| 3887/4220 [4:08:13<20:59,  3.78s/it, loss=2.86, epoch=0.921, learning_rate=3.09e-7]\u001b[A\n",
      " 92%|█████████▏| 3888/4220 [4:08:17<20:55,  3.78s/it, loss=2.86, epoch=0.921, learning_rate=3.09e-7]\u001b[A\n",
      " 92%|█████████▏| 3888/4220 [4:08:17<20:55,  3.78s/it, loss=2.85, epoch=0.921, learning_rate=3.07e-7]\u001b[A\n",
      " 92%|█████████▏| 3889/4220 [4:08:21<20:51,  3.78s/it, loss=2.85, epoch=0.921, learning_rate=3.07e-7]\u001b[A\n",
      " 92%|█████████▏| 3889/4220 [4:08:21<20:51,  3.78s/it, loss=2.39, epoch=0.921, learning_rate=3.05e-7]\u001b[A\n",
      " 92%|█████████▏| 3890/4220 [4:08:25<20:47,  3.78s/it, loss=2.39, epoch=0.921, learning_rate=3.05e-7]\u001b[A\n",
      " 92%|█████████▏| 3890/4220 [4:08:25<20:47,  3.78s/it, loss=2.47, epoch=0.922, learning_rate=3.03e-7]\u001b[A\n",
      " 92%|█████████▏| 3891/4220 [4:08:28<20:44,  3.78s/it, loss=2.47, epoch=0.922, learning_rate=3.03e-7]\u001b[A\n",
      " 92%|█████████▏| 3891/4220 [4:08:28<20:44,  3.78s/it, loss=2.62, epoch=0.922, learning_rate=3.02e-7]\u001b[A\n",
      " 92%|█████████▏| 3892/4220 [4:08:32<20:39,  3.78s/it, loss=2.62, epoch=0.922, learning_rate=3.02e-7]\u001b[A\n",
      " 92%|█████████▏| 3892/4220 [4:08:32<20:39,  3.78s/it, loss=2.87, epoch=0.922, learning_rate=3e-7]   \u001b[A\n",
      " 92%|█████████▏| 3893/4220 [4:08:36<20:35,  3.78s/it, loss=2.87, epoch=0.922, learning_rate=3e-7]\u001b[A\n",
      " 92%|█████████▏| 3893/4220 [4:08:36<20:35,  3.78s/it, loss=2.49, epoch=0.922, learning_rate=2.98e-7]\u001b[A\n",
      " 92%|█████████▏| 3894/4220 [4:08:40<20:32,  3.78s/it, loss=2.49, epoch=0.922, learning_rate=2.98e-7]\u001b[A\n",
      " 92%|█████████▏| 3894/4220 [4:08:40<20:32,  3.78s/it, loss=2.96, epoch=0.923, learning_rate=2.96e-7]\u001b[A\n",
      " 92%|█████████▏| 3895/4220 [4:08:43<20:29,  3.78s/it, loss=2.96, epoch=0.923, learning_rate=2.96e-7]\u001b[A\n",
      " 92%|█████████▏| 3895/4220 [4:08:43<20:29,  3.78s/it, loss=2.72, epoch=0.923, learning_rate=2.94e-7]\u001b[A\n",
      " 92%|█████████▏| 3896/4220 [4:08:47<20:25,  3.78s/it, loss=2.72, epoch=0.923, learning_rate=2.94e-7]\u001b[A\n",
      " 92%|█████████▏| 3896/4220 [4:08:47<20:25,  3.78s/it, loss=2.67, epoch=0.923, learning_rate=2.93e-7]\u001b[A\n",
      " 92%|█████████▏| 3897/4220 [4:08:51<20:21,  3.78s/it, loss=2.67, epoch=0.923, learning_rate=2.93e-7]\u001b[A\n",
      " 92%|█████████▏| 3897/4220 [4:08:51<20:21,  3.78s/it, loss=3.36, epoch=0.923, learning_rate=2.91e-7]\u001b[A\n",
      " 92%|█████████▏| 3898/4220 [4:08:55<20:17,  3.78s/it, loss=3.36, epoch=0.923, learning_rate=2.91e-7]\u001b[A\n",
      " 92%|█████████▏| 3898/4220 [4:08:55<20:17,  3.78s/it, loss=2.94, epoch=0.923, learning_rate=2.89e-7]\u001b[A\n",
      " 92%|█████████▏| 3899/4220 [4:08:59<20:12,  3.78s/it, loss=2.94, epoch=0.923, learning_rate=2.89e-7]\u001b[A\n",
      " 92%|█████████▏| 3899/4220 [4:08:59<20:12,  3.78s/it, loss=2.55, epoch=0.924, learning_rate=2.87e-7]\u001b[A\n",
      " 92%|█████████▏| 3900/4220 [4:09:02<20:09,  3.78s/it, loss=2.55, epoch=0.924, learning_rate=2.87e-7]\u001b[A\n",
      " 92%|█████████▏| 3900/4220 [4:09:02<20:09,  3.78s/it, loss=3.16, epoch=0.924, learning_rate=2.86e-7]\u001b[A\n",
      " 92%|█████████▏| 3901/4220 [4:09:06<20:05,  3.78s/it, loss=3.16, epoch=0.924, learning_rate=2.86e-7]\u001b[A\n",
      " 92%|█████████▏| 3901/4220 [4:09:06<20:05,  3.78s/it, loss=2.78, epoch=0.924, learning_rate=2.84e-7]\u001b[A\n",
      " 92%|█████████▏| 3902/4220 [4:09:10<20:02,  3.78s/it, loss=2.78, epoch=0.924, learning_rate=2.84e-7]\u001b[A\n",
      " 92%|█████████▏| 3902/4220 [4:09:10<20:02,  3.78s/it, loss=3.28, epoch=0.924, learning_rate=2.82e-7]\u001b[A\n",
      " 92%|█████████▏| 3903/4220 [4:09:14<19:58,  3.78s/it, loss=3.28, epoch=0.924, learning_rate=2.82e-7]\u001b[A\n",
      " 92%|█████████▏| 3903/4220 [4:09:14<19:58,  3.78s/it, loss=2.94, epoch=0.925, learning_rate=2.8e-7] \u001b[A\n",
      " 93%|█████████▎| 3904/4220 [4:09:18<19:55,  3.78s/it, loss=2.94, epoch=0.925, learning_rate=2.8e-7]\u001b[A\n",
      " 93%|█████████▎| 3904/4220 [4:09:18<19:55,  3.78s/it, loss=2.99, epoch=0.925, learning_rate=2.78e-7]\u001b[A\n",
      " 93%|█████████▎| 3905/4220 [4:09:21<19:51,  3.78s/it, loss=2.99, epoch=0.925, learning_rate=2.78e-7]\u001b[A\n",
      " 93%|█████████▎| 3905/4220 [4:09:21<19:51,  3.78s/it, loss=3.01, epoch=0.925, learning_rate=2.77e-7]\u001b[A\n",
      " 93%|█████████▎| 3906/4220 [4:09:25<19:47,  3.78s/it, loss=3.01, epoch=0.925, learning_rate=2.77e-7]\u001b[A\n",
      " 93%|█████████▎| 3906/4220 [4:09:25<19:47,  3.78s/it, loss=3.15, epoch=0.925, learning_rate=2.75e-7]\u001b[A\n",
      " 93%|█████████▎| 3907/4220 [4:09:29<19:43,  3.78s/it, loss=3.15, epoch=0.925, learning_rate=2.75e-7]\u001b[A\n",
      " 93%|█████████▎| 3907/4220 [4:09:29<19:43,  3.78s/it, loss=2.53, epoch=0.926, learning_rate=2.73e-7]\u001b[A\n",
      " 93%|█████████▎| 3908/4220 [4:09:33<19:39,  3.78s/it, loss=2.53, epoch=0.926, learning_rate=2.73e-7]\u001b[A\n",
      " 93%|█████████▎| 3908/4220 [4:09:33<19:39,  3.78s/it, loss=3.14, epoch=0.926, learning_rate=2.72e-7]\u001b[A\n",
      " 93%|█████████▎| 3909/4220 [4:09:36<19:35,  3.78s/it, loss=3.14, epoch=0.926, learning_rate=2.72e-7]\u001b[A\n",
      " 93%|█████████▎| 3909/4220 [4:09:36<19:35,  3.78s/it, loss=3.03, epoch=0.926, learning_rate=2.7e-7] \u001b[A\n",
      " 93%|█████████▎| 3910/4220 [4:09:40<19:32,  3.78s/it, loss=3.03, epoch=0.926, learning_rate=2.7e-7]\u001b[A\n",
      " 93%|█████████▎| 3910/4220 [4:09:40<19:32,  3.78s/it, loss=3.01, epoch=0.926, learning_rate=2.68e-7]\u001b[A\n",
      " 93%|█████████▎| 3911/4220 [4:09:44<19:28,  3.78s/it, loss=3.01, epoch=0.926, learning_rate=2.68e-7]\u001b[A\n",
      " 93%|█████████▎| 3911/4220 [4:09:44<19:28,  3.78s/it, loss=2.85, epoch=0.927, learning_rate=2.66e-7]\u001b[A\n",
      " 93%|█████████▎| 3912/4220 [4:09:48<19:24,  3.78s/it, loss=2.85, epoch=0.927, learning_rate=2.66e-7]\u001b[A\n",
      " 93%|█████████▎| 3912/4220 [4:09:48<19:24,  3.78s/it, loss=2.9, epoch=0.927, learning_rate=2.65e-7] \u001b[A\n",
      " 93%|█████████▎| 3913/4220 [4:09:52<19:20,  3.78s/it, loss=2.9, epoch=0.927, learning_rate=2.65e-7]\u001b[A\n",
      " 93%|█████████▎| 3913/4220 [4:09:52<19:20,  3.78s/it, loss=2.85, epoch=0.927, learning_rate=2.63e-7]\u001b[A\n",
      " 93%|█████████▎| 3914/4220 [4:09:55<19:17,  3.78s/it, loss=2.85, epoch=0.927, learning_rate=2.63e-7]\u001b[A\n",
      " 93%|█████████▎| 3914/4220 [4:09:55<19:17,  3.78s/it, loss=3.17, epoch=0.927, learning_rate=2.61e-7]\u001b[A\n",
      " 93%|█████████▎| 3915/4220 [4:09:59<19:14,  3.78s/it, loss=3.17, epoch=0.927, learning_rate=2.61e-7]\u001b[A\n",
      " 93%|█████████▎| 3915/4220 [4:09:59<19:14,  3.78s/it, loss=2.59, epoch=0.927, learning_rate=2.6e-7] \u001b[A\n",
      " 93%|█████████▎| 3916/4220 [4:10:03<19:10,  3.78s/it, loss=2.59, epoch=0.927, learning_rate=2.6e-7]\u001b[A\n",
      " 93%|█████████▎| 3916/4220 [4:10:03<19:10,  3.78s/it, loss=3.1, epoch=0.928, learning_rate=2.58e-7]\u001b[A\n",
      " 93%|█████████▎| 3917/4220 [4:10:07<19:06,  3.78s/it, loss=3.1, epoch=0.928, learning_rate=2.58e-7]\u001b[A\n",
      " 93%|█████████▎| 3917/4220 [4:10:07<19:06,  3.78s/it, loss=3.15, epoch=0.928, learning_rate=2.56e-7]\u001b[A\n",
      " 93%|█████████▎| 3918/4220 [4:10:10<19:02,  3.78s/it, loss=3.15, epoch=0.928, learning_rate=2.56e-7]\u001b[A\n",
      " 93%|█████████▎| 3918/4220 [4:10:10<19:02,  3.78s/it, loss=2.78, epoch=0.928, learning_rate=2.55e-7]\u001b[A\n",
      " 93%|█████████▎| 3919/4220 [4:10:14<18:58,  3.78s/it, loss=2.78, epoch=0.928, learning_rate=2.55e-7]\u001b[A\n",
      " 93%|█████████▎| 3919/4220 [4:10:14<18:58,  3.78s/it, loss=2.87, epoch=0.928, learning_rate=2.53e-7]\u001b[A\n",
      " 93%|█████████▎| 3920/4220 [4:10:18<18:54,  3.78s/it, loss=2.87, epoch=0.928, learning_rate=2.53e-7]\u001b[A\n",
      " 93%|█████████▎| 3920/4220 [4:10:18<18:54,  3.78s/it, loss=2.77, epoch=0.929, learning_rate=2.51e-7]\u001b[A\n",
      " 93%|█████████▎| 3921/4220 [4:10:22<18:50,  3.78s/it, loss=2.77, epoch=0.929, learning_rate=2.51e-7]\u001b[A\n",
      " 93%|█████████▎| 3921/4220 [4:10:22<18:50,  3.78s/it, loss=2.94, epoch=0.929, learning_rate=2.5e-7] \u001b[A\n",
      " 93%|█████████▎| 3922/4220 [4:10:26<18:46,  3.78s/it, loss=2.94, epoch=0.929, learning_rate=2.5e-7]\u001b[A\n",
      " 93%|█████████▎| 3922/4220 [4:10:26<18:46,  3.78s/it, loss=3.08, epoch=0.929, learning_rate=2.48e-7]\u001b[A\n",
      " 93%|█████████▎| 3923/4220 [4:10:29<18:42,  3.78s/it, loss=3.08, epoch=0.929, learning_rate=2.48e-7]\u001b[A\n",
      " 93%|█████████▎| 3923/4220 [4:10:29<18:42,  3.78s/it, loss=3.07, epoch=0.929, learning_rate=2.46e-7]\u001b[A\n",
      " 93%|█████████▎| 3924/4220 [4:10:33<18:39,  3.78s/it, loss=3.07, epoch=0.929, learning_rate=2.46e-7]\u001b[A\n",
      " 93%|█████████▎| 3924/4220 [4:10:33<18:39,  3.78s/it, loss=2.82, epoch=0.93, learning_rate=2.45e-7] \u001b[A\n",
      " 93%|█████████▎| 3925/4220 [4:10:37<18:35,  3.78s/it, loss=2.82, epoch=0.93, learning_rate=2.45e-7]\u001b[A\n",
      " 93%|█████████▎| 3925/4220 [4:10:37<18:35,  3.78s/it, loss=2.11, epoch=0.93, learning_rate=2.43e-7]\u001b[A\n",
      " 93%|█████████▎| 3926/4220 [4:10:41<18:31,  3.78s/it, loss=2.11, epoch=0.93, learning_rate=2.43e-7]\u001b[A\n",
      " 93%|█████████▎| 3926/4220 [4:10:41<18:31,  3.78s/it, loss=2.54, epoch=0.93, learning_rate=2.41e-7]\u001b[A\n",
      " 93%|█████████▎| 3927/4220 [4:10:44<18:27,  3.78s/it, loss=2.54, epoch=0.93, learning_rate=2.41e-7]\u001b[A\n",
      " 93%|█████████▎| 3927/4220 [4:10:44<18:27,  3.78s/it, loss=2.93, epoch=0.93, learning_rate=2.4e-7] \u001b[A\n",
      " 93%|█████████▎| 3928/4220 [4:10:48<18:24,  3.78s/it, loss=2.93, epoch=0.93, learning_rate=2.4e-7]\u001b[A\n",
      " 93%|█████████▎| 3928/4220 [4:10:48<18:24,  3.78s/it, loss=3, epoch=0.931, learning_rate=2.38e-7] \u001b[A\n",
      " 93%|█████████▎| 3929/4220 [4:10:52<18:20,  3.78s/it, loss=3, epoch=0.931, learning_rate=2.38e-7]\u001b[A\n",
      " 93%|█████████▎| 3929/4220 [4:10:52<18:20,  3.78s/it, loss=3.09, epoch=0.931, learning_rate=2.36e-7]\u001b[A\n",
      " 93%|█████████▎| 3930/4220 [4:10:56<18:16,  3.78s/it, loss=3.09, epoch=0.931, learning_rate=2.36e-7]\u001b[A\n",
      " 93%|█████████▎| 3930/4220 [4:10:56<18:16,  3.78s/it, loss=3.25, epoch=0.931, learning_rate=2.35e-7]\u001b[A\n",
      " 93%|█████████▎| 3931/4220 [4:11:00<18:12,  3.78s/it, loss=3.25, epoch=0.931, learning_rate=2.35e-7]\u001b[A\n",
      " 93%|█████████▎| 3931/4220 [4:11:00<18:12,  3.78s/it, loss=2.61, epoch=0.931, learning_rate=2.33e-7]\u001b[A\n",
      " 93%|█████████▎| 3932/4220 [4:11:03<18:08,  3.78s/it, loss=2.61, epoch=0.931, learning_rate=2.33e-7]\u001b[A\n",
      " 93%|█████████▎| 3932/4220 [4:11:03<18:08,  3.78s/it, loss=2.6, epoch=0.932, learning_rate=2.32e-7] \u001b[A\n",
      " 93%|█████████▎| 3933/4220 [4:11:07<18:05,  3.78s/it, loss=2.6, epoch=0.932, learning_rate=2.32e-7]\u001b[A\n",
      " 93%|█████████▎| 3933/4220 [4:11:07<18:05,  3.78s/it, loss=2.67, epoch=0.932, learning_rate=2.3e-7]\u001b[A\n",
      " 93%|█████████▎| 3934/4220 [4:11:11<18:01,  3.78s/it, loss=2.67, epoch=0.932, learning_rate=2.3e-7]\u001b[A\n",
      " 93%|█████████▎| 3934/4220 [4:11:11<18:01,  3.78s/it, loss=2.62, epoch=0.932, learning_rate=2.28e-7]\u001b[A\n",
      " 93%|█████████▎| 3935/4220 [4:11:15<17:57,  3.78s/it, loss=2.62, epoch=0.932, learning_rate=2.28e-7]\u001b[A\n",
      " 93%|█████████▎| 3935/4220 [4:11:15<17:57,  3.78s/it, loss=2.51, epoch=0.932, learning_rate=2.27e-7]\u001b[A\n",
      " 93%|█████████▎| 3936/4220 [4:11:19<17:54,  3.78s/it, loss=2.51, epoch=0.932, learning_rate=2.27e-7]\u001b[A\n",
      " 93%|█████████▎| 3936/4220 [4:11:19<17:54,  3.78s/it, loss=2.74, epoch=0.932, learning_rate=2.25e-7]\u001b[A\n",
      " 93%|█████████▎| 3937/4220 [4:11:22<17:50,  3.78s/it, loss=2.74, epoch=0.932, learning_rate=2.25e-7]\u001b[A\n",
      " 93%|█████████▎| 3937/4220 [4:11:22<17:50,  3.78s/it, loss=2.98, epoch=0.933, learning_rate=2.24e-7]\u001b[A\n",
      " 93%|█████████▎| 3938/4220 [4:11:26<17:46,  3.78s/it, loss=2.98, epoch=0.933, learning_rate=2.24e-7]\u001b[A\n",
      " 93%|█████████▎| 3938/4220 [4:11:26<17:46,  3.78s/it, loss=2.89, epoch=0.933, learning_rate=2.22e-7]\u001b[A\n",
      " 93%|█████████▎| 3939/4220 [4:11:30<17:42,  3.78s/it, loss=2.89, epoch=0.933, learning_rate=2.22e-7]\u001b[A\n",
      " 93%|█████████▎| 3939/4220 [4:11:30<17:42,  3.78s/it, loss=2.69, epoch=0.933, learning_rate=2.21e-7]\u001b[A\n",
      " 93%|█████████▎| 3940/4220 [4:11:34<17:39,  3.78s/it, loss=2.69, epoch=0.933, learning_rate=2.21e-7]\u001b[A\n",
      " 93%|█████████▎| 3940/4220 [4:11:34<17:39,  3.78s/it, loss=2.67, epoch=0.933, learning_rate=2.19e-7]\u001b[A\n",
      " 93%|█████████▎| 3941/4220 [4:11:37<17:35,  3.78s/it, loss=2.67, epoch=0.933, learning_rate=2.19e-7]\u001b[A\n",
      " 93%|█████████▎| 3941/4220 [4:11:37<17:35,  3.78s/it, loss=3.17, epoch=0.934, learning_rate=2.17e-7]\u001b[A\n",
      " 93%|█████████▎| 3942/4220 [4:11:41<17:31,  3.78s/it, loss=3.17, epoch=0.934, learning_rate=2.17e-7]\u001b[A\n",
      " 93%|█████████▎| 3942/4220 [4:11:41<17:31,  3.78s/it, loss=2.68, epoch=0.934, learning_rate=2.16e-7]\u001b[A\n",
      " 93%|█████████▎| 3943/4220 [4:11:45<17:27,  3.78s/it, loss=2.68, epoch=0.934, learning_rate=2.16e-7]\u001b[A\n",
      " 93%|█████████▎| 3943/4220 [4:11:45<17:27,  3.78s/it, loss=2.91, epoch=0.934, learning_rate=2.14e-7]\u001b[A\n",
      " 93%|█████████▎| 3944/4220 [4:11:49<17:23,  3.78s/it, loss=2.91, epoch=0.934, learning_rate=2.14e-7]\u001b[A\n",
      " 93%|█████████▎| 3944/4220 [4:11:49<17:23,  3.78s/it, loss=3.1, epoch=0.934, learning_rate=2.13e-7] \u001b[A\n",
      " 93%|█████████▎| 3945/4220 [4:11:53<17:20,  3.78s/it, loss=3.1, epoch=0.934, learning_rate=2.13e-7]\u001b[A\n",
      " 93%|█████████▎| 3945/4220 [4:11:53<17:20,  3.78s/it, loss=2.75, epoch=0.935, learning_rate=2.11e-7]\u001b[A\n",
      " 94%|█████████▎| 3946/4220 [4:11:56<17:16,  3.78s/it, loss=2.75, epoch=0.935, learning_rate=2.11e-7]\u001b[A\n",
      " 94%|█████████▎| 3946/4220 [4:11:56<17:16,  3.78s/it, loss=2.68, epoch=0.935, learning_rate=2.1e-7] \u001b[A\n",
      " 94%|█████████▎| 3947/4220 [4:12:00<17:12,  3.78s/it, loss=2.68, epoch=0.935, learning_rate=2.1e-7]\u001b[A\n",
      " 94%|█████████▎| 3947/4220 [4:12:00<17:12,  3.78s/it, loss=2.78, epoch=0.935, learning_rate=2.08e-7]\u001b[A\n",
      " 94%|█████████▎| 3948/4220 [4:12:04<17:08,  3.78s/it, loss=2.78, epoch=0.935, learning_rate=2.08e-7]\u001b[A\n",
      " 94%|█████████▎| 3948/4220 [4:12:04<17:08,  3.78s/it, loss=2.24, epoch=0.935, learning_rate=2.07e-7]\u001b[A\n",
      " 94%|█████████▎| 3949/4220 [4:12:08<17:05,  3.78s/it, loss=2.24, epoch=0.935, learning_rate=2.07e-7]\u001b[A\n",
      " 94%|█████████▎| 3949/4220 [4:12:08<17:05,  3.78s/it, loss=2.6, epoch=0.936, learning_rate=2.05e-7] \u001b[A\n",
      " 94%|█████████▎| 3950/4220 [4:12:11<17:01,  3.78s/it, loss=2.6, epoch=0.936, learning_rate=2.05e-7]\u001b[A\n",
      " 94%|█████████▎| 3950/4220 [4:12:11<17:01,  3.78s/it, loss=2.74, epoch=0.936, learning_rate=2.04e-7]\u001b[A\n",
      " 94%|█████████▎| 3951/4220 [4:12:15<16:57,  3.78s/it, loss=2.74, epoch=0.936, learning_rate=2.04e-7]\u001b[A\n",
      " 94%|█████████▎| 3951/4220 [4:12:15<16:57,  3.78s/it, loss=3.27, epoch=0.936, learning_rate=2.02e-7]\u001b[A\n",
      " 94%|█████████▎| 3952/4220 [4:12:19<16:53,  3.78s/it, loss=3.27, epoch=0.936, learning_rate=2.02e-7]\u001b[A\n",
      " 94%|█████████▎| 3952/4220 [4:12:19<16:53,  3.78s/it, loss=2.8, epoch=0.936, learning_rate=2.01e-7] \u001b[A\n",
      " 94%|█████████▎| 3953/4220 [4:12:23<16:49,  3.78s/it, loss=2.8, epoch=0.936, learning_rate=2.01e-7]\u001b[A\n",
      " 94%|█████████▎| 3953/4220 [4:12:23<16:49,  3.78s/it, loss=2.58, epoch=0.936, learning_rate=1.99e-7]\u001b[A\n",
      " 94%|█████████▎| 3954/4220 [4:12:27<16:45,  3.78s/it, loss=2.58, epoch=0.936, learning_rate=1.99e-7]\u001b[A\n",
      " 94%|█████████▎| 3954/4220 [4:12:27<16:45,  3.78s/it, loss=2.7, epoch=0.937, learning_rate=1.98e-7] \u001b[A\n",
      " 94%|█████████▎| 3955/4220 [4:12:30<16:41,  3.78s/it, loss=2.7, epoch=0.937, learning_rate=1.98e-7]\u001b[A\n",
      " 94%|█████████▎| 3955/4220 [4:12:30<16:41,  3.78s/it, loss=3.14, epoch=0.937, learning_rate=1.96e-7]\u001b[A\n",
      " 94%|█████████▎| 3956/4220 [4:12:34<16:38,  3.78s/it, loss=3.14, epoch=0.937, learning_rate=1.96e-7]\u001b[A\n",
      " 94%|█████████▎| 3956/4220 [4:12:34<16:38,  3.78s/it, loss=2.58, epoch=0.937, learning_rate=1.95e-7]\u001b[A\n",
      " 94%|█████████▍| 3957/4220 [4:12:38<16:34,  3.78s/it, loss=2.58, epoch=0.937, learning_rate=1.95e-7]\u001b[A\n",
      " 94%|█████████▍| 3957/4220 [4:12:38<16:34,  3.78s/it, loss=2.9, epoch=0.937, learning_rate=1.93e-7] \u001b[A\n",
      " 94%|█████████▍| 3958/4220 [4:12:42<16:31,  3.78s/it, loss=2.9, epoch=0.937, learning_rate=1.93e-7]\u001b[A\n",
      " 94%|█████████▍| 3958/4220 [4:12:42<16:31,  3.78s/it, loss=2.49, epoch=0.938, learning_rate=1.92e-7]\u001b[A\n",
      " 94%|█████████▍| 3959/4220 [4:12:46<16:26,  3.78s/it, loss=2.49, epoch=0.938, learning_rate=1.92e-7]\u001b[A\n",
      " 94%|█████████▍| 3959/4220 [4:12:46<16:26,  3.78s/it, loss=2.46, epoch=0.938, learning_rate=1.91e-7]\u001b[A\n",
      " 94%|█████████▍| 3960/4220 [4:12:49<16:23,  3.78s/it, loss=2.46, epoch=0.938, learning_rate=1.91e-7]\u001b[A\n",
      " 94%|█████████▍| 3960/4220 [4:12:49<16:23,  3.78s/it, loss=2.94, epoch=0.938, learning_rate=1.89e-7]\u001b[A\n",
      " 94%|█████████▍| 3961/4220 [4:12:53<16:19,  3.78s/it, loss=2.94, epoch=0.938, learning_rate=1.89e-7]\u001b[A\n",
      " 94%|█████████▍| 3961/4220 [4:12:53<16:19,  3.78s/it, loss=2.39, epoch=0.938, learning_rate=1.88e-7]\u001b[A\n",
      " 94%|█████████▍| 3962/4220 [4:12:57<16:15,  3.78s/it, loss=2.39, epoch=0.938, learning_rate=1.88e-7]\u001b[A\n",
      " 94%|█████████▍| 3962/4220 [4:12:57<16:15,  3.78s/it, loss=2.74, epoch=0.939, learning_rate=1.86e-7]\u001b[A\n",
      " 94%|█████████▍| 3963/4220 [4:13:01<16:11,  3.78s/it, loss=2.74, epoch=0.939, learning_rate=1.86e-7]\u001b[A\n",
      " 94%|█████████▍| 3963/4220 [4:13:01<16:11,  3.78s/it, loss=2.69, epoch=0.939, learning_rate=1.85e-7]\u001b[A\n",
      " 94%|█████████▍| 3964/4220 [4:13:04<16:07,  3.78s/it, loss=2.69, epoch=0.939, learning_rate=1.85e-7]\u001b[A\n",
      " 94%|█████████▍| 3964/4220 [4:13:04<16:07,  3.78s/it, loss=3.09, epoch=0.939, learning_rate=1.83e-7]\u001b[A\n",
      " 94%|█████████▍| 3965/4220 [4:13:08<16:04,  3.78s/it, loss=3.09, epoch=0.939, learning_rate=1.83e-7]\u001b[A\n",
      " 94%|█████████▍| 3965/4220 [4:13:08<16:04,  3.78s/it, loss=2.69, epoch=0.939, learning_rate=1.82e-7]\u001b[A\n",
      " 94%|█████████▍| 3966/4220 [4:13:12<16:00,  3.78s/it, loss=2.69, epoch=0.939, learning_rate=1.82e-7]\u001b[A\n",
      " 94%|█████████▍| 3966/4220 [4:13:12<16:00,  3.78s/it, loss=2.36, epoch=0.94, learning_rate=1.8e-7]  \u001b[A\n",
      " 94%|█████████▍| 3967/4220 [4:13:16<15:57,  3.78s/it, loss=2.36, epoch=0.94, learning_rate=1.8e-7]\u001b[A\n",
      " 94%|█████████▍| 3967/4220 [4:13:16<15:57,  3.78s/it, loss=2.35, epoch=0.94, learning_rate=1.79e-7]\u001b[A\n",
      " 94%|█████████▍| 3968/4220 [4:13:20<15:53,  3.78s/it, loss=2.35, epoch=0.94, learning_rate=1.79e-7]\u001b[A\n",
      " 94%|█████████▍| 3968/4220 [4:13:20<15:53,  3.78s/it, loss=2.73, epoch=0.94, learning_rate=1.78e-7]\u001b[A\n",
      " 94%|█████████▍| 3969/4220 [4:13:23<15:49,  3.78s/it, loss=2.73, epoch=0.94, learning_rate=1.78e-7]\u001b[A\n",
      " 94%|█████████▍| 3969/4220 [4:13:23<15:49,  3.78s/it, loss=3, epoch=0.94, learning_rate=1.76e-7]   \u001b[A\n",
      " 94%|█████████▍| 3970/4220 [4:13:27<15:46,  3.78s/it, loss=3, epoch=0.94, learning_rate=1.76e-7]\u001b[A\n",
      " 94%|█████████▍| 3970/4220 [4:13:27<15:46,  3.78s/it, loss=2.54, epoch=0.941, learning_rate=1.75e-7]\u001b[A\n",
      " 94%|█████████▍| 3971/4220 [4:13:31<15:41,  3.78s/it, loss=2.54, epoch=0.941, learning_rate=1.75e-7]\u001b[A\n",
      " 94%|█████████▍| 3971/4220 [4:13:31<15:41,  3.78s/it, loss=2.57, epoch=0.941, learning_rate=1.74e-7]\u001b[A\n",
      " 94%|█████████▍| 3972/4220 [4:13:35<15:38,  3.78s/it, loss=2.57, epoch=0.941, learning_rate=1.74e-7]\u001b[A\n",
      " 94%|█████████▍| 3972/4220 [4:13:35<15:38,  3.78s/it, loss=3.27, epoch=0.941, learning_rate=1.72e-7]\u001b[A\n",
      " 94%|█████████▍| 3973/4220 [4:13:38<15:34,  3.78s/it, loss=3.27, epoch=0.941, learning_rate=1.72e-7]\u001b[A\n",
      " 94%|█████████▍| 3973/4220 [4:13:38<15:34,  3.78s/it, loss=2.86, epoch=0.941, learning_rate=1.71e-7]\u001b[A\n",
      " 94%|█████████▍| 3974/4220 [4:13:42<15:30,  3.78s/it, loss=2.86, epoch=0.941, learning_rate=1.71e-7]\u001b[A\n",
      " 94%|█████████▍| 3974/4220 [4:13:42<15:30,  3.78s/it, loss=2.82, epoch=0.941, learning_rate=1.69e-7]\u001b[A\n",
      " 94%|█████████▍| 3975/4220 [4:13:46<15:26,  3.78s/it, loss=2.82, epoch=0.941, learning_rate=1.69e-7]\u001b[A\n",
      " 94%|█████████▍| 3975/4220 [4:13:46<15:26,  3.78s/it, loss=2.89, epoch=0.942, learning_rate=1.68e-7]\u001b[A\n",
      " 94%|█████████▍| 3976/4220 [4:13:50<15:22,  3.78s/it, loss=2.89, epoch=0.942, learning_rate=1.68e-7]\u001b[A\n",
      " 94%|█████████▍| 3976/4220 [4:13:50<15:22,  3.78s/it, loss=3.35, epoch=0.942, learning_rate=1.67e-7]\u001b[A\n",
      " 94%|█████████▍| 3977/4220 [4:13:54<15:19,  3.78s/it, loss=3.35, epoch=0.942, learning_rate=1.67e-7]\u001b[A\n",
      " 94%|█████████▍| 3977/4220 [4:13:54<15:19,  3.78s/it, loss=2.83, epoch=0.942, learning_rate=1.65e-7]\u001b[A\n",
      " 94%|█████████▍| 3978/4220 [4:13:57<15:15,  3.78s/it, loss=2.83, epoch=0.942, learning_rate=1.65e-7]\u001b[A\n",
      " 94%|█████████▍| 3978/4220 [4:13:57<15:15,  3.78s/it, loss=2.9, epoch=0.942, learning_rate=1.64e-7] \u001b[A\n",
      " 94%|█████████▍| 3979/4220 [4:14:01<15:11,  3.78s/it, loss=2.9, epoch=0.942, learning_rate=1.64e-7]\u001b[A\n",
      " 94%|█████████▍| 3979/4220 [4:14:01<15:11,  3.78s/it, loss=2.38, epoch=0.943, learning_rate=1.63e-7]\u001b[A\n",
      " 94%|█████████▍| 3980/4220 [4:14:05<15:07,  3.78s/it, loss=2.38, epoch=0.943, learning_rate=1.63e-7]\u001b[A\n",
      " 94%|█████████▍| 3980/4220 [4:14:05<15:07,  3.78s/it, loss=2.85, epoch=0.943, learning_rate=1.61e-7]\u001b[A\n",
      " 94%|█████████▍| 3981/4220 [4:14:09<15:03,  3.78s/it, loss=2.85, epoch=0.943, learning_rate=1.61e-7]\u001b[A\n",
      " 94%|█████████▍| 3981/4220 [4:14:09<15:03,  3.78s/it, loss=2.92, epoch=0.943, learning_rate=1.6e-7] \u001b[A\n",
      " 94%|█████████▍| 3982/4220 [4:14:13<15:00,  3.78s/it, loss=2.92, epoch=0.943, learning_rate=1.6e-7]\u001b[A\n",
      " 94%|█████████▍| 3982/4220 [4:14:13<15:00,  3.78s/it, loss=2.86, epoch=0.943, learning_rate=1.59e-7]\u001b[A\n",
      " 94%|█████████▍| 3983/4220 [4:14:16<14:56,  3.78s/it, loss=2.86, epoch=0.943, learning_rate=1.59e-7]\u001b[A\n",
      " 94%|█████████▍| 3983/4220 [4:14:16<14:56,  3.78s/it, loss=3.03, epoch=0.944, learning_rate=1.57e-7]\u001b[A\n",
      " 94%|█████████▍| 3984/4220 [4:14:20<14:53,  3.78s/it, loss=3.03, epoch=0.944, learning_rate=1.57e-7]\u001b[A\n",
      " 94%|█████████▍| 3984/4220 [4:14:20<14:53,  3.78s/it, loss=2.95, epoch=0.944, learning_rate=1.56e-7]\u001b[A\n",
      " 94%|█████████▍| 3985/4220 [4:14:24<14:48,  3.78s/it, loss=2.95, epoch=0.944, learning_rate=1.56e-7]\u001b[A\n",
      " 94%|█████████▍| 3985/4220 [4:14:24<14:48,  3.78s/it, loss=2.61, epoch=0.944, learning_rate=1.55e-7]\u001b[A\n",
      " 94%|█████████▍| 3986/4220 [4:14:28<14:45,  3.78s/it, loss=2.61, epoch=0.944, learning_rate=1.55e-7]\u001b[A\n",
      " 94%|█████████▍| 3986/4220 [4:14:28<14:45,  3.78s/it, loss=2.92, epoch=0.944, learning_rate=1.53e-7]\u001b[A\n",
      " 94%|█████████▍| 3987/4220 [4:14:31<14:40,  3.78s/it, loss=2.92, epoch=0.944, learning_rate=1.53e-7]\u001b[A\n",
      " 94%|█████████▍| 3987/4220 [4:14:31<14:40,  3.78s/it, loss=2.91, epoch=0.945, learning_rate=1.52e-7]\u001b[A\n",
      " 95%|█████████▍| 3988/4220 [4:14:35<14:37,  3.78s/it, loss=2.91, epoch=0.945, learning_rate=1.52e-7]\u001b[A\n",
      " 95%|█████████▍| 3988/4220 [4:14:35<14:37,  3.78s/it, loss=3.42, epoch=0.945, learning_rate=1.51e-7]\u001b[A\n",
      " 95%|█████████▍| 3989/4220 [4:14:39<14:33,  3.78s/it, loss=3.42, epoch=0.945, learning_rate=1.51e-7]\u001b[A\n",
      " 95%|█████████▍| 3989/4220 [4:14:39<14:33,  3.78s/it, loss=2.88, epoch=0.945, learning_rate=1.49e-7]\u001b[A\n",
      " 95%|█████████▍| 3990/4220 [4:14:43<14:29,  3.78s/it, loss=2.88, epoch=0.945, learning_rate=1.49e-7]\u001b[A\n",
      " 95%|█████████▍| 3990/4220 [4:14:43<14:29,  3.78s/it, loss=2.74, epoch=0.945, learning_rate=1.48e-7]\u001b[A\n",
      " 95%|█████████▍| 3991/4220 [4:14:47<14:25,  3.78s/it, loss=2.74, epoch=0.945, learning_rate=1.48e-7]\u001b[A\n",
      " 95%|█████████▍| 3991/4220 [4:14:47<14:25,  3.78s/it, loss=2.72, epoch=0.945, learning_rate=1.47e-7]\u001b[A\n",
      " 95%|█████████▍| 3992/4220 [4:14:50<14:21,  3.78s/it, loss=2.72, epoch=0.945, learning_rate=1.47e-7]\u001b[A\n",
      " 95%|█████████▍| 3992/4220 [4:14:50<14:21,  3.78s/it, loss=2.83, epoch=0.946, learning_rate=1.46e-7]\u001b[A\n",
      " 95%|█████████▍| 3993/4220 [4:14:54<14:18,  3.78s/it, loss=2.83, epoch=0.946, learning_rate=1.46e-7]\u001b[A\n",
      " 95%|█████████▍| 3993/4220 [4:14:54<14:18,  3.78s/it, loss=2.54, epoch=0.946, learning_rate=1.44e-7]\u001b[A\n",
      " 95%|█████████▍| 3994/4220 [4:14:58<14:14,  3.78s/it, loss=2.54, epoch=0.946, learning_rate=1.44e-7]\u001b[A\n",
      " 95%|█████████▍| 3994/4220 [4:14:58<14:14,  3.78s/it, loss=2.5, epoch=0.946, learning_rate=1.43e-7] \u001b[A\n",
      " 95%|█████████▍| 3995/4220 [4:15:02<14:10,  3.78s/it, loss=2.5, epoch=0.946, learning_rate=1.43e-7]\u001b[A\n",
      " 95%|█████████▍| 3995/4220 [4:15:02<14:10,  3.78s/it, loss=2.66, epoch=0.946, learning_rate=1.42e-7]\u001b[A\n",
      " 95%|█████████▍| 3996/4220 [4:15:05<14:06,  3.78s/it, loss=2.66, epoch=0.946, learning_rate=1.42e-7]\u001b[A\n",
      " 95%|█████████▍| 3996/4220 [4:15:05<14:06,  3.78s/it, loss=2.55, epoch=0.947, learning_rate=1.41e-7]\u001b[A\n",
      " 95%|█████████▍| 3997/4220 [4:15:09<14:02,  3.78s/it, loss=2.55, epoch=0.947, learning_rate=1.41e-7]\u001b[A\n",
      " 95%|█████████▍| 3997/4220 [4:15:09<14:02,  3.78s/it, loss=2.77, epoch=0.947, learning_rate=1.39e-7]\u001b[A\n",
      " 95%|█████████▍| 3998/4220 [4:15:13<13:59,  3.78s/it, loss=2.77, epoch=0.947, learning_rate=1.39e-7]\u001b[A\n",
      " 95%|█████████▍| 3998/4220 [4:15:13<13:59,  3.78s/it, loss=2.34, epoch=0.947, learning_rate=1.38e-7]\u001b[A\n",
      " 95%|█████████▍| 3999/4220 [4:15:17<13:55,  3.78s/it, loss=2.34, epoch=0.947, learning_rate=1.38e-7]\u001b[A\n",
      " 95%|█████████▍| 3999/4220 [4:15:17<13:55,  3.78s/it, loss=2.89, epoch=0.947, learning_rate=1.37e-7]\u001b[A\n",
      " 95%|█████████▍| 4000/4220 [4:15:21<13:52,  3.78s/it, loss=2.89, epoch=0.947, learning_rate=1.37e-7]\u001b[A\n",
      " 95%|█████████▍| 4000/4220 [4:15:21<13:52,  3.78s/it, loss=2.74, epoch=0.948, learning_rate=1.36e-7]\u001b[ARemoved shared tensor {'model.unembed.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "\n",
      " 95%|█████████▍| 4001/4220 [4:16:29<1:24:36, 23.18s/it, loss=2.74, epoch=0.948, learning_rate=1.36e-7]\u001b[A\n",
      " 95%|█████████▍| 4001/4220 [4:16:29<1:24:36, 23.18s/it, loss=2.58, epoch=0.948, learning_rate=1.34e-7]\u001b[A\n",
      " 95%|█████████▍| 4002/4220 [4:16:33<1:03:01, 17.35s/it, loss=2.58, epoch=0.948, learning_rate=1.34e-7]\u001b[A\n",
      " 95%|█████████▍| 4002/4220 [4:16:33<1:03:01, 17.35s/it, loss=3.54, epoch=0.948, learning_rate=1.33e-7]\u001b[A\n",
      " 95%|█████████▍| 4003/4220 [4:16:36<47:58, 13.27s/it, loss=3.54, epoch=0.948, learning_rate=1.33e-7]  \u001b[A\n",
      " 95%|█████████▍| 4003/4220 [4:16:36<47:58, 13.27s/it, loss=3.02, epoch=0.948, learning_rate=1.32e-7]\u001b[A\n",
      " 95%|█████████▍| 4004/4220 [4:16:40<37:28, 10.41s/it, loss=3.02, epoch=0.948, learning_rate=1.32e-7]\u001b[A\n",
      " 95%|█████████▍| 4004/4220 [4:16:40<37:28, 10.41s/it, loss=2.44, epoch=0.949, learning_rate=1.31e-7]\u001b[A\n",
      " 95%|█████████▍| 4005/4220 [4:16:44<30:08,  8.41s/it, loss=2.44, epoch=0.949, learning_rate=1.31e-7]\u001b[A\n",
      " 95%|█████████▍| 4005/4220 [4:16:44<30:08,  8.41s/it, loss=2.8, epoch=0.949, learning_rate=1.3e-7]  \u001b[A\n",
      " 95%|█████████▍| 4006/4220 [4:16:48<25:00,  7.01s/it, loss=2.8, epoch=0.949, learning_rate=1.3e-7]\u001b[A\n",
      " 95%|█████████▍| 4006/4220 [4:16:48<25:00,  7.01s/it, loss=2.38, epoch=0.949, learning_rate=1.28e-7]\u001b[A\n",
      " 95%|█████████▍| 4007/4220 [4:16:51<21:25,  6.03s/it, loss=2.38, epoch=0.949, learning_rate=1.28e-7]\u001b[A\n",
      " 95%|█████████▍| 4007/4220 [4:16:51<21:25,  6.03s/it, loss=2.63, epoch=0.949, learning_rate=1.27e-7]\u001b[A\n",
      " 95%|█████████▍| 4008/4220 [4:16:55<18:54,  5.35s/it, loss=2.63, epoch=0.949, learning_rate=1.27e-7]\u001b[A\n",
      " 95%|█████████▍| 4008/4220 [4:16:55<18:54,  5.35s/it, loss=2.49, epoch=0.95, learning_rate=1.26e-7] \u001b[A\n",
      " 95%|█████████▌| 4009/4220 [4:16:59<17:08,  4.87s/it, loss=2.49, epoch=0.95, learning_rate=1.26e-7]\u001b[A\n",
      " 95%|█████████▌| 4009/4220 [4:16:59<17:08,  4.87s/it, loss=2.86, epoch=0.95, learning_rate=1.25e-7]\u001b[A\n",
      " 95%|█████████▌| 4010/4220 [4:17:03<15:53,  4.54s/it, loss=2.86, epoch=0.95, learning_rate=1.25e-7]\u001b[A\n",
      " 95%|█████████▌| 4010/4220 [4:17:03<15:53,  4.54s/it, loss=3.45, epoch=0.95, learning_rate=1.24e-7]\u001b[A\n",
      " 95%|█████████▌| 4011/4220 [4:17:07<15:01,  4.31s/it, loss=3.45, epoch=0.95, learning_rate=1.24e-7]\u001b[A\n",
      " 95%|█████████▌| 4011/4220 [4:17:07<15:01,  4.31s/it, loss=3.06, epoch=0.95, learning_rate=1.23e-7]\u001b[A\n",
      " 95%|█████████▌| 4012/4220 [4:17:10<14:22,  4.15s/it, loss=3.06, epoch=0.95, learning_rate=1.23e-7]\u001b[A\n",
      " 95%|█████████▌| 4012/4220 [4:17:10<14:22,  4.15s/it, loss=2.41, epoch=0.95, learning_rate=1.21e-7]\u001b[A\n",
      " 95%|█████████▌| 4013/4220 [4:17:14<13:55,  4.04s/it, loss=2.41, epoch=0.95, learning_rate=1.21e-7]\u001b[A\n",
      " 95%|█████████▌| 4013/4220 [4:17:14<13:55,  4.04s/it, loss=2.85, epoch=0.951, learning_rate=1.2e-7]\u001b[A\n",
      " 95%|█████████▌| 4014/4220 [4:17:18<13:34,  3.95s/it, loss=2.85, epoch=0.951, learning_rate=1.2e-7]\u001b[A\n",
      " 95%|█████████▌| 4014/4220 [4:17:18<13:34,  3.95s/it, loss=2.5, epoch=0.951, learning_rate=1.19e-7]\u001b[A\n",
      " 95%|█████████▌| 4015/4220 [4:17:22<13:19,  3.90s/it, loss=2.5, epoch=0.951, learning_rate=1.19e-7]\u001b[A\n",
      " 95%|█████████▌| 4015/4220 [4:17:22<13:19,  3.90s/it, loss=3.02, epoch=0.951, learning_rate=1.18e-7]\u001b[A\n",
      " 95%|█████████▌| 4016/4220 [4:17:25<13:07,  3.86s/it, loss=3.02, epoch=0.951, learning_rate=1.18e-7]\u001b[A\n",
      " 95%|█████████▌| 4016/4220 [4:17:25<13:07,  3.86s/it, loss=2.3, epoch=0.951, learning_rate=1.17e-7] \u001b[A\n",
      " 95%|█████████▌| 4017/4220 [4:17:29<12:58,  3.84s/it, loss=2.3, epoch=0.951, learning_rate=1.17e-7]\u001b[A\n",
      " 95%|█████████▌| 4017/4220 [4:17:29<12:58,  3.84s/it, loss=2.52, epoch=0.952, learning_rate=1.16e-7]\u001b[A\n",
      " 95%|█████████▌| 4018/4220 [4:17:33<12:51,  3.82s/it, loss=2.52, epoch=0.952, learning_rate=1.16e-7]\u001b[A\n",
      " 95%|█████████▌| 4018/4220 [4:17:33<12:51,  3.82s/it, loss=3.36, epoch=0.952, learning_rate=1.15e-7]\u001b[A\n",
      " 95%|█████████▌| 4019/4220 [4:17:37<12:44,  3.80s/it, loss=3.36, epoch=0.952, learning_rate=1.15e-7]\u001b[A\n",
      " 95%|█████████▌| 4019/4220 [4:17:37<12:44,  3.80s/it, loss=2.68, epoch=0.952, learning_rate=1.13e-7]\u001b[A\n",
      " 95%|█████████▌| 4020/4220 [4:17:40<12:38,  3.79s/it, loss=2.68, epoch=0.952, learning_rate=1.13e-7]\u001b[A\n",
      " 95%|█████████▌| 4020/4220 [4:17:40<12:38,  3.79s/it, loss=2.57, epoch=0.952, learning_rate=1.12e-7]\u001b[A\n",
      " 95%|█████████▌| 4021/4220 [4:17:44<12:33,  3.79s/it, loss=2.57, epoch=0.952, learning_rate=1.12e-7]\u001b[A\n",
      " 95%|█████████▌| 4021/4220 [4:17:44<12:33,  3.79s/it, loss=3.1, epoch=0.953, learning_rate=1.11e-7] \u001b[A\n",
      " 95%|█████████▌| 4022/4220 [4:17:48<12:29,  3.79s/it, loss=3.1, epoch=0.953, learning_rate=1.11e-7]\u001b[A\n",
      " 95%|█████████▌| 4022/4220 [4:17:48<12:29,  3.79s/it, loss=3.11, epoch=0.953, learning_rate=1.1e-7]\u001b[A\n",
      " 95%|█████████▌| 4023/4220 [4:17:52<12:25,  3.78s/it, loss=3.11, epoch=0.953, learning_rate=1.1e-7]\u001b[A\n",
      " 95%|█████████▌| 4023/4220 [4:17:52<12:25,  3.78s/it, loss=3.13, epoch=0.953, learning_rate=1.09e-7]\u001b[A\n",
      " 95%|█████████▌| 4024/4220 [4:17:56<12:21,  3.78s/it, loss=3.13, epoch=0.953, learning_rate=1.09e-7]\u001b[A\n",
      " 95%|█████████▌| 4024/4220 [4:17:56<12:21,  3.78s/it, loss=2.77, epoch=0.953, learning_rate=1.08e-7]\u001b[A\n",
      " 95%|█████████▌| 4025/4220 [4:17:59<12:16,  3.78s/it, loss=2.77, epoch=0.953, learning_rate=1.08e-7]\u001b[A\n",
      " 95%|█████████▌| 4025/4220 [4:17:59<12:16,  3.78s/it, loss=3.17, epoch=0.954, learning_rate=1.07e-7]\u001b[A\n",
      " 95%|█████████▌| 4026/4220 [4:18:03<12:12,  3.78s/it, loss=3.17, epoch=0.954, learning_rate=1.07e-7]\u001b[A\n",
      " 95%|█████████▌| 4026/4220 [4:18:03<12:12,  3.78s/it, loss=2.44, epoch=0.954, learning_rate=1.06e-7]\u001b[A\n",
      " 95%|█████████▌| 4027/4220 [4:18:07<12:09,  3.78s/it, loss=2.44, epoch=0.954, learning_rate=1.06e-7]\u001b[A\n",
      " 95%|█████████▌| 4027/4220 [4:18:07<12:09,  3.78s/it, loss=2.43, epoch=0.954, learning_rate=1.05e-7]\u001b[A\n",
      " 95%|█████████▌| 4028/4220 [4:18:11<12:05,  3.78s/it, loss=2.43, epoch=0.954, learning_rate=1.05e-7]\u001b[A\n",
      " 95%|█████████▌| 4028/4220 [4:18:11<12:05,  3.78s/it, loss=3.39, epoch=0.954, learning_rate=1.04e-7]\u001b[A\n",
      " 95%|█████████▌| 4029/4220 [4:18:14<12:01,  3.78s/it, loss=3.39, epoch=0.954, learning_rate=1.04e-7]\u001b[A\n",
      " 95%|█████████▌| 4029/4220 [4:18:14<12:01,  3.78s/it, loss=2.67, epoch=0.955, learning_rate=1.02e-7]\u001b[A\n",
      " 95%|█████████▌| 4030/4220 [4:18:18<11:57,  3.78s/it, loss=2.67, epoch=0.955, learning_rate=1.02e-7]\u001b[A\n",
      " 95%|█████████▌| 4030/4220 [4:18:18<11:57,  3.78s/it, loss=2.3, epoch=0.955, learning_rate=1.01e-7] \u001b[A\n",
      " 96%|█████████▌| 4031/4220 [4:18:22<11:53,  3.78s/it, loss=2.3, epoch=0.955, learning_rate=1.01e-7]\u001b[A\n",
      " 96%|█████████▌| 4031/4220 [4:18:22<11:53,  3.78s/it, loss=2.75, epoch=0.955, learning_rate=1e-7]  \u001b[A\n",
      " 96%|█████████▌| 4032/4220 [4:18:26<11:49,  3.78s/it, loss=2.75, epoch=0.955, learning_rate=1e-7]\u001b[A\n",
      " 96%|█████████▌| 4032/4220 [4:18:26<11:49,  3.78s/it, loss=3.47, epoch=0.955, learning_rate=9.93e-8]\u001b[A\n",
      " 96%|█████████▌| 4033/4220 [4:18:30<11:46,  3.78s/it, loss=3.47, epoch=0.955, learning_rate=9.93e-8]\u001b[A\n",
      " 96%|█████████▌| 4033/4220 [4:18:30<11:46,  3.78s/it, loss=2.75, epoch=0.955, learning_rate=9.82e-8]\u001b[A\n",
      " 96%|█████████▌| 4034/4220 [4:18:33<11:42,  3.78s/it, loss=2.75, epoch=0.955, learning_rate=9.82e-8]\u001b[A\n",
      " 96%|█████████▌| 4034/4220 [4:18:33<11:42,  3.78s/it, loss=2.53, epoch=0.956, learning_rate=9.72e-8]\u001b[A\n",
      " 96%|█████████▌| 4035/4220 [4:18:37<11:39,  3.78s/it, loss=2.53, epoch=0.956, learning_rate=9.72e-8]\u001b[A\n",
      " 96%|█████████▌| 4035/4220 [4:18:37<11:39,  3.78s/it, loss=3.15, epoch=0.956, learning_rate=9.62e-8]\u001b[A\n",
      " 96%|█████████▌| 4036/4220 [4:18:41<11:35,  3.78s/it, loss=3.15, epoch=0.956, learning_rate=9.62e-8]\u001b[A\n",
      " 96%|█████████▌| 4036/4220 [4:18:41<11:35,  3.78s/it, loss=2.9, epoch=0.956, learning_rate=9.51e-8] \u001b[A\n",
      " 96%|█████████▌| 4037/4220 [4:18:45<11:31,  3.78s/it, loss=2.9, epoch=0.956, learning_rate=9.51e-8]\u001b[A\n",
      " 96%|█████████▌| 4037/4220 [4:18:45<11:31,  3.78s/it, loss=2.94, epoch=0.956, learning_rate=9.41e-8]\u001b[A\n",
      " 96%|█████████▌| 4038/4220 [4:18:48<11:27,  3.78s/it, loss=2.94, epoch=0.956, learning_rate=9.41e-8]\u001b[A\n",
      " 96%|█████████▌| 4038/4220 [4:18:48<11:27,  3.78s/it, loss=2.31, epoch=0.957, learning_rate=9.31e-8]\u001b[A\n",
      " 96%|█████████▌| 4039/4220 [4:18:52<11:23,  3.78s/it, loss=2.31, epoch=0.957, learning_rate=9.31e-8]\u001b[A\n",
      " 96%|█████████▌| 4039/4220 [4:18:52<11:23,  3.78s/it, loss=2.74, epoch=0.957, learning_rate=9.21e-8]\u001b[A\n",
      " 96%|█████████▌| 4040/4220 [4:18:56<11:20,  3.78s/it, loss=2.74, epoch=0.957, learning_rate=9.21e-8]\u001b[A\n",
      " 96%|█████████▌| 4040/4220 [4:18:56<11:20,  3.78s/it, loss=3.16, epoch=0.957, learning_rate=9.11e-8]\u001b[A\n",
      " 96%|█████████▌| 4041/4220 [4:19:00<11:16,  3.78s/it, loss=3.16, epoch=0.957, learning_rate=9.11e-8]\u001b[A\n",
      " 96%|█████████▌| 4041/4220 [4:19:00<11:16,  3.78s/it, loss=3.09, epoch=0.957, learning_rate=9.01e-8]\u001b[A\n",
      " 96%|█████████▌| 4042/4220 [4:19:04<11:12,  3.78s/it, loss=3.09, epoch=0.957, learning_rate=9.01e-8]\u001b[A\n",
      " 96%|█████████▌| 4042/4220 [4:19:04<11:12,  3.78s/it, loss=2.6, epoch=0.958, learning_rate=8.91e-8] \u001b[A\n",
      " 96%|█████████▌| 4043/4220 [4:19:07<11:08,  3.78s/it, loss=2.6, epoch=0.958, learning_rate=8.91e-8]\u001b[A\n",
      " 96%|█████████▌| 4043/4220 [4:19:07<11:08,  3.78s/it, loss=2.79, epoch=0.958, learning_rate=8.81e-8]\u001b[A\n",
      " 96%|█████████▌| 4044/4220 [4:19:11<11:04,  3.78s/it, loss=2.79, epoch=0.958, learning_rate=8.81e-8]\u001b[A\n",
      " 96%|█████████▌| 4044/4220 [4:19:11<11:04,  3.78s/it, loss=2.98, epoch=0.958, learning_rate=8.71e-8]\u001b[A\n",
      " 96%|█████████▌| 4045/4220 [4:19:15<11:01,  3.78s/it, loss=2.98, epoch=0.958, learning_rate=8.71e-8]\u001b[A\n",
      " 96%|█████████▌| 4045/4220 [4:19:15<11:01,  3.78s/it, loss=2.91, epoch=0.958, learning_rate=8.61e-8]\u001b[A\n",
      " 96%|█████████▌| 4046/4220 [4:19:19<10:57,  3.78s/it, loss=2.91, epoch=0.958, learning_rate=8.61e-8]\u001b[A\n",
      " 96%|█████████▌| 4046/4220 [4:19:19<10:57,  3.78s/it, loss=3, epoch=0.959, learning_rate=8.51e-8]   \u001b[A\n",
      " 96%|█████████▌| 4047/4220 [4:19:22<10:54,  3.78s/it, loss=3, epoch=0.959, learning_rate=8.51e-8]\u001b[A\n",
      " 96%|█████████▌| 4047/4220 [4:19:22<10:54,  3.78s/it, loss=2.87, epoch=0.959, learning_rate=8.42e-8]\u001b[A\n",
      " 96%|█████████▌| 4048/4220 [4:19:26<10:50,  3.78s/it, loss=2.87, epoch=0.959, learning_rate=8.42e-8]\u001b[A\n",
      " 96%|█████████▌| 4048/4220 [4:19:26<10:50,  3.78s/it, loss=2.46, epoch=0.959, learning_rate=8.32e-8]\u001b[A\n",
      " 96%|█████████▌| 4049/4220 [4:19:30<10:46,  3.78s/it, loss=2.46, epoch=0.959, learning_rate=8.32e-8]\u001b[A\n",
      " 96%|█████████▌| 4049/4220 [4:19:30<10:46,  3.78s/it, loss=3.11, epoch=0.959, learning_rate=8.23e-8]\u001b[A\n",
      " 96%|█████████▌| 4050/4220 [4:19:34<10:42,  3.78s/it, loss=3.11, epoch=0.959, learning_rate=8.23e-8]\u001b[A\n",
      " 96%|█████████▌| 4050/4220 [4:19:34<10:42,  3.78s/it, loss=2.7, epoch=0.959, learning_rate=8.13e-8] \u001b[A\n",
      " 96%|█████████▌| 4051/4220 [4:19:38<10:39,  3.78s/it, loss=2.7, epoch=0.959, learning_rate=8.13e-8]\u001b[A\n",
      " 96%|█████████▌| 4051/4220 [4:19:38<10:39,  3.78s/it, loss=2.82, epoch=0.96, learning_rate=8.04e-8]\u001b[A\n",
      " 96%|█████████▌| 4052/4220 [4:19:41<10:34,  3.78s/it, loss=2.82, epoch=0.96, learning_rate=8.04e-8]\u001b[A\n",
      " 96%|█████████▌| 4052/4220 [4:19:41<10:34,  3.78s/it, loss=3.11, epoch=0.96, learning_rate=7.94e-8]\u001b[A\n",
      " 96%|█████████▌| 4053/4220 [4:19:45<10:31,  3.78s/it, loss=3.11, epoch=0.96, learning_rate=7.94e-8]\u001b[A\n",
      " 96%|█████████▌| 4053/4220 [4:19:45<10:31,  3.78s/it, loss=3.5, epoch=0.96, learning_rate=7.85e-8] \u001b[A\n",
      " 96%|█████████▌| 4054/4220 [4:19:49<10:27,  3.78s/it, loss=3.5, epoch=0.96, learning_rate=7.85e-8]\u001b[A\n",
      " 96%|█████████▌| 4054/4220 [4:19:49<10:27,  3.78s/it, loss=2.77, epoch=0.96, learning_rate=7.75e-8]\u001b[A\n",
      " 96%|█████████▌| 4055/4220 [4:19:53<10:23,  3.78s/it, loss=2.77, epoch=0.96, learning_rate=7.75e-8]\u001b[A\n",
      " 96%|█████████▌| 4055/4220 [4:19:53<10:23,  3.78s/it, loss=3, epoch=0.961, learning_rate=7.66e-8]  \u001b[A\n",
      " 96%|█████████▌| 4056/4220 [4:19:57<10:19,  3.78s/it, loss=3, epoch=0.961, learning_rate=7.66e-8]\u001b[A\n",
      " 96%|█████████▌| 4056/4220 [4:19:57<10:19,  3.78s/it, loss=2.76, epoch=0.961, learning_rate=7.57e-8]\u001b[A\n",
      " 96%|█████████▌| 4057/4220 [4:20:00<10:16,  3.78s/it, loss=2.76, epoch=0.961, learning_rate=7.57e-8]\u001b[A\n",
      " 96%|█████████▌| 4057/4220 [4:20:00<10:16,  3.78s/it, loss=3.26, epoch=0.961, learning_rate=7.48e-8]\u001b[A\n",
      " 96%|█████████▌| 4058/4220 [4:20:04<10:12,  3.78s/it, loss=3.26, epoch=0.961, learning_rate=7.48e-8]\u001b[A\n",
      " 96%|█████████▌| 4058/4220 [4:20:04<10:12,  3.78s/it, loss=2.34, epoch=0.961, learning_rate=7.39e-8]\u001b[A\n",
      " 96%|█████████▌| 4059/4220 [4:20:08<10:08,  3.78s/it, loss=2.34, epoch=0.961, learning_rate=7.39e-8]\u001b[A\n",
      " 96%|█████████▌| 4059/4220 [4:20:08<10:08,  3.78s/it, loss=3.09, epoch=0.962, learning_rate=7.3e-8] \u001b[A\n",
      " 96%|█████████▌| 4060/4220 [4:20:12<10:04,  3.78s/it, loss=3.09, epoch=0.962, learning_rate=7.3e-8]\u001b[A\n",
      " 96%|█████████▌| 4060/4220 [4:20:12<10:04,  3.78s/it, loss=2.78, epoch=0.962, learning_rate=7.21e-8]\u001b[A\n",
      " 96%|█████████▌| 4061/4220 [4:20:15<10:00,  3.78s/it, loss=2.78, epoch=0.962, learning_rate=7.21e-8]\u001b[A\n",
      " 96%|█████████▌| 4061/4220 [4:20:15<10:00,  3.78s/it, loss=2.76, epoch=0.962, learning_rate=7.12e-8]\u001b[A\n",
      " 96%|█████████▋| 4062/4220 [4:20:19<09:57,  3.78s/it, loss=2.76, epoch=0.962, learning_rate=7.12e-8]\u001b[A\n",
      " 96%|█████████▋| 4062/4220 [4:20:19<09:57,  3.78s/it, loss=2.41, epoch=0.962, learning_rate=7.03e-8]\u001b[A\n",
      " 96%|█████████▋| 4063/4220 [4:20:23<09:53,  3.78s/it, loss=2.41, epoch=0.962, learning_rate=7.03e-8]\u001b[A\n",
      " 96%|█████████▋| 4063/4220 [4:20:23<09:53,  3.78s/it, loss=2.54, epoch=0.963, learning_rate=6.94e-8]\u001b[A\n",
      " 96%|█████████▋| 4064/4220 [4:20:27<09:49,  3.78s/it, loss=2.54, epoch=0.963, learning_rate=6.94e-8]\u001b[A\n",
      " 96%|█████████▋| 4064/4220 [4:20:27<09:49,  3.78s/it, loss=2.65, epoch=0.963, learning_rate=6.86e-8]\u001b[A\n",
      " 96%|█████████▋| 4065/4220 [4:20:31<09:46,  3.78s/it, loss=2.65, epoch=0.963, learning_rate=6.86e-8]\u001b[A\n",
      " 96%|█████████▋| 4065/4220 [4:20:31<09:46,  3.78s/it, loss=3.11, epoch=0.963, learning_rate=6.77e-8]\u001b[A\n",
      " 96%|█████████▋| 4066/4220 [4:20:34<09:42,  3.78s/it, loss=3.11, epoch=0.963, learning_rate=6.77e-8]\u001b[A\n",
      " 96%|█████████▋| 4066/4220 [4:20:34<09:42,  3.78s/it, loss=2.76, epoch=0.963, learning_rate=6.68e-8]\u001b[A\n",
      " 96%|█████████▋| 4067/4220 [4:20:38<09:38,  3.78s/it, loss=2.76, epoch=0.963, learning_rate=6.68e-8]\u001b[A\n",
      " 96%|█████████▋| 4067/4220 [4:20:38<09:38,  3.78s/it, loss=3.11, epoch=0.964, learning_rate=6.6e-8] \u001b[A\n",
      " 96%|█████████▋| 4068/4220 [4:20:42<09:34,  3.78s/it, loss=3.11, epoch=0.964, learning_rate=6.6e-8]\u001b[A\n",
      " 96%|█████████▋| 4068/4220 [4:20:42<09:34,  3.78s/it, loss=3.47, epoch=0.964, learning_rate=6.51e-8]\u001b[A\n",
      " 96%|█████████▋| 4069/4220 [4:20:46<09:31,  3.78s/it, loss=3.47, epoch=0.964, learning_rate=6.51e-8]\u001b[A\n",
      " 96%|█████████▋| 4069/4220 [4:20:46<09:31,  3.78s/it, loss=2.65, epoch=0.964, learning_rate=6.43e-8]\u001b[A\n",
      " 96%|█████████▋| 4070/4220 [4:20:49<09:27,  3.78s/it, loss=2.65, epoch=0.964, learning_rate=6.43e-8]\u001b[A\n",
      " 96%|█████████▋| 4070/4220 [4:20:49<09:27,  3.78s/it, loss=2.7, epoch=0.964, learning_rate=6.34e-8] \u001b[A\n",
      " 96%|█████████▋| 4071/4220 [4:20:53<09:23,  3.78s/it, loss=2.7, epoch=0.964, learning_rate=6.34e-8]\u001b[A\n",
      " 96%|█████████▋| 4071/4220 [4:20:53<09:23,  3.78s/it, loss=2.49, epoch=0.964, learning_rate=6.26e-8]\u001b[A\n",
      " 96%|█████████▋| 4072/4220 [4:20:57<09:19,  3.78s/it, loss=2.49, epoch=0.964, learning_rate=6.26e-8]\u001b[A\n",
      " 96%|█████████▋| 4072/4220 [4:20:57<09:19,  3.78s/it, loss=3.34, epoch=0.965, learning_rate=6.17e-8]\u001b[A\n",
      " 97%|█████████▋| 4073/4220 [4:21:01<09:15,  3.78s/it, loss=3.34, epoch=0.965, learning_rate=6.17e-8]\u001b[A\n",
      " 97%|█████████▋| 4073/4220 [4:21:01<09:15,  3.78s/it, loss=2.76, epoch=0.965, learning_rate=6.09e-8]\u001b[A\n",
      " 97%|█████████▋| 4074/4220 [4:21:05<09:11,  3.78s/it, loss=2.76, epoch=0.965, learning_rate=6.09e-8]\u001b[A\n",
      " 97%|█████████▋| 4074/4220 [4:21:05<09:11,  3.78s/it, loss=2.76, epoch=0.965, learning_rate=6.01e-8]\u001b[A\n",
      " 97%|█████████▋| 4075/4220 [4:21:08<09:08,  3.78s/it, loss=2.76, epoch=0.965, learning_rate=6.01e-8]\u001b[A\n",
      " 97%|█████████▋| 4075/4220 [4:21:08<09:08,  3.78s/it, loss=2.96, epoch=0.965, learning_rate=5.93e-8]\u001b[A\n",
      " 97%|█████████▋| 4076/4220 [4:21:12<09:04,  3.78s/it, loss=2.96, epoch=0.965, learning_rate=5.93e-8]\u001b[A\n",
      " 97%|█████████▋| 4076/4220 [4:21:12<09:04,  3.78s/it, loss=2.79, epoch=0.966, learning_rate=5.85e-8]\u001b[A\n",
      " 97%|█████████▋| 4077/4220 [4:21:16<09:00,  3.78s/it, loss=2.79, epoch=0.966, learning_rate=5.85e-8]\u001b[A\n",
      " 97%|█████████▋| 4077/4220 [4:21:16<09:00,  3.78s/it, loss=3.02, epoch=0.966, learning_rate=5.77e-8]\u001b[A\n",
      " 97%|█████████▋| 4078/4220 [4:21:20<08:56,  3.78s/it, loss=3.02, epoch=0.966, learning_rate=5.77e-8]\u001b[A\n",
      " 97%|█████████▋| 4078/4220 [4:21:20<08:56,  3.78s/it, loss=3.04, epoch=0.966, learning_rate=5.69e-8]\u001b[A\n",
      " 97%|█████████▋| 4079/4220 [4:21:23<08:53,  3.78s/it, loss=3.04, epoch=0.966, learning_rate=5.69e-8]\u001b[A\n",
      " 97%|█████████▋| 4079/4220 [4:21:23<08:53,  3.78s/it, loss=3.3, epoch=0.966, learning_rate=5.61e-8] \u001b[A\n",
      " 97%|█████████▋| 4080/4220 [4:21:27<08:49,  3.78s/it, loss=3.3, epoch=0.966, learning_rate=5.61e-8]\u001b[A\n",
      " 97%|█████████▋| 4080/4220 [4:21:27<08:49,  3.78s/it, loss=2.65, epoch=0.967, learning_rate=5.53e-8]\u001b[A\n",
      " 97%|█████████▋| 4081/4220 [4:21:31<08:45,  3.78s/it, loss=2.65, epoch=0.967, learning_rate=5.53e-8]\u001b[A\n",
      " 97%|█████████▋| 4081/4220 [4:21:31<08:45,  3.78s/it, loss=2.76, epoch=0.967, learning_rate=5.45e-8]\u001b[A\n",
      " 97%|█████████▋| 4082/4220 [4:21:35<08:41,  3.78s/it, loss=2.76, epoch=0.967, learning_rate=5.45e-8]\u001b[A\n",
      " 97%|█████████▋| 4082/4220 [4:21:35<08:41,  3.78s/it, loss=3.24, epoch=0.967, learning_rate=5.37e-8]\u001b[A\n",
      " 97%|█████████▋| 4083/4220 [4:21:39<08:38,  3.78s/it, loss=3.24, epoch=0.967, learning_rate=5.37e-8]\u001b[A\n",
      " 97%|█████████▋| 4083/4220 [4:21:39<08:38,  3.78s/it, loss=3.04, epoch=0.967, learning_rate=5.3e-8] \u001b[A\n",
      " 97%|█████████▋| 4084/4220 [4:21:42<08:34,  3.78s/it, loss=3.04, epoch=0.967, learning_rate=5.3e-8]\u001b[A\n",
      " 97%|█████████▋| 4084/4220 [4:21:42<08:34,  3.78s/it, loss=2.65, epoch=0.968, learning_rate=5.22e-8]\u001b[A\n",
      " 97%|█████████▋| 4085/4220 [4:21:46<08:30,  3.78s/it, loss=2.65, epoch=0.968, learning_rate=5.22e-8]\u001b[A\n",
      " 97%|█████████▋| 4085/4220 [4:21:46<08:30,  3.78s/it, loss=2.89, epoch=0.968, learning_rate=5.15e-8]\u001b[A\n",
      " 97%|█████████▋| 4086/4220 [4:21:50<08:26,  3.78s/it, loss=2.89, epoch=0.968, learning_rate=5.15e-8]\u001b[A\n",
      " 97%|█████████▋| 4086/4220 [4:21:50<08:26,  3.78s/it, loss=2.56, epoch=0.968, learning_rate=5.07e-8]\u001b[A\n",
      " 97%|█████████▋| 4087/4220 [4:21:54<08:22,  3.78s/it, loss=2.56, epoch=0.968, learning_rate=5.07e-8]\u001b[A\n",
      " 97%|█████████▋| 4087/4220 [4:21:54<08:22,  3.78s/it, loss=2.97, epoch=0.968, learning_rate=5e-8]   \u001b[A\n",
      " 97%|█████████▋| 4088/4220 [4:21:58<08:19,  3.78s/it, loss=2.97, epoch=0.968, learning_rate=5e-8]\u001b[A\n",
      " 97%|█████████▋| 4088/4220 [4:21:58<08:19,  3.78s/it, loss=2.63, epoch=0.968, learning_rate=4.92e-8]\u001b[A\n",
      " 97%|█████████▋| 4089/4220 [4:22:01<08:15,  3.78s/it, loss=2.63, epoch=0.968, learning_rate=4.92e-8]\u001b[A\n",
      " 97%|█████████▋| 4089/4220 [4:22:01<08:15,  3.78s/it, loss=3.04, epoch=0.969, learning_rate=4.85e-8]\u001b[A\n",
      " 97%|█████████▋| 4090/4220 [4:22:05<08:11,  3.78s/it, loss=3.04, epoch=0.969, learning_rate=4.85e-8]\u001b[A\n",
      " 97%|█████████▋| 4090/4220 [4:22:05<08:11,  3.78s/it, loss=2.99, epoch=0.969, learning_rate=4.77e-8]\u001b[A\n",
      " 97%|█████████▋| 4091/4220 [4:22:09<08:07,  3.78s/it, loss=2.99, epoch=0.969, learning_rate=4.77e-8]\u001b[A\n",
      " 97%|█████████▋| 4091/4220 [4:22:09<08:07,  3.78s/it, loss=3.03, epoch=0.969, learning_rate=4.7e-8] \u001b[A\n",
      " 97%|█████████▋| 4092/4220 [4:22:13<08:04,  3.78s/it, loss=3.03, epoch=0.969, learning_rate=4.7e-8]\u001b[A\n",
      " 97%|█████████▋| 4092/4220 [4:22:13<08:04,  3.78s/it, loss=2.71, epoch=0.969, learning_rate=4.63e-8]\u001b[A\n",
      " 97%|█████████▋| 4093/4220 [4:22:16<08:00,  3.78s/it, loss=2.71, epoch=0.969, learning_rate=4.63e-8]\u001b[A\n",
      " 97%|█████████▋| 4093/4220 [4:22:16<08:00,  3.78s/it, loss=2.74, epoch=0.97, learning_rate=4.56e-8] \u001b[A\n",
      " 97%|█████████▋| 4094/4220 [4:22:20<07:56,  3.78s/it, loss=2.74, epoch=0.97, learning_rate=4.56e-8]\u001b[A\n",
      " 97%|█████████▋| 4094/4220 [4:22:20<07:56,  3.78s/it, loss=2.03, epoch=0.97, learning_rate=4.49e-8]\u001b[A\n",
      " 97%|█████████▋| 4095/4220 [4:22:24<07:53,  3.78s/it, loss=2.03, epoch=0.97, learning_rate=4.49e-8]\u001b[A\n",
      " 97%|█████████▋| 4095/4220 [4:22:24<07:53,  3.78s/it, loss=2.89, epoch=0.97, learning_rate=4.42e-8]\u001b[A\n",
      " 97%|█████████▋| 4096/4220 [4:22:28<07:49,  3.78s/it, loss=2.89, epoch=0.97, learning_rate=4.42e-8]\u001b[A\n",
      " 97%|█████████▋| 4096/4220 [4:22:28<07:49,  3.78s/it, loss=2.25, epoch=0.97, learning_rate=4.35e-8]\u001b[A\n",
      " 97%|█████████▋| 4097/4220 [4:22:32<07:45,  3.78s/it, loss=2.25, epoch=0.97, learning_rate=4.35e-8]\u001b[A\n",
      " 97%|█████████▋| 4097/4220 [4:22:32<07:45,  3.78s/it, loss=2.83, epoch=0.971, learning_rate=4.28e-8]\u001b[A\n",
      " 97%|█████████▋| 4098/4220 [4:22:35<07:41,  3.78s/it, loss=2.83, epoch=0.971, learning_rate=4.28e-8]\u001b[A\n",
      " 97%|█████████▋| 4098/4220 [4:22:35<07:41,  3.78s/it, loss=2.79, epoch=0.971, learning_rate=4.21e-8]\u001b[A\n",
      " 97%|█████████▋| 4099/4220 [4:22:39<07:37,  3.78s/it, loss=2.79, epoch=0.971, learning_rate=4.21e-8]\u001b[A\n",
      " 97%|█████████▋| 4099/4220 [4:22:39<07:37,  3.78s/it, loss=2.8, epoch=0.971, learning_rate=4.14e-8] \u001b[A\n",
      " 97%|█████████▋| 4100/4220 [4:22:43<07:33,  3.78s/it, loss=2.8, epoch=0.971, learning_rate=4.14e-8]\u001b[A\n",
      " 97%|█████████▋| 4100/4220 [4:22:43<07:33,  3.78s/it, loss=2.39, epoch=0.971, learning_rate=4.07e-8]\u001b[A\n",
      " 97%|█████████▋| 4101/4220 [4:22:47<07:29,  3.78s/it, loss=2.39, epoch=0.971, learning_rate=4.07e-8]\u001b[A\n",
      " 97%|█████████▋| 4101/4220 [4:22:47<07:29,  3.78s/it, loss=2.29, epoch=0.972, learning_rate=4.01e-8]\u001b[A\n",
      " 97%|█████████▋| 4102/4220 [4:22:50<07:26,  3.78s/it, loss=2.29, epoch=0.972, learning_rate=4.01e-8]\u001b[A\n",
      " 97%|█████████▋| 4102/4220 [4:22:50<07:26,  3.78s/it, loss=2.44, epoch=0.972, learning_rate=3.94e-8]\u001b[A\n",
      " 97%|█████████▋| 4103/4220 [4:22:54<07:22,  3.78s/it, loss=2.44, epoch=0.972, learning_rate=3.94e-8]\u001b[A\n",
      " 97%|█████████▋| 4103/4220 [4:22:54<07:22,  3.78s/it, loss=2.39, epoch=0.972, learning_rate=3.87e-8]\u001b[A\n",
      " 97%|█████████▋| 4104/4220 [4:22:58<07:18,  3.78s/it, loss=2.39, epoch=0.972, learning_rate=3.87e-8]\u001b[A\n",
      " 97%|█████████▋| 4104/4220 [4:22:58<07:18,  3.78s/it, loss=2.58, epoch=0.972, learning_rate=3.81e-8]\u001b[A\n",
      " 97%|█████████▋| 4105/4220 [4:23:02<07:14,  3.78s/it, loss=2.58, epoch=0.972, learning_rate=3.81e-8]\u001b[A\n",
      " 97%|█████████▋| 4105/4220 [4:23:02<07:14,  3.78s/it, loss=2.93, epoch=0.973, learning_rate=3.74e-8]\u001b[A\n",
      " 97%|█████████▋| 4106/4220 [4:23:06<07:10,  3.78s/it, loss=2.93, epoch=0.973, learning_rate=3.74e-8]\u001b[A\n",
      " 97%|█████████▋| 4106/4220 [4:23:06<07:10,  3.78s/it, loss=2.71, epoch=0.973, learning_rate=3.68e-8]\u001b[A\n",
      " 97%|█████████▋| 4107/4220 [4:23:09<07:07,  3.78s/it, loss=2.71, epoch=0.973, learning_rate=3.68e-8]\u001b[A\n",
      " 97%|█████████▋| 4107/4220 [4:23:09<07:07,  3.78s/it, loss=2.38, epoch=0.973, learning_rate=3.62e-8]\u001b[A\n",
      " 97%|█████████▋| 4108/4220 [4:23:13<07:03,  3.78s/it, loss=2.38, epoch=0.973, learning_rate=3.62e-8]\u001b[A\n",
      " 97%|█████████▋| 4108/4220 [4:23:13<07:03,  3.78s/it, loss=2.71, epoch=0.973, learning_rate=3.55e-8]\u001b[A\n",
      " 97%|█████████▋| 4109/4220 [4:23:17<06:59,  3.78s/it, loss=2.71, epoch=0.973, learning_rate=3.55e-8]\u001b[A\n",
      " 97%|█████████▋| 4109/4220 [4:23:17<06:59,  3.78s/it, loss=2.38, epoch=0.973, learning_rate=3.49e-8]\u001b[A\n",
      " 97%|█████████▋| 4110/4220 [4:23:21<06:56,  3.78s/it, loss=2.38, epoch=0.973, learning_rate=3.49e-8]\u001b[A\n",
      " 97%|█████████▋| 4110/4220 [4:23:21<06:56,  3.78s/it, loss=2.48, epoch=0.974, learning_rate=3.43e-8]\u001b[A\n",
      " 97%|█████████▋| 4111/4220 [4:23:24<06:52,  3.78s/it, loss=2.48, epoch=0.974, learning_rate=3.43e-8]\u001b[A\n",
      " 97%|█████████▋| 4111/4220 [4:23:24<06:52,  3.78s/it, loss=2.75, epoch=0.974, learning_rate=3.37e-8]\u001b[A\n",
      " 97%|█████████▋| 4112/4220 [4:23:28<06:48,  3.78s/it, loss=2.75, epoch=0.974, learning_rate=3.37e-8]\u001b[A\n",
      " 97%|█████████▋| 4112/4220 [4:23:28<06:48,  3.78s/it, loss=2.67, epoch=0.974, learning_rate=3.31e-8]\u001b[A\n",
      " 97%|█████████▋| 4113/4220 [4:23:32<06:44,  3.78s/it, loss=2.67, epoch=0.974, learning_rate=3.31e-8]\u001b[A\n",
      " 97%|█████████▋| 4113/4220 [4:23:32<06:44,  3.78s/it, loss=2.93, epoch=0.974, learning_rate=3.25e-8]\u001b[A\n",
      " 97%|█████████▋| 4114/4220 [4:23:36<06:40,  3.78s/it, loss=2.93, epoch=0.974, learning_rate=3.25e-8]\u001b[A\n",
      " 97%|█████████▋| 4114/4220 [4:23:36<06:40,  3.78s/it, loss=2.94, epoch=0.975, learning_rate=3.19e-8]\u001b[A\n",
      " 98%|█████████▊| 4115/4220 [4:23:40<06:36,  3.78s/it, loss=2.94, epoch=0.975, learning_rate=3.19e-8]\u001b[A\n",
      " 98%|█████████▊| 4115/4220 [4:23:40<06:36,  3.78s/it, loss=2.55, epoch=0.975, learning_rate=3.13e-8]\u001b[A\n",
      " 98%|█████████▊| 4116/4220 [4:23:43<06:33,  3.78s/it, loss=2.55, epoch=0.975, learning_rate=3.13e-8]\u001b[A\n",
      " 98%|█████████▊| 4116/4220 [4:23:43<06:33,  3.78s/it, loss=2.76, epoch=0.975, learning_rate=3.07e-8]\u001b[A\n",
      " 98%|█████████▊| 4117/4220 [4:23:47<06:29,  3.78s/it, loss=2.76, epoch=0.975, learning_rate=3.07e-8]\u001b[A\n",
      " 98%|█████████▊| 4117/4220 [4:23:47<06:29,  3.78s/it, loss=3.11, epoch=0.975, learning_rate=3.01e-8]\u001b[A\n",
      " 98%|█████████▊| 4118/4220 [4:23:51<06:25,  3.78s/it, loss=3.11, epoch=0.975, learning_rate=3.01e-8]\u001b[A\n",
      " 98%|█████████▊| 4118/4220 [4:23:51<06:25,  3.78s/it, loss=2.75, epoch=0.976, learning_rate=2.95e-8]\u001b[A\n",
      " 98%|█████████▊| 4119/4220 [4:23:55<06:21,  3.78s/it, loss=2.75, epoch=0.976, learning_rate=2.95e-8]\u001b[A\n",
      " 98%|█████████▊| 4119/4220 [4:23:55<06:21,  3.78s/it, loss=2.95, epoch=0.976, learning_rate=2.9e-8] \u001b[A\n",
      " 98%|█████████▊| 4120/4220 [4:23:59<06:18,  3.78s/it, loss=2.95, epoch=0.976, learning_rate=2.9e-8]\u001b[A\n",
      " 98%|█████████▊| 4120/4220 [4:23:59<06:18,  3.78s/it, loss=2.48, epoch=0.976, learning_rate=2.84e-8]\u001b[A\n",
      " 98%|█████████▊| 4121/4220 [4:24:02<06:14,  3.78s/it, loss=2.48, epoch=0.976, learning_rate=2.84e-8]\u001b[A\n",
      " 98%|█████████▊| 4121/4220 [4:24:02<06:14,  3.78s/it, loss=3.11, epoch=0.976, learning_rate=2.78e-8]\u001b[A\n",
      " 98%|█████████▊| 4122/4220 [4:24:06<06:10,  3.78s/it, loss=3.11, epoch=0.976, learning_rate=2.78e-8]\u001b[A\n",
      " 98%|█████████▊| 4122/4220 [4:24:06<06:10,  3.78s/it, loss=2.75, epoch=0.977, learning_rate=2.73e-8]\u001b[A\n",
      " 98%|█████████▊| 4123/4220 [4:24:10<06:06,  3.78s/it, loss=2.75, epoch=0.977, learning_rate=2.73e-8]\u001b[A\n",
      " 98%|█████████▊| 4123/4220 [4:24:10<06:06,  3.78s/it, loss=2.9, epoch=0.977, learning_rate=2.67e-8] \u001b[A\n",
      " 98%|█████████▊| 4124/4220 [4:24:14<06:03,  3.78s/it, loss=2.9, epoch=0.977, learning_rate=2.67e-8]\u001b[A\n",
      " 98%|█████████▊| 4124/4220 [4:24:14<06:03,  3.78s/it, loss=2.79, epoch=0.977, learning_rate=2.62e-8]\u001b[A\n",
      " 98%|█████████▊| 4125/4220 [4:24:17<05:59,  3.78s/it, loss=2.79, epoch=0.977, learning_rate=2.62e-8]\u001b[A\n",
      " 98%|█████████▊| 4125/4220 [4:24:17<05:59,  3.78s/it, loss=3.02, epoch=0.977, learning_rate=2.56e-8]\u001b[A\n",
      " 98%|█████████▊| 4126/4220 [4:24:21<05:55,  3.78s/it, loss=3.02, epoch=0.977, learning_rate=2.56e-8]\u001b[A\n",
      " 98%|█████████▊| 4126/4220 [4:24:21<05:55,  3.78s/it, loss=2.91, epoch=0.977, learning_rate=2.51e-8]\u001b[A\n",
      " 98%|█████████▊| 4127/4220 [4:24:25<05:51,  3.78s/it, loss=2.91, epoch=0.977, learning_rate=2.51e-8]\u001b[A\n",
      " 98%|█████████▊| 4127/4220 [4:24:25<05:51,  3.78s/it, loss=3.37, epoch=0.978, learning_rate=2.46e-8]\u001b[A\n",
      " 98%|█████████▊| 4128/4220 [4:24:29<05:47,  3.78s/it, loss=3.37, epoch=0.978, learning_rate=2.46e-8]\u001b[A\n",
      " 98%|█████████▊| 4128/4220 [4:24:29<05:47,  3.78s/it, loss=2.94, epoch=0.978, learning_rate=2.41e-8]\u001b[A\n",
      " 98%|█████████▊| 4129/4220 [4:24:33<05:44,  3.78s/it, loss=2.94, epoch=0.978, learning_rate=2.41e-8]\u001b[A\n",
      " 98%|█████████▊| 4129/4220 [4:24:33<05:44,  3.78s/it, loss=2.79, epoch=0.978, learning_rate=2.36e-8]\u001b[A\n",
      " 98%|█████████▊| 4130/4220 [4:24:36<05:40,  3.78s/it, loss=2.79, epoch=0.978, learning_rate=2.36e-8]\u001b[A\n",
      " 98%|█████████▊| 4130/4220 [4:24:36<05:40,  3.78s/it, loss=2.9, epoch=0.978, learning_rate=2.3e-8]  \u001b[A\n",
      " 98%|█████████▊| 4131/4220 [4:24:40<05:36,  3.78s/it, loss=2.9, epoch=0.978, learning_rate=2.3e-8]\u001b[A\n",
      " 98%|█████████▊| 4131/4220 [4:24:40<05:36,  3.78s/it, loss=2.89, epoch=0.979, learning_rate=2.25e-8]\u001b[A\n",
      " 98%|█████████▊| 4132/4220 [4:24:44<05:32,  3.78s/it, loss=2.89, epoch=0.979, learning_rate=2.25e-8]\u001b[A\n",
      " 98%|█████████▊| 4132/4220 [4:24:44<05:32,  3.78s/it, loss=3.04, epoch=0.979, learning_rate=2.2e-8] \u001b[A\n",
      " 98%|█████████▊| 4133/4220 [4:24:48<05:29,  3.78s/it, loss=3.04, epoch=0.979, learning_rate=2.2e-8]\u001b[A\n",
      " 98%|█████████▊| 4133/4220 [4:24:48<05:29,  3.78s/it, loss=2.98, epoch=0.979, learning_rate=2.16e-8]\u001b[A\n",
      " 98%|█████████▊| 4134/4220 [4:24:51<05:25,  3.78s/it, loss=2.98, epoch=0.979, learning_rate=2.16e-8]\u001b[A\n",
      " 98%|█████████▊| 4134/4220 [4:24:51<05:25,  3.78s/it, loss=2.92, epoch=0.979, learning_rate=2.11e-8]\u001b[A\n",
      " 98%|█████████▊| 4135/4220 [4:24:55<05:21,  3.78s/it, loss=2.92, epoch=0.979, learning_rate=2.11e-8]\u001b[A\n",
      " 98%|█████████▊| 4135/4220 [4:24:55<05:21,  3.78s/it, loss=2.69, epoch=0.98, learning_rate=2.06e-8] \u001b[A\n",
      " 98%|█████████▊| 4136/4220 [4:24:59<05:17,  3.78s/it, loss=2.69, epoch=0.98, learning_rate=2.06e-8]\u001b[A\n",
      " 98%|█████████▊| 4136/4220 [4:24:59<05:17,  3.78s/it, loss=2.95, epoch=0.98, learning_rate=2.01e-8]\u001b[A\n",
      " 98%|█████████▊| 4137/4220 [4:25:03<05:13,  3.78s/it, loss=2.95, epoch=0.98, learning_rate=2.01e-8]\u001b[A\n",
      " 98%|█████████▊| 4137/4220 [4:25:03<05:13,  3.78s/it, loss=2.74, epoch=0.98, learning_rate=1.96e-8]\u001b[A\n",
      " 98%|█████████▊| 4138/4220 [4:25:07<05:10,  3.78s/it, loss=2.74, epoch=0.98, learning_rate=1.96e-8]\u001b[A\n",
      " 98%|█████████▊| 4138/4220 [4:25:07<05:10,  3.78s/it, loss=3.06, epoch=0.98, learning_rate=1.92e-8]\u001b[A\n",
      " 98%|█████████▊| 4139/4220 [4:25:10<05:06,  3.78s/it, loss=3.06, epoch=0.98, learning_rate=1.92e-8]\u001b[A\n",
      " 98%|█████████▊| 4139/4220 [4:25:10<05:06,  3.78s/it, loss=2.54, epoch=0.981, learning_rate=1.87e-8]\u001b[A\n",
      " 98%|█████████▊| 4140/4220 [4:25:14<05:02,  3.78s/it, loss=2.54, epoch=0.981, learning_rate=1.87e-8]\u001b[A\n",
      " 98%|█████████▊| 4140/4220 [4:25:14<05:02,  3.78s/it, loss=3.33, epoch=0.981, learning_rate=1.83e-8]\u001b[A\n",
      " 98%|█████████▊| 4141/4220 [4:25:18<04:58,  3.78s/it, loss=3.33, epoch=0.981, learning_rate=1.83e-8]\u001b[A\n",
      " 98%|█████████▊| 4141/4220 [4:25:18<04:58,  3.78s/it, loss=3.1, epoch=0.981, learning_rate=1.78e-8] \u001b[A\n",
      " 98%|█████████▊| 4142/4220 [4:25:22<04:55,  3.78s/it, loss=3.1, epoch=0.981, learning_rate=1.78e-8]\u001b[A\n",
      " 98%|█████████▊| 4142/4220 [4:25:22<04:55,  3.78s/it, loss=3.11, epoch=0.981, learning_rate=1.74e-8]\u001b[A\n",
      " 98%|█████████▊| 4143/4220 [4:25:26<04:51,  3.78s/it, loss=3.11, epoch=0.981, learning_rate=1.74e-8]\u001b[A\n",
      " 98%|█████████▊| 4143/4220 [4:25:26<04:51,  3.78s/it, loss=2.92, epoch=0.982, learning_rate=1.69e-8]\u001b[A\n",
      " 98%|█████████▊| 4144/4220 [4:25:29<04:47,  3.78s/it, loss=2.92, epoch=0.982, learning_rate=1.69e-8]\u001b[A\n",
      " 98%|█████████▊| 4144/4220 [4:25:29<04:47,  3.78s/it, loss=2.65, epoch=0.982, learning_rate=1.65e-8]\u001b[A\n",
      " 98%|█████████▊| 4145/4220 [4:25:33<04:43,  3.78s/it, loss=2.65, epoch=0.982, learning_rate=1.65e-8]\u001b[A\n",
      " 98%|█████████▊| 4145/4220 [4:25:33<04:43,  3.78s/it, loss=2.94, epoch=0.982, learning_rate=1.61e-8]\u001b[A\n",
      " 98%|█████████▊| 4146/4220 [4:25:37<04:39,  3.78s/it, loss=2.94, epoch=0.982, learning_rate=1.61e-8]\u001b[A\n",
      " 98%|█████████▊| 4146/4220 [4:25:37<04:39,  3.78s/it, loss=3.02, epoch=0.982, learning_rate=1.57e-8]\u001b[A\n",
      " 98%|█████████▊| 4147/4220 [4:25:41<04:36,  3.78s/it, loss=3.02, epoch=0.982, learning_rate=1.57e-8]\u001b[A\n",
      " 98%|█████████▊| 4147/4220 [4:25:41<04:36,  3.78s/it, loss=2.72, epoch=0.982, learning_rate=1.52e-8]\u001b[A\n",
      " 98%|█████████▊| 4148/4220 [4:25:44<04:32,  3.78s/it, loss=2.72, epoch=0.982, learning_rate=1.52e-8]\u001b[A\n",
      " 98%|█████████▊| 4148/4220 [4:25:44<04:32,  3.78s/it, loss=2.59, epoch=0.983, learning_rate=1.48e-8]\u001b[A\n",
      " 98%|█████████▊| 4149/4220 [4:25:48<04:28,  3.78s/it, loss=2.59, epoch=0.983, learning_rate=1.48e-8]\u001b[A\n",
      " 98%|█████████▊| 4149/4220 [4:25:48<04:28,  3.78s/it, loss=2.48, epoch=0.983, learning_rate=1.44e-8]\u001b[A\n",
      " 98%|█████████▊| 4150/4220 [4:25:52<04:24,  3.78s/it, loss=2.48, epoch=0.983, learning_rate=1.44e-8]\u001b[A\n",
      " 98%|█████████▊| 4150/4220 [4:25:52<04:24,  3.78s/it, loss=2.72, epoch=0.983, learning_rate=1.4e-8] \u001b[A\n",
      " 98%|█████████▊| 4151/4220 [4:25:56<04:20,  3.78s/it, loss=2.72, epoch=0.983, learning_rate=1.4e-8]\u001b[A\n",
      " 98%|█████████▊| 4151/4220 [4:25:56<04:20,  3.78s/it, loss=3.35, epoch=0.983, learning_rate=1.36e-8]\u001b[A\n",
      " 98%|█████████▊| 4152/4220 [4:26:00<04:17,  3.78s/it, loss=3.35, epoch=0.983, learning_rate=1.36e-8]\u001b[A\n",
      " 98%|█████████▊| 4152/4220 [4:26:00<04:17,  3.78s/it, loss=2.48, epoch=0.984, learning_rate=1.33e-8]\u001b[A\n",
      " 98%|█████████▊| 4153/4220 [4:26:04<04:33,  4.08s/it, loss=2.48, epoch=0.984, learning_rate=1.33e-8]\u001b[A\n",
      " 98%|█████████▊| 4153/4220 [4:26:04<04:33,  4.08s/it, loss=2.8, epoch=0.984, learning_rate=1.29e-8] \u001b[A\n",
      " 98%|█████████▊| 4154/4220 [4:26:08<04:23,  3.99s/it, loss=2.8, epoch=0.984, learning_rate=1.29e-8]\u001b[A\n",
      " 98%|█████████▊| 4154/4220 [4:26:08<04:23,  3.99s/it, loss=3.17, epoch=0.984, learning_rate=1.25e-8]\u001b[A\n",
      " 98%|█████████▊| 4155/4220 [4:26:12<04:15,  3.93s/it, loss=3.17, epoch=0.984, learning_rate=1.25e-8]\u001b[A\n",
      " 98%|█████████▊| 4155/4220 [4:26:12<04:15,  3.93s/it, loss=2.67, epoch=0.984, learning_rate=1.21e-8]\u001b[A\n",
      " 98%|█████████▊| 4156/4220 [4:26:16<04:08,  3.88s/it, loss=2.67, epoch=0.984, learning_rate=1.21e-8]\u001b[A\n",
      " 98%|█████████▊| 4156/4220 [4:26:16<04:08,  3.88s/it, loss=2.74, epoch=0.985, learning_rate=1.18e-8]\u001b[A\n",
      " 99%|█████████▊| 4157/4220 [4:26:19<04:02,  3.85s/it, loss=2.74, epoch=0.985, learning_rate=1.18e-8]\u001b[A\n",
      " 99%|█████████▊| 4157/4220 [4:26:19<04:02,  3.85s/it, loss=2.43, epoch=0.985, learning_rate=1.14e-8]\u001b[A\n",
      " 99%|█████████▊| 4158/4220 [4:26:23<03:57,  3.83s/it, loss=2.43, epoch=0.985, learning_rate=1.14e-8]\u001b[A\n",
      " 99%|█████████▊| 4158/4220 [4:26:23<03:57,  3.83s/it, loss=2.64, epoch=0.985, learning_rate=1.1e-8] \u001b[A\n",
      " 99%|█████████▊| 4159/4220 [4:26:27<03:52,  3.81s/it, loss=2.64, epoch=0.985, learning_rate=1.1e-8]\u001b[A\n",
      " 99%|█████████▊| 4159/4220 [4:26:27<03:52,  3.81s/it, loss=2.96, epoch=0.985, learning_rate=1.07e-8]\u001b[A\n",
      " 99%|█████████▊| 4160/4220 [4:26:31<03:48,  3.80s/it, loss=2.96, epoch=0.985, learning_rate=1.07e-8]\u001b[A\n",
      " 99%|█████████▊| 4160/4220 [4:26:31<03:48,  3.80s/it, loss=2.67, epoch=0.986, learning_rate=1.04e-8]\u001b[A\n",
      " 99%|█████████▊| 4161/4220 [4:26:35<03:43,  3.80s/it, loss=2.67, epoch=0.986, learning_rate=1.04e-8]\u001b[A\n",
      " 99%|█████████▊| 4161/4220 [4:26:35<03:43,  3.80s/it, loss=2.81, epoch=0.986, learning_rate=1e-8]   \u001b[A\n",
      " 99%|█████████▊| 4162/4220 [4:26:38<03:39,  3.79s/it, loss=2.81, epoch=0.986, learning_rate=1e-8]\u001b[A\n",
      " 99%|█████████▊| 4162/4220 [4:26:38<03:39,  3.79s/it, loss=2.39, epoch=0.986, learning_rate=9.69e-9]\u001b[A\n",
      " 99%|█████████▊| 4163/4220 [4:26:42<03:35,  3.79s/it, loss=2.39, epoch=0.986, learning_rate=9.69e-9]\u001b[A\n",
      " 99%|█████████▊| 4163/4220 [4:26:42<03:35,  3.79s/it, loss=2.31, epoch=0.986, learning_rate=9.36e-9]\u001b[A\n",
      " 99%|█████████▊| 4164/4220 [4:26:46<03:32,  3.79s/it, loss=2.31, epoch=0.986, learning_rate=9.36e-9]\u001b[A\n",
      " 99%|█████████▊| 4164/4220 [4:26:46<03:32,  3.79s/it, loss=2.8, epoch=0.986, learning_rate=9.04e-9] \u001b[A\n",
      " 99%|█████████▊| 4165/4220 [4:26:50<03:28,  3.78s/it, loss=2.8, epoch=0.986, learning_rate=9.04e-9]\u001b[A\n",
      " 99%|█████████▊| 4165/4220 [4:26:50<03:28,  3.78s/it, loss=2.86, epoch=0.987, learning_rate=8.73e-9]\u001b[A\n",
      " 99%|█████████▊| 4166/4220 [4:26:53<03:24,  3.78s/it, loss=2.86, epoch=0.987, learning_rate=8.73e-9]\u001b[A\n",
      " 99%|█████████▊| 4166/4220 [4:26:53<03:24,  3.78s/it, loss=2.8, epoch=0.987, learning_rate=8.42e-9] \u001b[A\n",
      " 99%|█████████▊| 4167/4220 [4:26:57<03:20,  3.78s/it, loss=2.8, epoch=0.987, learning_rate=8.42e-9]\u001b[A\n",
      " 99%|█████████▊| 4167/4220 [4:26:57<03:20,  3.78s/it, loss=3.31, epoch=0.987, learning_rate=8.12e-9]\u001b[A\n",
      " 99%|█████████▉| 4168/4220 [4:27:01<03:16,  3.78s/it, loss=3.31, epoch=0.987, learning_rate=8.12e-9]\u001b[A\n",
      " 99%|█████████▉| 4168/4220 [4:27:01<03:16,  3.78s/it, loss=2.98, epoch=0.987, learning_rate=7.82e-9]\u001b[A\n",
      " 99%|█████████▉| 4169/4220 [4:27:05<03:12,  3.78s/it, loss=2.98, epoch=0.987, learning_rate=7.82e-9]\u001b[A\n",
      " 99%|█████████▉| 4169/4220 [4:27:05<03:12,  3.78s/it, loss=2.81, epoch=0.988, learning_rate=7.53e-9]\u001b[A\n",
      " 99%|█████████▉| 4170/4220 [4:27:09<03:09,  3.78s/it, loss=2.81, epoch=0.988, learning_rate=7.53e-9]\u001b[A\n",
      " 99%|█████████▉| 4170/4220 [4:27:09<03:09,  3.78s/it, loss=2.82, epoch=0.988, learning_rate=7.24e-9]\u001b[A\n",
      " 99%|█████████▉| 4171/4220 [4:27:12<03:05,  3.78s/it, loss=2.82, epoch=0.988, learning_rate=7.24e-9]\u001b[A\n",
      " 99%|█████████▉| 4171/4220 [4:27:12<03:05,  3.78s/it, loss=2.86, epoch=0.988, learning_rate=6.96e-9]\u001b[A\n",
      " 99%|█████████▉| 4172/4220 [4:27:16<03:01,  3.78s/it, loss=2.86, epoch=0.988, learning_rate=6.96e-9]\u001b[A\n",
      " 99%|█████████▉| 4172/4220 [4:27:16<03:01,  3.78s/it, loss=2.92, epoch=0.988, learning_rate=6.68e-9]\u001b[A\n",
      " 99%|█████████▉| 4173/4220 [4:27:20<02:57,  3.78s/it, loss=2.92, epoch=0.988, learning_rate=6.68e-9]\u001b[A\n",
      " 99%|█████████▉| 4173/4220 [4:27:20<02:57,  3.78s/it, loss=2.76, epoch=0.989, learning_rate=6.41e-9]\u001b[A\n",
      " 99%|█████████▉| 4174/4220 [4:27:24<02:54,  3.78s/it, loss=2.76, epoch=0.989, learning_rate=6.41e-9]\u001b[A\n",
      " 99%|█████████▉| 4174/4220 [4:27:24<02:54,  3.78s/it, loss=3.09, epoch=0.989, learning_rate=6.15e-9]\u001b[A\n",
      " 99%|█████████▉| 4175/4220 [4:27:27<02:50,  3.78s/it, loss=3.09, epoch=0.989, learning_rate=6.15e-9]\u001b[A\n",
      " 99%|█████████▉| 4175/4220 [4:27:27<02:50,  3.78s/it, loss=2.7, epoch=0.989, learning_rate=5.89e-9] \u001b[A\n",
      " 99%|█████████▉| 4176/4220 [4:27:31<02:46,  3.78s/it, loss=2.7, epoch=0.989, learning_rate=5.89e-9]\u001b[A\n",
      " 99%|█████████▉| 4176/4220 [4:27:31<02:46,  3.78s/it, loss=2.79, epoch=0.989, learning_rate=5.64e-9]\u001b[A\n",
      " 99%|█████████▉| 4177/4220 [4:27:35<02:42,  3.78s/it, loss=2.79, epoch=0.989, learning_rate=5.64e-9]\u001b[A\n",
      " 99%|█████████▉| 4177/4220 [4:27:35<02:42,  3.78s/it, loss=2.4, epoch=0.99, learning_rate=5.39e-9]  \u001b[A\n",
      " 99%|█████████▉| 4178/4220 [4:27:39<02:38,  3.78s/it, loss=2.4, epoch=0.99, learning_rate=5.39e-9]\u001b[A\n",
      " 99%|█████████▉| 4178/4220 [4:27:39<02:38,  3.78s/it, loss=2.43, epoch=0.99, learning_rate=5.15e-9]\u001b[A\n",
      " 99%|█████████▉| 4179/4220 [4:27:43<02:35,  3.78s/it, loss=2.43, epoch=0.99, learning_rate=5.15e-9]\u001b[A\n",
      " 99%|█████████▉| 4179/4220 [4:27:43<02:35,  3.78s/it, loss=2.96, epoch=0.99, learning_rate=4.91e-9]\u001b[A\n",
      " 99%|█████████▉| 4180/4220 [4:27:46<02:31,  3.78s/it, loss=2.96, epoch=0.99, learning_rate=4.91e-9]\u001b[A\n",
      " 99%|█████████▉| 4180/4220 [4:27:46<02:31,  3.78s/it, loss=2.86, epoch=0.99, learning_rate=4.68e-9]\u001b[A\n",
      " 99%|█████████▉| 4181/4220 [4:27:50<02:27,  3.78s/it, loss=2.86, epoch=0.99, learning_rate=4.68e-9]\u001b[A\n",
      " 99%|█████████▉| 4181/4220 [4:27:50<02:27,  3.78s/it, loss=2.89, epoch=0.991, learning_rate=4.45e-9]\u001b[A\n",
      " 99%|█████████▉| 4182/4220 [4:27:54<02:23,  3.78s/it, loss=2.89, epoch=0.991, learning_rate=4.45e-9]\u001b[A\n",
      " 99%|█████████▉| 4182/4220 [4:27:54<02:23,  3.78s/it, loss=3.07, epoch=0.991, learning_rate=4.23e-9]\u001b[A\n",
      " 99%|█████████▉| 4183/4220 [4:27:58<02:19,  3.78s/it, loss=3.07, epoch=0.991, learning_rate=4.23e-9]\u001b[A\n",
      " 99%|█████████▉| 4183/4220 [4:27:58<02:19,  3.78s/it, loss=2.81, epoch=0.991, learning_rate=4.02e-9]\u001b[A\n",
      " 99%|█████████▉| 4184/4220 [4:28:02<02:16,  3.78s/it, loss=2.81, epoch=0.991, learning_rate=4.02e-9]\u001b[A\n",
      " 99%|█████████▉| 4184/4220 [4:28:02<02:16,  3.78s/it, loss=2.91, epoch=0.991, learning_rate=3.81e-9]\u001b[A\n",
      " 99%|█████████▉| 4185/4220 [4:28:05<02:12,  3.78s/it, loss=2.91, epoch=0.991, learning_rate=3.81e-9]\u001b[A\n",
      " 99%|█████████▉| 4185/4220 [4:28:05<02:12,  3.78s/it, loss=2.94, epoch=0.991, learning_rate=3.61e-9]\u001b[A\n",
      " 99%|█████████▉| 4186/4220 [4:28:09<02:08,  3.78s/it, loss=2.94, epoch=0.991, learning_rate=3.61e-9]\u001b[A\n",
      " 99%|█████████▉| 4186/4220 [4:28:09<02:08,  3.78s/it, loss=2.75, epoch=0.992, learning_rate=3.41e-9]\u001b[A\n",
      " 99%|█████████▉| 4187/4220 [4:28:13<02:04,  3.78s/it, loss=2.75, epoch=0.992, learning_rate=3.41e-9]\u001b[A\n",
      " 99%|█████████▉| 4187/4220 [4:28:13<02:04,  3.78s/it, loss=2.5, epoch=0.992, learning_rate=3.22e-9] \u001b[A\n",
      " 99%|█████████▉| 4188/4220 [4:28:17<02:01,  3.78s/it, loss=2.5, epoch=0.992, learning_rate=3.22e-9]\u001b[A\n",
      " 99%|█████████▉| 4188/4220 [4:28:17<02:01,  3.78s/it, loss=2.89, epoch=0.992, learning_rate=3.03e-9]\u001b[A\n",
      " 99%|█████████▉| 4189/4220 [4:28:20<01:57,  3.78s/it, loss=2.89, epoch=0.992, learning_rate=3.03e-9]\u001b[A\n",
      " 99%|█████████▉| 4189/4220 [4:28:20<01:57,  3.78s/it, loss=3.03, epoch=0.992, learning_rate=2.85e-9]\u001b[A\n",
      " 99%|█████████▉| 4190/4220 [4:28:24<01:53,  3.78s/it, loss=3.03, epoch=0.992, learning_rate=2.85e-9]\u001b[A\n",
      " 99%|█████████▉| 4190/4220 [4:28:24<01:53,  3.78s/it, loss=3.01, epoch=0.993, learning_rate=2.68e-9]\u001b[A\n",
      " 99%|█████████▉| 4191/4220 [4:28:28<01:49,  3.78s/it, loss=3.01, epoch=0.993, learning_rate=2.68e-9]\u001b[A\n",
      " 99%|█████████▉| 4191/4220 [4:28:28<01:49,  3.78s/it, loss=3.19, epoch=0.993, learning_rate=2.51e-9]\u001b[A\n",
      " 99%|█████████▉| 4192/4220 [4:28:32<01:45,  3.78s/it, loss=3.19, epoch=0.993, learning_rate=2.51e-9]\u001b[A\n",
      " 99%|█████████▉| 4192/4220 [4:28:32<01:45,  3.78s/it, loss=2.69, epoch=0.993, learning_rate=2.34e-9]\u001b[A\n",
      " 99%|█████████▉| 4193/4220 [4:28:36<01:42,  3.78s/it, loss=2.69, epoch=0.993, learning_rate=2.34e-9]\u001b[A\n",
      " 99%|█████████▉| 4193/4220 [4:28:36<01:42,  3.78s/it, loss=2.85, epoch=0.993, learning_rate=2.18e-9]\u001b[A\n",
      " 99%|█████████▉| 4194/4220 [4:28:39<01:38,  3.78s/it, loss=2.85, epoch=0.993, learning_rate=2.18e-9]\u001b[A\n",
      " 99%|█████████▉| 4194/4220 [4:28:39<01:38,  3.78s/it, loss=3.18, epoch=0.994, learning_rate=2.03e-9]\u001b[A\n",
      " 99%|█████████▉| 4195/4220 [4:28:43<01:34,  3.78s/it, loss=3.18, epoch=0.994, learning_rate=2.03e-9]\u001b[A\n",
      " 99%|█████████▉| 4195/4220 [4:28:43<01:34,  3.78s/it, loss=3.12, epoch=0.994, learning_rate=1.88e-9]\u001b[A\n",
      " 99%|█████████▉| 4196/4220 [4:28:47<01:30,  3.78s/it, loss=3.12, epoch=0.994, learning_rate=1.88e-9]\u001b[A\n",
      " 99%|█████████▉| 4196/4220 [4:28:47<01:30,  3.78s/it, loss=3.12, epoch=0.994, learning_rate=1.74e-9]\u001b[A\n",
      " 99%|█████████▉| 4197/4220 [4:28:51<01:26,  3.78s/it, loss=3.12, epoch=0.994, learning_rate=1.74e-9]\u001b[A\n",
      " 99%|█████████▉| 4197/4220 [4:28:51<01:26,  3.78s/it, loss=2.57, epoch=0.994, learning_rate=1.6e-9] \u001b[A\n",
      " 99%|█████████▉| 4198/4220 [4:28:54<01:23,  3.78s/it, loss=2.57, epoch=0.994, learning_rate=1.6e-9]\u001b[A\n",
      " 99%|█████████▉| 4198/4220 [4:28:54<01:23,  3.78s/it, loss=2.58, epoch=0.995, learning_rate=1.47e-9]\u001b[A\n",
      "100%|█████████▉| 4199/4220 [4:28:58<01:19,  3.78s/it, loss=2.58, epoch=0.995, learning_rate=1.47e-9]\u001b[A\n",
      "100%|█████████▉| 4199/4220 [4:28:58<01:19,  3.78s/it, loss=2.61, epoch=0.995, learning_rate=1.35e-9]\u001b[A\n",
      "100%|█████████▉| 4200/4220 [4:29:02<01:15,  3.78s/it, loss=2.61, epoch=0.995, learning_rate=1.35e-9]\u001b[A\n",
      "100%|█████████▉| 4200/4220 [4:29:02<01:15,  3.78s/it, loss=3.24, epoch=0.995, learning_rate=1.23e-9]\u001b[A\n",
      "100%|█████████▉| 4201/4220 [4:29:06<01:11,  3.78s/it, loss=3.24, epoch=0.995, learning_rate=1.23e-9]\u001b[A\n",
      "100%|█████████▉| 4201/4220 [4:29:06<01:11,  3.78s/it, loss=2.6, epoch=0.995, learning_rate=1.11e-9] \u001b[A\n",
      "100%|█████████▉| 4202/4220 [4:29:10<01:08,  3.78s/it, loss=2.6, epoch=0.995, learning_rate=1.11e-9]\u001b[A\n",
      "100%|█████████▉| 4202/4220 [4:29:10<01:08,  3.78s/it, loss=2.42, epoch=0.995, learning_rate=1.01e-9]\u001b[A\n",
      "100%|█████████▉| 4203/4220 [4:29:13<01:04,  3.78s/it, loss=2.42, epoch=0.995, learning_rate=1.01e-9]\u001b[A\n",
      "100%|█████████▉| 4203/4220 [4:29:13<01:04,  3.78s/it, loss=2.82, epoch=0.996, learning_rate=9.02e-10]\u001b[A\n",
      "100%|█████████▉| 4204/4220 [4:29:17<01:00,  3.78s/it, loss=2.82, epoch=0.996, learning_rate=9.02e-10]\u001b[A\n",
      "100%|█████████▉| 4204/4220 [4:29:17<01:00,  3.78s/it, loss=2.76, epoch=0.996, learning_rate=8.05e-10]\u001b[A\n",
      "100%|█████████▉| 4205/4220 [4:29:21<00:56,  3.78s/it, loss=2.76, epoch=0.996, learning_rate=8.05e-10]\u001b[A\n",
      "100%|█████████▉| 4205/4220 [4:29:21<00:56,  3.78s/it, loss=3.01, epoch=0.996, learning_rate=7.13e-10]\u001b[A\n",
      "100%|█████████▉| 4206/4220 [4:29:25<00:52,  3.78s/it, loss=3.01, epoch=0.996, learning_rate=7.13e-10]\u001b[A\n",
      "100%|█████████▉| 4206/4220 [4:29:25<00:52,  3.78s/it, loss=2.51, epoch=0.996, learning_rate=6.26e-10]\u001b[A\n",
      "100%|█████████▉| 4207/4220 [4:29:28<00:49,  3.78s/it, loss=2.51, epoch=0.996, learning_rate=6.26e-10]\u001b[A\n",
      "100%|█████████▉| 4207/4220 [4:29:28<00:49,  3.78s/it, loss=2.75, epoch=0.997, learning_rate=5.46e-10]\u001b[A\n",
      "100%|█████████▉| 4208/4220 [4:29:32<00:45,  3.78s/it, loss=2.75, epoch=0.997, learning_rate=5.46e-10]\u001b[A\n",
      "100%|█████████▉| 4208/4220 [4:29:32<00:45,  3.78s/it, loss=2.88, epoch=0.997, learning_rate=4.71e-10]\u001b[A\n",
      "100%|█████████▉| 4209/4220 [4:29:36<00:41,  3.78s/it, loss=2.88, epoch=0.997, learning_rate=4.71e-10]\u001b[A\n",
      "100%|█████████▉| 4209/4220 [4:29:36<00:41,  3.78s/it, loss=3.17, epoch=0.997, learning_rate=4.01e-10]\u001b[A\n",
      "100%|█████████▉| 4210/4220 [4:29:40<00:37,  3.78s/it, loss=3.17, epoch=0.997, learning_rate=4.01e-10]\u001b[A\n",
      "100%|█████████▉| 4210/4220 [4:29:40<00:37,  3.78s/it, loss=2.71, epoch=0.997, learning_rate=3.37e-10]\u001b[A\n",
      "100%|█████████▉| 4211/4220 [4:29:44<00:34,  3.78s/it, loss=2.71, epoch=0.997, learning_rate=3.37e-10]\u001b[A\n",
      "100%|█████████▉| 4211/4220 [4:29:44<00:34,  3.78s/it, loss=2.85, epoch=0.998, learning_rate=2.78e-10]\u001b[A\n",
      "100%|█████████▉| 4212/4220 [4:29:47<00:30,  3.78s/it, loss=2.85, epoch=0.998, learning_rate=2.78e-10]\u001b[A\n",
      "100%|█████████▉| 4212/4220 [4:29:47<00:30,  3.78s/it, loss=3.49, epoch=0.998, learning_rate=2.26e-10]\u001b[A\n",
      "100%|█████████▉| 4213/4220 [4:29:51<00:26,  3.78s/it, loss=3.49, epoch=0.998, learning_rate=2.26e-10]\u001b[A\n",
      "100%|█████████▉| 4213/4220 [4:29:51<00:26,  3.78s/it, loss=2.42, epoch=0.998, learning_rate=1.78e-10]\u001b[A\n",
      "100%|█████████▉| 4214/4220 [4:29:55<00:22,  3.78s/it, loss=2.42, epoch=0.998, learning_rate=1.78e-10]\u001b[A\n",
      "100%|█████████▉| 4214/4220 [4:29:55<00:22,  3.78s/it, loss=2.72, epoch=0.998, learning_rate=1.36e-10]\u001b[A\n",
      "100%|█████████▉| 4215/4220 [4:29:59<00:18,  3.78s/it, loss=2.72, epoch=0.998, learning_rate=1.36e-10]\u001b[A\n",
      "100%|█████████▉| 4215/4220 [4:29:59<00:18,  3.78s/it, loss=3.54, epoch=0.999, learning_rate=1e-10]   \u001b[A\n",
      "100%|█████████▉| 4216/4220 [4:30:03<00:15,  3.78s/it, loss=3.54, epoch=0.999, learning_rate=1e-10]\u001b[A\n",
      "100%|█████████▉| 4216/4220 [4:30:03<00:15,  3.78s/it, loss=2.69, epoch=0.999, learning_rate=6.96e-11]\u001b[A\n",
      "100%|█████████▉| 4217/4220 [4:30:06<00:11,  3.78s/it, loss=2.69, epoch=0.999, learning_rate=6.96e-11]\u001b[A\n",
      "100%|█████████▉| 4217/4220 [4:30:06<00:11,  3.78s/it, loss=2.49, epoch=0.999, learning_rate=4.45e-11]\u001b[A\n",
      "100%|█████████▉| 4218/4220 [4:30:10<00:07,  3.78s/it, loss=2.49, epoch=0.999, learning_rate=4.45e-11]\u001b[A\n",
      "100%|█████████▉| 4218/4220 [4:30:10<00:07,  3.78s/it, loss=3.1, epoch=0.999, learning_rate=2.51e-11] \u001b[A\n",
      "100%|█████████▉| 4219/4220 [4:30:14<00:03,  3.78s/it, loss=3.1, epoch=0.999, learning_rate=2.51e-11]\u001b[A\n",
      "100%|█████████▉| 4219/4220 [4:30:14<00:03,  3.78s/it, loss=2.63, epoch=1, learning_rate=1.11e-11]   \u001b[A\n",
      "100%|██████████| 4220/4220 [4:30:18<00:00,  3.79s/it, loss=2.63, epoch=1, learning_rate=1.11e-11]\u001b[A\n",
      "100%|██████████| 4220/4220 [4:30:18<00:00,  3.79s/it, loss=2.73, epoch=1, learning_rate=2.78e-12]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4220\n",
      "4220\n",
      "broke\n",
      "4220\n",
      "4220\n",
      "broke\n",
      "Training Finished\n",
      "Saving model to ./loop/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4220/4220 [4:31:13<00:00,  3.86s/it, loss=2.73, epoch=1, learning_rate=2.78e-12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine batchsize effect on model\n",
    "batchsizes = [64,128]\n",
    "OUT_DIR='./loop/'\n",
    "data_path = data_files\n",
    "\n",
    "val_loss_lst = []\n",
    "for i in batchsizes:\n",
    "    outdir = OUT_DIR + str(i)\n",
    "    del model\n",
    "    model = EvoForRegression()\n",
    "    train_model(model,outdir,data_path,batch_size = i,warmup_steps = 10,epochs = 1,learning_rate=2e-5,checkpointing_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177aa225-c4c2-4861-a89f-1932f002e406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef1cb6-ed40-4491-859e-163c4f2d8ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
